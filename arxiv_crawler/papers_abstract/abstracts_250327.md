# Abstracts of Papers

## Physics
### A Pretraining-Finetuning Computational Framework for Material Homogenization
**Authors**: Yizheng Wang, Xiang Li, Ziming Yan, Shuaifeng Ma, Jinshuai Bai, Bokai Liu, Timon Rabczuk, Yinghua Liu

**Published Date**: 2024-03-18

**Updated Date**: 2025-03-26

**PDF Url**: [2404.07943v2](http://arxiv.org/pdf/2404.07943v2)

**Abstract**: Homogenization is a fundamental tool for studying multiscale physical
phenomena. Traditional numerical homogenization methods, heavily reliant on
finite element analysis, demand significant computational resources, especially
for complex geometries, materials, and high-resolution problems. To address
these challenges, we propose PreFine-Homo, a novel numerical homogenization
framework comprising two phases: pretraining and fine-tuning. In the
pretraining phase, a Fourier Neural Operator (FNO) is trained on large datasets
to learn the mapping from input geometries and material properties to
displacement fields. In the fine-tuning phase, the pretrained predictions serve
as initial solutions for iterative algorithms, drastically reducing the number
of iterations needed for convergence. The pretraining phase of PreFine-Homo
delivers homogenization results up to 1000 times faster than conventional
methods, while the fine-tuning phase further enhances accuracy. Moreover, the
fine-tuning phase grants PreFine-Homo unlimited generalization capabilities,
enabling continuous learning and improvement as data availability increases. We
validate PreFine-Homo by predicting the effective elastic tensor for 3D
periodic materials, specifically Triply Periodic Minimal Surfaces (TPMS). The
results demonstrate that PreFine-Homo achieves high precision, exceptional
efficiency, robust learning capabilities, and strong extrapolation ability,
establishing it as a powerful tool for multiscale homogenization tasks.


### On the magnetic perturbation theory for Chern insulators
**Authors**: Horia D. Cornean, Massimo Moscolari

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20763v1](http://arxiv.org/pdf/2503.20763v1)

**Abstract**: The gauge covariant magnetic perturbation theory is tailored for one-body
Schr\"odinger operators perturbed by long-range magnetic fields. In this work
we present a self-contained exposition of the method, by outlining its
technical foundations and discussing the physical heuristics behind the proofs.
We apply it in order to prove the stability of spectral gaps and to study the
location of the discrete spectrum. We also analyze the (lack of) continuity
with respect to the magnetic field of spectral projections corresponding to
finite spectral islands, which is a particularly important situation for
systems modelling Chern insulators. Finally, we show how to construct
approximate projections that have an explicit dependence with respect to the
magnetic field parameter.


### Stabilizing Neural Likelihood Ratio Estimation
**Authors**: Fernando Torales Acosta, Tanvi Wamorkar, Vinicius Mikuni, Benjamin Nachman

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20753v1](http://arxiv.org/pdf/2503.20753v1)

**Abstract**: Likelihood ratios are used for a variety of applications in particle physics
data analysis, including parameter estimation, unfolding, and anomaly
detection. When the data are high-dimensional, neural networks provide an
effective tools for approximating these ratios. However, neural network
training has an inherent stochasticity that limits their precision. A
widely-used approach to reduce these fluctuations is to train many times and
average the output (ensembling). We explore different approaches to ensembling
and pretraining neural networks for stabilizing likelihood ratio estimation.
For numerical studies focus on unbinned unfolding with OmniFold, as it requires
many likelihood ratio estimations. We find that ensembling approaches that
aggregate the models at step 1, before pushing the weights to step 2 improve
both bias and variance of final results. Variance can be further improved by
pre-training, however at the cost increasing bias.


### Accelerated State Expansion of a Nanoparticle in a Dark Inverted Potential
**Authors**: Gregoire F. M. Tomassi, Daniel Veldhuizen, Bruno Melo, Davide Candoli, Andreu Riera-Campeny, Oriol Romero-Isart, Nadine Meyer, Romain Quidant

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20707v1](http://arxiv.org/pdf/2503.20707v1)

**Abstract**: While the wave packet of a massive particle grows linearly under free
dynamics, it grows exponentially in an inverted harmonic potential, offering a
pathway to rapidly increase quantum fluctuations to macroscopic dimensions. In
this work, we experimentally demonstrate this principle by expanding the
center-of-mass thermal state of a 125nm silica nanoparticle to a position
uncertainty of 43.4nm within 260 $\mu$s. This expansion, achieved using an
inverted dark potential to minimize decoherence from photon recoil, represents
a 952-fold increase, reaching a scale comparable to the nanoparticle's physical
size. This work represents a key advancement toward preparing macroscopic
quantum superpositions at unprecedented mass and length scales.


### CyberDiver: an untethered robotic impactor for water-entry experiments
**Authors**: John T. Antolik, Eli A. Silver, Jesse L. Belden, Daniel M. Harris

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20702v1](http://arxiv.org/pdf/2503.20702v1)

**Abstract**: We present the CyberDiver, an untethered robotic impactor capable of actively
modulating the fluid physics during high-speed water entry. First, we utilize
the CyberDiver to extend our understanding of the water entry of passively
flexible systems, designing a high-bandwidth controller that enables the
CyberDiver to operate as a cyber-physical system that permits an arbitrary
programmable structural coupling to be experimentally tested. Onboard sensors
record the body acceleration during impact and reveal that the introduction of
damping or a nonlinear force-versus-displacement structural law can
significantly reduce impact loading as compared to a linear elastic case, with
implications for damage mitigation in aerospace and naval applications. Next,
by operating the CyberDiver in a displacement control mode, we demonstrate that
the splash size can be dramatically altered depending on the parameters of an
active maneuver, laying a groundwork for better understanding the techniques of
human competitive divers.


### Low-Energy Constants of Chiral Perturbation Theory from Pion Scalar Form Factors in $N_f=2+1$-Flavor Lattice QCD with Controlled Errors
**Authors**: Georg von Hippel, Konstantin Ottnad

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20689v1](http://arxiv.org/pdf/2503.20689v1)

**Abstract**: We determine the low-energy constants (LECs) $f_0$, $L_4^r$ and $L_5^r$ of
SU(3) Chiral Perturbation Theory ($\chi$PT) from a lattice QCD calculation of
the scalar form factors of the pion with fully controlled systematics. Lattice
results are computed on a large set of $N_f=2+1$ gauge ensembles covering four
lattice spacings $a\in[0.049,0.086]\mathrm{fm}$, pion masses
$M_\pi\in[130,350]\mathrm{MeV}$, and various large physical volumes. By
determining the notorious quark-disconnected contributions with unprecedented
precision and using a large range of source-sink separations
$t_\mathrm{sep}\in[1.0,3.25]\mathrm{fm}$, we are able for the first time to
obtain the scalar radii from a $z$-expansion parameterization of the form
factors rather than a simple linear approximation at small momentum transfer.
The LECs are obtained from the physical extrapolation of the radii using NLO
SU(3) NLO $\chi$PT to parameterize the quark mass dependence. Systematic
uncertainties are estimated via model averages based on the Akaike Information
Criterion. Our determination of $L_4^r$ is the first lattice determination to
obtain a result not compatible with zero.


### The Scalar Size of the Pion from Lattice QCD
**Authors**: Konstantin Ottnad, Georg von Hippel

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20687v1](http://arxiv.org/pdf/2503.20687v1)

**Abstract**: We present a lattice QCD calculation of the pion scalar form factor and
associated radii with fully controlled systematics. Lattice results are
computed on a large set of 17 gauge ensembles with $N_f=2+1$ Wilson
Clover-improved sea quarks. These ensembles cover four values of the lattice
spacing between $a=0.049\mathrm{fm}$ and $a=0.086\mathrm{fm}$, a pion mass
range of $130 - 350\mathrm{MeV}$ and various physical volumes. A precise
determination of the notorious quark-disconnected contributions facilitates an
unprecedented momentum resolution for the form factor, particularly on large
and fine ensembles in the vicinity of physical quark mass. A large range of
source-sink separations $1.0\mathrm{fm} \lesssim t_\mathrm{sep} \lesssim
3.25\mathrm{fm}$ is used to reliably extract the relevant ground state matrix
elements at vanishing and non-vanishing momentum transfer. This allows us for
the first time to obtain the scalar radii from a $z$-expansion parametrization
of the $Q^2$-dependence of the resulting form factors rather than a simple,
linear approximation at small momentum transfer. The physical extrapolation for
the radii is carried out using three-flavor NLO chiral perturbation theory to
parametrize the quark mass dependence in terms of three low-energy constants,
including the first lattice determination of $L_4^r$. Systematic uncertainties
on the final results related to the ground state extraction, form factor
parametrization as well as the physical extrapolation are accounted for via
model averages based on the Akaike Information Criterion.


### Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data
**Authors**: Haozhe Si, Yuxuan Wan, Minh Do, Deepak Vasisht, Han Zhao, Hendrik F. Hamann

**Published Date**: 2025-03-17

**Updated Date**: 2025-03-26

**PDF Url**: [2503.12843v3](http://arxiv.org/pdf/2503.12843v3)

**Abstract**: Geospatial raster data, such as that collected by satellite-based imaging
systems at different times and spectral bands, hold immense potential for
enabling a wide range of high-impact applications. This potential stems from
the rich information that is spatially and temporally contextualized across
multiple channels and sensing modalities. Recent work has adapted existing
self-supervised learning approaches for such geospatial data. However, they
fall short of scalable model architectures, leading to inflexibility and
computational inefficiencies when faced with an increasing number of channels
and modalities. To address these limitations, we introduce Low-rank Efficient
Spatial-Spectral Vision Transformer with three key innovations: i) the LESS
Attention Block that approximates high-dimensional spatial-spectral attention
through Kronecker's product of the low-dimensional spatial and spectral
attention components; ii) the Continuous Positional-Channel Embedding Layer
that preserves both the continuity and physical characteristics of each
spatial-spectral patch; and iii) the Perception Field Mask that exploits local
spatial dependencies by constraining attention to neighboring patches. To
evaluate the proposed innovations, we construct GFM-Bench, which serves as a
comprehensive benchmark for such geospatial raster data. We pretrain LESS ViT
using a Hyperspectral Masked Autoencoder framework with integrated positional
and channel masking strategies. Experimental results demonstrate that our
proposed method achieves competitive performance against state-of-the-art
multi-modal geospatial foundation models while outperforming them on
cross-satellite generalization tasks with higher computational efficiency. The
flexibility and extensibility of our framework make it a promising direction
for future geospatial data analysis tasks that involve a wide range of
modalities and channels.


### Jet Substructure Analysis for Distinguishing Left- and Right-Handed Couplings of Heavy Neutrino in $W'$ Decay at the HL-LHC
**Authors**: Songshaptak De, Atri Dey, Tousik Samui

**Published Date**: 2024-11-22

**Updated Date**: 2025-03-26

**PDF Url**: [2411.14910v2](http://arxiv.org/pdf/2411.14910v2)

**Abstract**: The search for heavy $W'$ bosons in their decay modes to a lepton and a heavy
neutrino offers a promising avenue for probing new physics beyond the Standard
Model. This work focuses on such a signature with an energetic lepton plus a
fat jet, originating from the heavy neutrino and containing a lepton. We have
employed the jet substructure techniques to isolate the embedded lepton as a
subjet of the fat jet. The Lepton Subjet Fraction ($LSF$) and Lepton Mass Drop
($LMD$) variables constructed from the lepton subjet help in separating the
signal region from the background. We further study the polarization properties
of the $W'$ coupling to the lepton and heavy neutrino through the decay
products of the neutrino. Instead of relying on a specific model, we employ
generic couplings and explore the discrimination power. Jet substructure-based
angular variables $z_\ell$, $z_\theta$, and $z_k$ are combined to form BDT
scores to obtain better separation power between left-chiral ($V-A$) and
right-chiral ($V+A$) coupling configurations. By using $CL_s$ type profile
likelihood estimator, we could achieve $\sim$ 2$\sigma$ $-$ 3$\sigma$
significance of excluding one coupling configuration in favour of the other.


## Diffusion
### High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching
**Authors**: Guoqiang Zhang, Kenta Niwa, J. P. Lewis, Cedric Mesnage, W. Bastiaan Kleijn

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20744v1](http://arxiv.org/pdf/2503.20744v1)

**Abstract**: We introduce relative and absolute position matching (RAPM), a diffusion
distillation method resulting in high quality generation that can be trained
efficiently on a single GPU. Recent diffusion distillation research has
achieved excellent results for high-resolution text-to-image generation with
methods such as phased consistency models (PCM) and improved distribution
matching distillation (DMD2). However, these methods generally require many
GPUs (e.g.~8-64) and significant batchsizes (e.g.~128-2048) during training,
resulting in memory and compute requirements that are beyond the resources of
some researchers. RAPM provides effective single-GPU diffusion distillation
training with a batchsize of 1. The new method attempts to mimic the sampling
trajectories of the teacher model by matching the relative and absolute
positions. The design of relative positions is inspired by PCM. Two
discriminators are introduced accordingly in RAPM, one for matching relative
positions and the other for absolute positions. Experimental results on
StableDiffusion (SD) V1.5 and SDXL indicate that RAPM with 4 timesteps produces
comparable FID scores as the best method with 1 timestep under very limited
computational resources.


### RecTable: Fast Modeling Tabular Data with Rectified Flow
**Authors**: Masane Fuchi, Tomohiro Takagi

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20731v1](http://arxiv.org/pdf/2503.20731v1)

**Abstract**: Score-based or diffusion models generate high-quality tabular data,
surpassing GAN-based and VAE-based models. However, these methods require
substantial training time. In this paper, we introduce RecTable, which uses the
rectified flow modeling, applied in such as text-to-image generation and
text-to-video generation. RecTable features a simple architecture consisting of
a few stacked gated linear unit blocks. Additionally, our training strategies
are also simple, incorporating a mixed-type noise distribution and a
logit-normal timestep distribution. Our experiments demonstrate that RecTable
achieves competitive performance compared to the several state-of-the-art
diffusion and score-based models while reducing the required training time. Our
code is available at https://github.com/fmp453/rectable.


### A weakly-supervised deep learning model for fast localisation and delineation of the skeleton, internal organs, and spinal canal on Whole-Body Diffusion-Weighted MRI (WB-DWI)
**Authors**: A. Candito, A. Dragan, R. Holbrey, A. Ribeiro, R. Donners, C. Messiou, N. Tunariu, D. -M. Koh, M. D. Blackledge, The Institute of Cancer Research, London, United Kingdom, The Royal Marsden NHS Foundation Trust, London, United Kingdom, University Hospital Basel, Basel, Switzerland

**Published Date**: 2025-03-26

**Updated Date**: 2025-03-26

**PDF Url**: [2503.20722v1](http://arxiv.org/pdf/2503.20722v1)

**Abstract**: Background: Apparent Diffusion Coefficient (ADC) values and Total Diffusion
Volume (TDV) from Whole-body diffusion-weighted MRI (WB-DWI) are recognized
cancer imaging biomarkers. However, manual disease delineation for ADC and TDV
measurements is unfeasible in clinical practice, demanding automation. As a
first step, we propose an algorithm to generate fast and reproducible
probability maps of the skeleton, adjacent internal organs (liver, spleen,
urinary bladder, and kidneys), and spinal canal. Methods: We developed an
automated deep-learning pipeline based on a 3D patch-based Residual U-Net
architecture that localizes and delineates these anatomical structures on
WB-DWI. The algorithm was trained using "soft-labels" (non-binary
segmentations) derived from a computationally intensive atlas-based approach.
For training and validation, we employed a multi-center WB-DWI dataset
comprising 532 scans from patients with Advanced Prostate Cancer (APC) or
Multiple Myeloma (MM), with testing on 45 patients. Results: Our
weakly-supervised deep learning model achieved an average dice
score/precision/recall of 0.66/0.6/0.73 for skeletal delineations,
0.8/0.79/0.81 for internal organs, and 0.85/0.79/0.94 for spinal canal, with
surface distances consistently below 3 mm. Relative median ADC and
log-transformed volume differences between automated and manual expert-defined
full-body delineations were below 10% and 4%, respectively. The computational
time for generating probability maps was 12x faster than the atlas-based
registration algorithm (25 s vs. 5 min). An experienced radiologist rated the
model's accuracy "good" or "excellent" on test datasets. Conclusion: Our model
offers fast and reproducible probability maps for localizing and delineating
body regions on WB-DWI, enabling ADC and TDV quantification, potentially
supporting clinicians in disease staging and treatment response assessment.


### Text-to-Model: Text-Conditioned Neural Network Diffusion for Train-Once-for-All Personalization
**Authors**: Zexi Li, Lingzhi Gao, Chao Wu

**Published Date**: 2024-05-23

**Updated Date**: 2025-03-26

**PDF Url**: [2405.14132v2](http://arxiv.org/pdf/2405.14132v2)

**Abstract**: Generative artificial intelligence (GenAI) has made significant progress in
understanding world knowledge and generating content from human languages
across various modalities, like text-to-text large language models,
text-to-image stable diffusion, and text-to-video Sora. While in this paper, we
investigate the capability of GenAI for text-to-model generation, to see
whether GenAI can comprehend hyper-level knowledge embedded within AI itself
parameters. Specifically, we study a practical scenario termed
train-once-for-all personalization, aiming to generate personalized models for
diverse end-users and tasks using text prompts. Inspired by the recent
emergence of neural network diffusion, we present Tina, a text-conditioned
neural network diffusion for train-once-for-all personalization. Tina leverages
a diffusion transformer model conditioned on task descriptions embedded using a
CLIP model. Despite the astronomical number of potential personalized tasks
(e.g., $1.73\times10^{13}$), by our design, Tina demonstrates remarkable
in-distribution and out-of-distribution generalization even trained on small
datasets ($\sim 1000$). We further verify whether and how \Tina understands
world knowledge by analyzing its capabilities under zero-shot/few-shot image
prompts, different numbers of personalized classes, prompts of natural language
descriptions, and predicting unseen entities.


### Data Augmentation in Earth Observation: A Diffusion Model Approach
**Authors**: Tiago Sousa, Beno√Æt Ries, Nicolas Guelfi

**Published Date**: 2024-06-10

**Updated Date**: 2025-03-26

**PDF Url**: [2406.06218v2](http://arxiv.org/pdf/2406.06218v2)

**Abstract**: High-quality Earth Observation (EO) imagery is essential for accurate
analysis and informed decision making across sectors. However, data scarcity
caused by atmospheric conditions, seasonal variations, and limited geographical
coverage hinders the effective application of Artificial Intelligence (AI) in
EO. Traditional data augmentation techniques, which rely on basic parameterized
image transformations, often fail to introduce sufficient diversity across key
semantic axes. These axes include natural changes such as snow and floods,
human impacts like urbanization and roads, and disasters such as wildfires and
storms, which limits the accuracy of AI models in EO applications. To address
this, we propose a four-stage data augmentation approach that integrates
diffusion models to enhance semantic diversity. Our method employs meta-prompts
for instruction generation, vision-language models for rich captioning,
EO-specific diffusion model fine-tuning, and iterative data augmentation.
Extensive experiments using four augmentation techniques demonstrate that our
approach consistently outperforms established methods, generating semantically
diverse EO images and improving AI model performance.


