# Abstracts of Papers

## Physics
### Bogoliubov quasi-particles in superconductors are integer-charged particles inapplicable for braiding quantum information
**Authors**: Zhiyu Fan, Wei Ku

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09663v1](http://arxiv.org/pdf/2509.09663v1)

**Abstract**: We present a rigorous proof that under a number-conserving Hamiltonian,
one-body quasi-particles generally possess quantized charge and inertial mass
identical to the bare particles. It follows that, Bogoliubov zero modes in the
vortex (or on the edge) of superconductors $\textit{cannot}$ be their own
anti-particles capable of braiding quantum information. As such, the heavily
pursued Majorana zero mode-based route for quantum computation requires a
serious re-consideration. This study further reveals the conceptual challenge
in preparing and manipulating braid-able quantum states via physical
thermalization or slow external fields. These profound results should reignite
the long-standing quest for a number-conserving theory of superconductivity and
superfluidity without fictitiously breaking global U(1) symmetry.


### Lanczos algorithm for lattice QCD matrix elements
**Authors**: Daniel C. Hackett, Michael L. Wagman

**Published Date**: 2024-07-31

**Updated Date**: 2025-09-11

**PDF Url**: [2407.21777v2](http://arxiv.org/pdf/2407.21777v2)

**Abstract**: Recent work found that an analysis formalism based on the Lanczos algorithm
allows energy levels to be extracted from Euclidean correlation functions with
faster ground-state convergence than effective masses, convergent estimators
for multiple states from a single correlator, and two-sided error bounds. After
filtering out spurious eigenvalues and using outlier-robust estimators within a
nested bootstrap framework, Lanczos estimators behave more like multi-state fit
results than effective masses -- but without involving statistical fitting. We
extend this formalism to the determination of matrix elements from three-point
correlation functions and provide a physical picture of "spurious state
filtering" involving restriction to a Hermitian subspace. We demonstrate
similar advantages for matrix elements as for spectroscopy through example
applications to noiseless mock-data and (bare) forward matrix elements of the
strange scalar current between both ground and excited states with the quantum
numbers of the nucleon.


### Identification of phase correlations in Financial Stock Market Turbulence
**Authors**: Kiran Sharma, Abhijit Dutta, Rupak Mukherjee

**Published Date**: 2025-08-12

**Updated Date**: 2025-09-11

**PDF Url**: [2508.20105v2](http://arxiv.org/pdf/2508.20105v2)

**Abstract**: The basis of arbitrage methods depends on the circulation of information
within the framework of the financial market. Following the work of Modigliani
and Miller, it has become a vital part of discussions related to the study of
financial networks and predictions. The emergence of the efficient market
hypothesis by Fama, Fisher, Jensen and Roll in the early 1970s opened up the
door for discussion of information affecting the price in the market and
thereby creating asymmetries and price distortion. Whenever the micro and
macroeconomic factors change, there is a high probability of information
asymmetry in the market, and this asymmetry of information creates turbulence
in the market. The analysis and interpretation of turbulence caused by the
differences in information is crucial in understanding the nature of the stock
market using price patterns and fluctuations. Even so, the traditional
approaches are not capable of analyzing the cyclical price fluctuations outside
the realm of wave structures of securities prices, and a proper and effective
technique to assess the nature of the Financial market. Consequently, the
analysis of the price fluctuations by applying the theories and computational
techniques of mathematical physics ensures that such cycles are disintegrated,
and the outcome of decomposed cycles is elucidated to understand the impression
of the information on the genesis and discovery of price and to assess the
nature of stock market turbulence. In this regard, the paper will provide a
framework of Spectrum analysis that decomposes the pricing patterns and is
capable of determining the pricing behavior, eventually assisting in examining
the nature of turbulence in the National Stock Exchange of India.


### Resource quantification for programming low-depth quantum circuits
**Authors**: Entong He, Yuxiang Yang

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09642v1](http://arxiv.org/pdf/2509.09642v1)

**Abstract**: Noisy intermediate-scale quantum (NISQ) devices pave the way to implement
quantum algorithms that exhibit supremacy over their classical counterparts.
Due to the intrinsic noise and decoherence in the physical system, NISQ
computations are naturally modeled as large-size but low-depth quantum
circuits. Practically, to execute such quantum circuits, we need to pass
commands to a programmable quantum computer. Existing programming approaches,
dedicated to generic unitary transformations, are inefficient in terms of the
computational resources under the low-depth assumption and remain far from
satisfactory. As such, to realize NISQ algorithms, it is crucial to find an
efficient way to program low-depth circuits as the qubit number $N$ increases.
Here, we investigate the gate complexity and the size of quantum memory (known
as the program cost) required to program low-depth brickwork circuits. We
unveil a $\sim N \text{poly} \log N$ worst-case program cost of universal
programming of low-depth brickwork circuits in the large $N$ regime, which is a
tight characterization. Moreover, we analyze the trade-off between the cost of
describing the layout of local gates and the cost of programming them to the
targeted unitaries via the light-cone argument. Our findings suggest that
faithful gate-wise programming is optimal in the low-depth regime.


### Chirality-Driven Magnetization Emerges from Relativistic Four-Current Dynamics
**Authors**: Shiv Upadhyay, Xuechen Zheng, Tian Wang, Agam Shayit, Jun Liu, Dali Sun, Xiaosong Li

**Published Date**: 2025-04-03

**Updated Date**: 2025-09-11

**PDF Url**: [2504.03781v2](http://arxiv.org/pdf/2504.03781v2)

**Abstract**: Chirality-induced spin selectivity (CISS) is a striking quantum phenomenon in
which electron transport through chiral molecules leads to spin polarization --
even in the absence of external magnetic fields or magnetic components.
Although observed in systems such as DNA, helicenes, proteins, and polymers,
the fundamental physical origin of CISS remains unresolved. Here, we introduce
a time-dependent relativistic four-current framework, in which charge and
current densities evolve according to the time-dependent variational principle.
Real-time relativistic four-current simulations enable direct analysis of
helical currents and induced magnetization dynamics. Applied to helicenes --
axially chiral molecules lacking stereocenters -- our simulations reveal
curvature-induced helical electron currents that generate spontaneous magnetic
fields aligned along the molecular axis. These fields are handedness-dependent
and reach magnitudes of $10^{-1}$ Tesla per single helicene strand. Our results
suggest that CISS may arise from intrinsic, relativistic curvature-induced
helical currents and the associated magnetic fields within chiral molecules.
This four-current mechanism offers a self-contained explanation for the driving
force underlying spin selectivity, independent of interfacial effects or
unphysically enhanced spin-orbit coupling. Furthermore, our results provide a
new perspective that offers a unifying framework with the potential to
reconcile many existing hypotheses and theoretical models, while also
suggesting several testable predictions that can be examined experimentally.


### Joint parameter estimations for spin glasses
**Authors**: Wei-Kuo Chen, Arnab Sen, Qiang Wu

**Published Date**: 2024-06-15

**Updated Date**: 2025-09-11

**PDF Url**: [2406.10760v2](http://arxiv.org/pdf/2406.10760v2)

**Abstract**: Spin glass models with quadratic-type Hamiltonians are disordered statistical
physics systems with competing ferromagnetic and anti-ferromagnetic spin
interactions. The corresponding Gibbs measures belong to the exponential family
parametrized by (inverse) temperature $\beta>0$ and external field
$h\in\mathbb{R}$. Given a sample from these Gibbs measures, a statistically
fundamental question is to infer the temperature and external field parameters.
In 2007, Chatterjee (Ann. Statist. 35 (2007), no.5, 1931-1946) first proved
that in the absence of external field $h=0$, the maximum pseudolikelihood
estimator for $\beta$ is $\sqrt{N}$-consistent under some mild assumptions on
the disorder matrices. It was left open whether the same method can be used to
estimate the temperature and external field simultaneously. In this paper,
under some easily verifiable conditions, we prove that the bivariate maximum
pseudolikelihood estimator is indeed jointly $\sqrt{N}$-consistent for the
temperature and external field parameters. The examples cover the classical
Sherrington-Kirkpatrick model and its diluted variants.


### Functional Groups are All you Need for Chemically Interpretable Molecular Property Prediction
**Authors**: Roshan Balaji, Joe Bobby, Nirav Pravinbhai Bhatt

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09619v1](http://arxiv.org/pdf/2509.09619v1)

**Abstract**: Molecular property prediction using deep learning (DL) models has accelerated
drug and materials discovery, but the resulting DL models often lack
interpretability, hindering their adoption by chemists. This work proposes
developing molecule representations using the concept of Functional Groups (FG)
in chemistry. We introduce the Functional Group Representation (FGR) framework,
a novel approach to encoding molecules based on their fundamental chemical
substructures. Our method integrates two types of functional groups: those
curated from established chemical knowledge (FG), and those mined from a large
molecular corpus using sequential pattern mining (MFG). The resulting FGR
framework encodes molecules into a lower-dimensional latent space by leveraging
pre-training on a large dataset of unlabeled molecules. Furthermore, the
proposed framework allows the inclusion of 2D structure-based descriptors of
molecules. We demonstrate that the FGR framework achieves state-of-the-art
performance on a diverse range of 33 benchmark datasets spanning physical
chemistry, biophysics, quantum mechanics, biological activity, and
pharmacokinetics while enabling chemical interpretability. Crucially, the
model's representations are intrinsically aligned with established chemical
principles, allowing chemists to directly link predicted properties to specific
functional groups and facilitating novel insights into structure-property
relationships. Our work presents a significant step toward developing
high-performing, chemically interpretable DL models for molecular discovery.


### ReBaNO: Reduced Basis Neural Operator Mitigating Generalization Gaps and Achieving Discretization Invariance
**Authors**: Haolan Zheng, Yanlai Chen, Jiequn Han, Yue Yu

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09611v1](http://arxiv.org/pdf/2509.09611v1)

**Abstract**: We propose a novel data-lean operator learning algorithm, the Reduced Basis
Neural Operator (ReBaNO), to solve a group of PDEs with multiple distinct
inputs. Inspired by the Reduced Basis Method and the recently introduced
Generative Pre-Trained Physics-Informed Neural Networks, ReBaNO relies on a
mathematically rigorous greedy algorithm to build its network structure offline
adaptively from the ground up. Knowledge distillation via task-specific
activation function allows ReBaNO to have a compact architecture requiring
minimal computational cost online while embedding physics. In comparison to
state-of-the-art operator learning algorithms such as PCA-Net, DeepONet, FNO,
and CNO, numerical results demonstrate that ReBaNO significantly outperforms
them in terms of eliminating/shrinking the generalization gap for both in- and
out-of-distribution tests and being the only operator learning algorithm
achieving strict discretization invariance.


### Are arXiv submissions on Wednesday better cited? Introducing Big Data methods in undergraduate courses on scientific computing
**Authors**: StÃ©phane Delorme, Leon Mach, Hubert Paszkiewicz, Richard Ruiz

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09601v1](http://arxiv.org/pdf/2509.09601v1)

**Abstract**: Extracting information from big data sets, both real and simulated, is a
modern hallmark of the physical sciences. In practice, students face barriers
to learning ``Big Data'' methods in undergraduate physics and astronomy
curricula. As an attempt to alleviate some of these challenges, we present a
simple, farm-to-table data analysis pipeline that can collect, process, and
plot data from the 800k entries common to the arXiv preprint repository and the
bibliographical database inSpireHEP. The pipeline employs contemporary research
practices and can be implemented using open-sourced Python libraries common to
undergraduate courses on Scientific Computing. To support the use such
pipelines in classroom contexts, we make public an example implementation,
authored by two undergraduate physics students, that runs on off-the-shelf
laptops. For advanced students, we discuss applications of the pipeline,
including for online DAQ monitoring and commercialization.


### Programmable 200 GOPS Hopfield-inspired photonic Ising machine
**Authors**: Nayem AL-Kayed, Charles St-Arnault, Hugh Morison, A. Aadhi, Chaoran Huang, Alexander N. Tait, David V. Plant, Bhavin J. Shastri

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09581v1](http://arxiv.org/pdf/2509.09581v1)

**Abstract**: Ising machines offer a compelling approach to addressing NP-hard problems,
but physical realizations that are simultaneously scalable, reconfigurable,
fast, and stable remain elusive. Quantum annealers, like D-Wave's cryogenic
hardware, target combinatorial optimization tasks, but quadratic scaling of
qubit requirements with problem size limits their scalability on dense graphs.
Here, we introduce a programmable, stable, room-temperature optoelectronic
oscillator (OEO)-based Ising machine with linear scaling in spin
representation. Inspired by Hopfield networks, our architecture solves
fully-connected problems with up to 256 spins (65,536 couplings), and $>$41,000
spins (205,000+ couplings) if sparse. Our system leverages cascaded thin-film
lithium niobate modulators, a semiconductor optical amplifier, and a digital
signal processing (DSP) engine in a recurrent time-encoded loop, demonstrating
potential $>$200 giga-operations per second for spin coupling and nonlinearity.
This platform achieves the largest spin configuration in an OEO-based photonic
Ising machine, enabled by high intrinsic speed. We experimentally demonstrate
best-in-class solution quality for Max-Cut problems of arbitrary graph
topologies (2,000 and 20,000 spins) among photonic Ising machines and obtain
ground-state solutions for number partitioning and lattice protein folding -
benchmarks previously unaddressed by photonic systems. Our system leverages
inherent noise from high baud rates to escape local minima and accelerate
convergence. Finally, we show that embedding DSP - traditionally used in
optical communications - within optical computation enhances convergence and
solution quality, opening new frontiers in scalable, ultrafast computing for
optimization, neuromorphic processing, and analog AI.


## Diffusion
### Mechanistic Learning with Guided Diffusion Models to Predict Spatio-Temporal Brain Tumor Growth
**Authors**: Daria Laslo, Efthymios Georgiou, Marius George Linguraru, Andreas Rauschecker, Sabine Muller, Catherine R. Jutzeler, Sarah Bruningk

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09610v1](http://arxiv.org/pdf/2509.09610v1)

**Abstract**: Predicting the spatio-temporal progression of brain tumors is essential for
guiding clinical decisions in neuro-oncology. We propose a hybrid mechanistic
learning framework that combines a mathematical tumor growth model with a
guided denoising diffusion implicit model (DDIM) to synthesize anatomically
feasible future MRIs from preceding scans. The mechanistic model, formulated as
a system of ordinary differential equations, captures temporal tumor dynamics
including radiotherapy effects and estimates future tumor burden. These
estimates condition a gradient-guided DDIM, enabling image synthesis that
aligns with both predicted growth and patient anatomy. We train our model on
the BraTS adult and pediatric glioma datasets and evaluate on 60 axial slices
of in-house longitudinal pediatric diffuse midline glioma (DMG) cases. Our
framework generates realistic follow-up scans based on spatial similarity
metrics. It also introduces tumor growth probability maps, which capture both
clinically relevant extent and directionality of tumor growth as shown by 95th
percentile Hausdorff Distance. The method enables biologically informed image
generation in data-limited scenarios, offering generative-space-time
predictions that account for mechanistic priors.


### Improving Video Diffusion Transformer Training by Multi-Feature Fusion and Alignment from Self-Supervised Vision Encoders
**Authors**: Dohun Lee, Hyeonho Jeong, Jiwook Kim, Duygu Ceylan, Jong Chul Ye

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09547v1](http://arxiv.org/pdf/2509.09547v1)

**Abstract**: Video diffusion models have advanced rapidly in the recent years as a result
of series of architectural innovations (e.g., diffusion transformers) and use
of novel training objectives (e.g., flow matching). In contrast, less attention
has been paid to improving the feature representation power of such models. In
this work, we show that training video diffusion models can benefit from
aligning the intermediate features of the video generator with feature
representations of pre-trained vision encoders. We propose a new metric and
conduct an in-depth analysis of various vision encoders to evaluate their
discriminability and temporal consistency, thereby assessing their suitability
for video feature alignment. Based on the analysis, we present Align4Gen which
provides a novel multi-feature fusion and alignment method integrated into
video diffusion model training. We evaluate Align4Gen both for unconditional
and class-conditional video generation tasks and show that it results in
improved video generation as quantified by various metrics. Full video results
are available on our project page: https://align4gen.github.io/align4gen/


### Explainable AI for Accelerated Microstructure Imaging: A SHAP-Guided Protocol on the Connectome 2.0 scanner
**Authors**: Quentin Uhl, Tommaso Pavan, Julianna Gerold, Kwok-Shing Chan, Yohan Jun, Shohei Fujita, Aneri Bhatt, Yixin Ma, Qiaochu Wang, Hong-Hsi Lee, Susie Y. Huang, Berkin Bilgic, Ileana Jelescu

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09513v1](http://arxiv.org/pdf/2509.09513v1)

**Abstract**: The diffusion MRI Neurite Exchange Imaging model offers a promising framework
for probing gray matter microstructure by estimating parameters such as
compartment sizes, diffusivities, and inter-compartmental water exchange time.
However, existing protocols require long scan times. This study proposes a
reduced acquisition scheme for the Connectome 2.0 scanner that preserves model
accuracy while substantially shortening scan duration. We developed a
data-driven framework using explainable artificial intelligence with a guided
recursive feature elimination strategy to identify an optimal 8-feature subset
from a 15-feature protocol. The performance of this optimized protocol was
validated in vivo and benchmarked against the full acquisition and alternative
reduction strategies. Parameter accuracy, preservation of anatomical contrast,
and test-retest reproducibility were assessed. The reduced protocol yielded
parameter estimates and cortical maps comparable to the full protocol, with low
estimation errors in synthetic data and minimal impact on test-retest
variability. Compared to theory-driven and heuristic reduction schemes, the
optimized protocol demonstrated superior robustness, reducing the deviation in
water exchange time estimates by over two-fold. In conclusion, this hybrid
optimization framework enables viable imaging of neurite exchange in 14 minutes
without loss of parameter fidelity. This approach supports the broader
application of exchange-sensitive diffusion magnetic resonance imaging in
neuroscience and clinical research, and offers a generalizable method for
designing efficient acquisition protocols in biophysical parameter mapping.


### Learning functions through Diffusion Maps
**Authors**: Alvaro Almeida Gomez

**Published Date**: 2025-09-03

**Updated Date**: 2025-09-11

**PDF Url**: [2509.03758v2](http://arxiv.org/pdf/2509.03758v2)

**Abstract**: We propose a data-driven method for approximating real-valued functions on
smooth manifolds, building on the Diffusion Maps framework under the manifold
hypothesis. Given pointwise evaluations of a function, the method constructs a
smooth extension to the ambient space by exploiting diffusion geometry and its
connection to the heat equation and the Laplace-Beltrami operator.
  To address the computational challenges of high-dimensional data, we
introduce a dimensionality reduction strategy based on the low-rank structure
of the distance matrix, revealed via singular value decomposition (SVD). In
addition, we develop an online updating mechanism that enables efficient
incorporation of new data, thereby improving scalability and reducing
computational cost.
  Numerical experiments, including applications to sparse CT reconstruction,
demonstrate that the proposed methodology outperforms classical feedforward
neural networks and interpolation methods in terms of both accuracy and
efficiency.


### SEDM: Scalable Self-Evolving Distributed Memory for Agents
**Authors**: Haoran Xu, Jiacong Hu, Ke Zhang, Lei Yu, Yuxin Tang, Xinyuan Song, Yiqun Duan, Lynn Ai, Bill Shi

**Published Date**: 2025-09-11

**Updated Date**: 2025-09-11

**PDF Url**: [2509.09498v1](http://arxiv.org/pdf/2509.09498v1)

**Abstract**: Long-term multi-agent systems inevitably generate vast amounts of
trajectories and historical interactions, which makes efficient memory
management essential for both performance and scalability. Existing methods
typically depend on vector retrieval and hierarchical storage, yet they are
prone to noise accumulation, uncontrolled memory expansion, and limited
generalization across domains. To address these challenges, we present SEDM,
Self-Evolving Distributed Memory, a verifiable and adaptive framework that
transforms memory from a passive repository into an active, self-optimizing
component. SEDM integrates verifiable write admission based on reproducible
replay, a self-scheduling memory controller that dynamically ranks and
consolidates entries according to empirical utility, and cross-domain knowledge
diffusion that abstracts reusable insights to support transfer across
heterogeneous tasks. Evaluations on benchmark datasets demonstrate that SEDM
improves reasoning accuracy while reducing token overhead compared with strong
memory baselines, and further enables knowledge distilled from fact
verification to enhance multi-hop reasoning. The results highlight SEDM as a
scalable and sustainable memory mechanism for open-ended multi-agent
collaboration. The code will be released in the later stage of this project.


