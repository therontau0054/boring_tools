# Abstracts of Papers

## Physics
### Parton distributions confront LHC Run II data: a quantitative appraisal
**Authors**: Amedeo Chiefa, Mark N. Costantini, Juan Cruz-Martinez, Emanuele R. Nocera, Tanjona R. Rabemananjara, Juan Rojo, Tanishq Sharma, Roy Stegeman, Maria Ubiali

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10359v1](http://arxiv.org/pdf/2501.10359v1)

**Abstract**: We present a systematic comparison of theoretical predictions and various
high-precision experimental measurements, specifically of differential cross
sections performed by the LHC run II for Drell-Yan gauge boson, top-quark pair,
single-inclusive jet and di-jet production, and by HERA for single-inclusive
jet and di-jet production. Theoretical predictions are computed at
next-to-next-to-leading order (NNLO) accuracy in perturbative Quantum
Chromodynamics. The most widely employed sets of Parton Distribution Functions
(PDFs) are used, and PDF, strong coupling, and missing higher order
uncertainties are taken into account. We quantitatively assess the predictive
power of each PDF set and the contribution of the different sources of
experimental and theoretical uncertainty to the agreement between data and
predictions. We show that control over all of these aspects is crucial to
precision physics studies, such as the determination of Standard Model
parameters at the LHC.


### Exploring the Standard Model and Beyond from the Evidence of CE$ν$NS with Reactor Antineutrinos in CONUS+
**Authors**: M. Alpízar-Venegas, L. J. Flores, Eduardo Peinado, E. Vázquez-Jáuregui

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10355v1](http://arxiv.org/pdf/2501.10355v1)

**Abstract**: The observation of the Coherent Elastic Neutrino-Nucleus Scattering
(CE$\nu$NS) process using reactor antineutrinos offers a unique opportunity to
probe the Standard Model and explore Beyond the Standard Model scenarios. This
study reports on the latest results from the CONUS+ experiment conducted at the
Leibstadt nuclear power plant (KKL), Switzerland. The CONUS collaboration
reports $395 \pm 106$ events detected from reactor antineutrinos with an
exposure of 347 kg$\cdot$days, utilizing high-purity germanium detectors
operated at sub-keV thresholds. A $\chi^2$-based statistical analysis was
performed on these results, incorporating systematic uncertainties. This
analysis was used to extract the weak mixing angle, establish a limit on the
neutrino magnetic moment, and impose constraints on neutrino non-standard
interactions using reactor antineutrinos. The results confirm the potential of
CE$\nu$NS experiments in the study of fundamental neutrino properties and
probing new physics.


### Resolving discrepancies in bang-time predictions for ICF experiments on the NIF: Insights from the Build-A-Hohlraum Campaign
**Authors**: G. F. Swadling, W. A. Farmer, H. Chen, N. Aybar, M. S. Rubery, M. B. Schneider, D. A. Liedahl, N. C. Lemos, E. Tubman, J. S. Ross, D. E. Hinkel, O. L. Landen, M. D. Rosen, S. Rogers K. Newman, D. Yanagisawa, N. Roskopf, S. Vonhof, L. Aghaian, M. Mauldin, B. L. Reichelt, J. Kunimune

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10350v1](http://arxiv.org/pdf/2501.10350v1)

**Abstract**: This study investigated discrepancies between measured and simulated x-ray
drive in Inertial Confinement Fusion (ICF) hohlraums at the National Ignition
Facility (NIF). Despite advances in radiation-hydrodynamic simulations, a
consistent "drive deficit" remains. Experimentally measured ICF capsule
bang-times are systematically 400-700 ps later than simulations predict. The
Build-A-Hohlraum (BAH) campaign explored potential causes for this discrepancy
by systematically varying hohlraum features, including laser entrance hole
(LEH) windows, capsules, and gas fills. Overall, the agreement between
simulated and experimental x-ray drive was found to be largely unaffected by
these changes. The data allows us to exclude some hypotheses put forward to
potentially explain the discrepancy. Errors in the local thermodynamic
equilibrium (LTE) atomic modeling, errors in the modeling of LEH closure and
errors due to a lack of plasma species mix physics in simulations are shown to
be inconsistent with our measurements. Instead, the data supports the
hypothesis that errors in NLTE emission modeling are a significant contributor
to the discrepancy. X-ray emission in the 2 - 4 keV range is found to be
approximately 30% lower than in simulations. This is accompanied by higher than
predicted electron temperatures in the gold bubble region, pointing to errors
in non-LTE modeling. Introducing an opacity multiplier of 0.87 on energy groups
above 1.8 keV improves agreement with experimental data, reducing the bang-time
discrepancy from 300 ps to 100 ps. These results underscore the need for
refined NLTE opacity models to enhance the predictive power of hohlraum
simulations.


### Top observables as precise probes of the ALP
**Authors**: Anh Vu Phan

**Published Date**: 2024-12-09

**Updated Date**: 2025-01-17

**PDF Url**: [2412.06506v2](http://arxiv.org/pdf/2412.06506v2)

**Abstract**: Measurements of the top quark by the ATLAS and CMS experiments go beyond
testing the Standard Model (SM) with high precision. Axion-like particles
(ALPs), a potential SM extension involving new pseudoscalar particles, exhibit
strong interactions with heavy SM fermions. Consequently, they can
significantly affect the kinematic distributions of top quarks in top-antitop
pair production. Moreover, such strong interactions can induce other ALP
couplings at low energies, leading to a rich phenomenology. We summarize recent
developments in probing the ALP-top coupling and use LHC data from run 2 to
constrain the ALP parameter space.


### Mass and wind luminosity of young Galactic open clusters in Gaia DR2
**Authors**: Silvia Celli, Andreas Specovius, Stefano Menchiari, Alison Mitchell, Giovanni Morlino

**Published Date**: 2023-11-15

**Updated Date**: 2025-01-17

**PDF Url**: [2311.09089v3](http://arxiv.org/pdf/2311.09089v3)

**Abstract**: Context. Star clusters constitute a significant part of the stellar
population in our Galaxy. The feedback processes they exert on the interstellar
medium impact multiple physical processes from the chemical to the dynamical
evolution of the Galaxy. In addition, young and massive stellar clusters might
act as efficient particle accelerators and contribute to the production of
cosmic rays. Aims. We aim at evaluating the wind luminosity driven by the young
(< 30 Myr) Galactic open stellar clusters observed by the Gaia space mission.
This is crucial for determining the energy channeled into accelerated
particles. Methods. To do this, we developed a method relying on the number,
magnitude, and line-of-sight extinction of the stars observed per cluster.
Assuming that the stellar mass function follows a Kroupa mass distribution and
accounting for the maximum stellar mass allowed by the age and mass of the
parent cluster, we conservatively estimated the mass and wind luminosity of 387
local clusters within the second data release of Gaia. Results. We compared the
results of our computation with recent estimates of young cluster masses. With
respect to these, our sample is three times more abundant, particularly above a
few thousand solar masses. This is of the utmost relevance for predicting the
gamma-ray emission resulting from the interaction of accelerated particles. The
cluster wind luminosity distribution we obtained extends up to 3x10^38 erg/s.
This is a promising feature in terms of potential particle acceleration
scenarios.


### Elucidating the high compliance mechanism by which the urinary bladder fills under low pressures
**Authors**: Fatemeh Azari, Anne M. Robertson, Yasutaka Tobe, Paul N. Watton, Lori A. Birder, Naoki Yoshimura, Kanako Matsuoka, Christopher Hardin, Simon Watkins

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10312v1](http://arxiv.org/pdf/2501.10312v1)

**Abstract**: The high compliance of the urinary bladder during filling is essential for
its proper function, enabling it to accommodate significant volumetric
increases with minimal rise in transmural pressure. This study aimed to
elucidate the physical mechanisms underlying this phenomenon by analyzing the
ex vivo filling process in rat from a fully voided state to complete
distension, without preconditioning, using three complementary imaging
modalities. High-resolution micro-CT at 10.8 {\mu}m resolution was used to
generate detailed 3D reconstructions of the bladder lumen, revealing a 62 fold
increase in bladder volume during filling. Pressure-volume studies of whole
bladder delineated three mechanical filling regimes: an initial high-compliance
phase, a transitional phase, and a final high-pressure phase. While prior
studies conjectured small mucosal rugae (450 {\mu}m) are responsible for the
high compliance phase, multiphoton microscopy (MPM) of the dome of the voided
bladder revealed large folds an order of magnitude larger than these rugae.
Bladder imaging during the inflation process demonstrated flattening of these
large scale folds is responsible for volume increases in the initial high
compliance phase. The 3D reconstructions of the bladder lumen in the filled and
voided state revealed a high voiding efficiency of 97.13%. The MPM imaging
results suggest the large scale folds in the dome enable this high voiding
fraction by driving urine toward the bladder outlet. These insights are vital
for computational models of bladder biomechanics and understanding changes to
bladder function due to pathological conditions such as bladder outlet
obstruction and age-related dysfunction.


### The Auger-Meitner Radioisotope Microscope: an instrument for characterization of Auger electron multiplicities and energy distributions
**Authors**: Patrick R. Stollenwerk, Stephen H. Southworth, Francesco Granato, Amy Renne, Brahim Mustapha, Kevin G. Bailey, Peter Mueller, Jerry Nolen, Thomas P. O'Connor, Junqi Xie, Linda Young, Matthew R. Dietrich

**Published Date**: 2024-10-30

**Updated Date**: 2025-01-17

**PDF Url**: [2410.23103v2](http://arxiv.org/pdf/2410.23103v2)

**Abstract**: We describe a new instrument, the Argonne Auger Radioisotope Microscope
(ARM), capable of characterizing the Auger electron emission of radionuclides,
including candidates relevant in nuclear medicine. Our approach relies on
event-by-event ion-electron coincidence, time-of-flight, and spatial readout
measurement to determine correlated electron multiplicity and energy
distributions of Auger decays. We present a proof-of-principle measurement with
the ARM using X-ray photoionization of stable krypton beyond the K-edge and
identify a bifurcation in the electron multiplicity distribution depending on
the emission of K-LX electrons. Extension of the ARM to the characterization of
radioactive sources of Auger electron emissions is enabled by the combination
of two recent developments: (1) cryogenic buffer gas beam technology to
introduce Auger emitters into the detection region with well-defined initial
conditions, and (2) large-area micro-channel plate detectors with multi-hit
detection capabilities to simultaneously detect multiple electrons emitted in a
single decay.
  The ARM will generate new experimental data on Auger multiplicities that can
be used to benchmark atomic relaxation and decay models. This data will provide
insight into the low-energy regime of Auger electrons where intensity
calculations are most challenging and experimental data is limited. In
particular, accurate multiplicity data of the low-energy regime can be used to
inform oncological dosimetry models, where electron energies less than 500 eV
are known to be most effective in damaging DNA and cell membranes.


### Matrix Product Density Operators: Renormalization Fixed Points and Boundary Theories
**Authors**: J. I. Cirac, D. Perez-Garcia, N. Schuch, F. Verstraete

**Published Date**: 2016-06-02

**Updated Date**: 2025-01-17

**PDF Url**: [1606.00608v4](http://arxiv.org/pdf/1606.00608v4)

**Abstract**: We consider the tensors generating matrix product states and density
operators in a spin chain. For pure states, we revise the renormalization
procedure introduced by F. Verstraete et al. in 2005 and characterize the
tensors corresponding to the fixed points. We relate them to the states
possessing zero correlation length, saturation of the area law, as well as to
those which generate ground states of local and commuting Hamiltonians. For
mixed states, we introduce the concept of renormalization fixed points and
characterize the corresponding tensors. We also relate them to concepts like
finite correlation length, saturation of the area law, as well as to those
which generate Gibbs states of local and commuting Hamiltonians. One of the
main result of this work is that the resulting fixed points can be associated
to the boundary theories of two-dimensional topological states, through the
bulk-boundary correspondence introduced by Cirac et al. in 2011.


### Intense Laser-Driven Phenomena In Weyl Semimetals
**Authors**: Amar Bharti

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10293v1](http://arxiv.org/pdf/2501.10293v1)

**Abstract**: Condensed-matter provides attractive platforms to realize exotic particles,
originally proposed in high-energy physics. Weyl semimetal (WSM) is a material
in which low-energy collective excitations are governed by massless Weyl
fermions, which appear in pairs of opposite chirality and are topologically
protected. Thus, the discovery of topological materials such as WSM has
heralded a new era in contemporary physics. Moreover, these materials offer
exciting opportunities in next-generation signal processing and
optoelectronics. This thesis explores different facets of the intense
laser-driven phenomena in WSM for applications in emerging lightwave-driven
Petahertz electronics and quantum technologies.


### A precise study of the SU(3) Yang-Mills theory across the deconfinement transition
**Authors**: Leonardo Giusti, Mitsuaki Hirasawa, Michele Pepe, Luca Virzì

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10284v1](http://arxiv.org/pdf/2501.10284v1)

**Abstract**: We perform a detailed computation of key quantities across the first-order
deconfinement phase transition of the SU(3) Yang-Mills theory. Specifically, we
calculate the entropy density, $s(T_c)/T_c^3$, on both sides of the transition
and determine the latent heat $h$. The calculations are carried out in the
lattice regularization with the Wilson action, employing shifted boundary
conditions in the temporal direction. Our simulations are performed at five
different values of the lattice spacing in order to extrapolate the results to
the continuum limit. The latent heat can be measured also as the discontinuity
in the trace anomaly of the energy-momentum tensor: our result using the
entropy density is compatible with the one obtained from the trace anomaly,
giving a combined estimate $h=1.175(10)$. Additionally, we determine the
critical temperature $T_c$ in physical units with permille accuracy, yielding
$T_c \sqrt{t_0} = 0.24915(29)$. These results allow to connect with precision
the confined and the deconfined phases and we present an improved computation
of the Equation of State across the deconfinement transition for $T$ between 0
and $3.4 T_c$.


## Diffusion
### Moonshine: Distilling Game Content Generators into Steerable Generative Models
**Authors**: Yuhe Nie, Michael Middleton, Tim Merino, Nidhushan Kanagaraja, Ashutosh Kumar, Zhan Zhuang, Julian Togelius

**Published Date**: 2024-08-18

**Updated Date**: 2025-01-17

**PDF Url**: [2408.09594v2](http://arxiv.org/pdf/2408.09594v2)

**Abstract**: Procedural Content Generation via Machine Learning (PCGML) has enhanced game
content creation, yet challenges in controllability and limited training data
persist. This study addresses these issues by distilling a constructive PCG
algorithm into a controllable PCGML model. We first generate a large amount of
content with a constructive algorithm and label it using a Large Language Model
(LLM). We use these synthetic labels to condition two PCGML models for
content-specific generation, a diffusion model and the five-dollar model. This
neural network distillation process ensures that the generation aligns with the
original algorithm while introducing controllability through plain text. We
define this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering
an alternative to prevalent text-to-image multi-modal tasks. We compare our
distilled models with the baseline constructive algorithm. Our analysis of the
variety, accuracy, and quality of our generation demonstrates the efficacy of
distilling constructive methods into controllable text-conditioned PCGML
models.


### DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning
**Authors**: Yukun Cao, Lisheng Wang, Luobin Huang

**Published Date**: 2024-11-03

**Updated Date**: 2025-01-17

**PDF Url**: [2411.01477v2](http://arxiv.org/pdf/2411.01477v2)

**Abstract**: Temporal knowledge graph (TKG) reasoning that infers future missing facts is
an essential and challenging task. Predicting future events typically relies on
closely related historical facts, yielding more accurate results for repetitive
or periodic events. However, for future events with sparse historical
interactions, the effectiveness of this method, which focuses on leveraging
high-frequency historical information, diminishes. Recently, the capabilities
of diffusion models in image generation have opened new opportunities for TKG
reasoning. Therefore, we propose a graph node diffusion model with dual-domain
periodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)
introduces noise into sparsely related events to simulate new events,
generating high-quality data that better conforms to the actual distribution.
This generative mechanism significantly enhances the model's ability to reason
about new events. Additionally, the dual-domain periodic contrastive learning
(DPCL) maps periodic and non-periodic event entities to Poincar\'e and
Euclidean spaces, leveraging their characteristics to distinguish similar
periodic events effectively. Experimental results on four public datasets
demonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG
models in event prediction, demonstrating our approach's effectiveness. This
study also investigates the combined effectiveness of GNDiff and DPCL in TKG
tasks.


### Generate E-commerce Product Background by Integrating Category Commonality and Personalized Style
**Authors**: Haohan Wang, Wei Feng, Yaoyu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao

**Published Date**: 2023-12-20

**Updated Date**: 2025-01-17

**PDF Url**: [2312.13309v2](http://arxiv.org/pdf/2312.13309v2)

**Abstract**: The state-of-the-art methods for e-commerce product background generation
suffer from the inefficiency of designing product-wise prompts when scaling up
the production, as well as the ineffectiveness of describing fine-grained
styles when customizing personalized backgrounds for some specific brands. To
address these obstacles, we integrate the category commonality and personalized
style into diffusion models. Concretely, we propose a Category-Wise Generator
to enable large-scale background generation with only one model for the first
time. A unique identifier in the prompt is assigned to each category, whose
attention is located on the background by a mask-guided cross attention layer
to learn the category-wise style. Furthermore, for products with specific and
fine-grained requirements in layout, elements, etc, a Personality-Wise
Generator is devised to learn such personalized style directly from a reference
image to resolve textual ambiguities, and is trained in a self-supervised
manner for more efficient training data usage. To advance research in this
field, the first large-scale e-commerce product background generation dataset
BG60k is constructed, which covers more than 60k product images from over 2k
categories. Experiments demonstrate that our method could generate high-quality
backgrounds for different categories, and maintain the personalized background
style of reference images. BG60k will be available at
\url{https://github.com/Whileherham/BG60k}.


### Mitigating analytical variability in fMRI results with style transfer
**Authors**: Elodie Germani, Camille Maumet, Elisa Fromont

**Published Date**: 2024-04-04

**Updated Date**: 2025-01-17

**PDF Url**: [2404.03703v3](http://arxiv.org/pdf/2404.03703v3)

**Abstract**: We propose a novel approach to improve the reproducibility of neuroimaging
results by converting statistic maps across different functional MRI pipelines.
We make the assumption that pipelines used to compute fMRI statistic maps can
be considered as a style component and we propose to use different generative
models, among which, Generative Adversarial Networks (GAN) and Diffusion Models
(DM) to convert statistic maps across different pipelines. We explore the
performance of multiple GAN frameworks, and design a new DM framework for
unsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI
statistic maps using the latent space of an auxiliary classifier that
distinguishes statistic maps from different pipelines and extend traditional
sampling techniques used in DM to improve the transition performance. Our
experiments demonstrate that our proposed methods aresuccessful: pipelines can
indeed be transferred as a style component, providing animportant source of
data augmentation for future medical studies.


### Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks
**Authors**: Junlan Chen, Qijie He, Pei Liu, Wei Ma, Ziyuan Pu

**Published Date**: 2025-01-17

**Updated Date**: 2025-01-17

**PDF Url**: [2501.10017v1](http://arxiv.org/pdf/2501.10017v1)

**Abstract**: Crash frequency modelling analyzes the impact of factors like traffic volume,
road geometry, and environmental conditions on crash occurrences. Inaccurate
predictions can distort our understanding of these factors, leading to
misguided policies and wasted resources, which jeopardize traffic safety. A key
challenge in crash frequency modelling is the prevalence of excessive zero
observations, caused by underreporting, the low probability of crashes, and
high data collection costs. These zero observations often reduce model accuracy
and introduce bias, complicating safety decision making. While existing
approaches, such as statistical methods, data aggregation, and resampling,
attempt to address this issue, they either rely on restrictive assumptions or
result in significant information loss, distorting crash data. To overcome
these limitations, we propose a hybrid VAE-Diffusion neural network, designed
to reduce zero observations and handle the complexities of multi-type tabular
crash data (count, ordinal, nominal, and real-valued variables). We assess the
synthetic data quality generated by this model through metrics like similarity,
accuracy, diversity, and structural consistency, and compare its predictive
performance against traditional statistical models. Our findings demonstrate
that the hybrid VAE-Diffusion model outperforms baseline models across all
metrics, offering a more effective approach to augmenting crash data and
improving the accuracy of crash frequency predictions. This study highlights
the potential of synthetic data to enhance traffic safety by improving crash
frequency modelling and informing better policy decisions.


