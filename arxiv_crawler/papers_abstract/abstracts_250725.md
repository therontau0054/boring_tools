# Abstracts of Papers

## Physics
### Moving Out: Physically-grounded Human-AI Collaboration
**Authors**: Xuhui Kang, Sung-Wook Lee, Haolin Liu, Yuyan Wang, Yen-Ling Kuo

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18623v1](http://arxiv.org/pdf/2507.18623v1)

**Abstract**: The ability to adapt to physical actions and constraints in an environment is
crucial for embodied agents (e.g., robots) to effectively collaborate with
humans. Such physically grounded human-AI collaboration must account for the
increased complexity of the continuous state-action space and constrained
dynamics caused by physical constraints. In this paper, we introduce
\textit{Moving Out}, a new human-AI collaboration benchmark that resembles a
wide range of collaboration modes affected by physical attributes and
constraints, such as moving heavy items together and maintaining consistent
actions to move a big item around a corner. Using Moving Out, we designed two
tasks and collected human-human interaction data to evaluate models' abilities
to adapt to diverse human behaviors and unseen physical attributes. To address
the challenges in physical environments, we propose a novel method, BASS
(Behavior Augmentation, Simulation, and Selection), to enhance the diversity of
agents and their understanding of the outcome of actions. Our experiments show
that BASS outperforms state-of-the-art models in AI-AI and human-AI
collaboration. The project page is available at
\href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\_ai/}.


### Strong CP Phase and Parity in the Hamiltonian Formalism
**Authors**: Ravi Kuchimanchi

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18620v1](http://arxiv.org/pdf/2507.18620v1)

**Abstract**: Solutions to the strong CP problem based on P or CP symmetries are typically
framed using the Lagrangian formalism. In this work, we analyze the strong CP
phase in QCD from the Hamiltonian perspective, focusing on the invariance of
the Hamiltonian H under P (or a generalized parity operator $\mathcal{P}$). For
$\mathcal{P}$ to be a physical symmetry, it must preserve the Hilbert space
$\mathcal{H}_\theta$ associated with the $\theta$-vacuum (i.e., $\mathcal{P}:
\mathcal{H}_\theta \rightarrow \mathcal{H}_\theta$). This requirement implies
that the strong CP phase $\bar{\theta} = \theta + \arg \det M$ must vanish,
i.e., $\theta$ must cancel the phase of the quark mass matrix $M$.
Equivalently, we show that this condition follows from requiring that parity
commute with the large gauge transformation operator of QCD.


### Persistent currents in ultracold gases
**Authors**: Juan Polo, Wayne Jordan Chetcuti, Tobias Haug, Anna Minguzzi, Kevin Wright, Luigi Amico

**Published Date**: 2024-10-22

**Updated Date**: 2025-07-24

**PDF Url**: [2410.17318v3](http://arxiv.org/pdf/2410.17318v3)

**Abstract**: Persistent currents flowing in spatially closed tracks define one of the most
iconic concepts in mesoscopic physics. They have been studied in solid-state
platforms such as superfluids, superconductors and metals. Cold atoms trapped
in magneto-optical toroidal circuits and driven by suitable artificial gauge
fields allow us to study persistent currents with unprecedented control and
flexibility of the system's physical conditions. Here, we review persistent
currents of ultracold matter. Capitalizing on the remarkable progress in
driving different atomic species to quantum degeneracy, persistent currents of
single or multicomponent bosons/fermions, and their mixtures can be addressed
within the present experimental know-how. This way, fundamental concepts of
quantum science and many-body physics, like macroscopic quantum coherence,
solitons, vortex dynamics, fermionic pairing and BEC-BCS crossover can be
studied from a novel perspective. Finally, we discuss how persistent currents
can form the basis of new technological applications like matter-wave
gyroscopes and interferometers.


### Stability of Big Bang singularity for the Einstein-Maxwell-scalar field-Vlasov system in the full strong sub-critical regime
**Authors**: Xinliang An, Taoran He, Dawei Shen

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18585v1](http://arxiv.org/pdf/2507.18585v1)

**Abstract**: In $3+1$ dimensions, we study the stability of Kasner solutions for the
Einstein-Maxwell-scalar field-Vlasov system. This system incorporates gravity,
electromagnetic, weak and strong interactions for the initial stage of our
universe. Due to the presence of the Vlasov field, various new challenges
arise. By observing detailed mathematical structures and designing new delicate
arguments, we identify a new strong sub-critical regime and prove the nonlinear
stability with Kasner exponents lying in this full regime. This extends the
result of Fournodavlos-Rodnianski-Speck [8] from the Einstein-scalar field
system to the physically more complex system with the Vlasov field.


### Alleviating the Hubble tension with Torsion Condensation (TorC)
**Authors**: Sinah Legner, Will Handley, Will Barker

**Published Date**: 2025-07-12

**Updated Date**: 2025-07-24

**PDF Url**: [2507.09228v2](http://arxiv.org/pdf/2507.09228v2)

**Abstract**: Constraints on the cosmological parameters of Torsion Condensation (TorC) are
investigated using Planck 2018 Cosmic Microwave Background data. TorC is a case
of Poincar\'e gauge theory -- a formulation of gravity motivated by the gauge
field theories underlying fundamental forces in the standard model of particle
physics. Unlike general relativity, TorC incorporates intrinsic torsion degrees
of freedom while maintaining second-order field equations. At specific
parameter values, it reduces to the $\Lambda$CDM model, providing a natural
extension to standard cosmology. The base model of TorC introduces two
parameters beyond those in $\Lambda$CDM: the initial value of the torsion
scalar field and its time derivative -- one can absorb the latter by allowing
the dark energy density to float. To constrain these parameters, `PolyChord`
nested sampling algorithm is employed, interfaced via `Cobaya` with a modified
version of `CAMB`. Our results indicate that TorC allows for a larger inferred
Hubble constant, offering a potential resolution to the Hubble tension. Tension
analysis using the $R$-statistic shows that TorC alleviates the statistical
tension between the Planck 2018 and SH0Es 2020 datasets, though this
improvement is not sufficient to decisively favour TorC over $\Lambda$CDM in a
Bayesian model comparison. This study highlights TorC as a compelling theory of
gravity, demonstrating its potential to address cosmological tensions and
motivating further investigations of extended theories of gravity within a
cosmological context. As current and upcoming surveys -- including Euclid,
Roman Space Telescope, Vera C. Rubin Observatory, LISA, and Simons Observatory
-- deliver data on gravity across all scales, they will offer critical tests of
gravity models like TorC, making the present a pivotal moment for exploring
extended theories of gravity.


### Jacobi Hamiltonian Integrators
**Authors**: Adérito Araújo, Gonçalo Inocêncio Oliveira, João Nuno Mestre

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18573v1](http://arxiv.org/pdf/2507.18573v1)

**Abstract**: We develop a method of constructing structure-preserving integrators for
Hamiltonian systems in Jacobi manifolds. Hamiltonian mechanics, rooted in
symplectic and Poisson geometry, has long provided a foundation for modelling
conservative systems in classical physics. Jacobi manifolds, generalizing both
contact and Poisson manifolds, extend this theory and are suitable for
incorporating time-dependent, dissipative and thermodynamic phenomena.
  Building on recent advances in geometric integrators - specifically Poisson
Hamiltonian Integrators (PHI), which preserve key features of Poisson systems -
we propose a construction of Jacobi Hamiltonian Integrators. Our approach
explores the correspondence between Jacobi and homogeneous Poisson manifolds,
with the aim of extending the PHI techniques while ensuring preservation of the
homogeneity structure.
  This work develops the theoretical tools required for this generalization and
outlines a numerical integration technique compatible with Jacobi dynamics. By
focusing on the homogeneous Poisson perspective rather than on direct contact
realizations, we provide a clear pathway for structure-preserving integration
of time-dependent and dissipative systems within the Jacobi framework.


### About diffusion equations in bounded systems
**Authors**: F. Sattin, D. F. Escande

**Published Date**: 2025-05-05

**Updated Date**: 2025-07-24

**PDF Url**: [2505.02496v2](http://arxiv.org/pdf/2505.02496v2)

**Abstract**: Differential equations need boundary conditions (BC's) for their solution. It
is commonly acknowledged that differential equations and BC's are
representative of independent physical processes, and no correlations between
them is required. Two recent papers [D. Hilhorst, et al, Nonlinear Analysis,
245, 113561 (2024); J-W.Chung, et al, Jour. Math. Phys. 65, 071501 (2024)]
focus on diffusion equations (DE's) in a case with continuity of the physics at
the boundary, where transport coefficients go smoothly to zero in a very small
layer about it. They argue that, once the analytical expression of the DE is
chosen, only one kind of BC's may emerge (e.g., Neumann rather than Dirichlet).
In this paper, we show that this case is very peculiar. Indeed, DE's generally
arise as long-wavelength limit out of a stochastic picture of microscopic
dynamics, in the form of an integro-differential Master Equation (ME).
Accordingly, they are justified only on a statistical basis, provide accurate
pictures of the system's evolution only over large enough length and time
scales. In realistic cases, the width of the interface between the interior and
exterior of the system is much smaller than transport scales, providing
effectively a discontinuity and therefore a decorrelation between DE and BC.


### The Integral Decimation Method for Quantum Dynamics and Statistical Mechanics
**Authors**: Ryan T. Grimm, Alexander J. Staat, Joel D. Eaves

**Published Date**: 2025-06-12

**Updated Date**: 2025-07-24

**PDF Url**: [2506.11341v3](http://arxiv.org/pdf/2506.11341v3)

**Abstract**: The solutions to many problems in the mathematical, computational, and
physical sciences often involve multidimensional integrals. A direct numerical
evaluation of the integral incurs a computational cost that is exponential in
the number of dimensions, a phenomenon called the curse of dimensionality. The
problem is so substantial that one usually employs sampling methods, like Monte
Carlo, to avoid integration altogether. Here, we derive and implement a quantum
algorithm to compress a multidimensional integrand into a product of
matrix-valued functions - a spectral tensor train - changing the computational
complexity of integration from exponential to polynomial. The algorithm
compresses the integrand by applying a sequence of quantum gates to an
unentangled quantum state, where each term corresponds to a body-ordered term
in the potential. Because it allows for the systematic elimination of small
contributions to the integral through decimation, we call the method integral
decimation. The functions in the spectral basis are analytically differentiable
and integrable, and in applications to the partition function, integral
decimation numerically factorizes an interacting system into a product of
noninteracting ones. We illustrate integral decimation by evaluating the
absolute free energy and entropy of a chiral XY model as a continuous function
of temperature. We also compute the nonequilibrium time-dependent reduced
density matrix of a quantum chain with between two and forty levels, each
coupled to colored noise. When other methods provide numerical solutions to
these models, they quantitatively agree with integral decimation. When
conventional methods become intractable, integral decimation can be a powerful
alternative.


### Quasi-1D Coulomb drag in the nonlinear regime
**Authors**: Mingyang Zheng, Rebika Makaju, Rasul Gazizulin, Alex Levchenko, Sadhvikas J. Addamane, Dominique Laroche

**Published Date**: 2024-10-23

**Updated Date**: 2025-07-24

**PDF Url**: [2410.17569v2](http://arxiv.org/pdf/2410.17569v2)

**Abstract**: One-dimensional Coulomb drag has been an essential tool to probe the physics
of interacting Tomonaga-Luttinger liquids. To date, most experimental work has
focused on the linear regime while the predictions for Luttinger liquids beyond
the linear response theory remain largely untested. In this letter, we report
measurements of momentum transfer induced Coulomb drag between
vertically-coupled quasi-one-dimensional quantum wires in the nonlinear regime.
Measurements were performed at ultra-low temperatures between wires only 15 nm
apart. Our results reveal a nonlinear dependence of the drag voltage as a
function of the drive current superimposed with an oscillatory contribution, in
agreement with theoretical predictions for Coulomb drag between
Tomonaga-Luttinger liquids. Additionally, the observed current-voltage
($I$-$V$) characteristics exhibit a nonmonotonic temperature dependence,
further corroborating the presence of non-Fermi-liquid behavior in our system.
These findings are observed both in the single and in the multiple subband
regimes and in the presence of disorder, extending the onset of this behavior
beyond the clean single channel Tomonaga-Luttinger regime where the predictions
were originally formulated.


## Diffusion
### Diffusion Beats Autoregressive in Data-Constrained Settings
**Authors**: Mihir Prabhudesai, Menging Wu, Amir Zadeh, Katerina Fragkiadaki, Deepak Pathak

**Published Date**: 2025-07-21

**Updated Date**: 2025-07-24

**PDF Url**: [2507.15857v2](http://arxiv.org/pdf/2507.15857v2)

**Abstract**: Autoregressive (AR) models have long dominated the landscape of large
language models, driving progress across a wide range of tasks. Recently,
diffusion-based language models have emerged as a promising alternative, though
their advantages over AR models remain underexplored. In this paper, we
systematically study masked diffusion models in data-constrained settings-where
training involves repeated passes over limited data-and find that they
significantly outperform AR models when compute is abundant but data is scarce.
Diffusion models make better use of repeated data, achieving lower validation
loss and superior downstream performance. We interpret this advantage as
implicit data augmentation: masked diffusion exposes the model to a diverse
distribution of token orderings and prediction tasks, unlike AR's fixed
left-to-right factorization. We find new scaling laws for diffusion models and
derive a closed-form expression for the critical compute threshold at which
diffusion begins to outperform AR. These results suggest that when data, not
compute, is the bottleneck, diffusion models offer a compelling alternative to
the standard AR paradigm. Our code is available at:
https://diffusion-scaling.github.io.


### Demystify Protein Generation with Hierarchical Conditional Diffusion Models
**Authors**: Zinan Ling, Yi Shi, Da Yan, Yang Zhou, Bo Hui

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18603v1](http://arxiv.org/pdf/2507.18603v1)

**Abstract**: Generating novel and functional protein sequences is critical to a wide range
of applications in biology. Recent advancements in conditional diffusion models
have shown impressive empirical performance in protein generation tasks.
However, reliable generations of protein remain an open research question in de
novo protein design, especially when it comes to conditional diffusion models.
Considering the biological function of a protein is determined by multi-level
structures, we propose a novel multi-level conditional diffusion model that
integrates both sequence-based and structure-based information for efficient
end-to-end protein design guided by specified functions. By generating
representations at different levels simultaneously, our framework can
effectively model the inherent hierarchical relations between different levels,
resulting in an informative and discriminative representation of the generated
protein. We also propose a Protein-MMD, a new reliable evaluation metric, to
evaluate the quality of generated protein with conditional diffusion models.
Our new metric is able to capture both distributional and functional
similarities between real and generated protein sequences while ensuring
conditional consistency. We experiment with the benchmark datasets, and the
results on conditional protein generation tasks demonstrate the efficacy of the
proposed generation framework and evaluation metric.


### Elucidating the Design Space of Arbitrary-Noise-Based Diffusion Models
**Authors**: Xingyu Qiu, Mengying Yang, Xinghua Ma, Dong Liang, Yuzhen Li, Fanding Li, Gongning Luo, Wei Wang, Kuanquan Wang, Shuo Li

**Published Date**: 2025-07-24

**Updated Date**: 2025-07-24

**PDF Url**: [2507.18534v1](http://arxiv.org/pdf/2507.18534v1)

**Abstract**: EDM elucidates the unified design space of diffusion models, yet its fixed
noise patterns restricted to pure Gaussian noise, limit advancements in image
restoration. Our study indicates that forcibly injecting Gaussian noise
corrupts the degraded images, overextends the image transformation distance,
and increases restoration complexity. To address this problem, our proposed EDA
Elucidates the Design space of Arbitrary-noise-based diffusion models.
Theoretically, EDA expands the freedom of noise pattern while preserving the
original module flexibility of EDM, with rigorous proof that increased noise
complexity incurs no additional computational overhead during restoration. EDA
is validated on three typical tasks: MRI bias field correction (global smooth
noise), CT metal artifact reduction (global sharp noise), and natural image
shadow removal (local boundary-aware noise). With only 5 sampling steps, EDA
outperforms most task-specific methods and achieves state-of-the-art
performance in bias field correction and shadow removal.


### Att-Adapter: A Robust and Precise Domain-Specific Multi-Attributes T2I Diffusion Adapter via Conditional Variational Autoencoder
**Authors**: Wonwoong Cho, Yan-Ying Chen, Matthew Klenk, David I. Inouye, Yanxia Zhang

**Published Date**: 2025-03-15

**Updated Date**: 2025-07-24

**PDF Url**: [2503.11937v4](http://arxiv.org/pdf/2503.11937v4)

**Abstract**: Text-to-Image (T2I) Diffusion Models have achieved remarkable performance in
generating high quality images. However, enabling precise control of continuous
attributes, especially multiple attributes simultaneously, in a new domain
(e.g., numeric values like eye openness or car width) with text-only guidance
remains a significant challenge. To address this, we introduce the Attribute
(Att) Adapter, a novel plug-and-play module designed to enable fine-grained,
multi-attributes control in pretrained diffusion models. Our approach learns a
single control adapter from a set of sample images that can be unpaired and
contain multiple visual attributes. The Att-Adapter leverages the decoupled
cross attention module to naturally harmonize the multiple domain attributes
with text conditioning. We further introduce Conditional Variational
Autoencoder (CVAE) to the Att-Adapter to mitigate overfitting, matching the
diverse nature of the visual world. Evaluations on two public datasets show
that Att-Adapter outperforms all LoRA-based baselines in controlling continuous
attributes. Additionally, our method enables a broader control range and also
improves disentanglement across multiple attributes, surpassing StyleGAN-based
techniques. Notably, Att-Adapter is flexible, requiring no paired synthetic
data for training, and is easily scalable to multiple attributes within a
single model.


## Quantitative Finance
### EFS: Evolutionary Factor Searching for Sparse Portfolio Optimization Using Large Language Models
**Authors**: Haochen Luo, Yuan Zhang, Chen Liu

**Published Date**: 2025-07-23

**Updated Date**: 2025-07-23

**PDF Url**: [2507.17211v1](http://arxiv.org/pdf/2507.17211v1)

**Abstract**: Sparse portfolio optimization is a fundamental yet challenging problem in
quantitative finance, since traditional approaches heavily relying on
historical return statistics and static objectives can hardly adapt to dynamic
market regimes. To address this issue, we propose Evolutionary Factor Search
(EFS), a novel framework that leverages large language models (LLMs) to
automate the generation and evolution of alpha factors for sparse portfolio
construction. By reformulating the asset selection problem as a top-m ranking
task guided by LLM-generated factors, EFS incorporates an evolutionary feedback
loop to iteratively refine the factor pool based on performance. Extensive
experiments on five Fama-French benchmark datasets and three real-market
datasets (US50, HSI45 and CSI300) demonstrate that EFS significantly
outperforms both statistical-based and optimization-based baselines, especially
in larger asset universes and volatile conditions. Comprehensive ablation
studies validate the importance of prompt composition, factor diversity, and
LLM backend choice. Our results highlight the promise of language-guided
evolution as a robust and interpretable paradigm for portfolio optimization
under structural constraints.


