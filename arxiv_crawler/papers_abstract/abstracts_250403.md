# Abstracts of Papers

## Physics
### Accurate and Honest Approximation of Correlated Qubit Noise
**Authors**: F. Setiawan, Alexander V. Gramolin, Elisha S. Matekole, Hari Krovi, Jacob M. Taylor

**Published Date**: 2023-11-15

**Updated Date**: 2025-04-02

**PDF Url**: [2311.09305v2](http://arxiv.org/pdf/2311.09305v2)

**Abstract**: Accurate modeling of noise in realistic quantum processors is critical for
constructing fault-tolerant quantum computers. While a full simulation of
actual noisy quantum circuits provides information about correlated noise among
all qubits and is therefore accurate, it is, however, computationally expensive
as it requires resources that grow exponentially with the number of qubits. We
propose an efficient systematic construction of approximate noise channels,
where their accuracy can be enhanced by incorporating noise components with
higher qubit-qubit correlation degree. To formulate such approximate channels,
we first present a method, dubbed the cluster expansion approach, to decompose
the Lindbladian generator of an actual noise channel into components based on
interqubit correlation degree. We generate a $k$-th order approximate noise
channel by truncating the cluster expansion and incorporating noise components
with correlations up to the $k$-th degree. We require that the approximate
noise channels must be accurate and also ``honest", i.e., the actual errors are
not underestimated in our physical models. As an example application, we apply
our method to model noise in a three-qubit quantum processor that stabilizes a
[[2,0,2]] codeword, which is one of the four Bell states. We find that, for
realistic noise strength typical for fixed-frequency superconducting qubits
coupled via always-on static interactions, correlated noise beyond two-qubit
correlation can significantly affect the code simulation accuracy. Since our
approach provides a systematic characterization of multi-qubit noise
correlations, it enables the potential for accurate, honest and scalable
approximations to simulate large numbers of qubits from full modeling or
experimental characterizations of small enough quantum subsystems, which are
efficient but still retain essential noise features of the entire device.


### Limits to Analog Reservoir Learning
**Authors**: Anthony M. Polloreno

**Published Date**: 2023-07-26

**Updated Date**: 2025-04-02

**PDF Url**: [2307.14474v3](http://arxiv.org/pdf/2307.14474v3)

**Abstract**: Reservoir computation is a recurrent framework for learning and predicting
time series data, that benefits from extremely simple training and
interpretability, often as the the dynamics of a physical system. In this
paper, we will study the impact of noise on the learning capabilities of analog
reservoir computers. Recent work on reservoir computation has shown that the
information processing capacity (IPC) is a useful metric for quantifying the
degradation of the performance due to noise. We further this analysis and
demonstrate that this degradation of the IPC limits the possible features that
can be meaningfully constructed in an analog reservoir computing setting. We
borrow a result from quantum complexity theory that relates the circuit model
of computation to a continuous time model, and demonstrate an exponential
reduction in the accessible volume of reservoir configurations. We conclude by
relating this degradation in the IPC to the fat-shattering dimension of a
family of functions describing the reservoir dynamics, which allows us to
express our result in terms of a classification task. We conclude that any
physical, analog reservoir computer that is exposed to noise can only be used
to perform a polynomial amount of learning, despite the exponentially large
latent space, even with an exponential amount of post-processing.


### Exceptional Points and Stability in Nonlinear Models of Population Dynamics having $\mathcal{PT}$ symmetry
**Authors**: Alexander Felski, Flore K. Kunst

**Published Date**: 2024-11-19

**Updated Date**: 2025-04-02

**PDF Url**: [2411.12167v2](http://arxiv.org/pdf/2411.12167v2)

**Abstract**: Nonlinearity and non-Hermiticity, for example due to environmental gain-loss
processes, are a common occurrence throughout numerous areas of science and lie
at the root of many remarkable phenomena. For the latter,
parity-time-reflection ($\mathcal{PT}$) symmetry has played an eminent role in
understanding exceptional-point structures and phase transitions in these
systems. Yet their interplay has remained by-and-large unexplored. We analyze
models governed by the replicator equation of evolutionary game theory and
related Lotka-Volterra systems of population dynamics. These are foundational
nonlinear models that find widespread application and offer a broad platform
for non-Hermitian theory beyond physics. In this context we study the emergence
of exceptional points in two cases: (a) when the governing symmetry properties
are tied to global properties of the models, and, in contrast, (b) when these
symmetries emerge locally around stationary states--in which case the
connection between the linear non-Hermitian model and an underlying nonlinear
system becomes tenuous. We outline further that when the relevant symmetries
are related to global properties, the location of exceptional points in the
linearization around coexistence equilibria coincides with abrupt global
changes in the stability of the nonlinear dynamics. Exceptional points may thus
offer a new local characteristic for the understanding of these systems.
Tri-trophic models of population ecology serve as test cases for
higher-dimensional systems.


### Multidisciplinary Science in the Multimessenger Era
**Authors**: Eric Burns, Christopher L. Fryer, Ivan Agullo, Jennifer Andrews, Elias Aydi, Matthew G. Baring, Eddie Baron, Peter G. Boorman, Mohammad Ali Boroumand, Eric Borowski, Floor S. Broekgaarden, Poonam Chandra, Emmanouil Chatzopoulos, Hsin-Yu Chen, Kelly A. Chipps, Francesca Civano, Luca Comisso, Alejandro Cárdenas-Avendaño, Phong Dang, Catherine M. Deibel, Tarraneh Eftekhari, Courey Elliott, Ryan J. Foley, Christopher J. Fontes, Amy Gall, Gwendolyn R. Galleher, Gabriela Gonzalez, Fan Guo, Maria C. Babiuc Hamilton, J. Patrick Harding, Joseph Henning, Falk Herwig, William Raphael Hix, Anna Y. Q. Ho, Kelly Holley-Bockelmann, Rebekah Hounsell, C. Michelle Hui, Thomas Brian Humensky, Aimee Hungerford, Robert I. Hynes, Weidong Jin, Heather Johns, Maria Gatu Johnson, Jamie A. Kennea, Carolyn Kuranz, Gavin P. Lamb, Kristina D. Launey, Tiffany R. Lewis, Ioannis Liodakis, Daniel Livescu, Stuart Loch, Nicholas R. MacDonald, Thomas Maccarone, Lea Marcotulli, Athina Meli, Bronson Messer, M. Coleman Miller, Valarie Milton, Elias R. Most, Darin C. Mumma, Matthew R. Mumpower, Michela Negro, Eliza Neights, Peter Nugent, Dheeraj R Pasham, David Radice, Bindu Rani, Jocelyn S. Read, Rene Reifarth, Emily Reily, Lauren Rhodes, Andrea Richard, Paul M. Ricker, Christopher J. Roberts, Hendrik Schatz, Peter Shawhan, Endre Takacs, John A. Tomsick, Aaron C. Trigg, Todd Urbatsch, Nicole Vassh, V. Ashley Villar, Zorawar Wadiasingh, Gaurav Waratkar, Michael Zingale

**Published Date**: 2025-02-05

**Updated Date**: 2025-04-02

**PDF Url**: [2502.03577v2](http://arxiv.org/pdf/2502.03577v2)

**Abstract**: Astrophysical observations of the cosmos allow us to probe extreme physics
and answer foundational questions on our universe. Modern astronomy is
increasingly operating under a holistic approach, probing the same question
with multiple diagnostics including how sources vary over time, how they appear
across the electromagnetic spectrum, and through their other signatures,
including gravitational waves, neutrinos, cosmic rays, and dust on Earth.
Astrophysical observations are now reaching the point where approximate physics
models are insufficient. Key sources of interest are explosive transients,
whose understanding requires multidisciplinary studies at the intersection of
astrophysics, gravity, nuclear science, plasma physics, fluid dynamics and
turbulence, computation, particle physics, atomic, molecular, and optical
science, condensed matter and materials science, radiation transport, and high
energy density physics. This white paper provides an overview of the major
scientific advances that lay at the intersection of physics and astronomy and
are best probed through time-domain and multimessenger astrophysics, an
exploration of how multidisciplinary science can be fostered, and introductory
descriptions of the relevant scientific disciplines and key astrophysical
sources of interest.


### Deviation from $μ-τ$ Symmetry with New Approaches
**Authors**: Pralay Chakraborty, Tanmay Dev, Subhankar Roy

**Published Date**: 2024-04-22

**Updated Date**: 2025-04-02

**PDF Url**: [2404.14264v2](http://arxiv.org/pdf/2404.14264v2)

**Abstract**: We propose two new predictive neutrino mass matrix textures that deviate from
$\mu$-$\tau$ symmetry and explore their phenomenological implications. These
textures are significant due to their predictive nature and the unique approach
they introduce for breaking the $\mu$-$\tau$ symmetry. Both textures predict
six physical parameters and impose sharp constraints on $\theta_{23}$ and
$\delta$, considering both normal and inverted neutrino mass orderings. In
addition, we realize the textures in their exact form within the framework of
the seesaw mechanism, based on the $SU(2)_L \times A_4 \times Z_3$ symmetry
group.


### Representing Flow Fields with Divergence-Free Kernels for Reconstruction
**Authors**: Xingyu Ni, Jingrui Xing, Xingqiao Li, Bin Wang, Baoquan Chen

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01913v1](http://arxiv.org/pdf/2504.01913v1)

**Abstract**: Accurately reconstructing continuous flow fields from sparse or indirect
measurements remains an open challenge, as existing techniques often suffer
from oversmoothing artifacts, reliance on heterogeneous architectures, and the
computational burden of enforcing physics-informed losses in implicit neural
representations (INRs). In this paper, we introduce a novel flow field
reconstruction framework based on divergence-free kernels (DFKs), which
inherently enforce incompressibility while capturing fine structures without
relying on hierarchical or heterogeneous representations. Through qualitative
analysis and quantitative ablation studies, we identify the matrix-valued
radial basis functions derived from Wendland's $\mathcal{C}^4$ polynomial
(DFKs-Wen4) as the optimal form of analytically divergence-free approximation
for velocity fields, owing to their favorable numerical properties, including
compact support, positive definiteness, and second-order differentiablility.
Experiments across various reconstruction tasks, spanning data compression,
inpainting, super-resolution, and time-continuous flow inference, has
demonstrated that DFKs-Wen4 outperform INRs and other divergence-free
representations in both reconstruction accuracy and computational efficiency
while requiring the fewest trainable parameters.


### Advancing AI-Scientist Understanding: Making LLM Think Like a Physicist with Interpretable Reasoning
**Authors**: Yinggan Xu, Hana Kimlee, Yijia Xiao, Di Luo

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01911v1](http://arxiv.org/pdf/2504.01911v1)

**Abstract**: Large Language Models (LLMs) are playing an expanding role in physics
research by enhancing reasoning, symbolic manipulation, and numerical
computation. However, ensuring the reliability and interpretability of their
outputs remains a significant challenge. In our framework, we conceptualize the
collaboration between AI and human scientists as a dynamic interplay among
three modules: the reasoning module, the interpretation module, and the
AI-scientist interaction module. Recognizing that effective physics reasoning
demands rigorous logical consistency, quantitative precision, and deep
integration with established theoretical models, we introduce the
interpretation module to improve the understanding of AI-generated outputs,
which is not previously explored in the literature. This module comprises
multiple specialized agents, including summarizers, model builders, UI
builders, and testers, which collaboratively structure LLM outputs within a
physically grounded framework, by constructing a more interpretable science
model. A case study demonstrates that our approach enhances transparency,
facilitates validation, and strengthens AI-augmented reasoning in scientific
discovery.


### Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning
**Authors**: NVIDIA, :, Alisson Azzolini, Hannah Brandon, Prithvijit Chattopadhyay, Huayu Chen, Jinju Chu, Yin Cui, Jenna Diamond, Yifan Ding, Francesco Ferroni, Rama Govindaraju, Jinwei Gu, Siddharth Gururani, Imad El Hanafi, Zekun Hao, Jacob Huffman, Jingyi Jin, Brendan Johnson, Rizwan Khan, George Kurian, Elena Lantz, Nayeon Lee, Zhaoshuo Li, Xuan Li, Tsung-Yi Lin, Yen-Chen Lin, Ming-Yu Liu, Alice Luo, Andrew Mathau, Yun Ni, Lindsey Pavao, Wei Ping, David W. Romero, Misha Smelyanskiy, Shuran Song, Lyne Tchapmi, Andrew Z. Wang, Boxin Wang, Haoxiang Wang, Fangyin Wei, Jiashu Xu, Yao Xu, Xiaodong Yang, Zhuolin Yang, Xiaohui Zeng, Zhe Zhang

**Published Date**: 2025-03-18

**Updated Date**: 2025-04-02

**PDF Url**: [2503.15558v2](http://arxiv.org/pdf/2503.15558v2)

**Abstract**: Physical AI systems need to perceive, understand, and perform complex actions
in the physical world. In this paper, we present the Cosmos-Reason1 models that
can understand the physical world and generate appropriate embodied decisions
(e.g., next step action) in natural language through long chain-of-thought
reasoning processes. We begin by defining key capabilities for Physical AI
reasoning, with a focus on physical common sense and embodied reasoning. To
represent physical common sense, we use a hierarchical ontology that captures
fundamental knowledge about space, time, and physics. For embodied reasoning,
we rely on a two-dimensional ontology that generalizes across different
physical embodiments. Building on these capabilities, we develop two multimodal
large language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B. We curate data
and train our models in four stages: vision pre-training, general supervised
fine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL)
as the post-training. To evaluate our models, we build comprehensive benchmarks
for physical common sense and embodied reasoning according to our ontologies.
Evaluation results show that Physical AI SFT and reinforcement learning bring
significant improvements. To facilitate the development of Physical AI, we will
make our code and pre-trained models available under the NVIDIA Open Model
License at https://github.com/nvidia-cosmos/cosmos-reason1.


### The Trinity of black hole correspondences: Shadows-quasinormal modes-graybody factors and cautionary remarks
**Authors**: Davide Pedrotti, Marco Calzà

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01909v1](http://arxiv.org/pdf/2504.01909v1)

**Abstract**: Correspondences between apparently distant concepts are ubiquitous in
theoretical physics. In the context of Black Holes (BHs), Quasi-Normal Modes
(QNMs) were shown to be linked to both the shadows, in the so-called eikonal
limit, and Gray-Body Factors (GBFs), using the WKB approximation. We test the
accuracy of the quasinormal modes-graybody factors correspondence's in the
context of the Hawking spectra for static and rotating black hole
configurations, with particular attention to the superradiant regime. Our
analysis reveals the correspondence failure to accurately reproduce the Hawking
spectrum due to divergences. Furthermore, we bridge the gap between black
shadows and graybody factors by drawing a correspondence between such
quantities in the case of generic static and spherically symmetric spacetime
configurations. The shadow-GBF correspondence is tested for some case studies,
including regular BHs, and its limitations and applicability are thereof
discussed. This study opens new perspectives, by introducing a new
correspondence and remarking on the caution needed when considering these
connections.


### Physical Modeling of Saturated Common Mode Choke
**Authors**: Anna Takacs, Balazs Gyure-Garami, Adam Z. Abraham, Peter T. Benko, Norbert M. Nemes, Ferenc Simon, Bence Bernath

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01900v1](http://arxiv.org/pdf/2504.01900v1)

**Abstract**: Common mode chokes (CMCs) are conventional circuit elements performing
several tasks, including noise suppression, hindering electromagnetic
interference, providing signal integrity, and circuit protection. Much as they
are widely used, their fundamental construction and description are often
qualitative and lack an understanding of the underlying physical principles. We
discuss the behavior of a commercial CMC based on the physical description of
the superparamagnetic core and parasitic circuit elements. The results are
validated using a DC bias current and an external magnetic field, which affect
the magnetic properties. The behavior of the CMCs in the strongly non-linear
regime is also described.


## Diffusion
### Diffusion-Guided Gaussian Splatting for Large-Scale Unconstrained 3D Reconstruction and Novel View Synthesis
**Authors**: Niluthpol Chowdhury Mithun, Tuan Pham, Qiao Wang, Ben Southall, Kshitij Minhas, Bogdan Matei, Stephan Mandt, Supun Samarasekera, Rakesh Kumar

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01960v1](http://arxiv.org/pdf/2504.01960v1)

**Abstract**: Recent advancements in 3D Gaussian Splatting (3DGS) and Neural Radiance
Fields (NeRF) have achieved impressive results in real-time 3D reconstruction
and novel view synthesis. However, these methods struggle in large-scale,
unconstrained environments where sparse and uneven input coverage, transient
occlusions, appearance variability, and inconsistent camera settings lead to
degraded quality. We propose GS-Diff, a novel 3DGS framework guided by a
multi-view diffusion model to address these limitations. By generating
pseudo-observations conditioned on multi-view inputs, our method transforms
under-constrained 3D reconstruction problems into well-posed ones, enabling
robust optimization even with sparse data. GS-Diff further integrates several
enhancements, including appearance embedding, monocular depth priors, dynamic
object modeling, anisotropy regularization, and advanced rasterization
techniques, to tackle geometric and photometric challenges in real-world
settings. Experiments on four benchmarks demonstrate that GS-Diff consistently
outperforms state-of-the-art baselines by significant margins.


### Deep Representation Learning for Unsupervised Clustering of Myocardial Fiber Trajectories in Cardiac Diffusion Tensor Imaging
**Authors**: Mohini Anand, Xavier Tricoche

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01953v1](http://arxiv.org/pdf/2504.01953v1)

**Abstract**: Understanding the complex myocardial architecture is critical for diagnosing
and treating heart disease. However, existing methods often struggle to
accurately capture this intricate structure from Diffusion Tensor Imaging (DTI)
data, particularly due to the lack of ground truth labels and the ambiguous,
intertwined nature of fiber trajectories. We present a novel deep learning
framework for unsupervised clustering of myocardial fibers, providing a
data-driven approach to identifying distinct fiber bundles. We uniquely combine
a Bidirectional Long Short-Term Memory network to capture local sequential
information along fibers, with a Transformer autoencoder to learn global shape
features, with pointwise incorporation of essential anatomical context.
Clustering these representations using a density-based algorithm identifies 33
to 62 robust clusters, successfully capturing the subtle distinctions in fiber
trajectories with varying levels of granularity. Our framework offers a new,
flexible, and quantitative way to analyze myocardial structure, achieving a
level of delineation that, to our knowledge, has not been previously achieved,
with potential applications in improving surgical planning, characterizing
disease-related remodeling, and ultimately, advancing personalized cardiac
care.


### A Unified Approach to Analysis and Design of Denoising Markov Models
**Authors**: Yinuo Ren, Grant M. Rotskoff, Lexing Ying

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01938v1](http://arxiv.org/pdf/2504.01938v1)

**Abstract**: Probabilistic generative models based on measure transport, such as diffusion
and flow-based models, are often formulated in the language of Markovian
stochastic dynamics, where the choice of the underlying process impacts both
algorithmic design choices and theoretical analysis. In this paper, we aim to
establish a rigorous mathematical foundation for denoising Markov models, a
broad class of generative models that postulate a forward process transitioning
from the target distribution to a simple, easy-to-sample distribution,
alongside a backward process particularly constructed to enable efficient
sampling in the reverse direction. Leveraging deep connections with
nonequilibrium statistical mechanics and generalized Doob's $h$-transform, we
propose a minimal set of assumptions that ensure: (1) explicit construction of
the backward generator, (2) a unified variational objective directly minimizing
the measure transport discrepancy, and (3) adaptations of the classical
score-matching approach across diverse dynamics. Our framework unifies existing
formulations of continuous and discrete diffusion models, identifies the most
general form of denoising Markov models under certain regularity assumptions on
forward generators, and provides a systematic recipe for designing denoising
Markov models driven by arbitrary L\'evy-type processes. We illustrate the
versatility and practical effectiveness of our approach through novel denoising
Markov models employing geometric Brownian motion and jump processes as forward
dynamics, highlighting the framework's potential flexibility and capability in
modeling complex distributions.


### Equivariant Spherical CNNs for Accurate Fiber Orientation Distribution Estimation in Neonatal Diffusion MRI with Reduced Acquisition Time
**Authors**: Haykel Snoussi, Davood Karimi

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01925v1](http://arxiv.org/pdf/2504.01925v1)

**Abstract**: Early and accurate assessment of brain microstructure using diffusion
Magnetic Resonance Imaging (dMRI) is crucial for identifying neurodevelopmental
disorders in neonates, but remains challenging due to low signal-to-noise ratio
(SNR), motion artifacts, and ongoing myelination. In this study, we propose a
rotationally equivariant Spherical Convolutional Neural Network (sCNN)
framework tailored for neonatal dMRI. We predict the Fiber Orientation
Distribution (FOD) from multi-shell dMRI signals acquired with a reduced set of
gradient directions (30% of the full protocol), enabling faster and more
cost-effective acquisitions. We train and evaluate the performance of our sCNN
using real data from 43 neonatal dMRI datasets provided by the Developing Human
Connectome Project (dHCP). Our results demonstrate that the sCNN achieves
significantly lower mean squared error (MSE) and higher angular correlation
coefficient (ACC) compared to a Multi-Layer Perceptron (MLP) baseline,
indicating improved accuracy in FOD estimation. Furthermore, tractography
results based on the sCNN-predicted FODs show improved anatomical plausibility,
coverage, and coherence compared to those from the MLP. These findings
highlight that sCNNs, with their inherent rotational equivariance, offer a
promising approach for accurate and clinically efficient dMRI analysis, paving
the way for improved diagnostic capabilities and characterization of early
brain development.


### Multi-fidelity Parameter Estimation Using Conditional Diffusion Models
**Authors**: Caroline Tatsuoka, Minglei Yang, Dongbin Xiu, Guannan Zhang

**Published Date**: 2025-04-02

**Updated Date**: 2025-04-02

**PDF Url**: [2504.01894v1](http://arxiv.org/pdf/2504.01894v1)

**Abstract**: We present a multi-fidelity method for uncertainty quantification of
parameter estimates in complex systems, leveraging generative models trained to
sample the target conditional distribution. In the Bayesian inference setting,
traditional parameter estimation methods rely on repeated simulations of
potentially expensive forward models to determine the posterior distribution of
the parameter values, which may result in computationally intractable
workflows. Furthermore, methods such as Markov Chain Monte Carlo (MCMC)
necessitate rerunning the entire algorithm for each new data observation,
further increasing the computational burden. Hence, we propose a novel method
for efficiently obtaining posterior distributions of parameter estimates for
high-fidelity models given data observations of interest. The method first
constructs a low-fidelity, conditional generative model capable of amortized
Bayesian inference and hence rapid posterior density approximation over a
wide-range of data observations. When higher accuracy is needed for a specific
data observation, the method employs adaptive refinement of the density
approximation. It uses outputs from the low-fidelity generative model to refine
the parameter sampling space, ensuring efficient use of the computationally
expensive high-fidelity solver. Subsequently, a high-fidelity, unconditional
generative model is trained to achieve greater accuracy in the target posterior
distribution. Both low- and high- fidelity generative models enable efficient
sampling from the target posterior and do not require repeated simulation of
the high-fidelity forward model. We demonstrate the effectiveness of the
proposed method on several numerical examples, including cases with multi-modal
densities, as well as an application in plasma physics for a runaway electron
simulation model.


