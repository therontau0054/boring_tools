# Abstracts of Papers

## Physics
### MetaboNet: The Largest Publicly Available Consolidated Dataset for Type 1 Diabetes Management
**Authors**: Miriam K. Wolff, Peter Calhoun, Eleonora Maria Aiello, Yao Qin, Sam F. Royston

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11505v1](https://arxiv.org/pdf/2601.11505v1)

**Abstract**: Progress in Type 1 Diabetes (T1D) algorithm development is limited by the fragmentation and lack of standardization across existing T1D management datasets. Current datasets differ substantially in structure and are time-consuming to access and process, which impedes data integration and reduces the comparability and generalizability of algorithmic developments. This work aims to establish a unified and accessible data resource for T1D algorithm development. Multiple publicly available T1D datasets were consolidated into a unified resource, termed the MetaboNet dataset. Inclusion required the availability of both continuous glucose monitoring (CGM) data and corresponding insulin pump dosing records. Additionally, auxiliary information such as reported carbohydrate intake and physical activity was retained when present. The MetaboNet dataset comprises 3135 subjects and 1228 patient-years of overlapping CGM and insulin data, making it substantially larger than existing standalone benchmark datasets. The resource is distributed as a fully public subset available for immediate download at https://metabo-net.org/ , and with a Data Use Agreement (DUA)-restricted subset accessible through their respective application processes. For the datasets in the latter subset, processing pipelines are provided to automatically convert the data into the standardized MetaboNet format. A consolidated public dataset for T1D research is presented, and the access pathways for both its unrestricted and DUA-governed components are described. The resulting dataset covers a broad range of glycemic profiles and demographics and thus can yield more generalizable algorithmic performance than individual datasets.


### QUPID: A Partitioned Quantum Neural Network for Anomaly Detection in Smart Grid
**Authors**: Hoang M. Ngo, Tre' R. Jeter, Jung Taek Seo, My T. Thai

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11500v1](https://arxiv.org/pdf/2601.11500v1)

**Abstract**: Smart grid infrastructures have revolutionized energy distribution, but their day-to-day operations require robust anomaly detection methods to counter risks associated with cyber-physical threats and system faults potentially caused by natural disasters, equipment malfunctions, and cyber attacks. Conventional machine learning (ML) models are effective in several domains, yet they struggle to represent the complexities observed in smart grid systems. Furthermore, traditional ML models are highly susceptible to adversarial manipulations, making them increasingly unreliable for real-world deployment. Quantum ML (QML) provides a unique advantage, utilizing quantum-enhanced feature representations to model the intricacies of the high-dimensional nature of smart grid systems while demonstrating greater resilience to adversarial manipulation. In this work, we propose QUPID, a partitioned quantum neural network (PQNN) that outperforms traditional state-of-the-art ML models in anomaly detection. We extend our model to R-QUPID that even maintains its performance when including differential privacy (DP) for enhanced robustness. Moreover, our partitioning framework addresses a significant scalability problem in QML by efficiently distributing computational workloads, making quantum-enhanced anomaly detection practical in large-scale smart grid environments. Our experimental results across various scenarios exemplifies the efficacy of QUPID and R-QUPID to significantly improve anomaly detection capabilities and robustness compared to traditional ML approaches.


### Conformal Symmetry and the Thermal Effects of Acceleration in Classical Physic
**Authors**: Timothy H Boyer

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11494v1](https://arxiv.org/pdf/2601.11494v1)

**Abstract**: An accelerating Rindler frame in Minkowski spacetime acting for a finite time interval is used to carry a box of particles or waves between two relativistic inertial frames. The finite spatial extent of the box allows treatment of the equations of motion for particles or for waves, while the Rindler acceleration provides a substitute for scattering to test for thermal equilibrium. In the case of equilibrium for relativist particles, the Juttner distribution is derived. For relativistic waves, a full derivation of the Planck spectrum including zero-point radiation is obtained within classical theory. For relativistic waves, relativistic behavior and conformal symmetry are crucial. It is emphasized that the classical two-point correlation function for classical zero-point radiation depends upon the geodesic separation between the spacetime points and is independent of the coordinate system choice. The classical point of view here does not give any support for the idea that a system in uniform acceleration through classical zero-point radiation finds a thermal system.


### Transversal Clifford-Hierarchy Gates via Non-Abelian Surface Codes
**Authors**: Alison Warman, Sakura Schafer-Nameki

**Published Date**: 2025-12-15

**Updated Date**: 2026-01-16

**PDF Url**: [2512.13777v2](https://arxiv.org/pdf/2512.13777v2)

**Abstract**: We present an entirely 2D transversal realization of phase gates at any level of the Clifford hierarchy, and beyond, using non-Abelian surface codes. Our construction encodes a logical qubit in the quantum double $D(G)$ of a non-Abelian group $G$ on a triangular spatial patch. The logical gate is implemented transversally by stacking on the spatial region a symmetry-protected topological (SPT) phase specified by a group 2-cocycle. The Bravyi--König theorem limits the unitary gates implementable by constant-depth quantum circuits on Pauli stabilizer codes in $D$ dimensions to the $D$-th level of the Clifford hierarchy. We bypass this limitation, by constructing transversal unitary gates at arbitrary levels of the Clifford hierarchy purely in 2D, without sacrificing locality or fault tolerance, at the cost of using the quantum double of a non-Abelian group $G$. Specifically, for $G = D_{4N}$, the dihedral group of order $8N$, we realize the phase gate $T^{1/N} = \mathrm{diag}(1, e^{iπ/(4N)})$ in the logical $\overline{Z}$ basis. In this context we propose a non-abelian stabilizer group formalism, which we work out for dihedral groups. For $8N = 2^n$, the logical gate lies at the $n$-th level of the Clifford hierarchy and, importantly, has a qubit-only realization: we show that it can be constructed in terms of Clifford-hierarchy stabilizers for a code with $n$ physical qubits on each edge of the lattice. We also discuss code-switching to the $\mathbb{Z}_2 \times \mathbb{Z}_2$ and $\mathbb{Z}_2$ surface-codes, which can be utilized for the quantum error correction in this setup.


### Learning Semantic-Geometric Task Graph-Representations from Human Demonstrations
**Authors**: Franziska Herbert, Vignesh Prasad, Han Liu, Dorothea Koert, Georgia Chalvatzaki

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11460v1](https://arxiv.org/pdf/2601.11460v1)

**Abstract**: Learning structured task representations from human demonstrations is essential for understanding long-horizon manipulation behaviors, particularly in bimanual settings where action ordering, object involvement, and interaction geometry can vary significantly. A key challenge lies in jointly capturing the discrete semantic structure of tasks and the temporal evolution of object-centric geometric relations in a form that supports reasoning over task progression. In this work, we introduce a semantic-geometric task graph-representation that encodes object identities, inter-object relations, and their temporal geometric evolution from human demonstrations. Building on this formulation, we propose a learning framework that combines a Message Passing Neural Network (MPNN) encoder with a Transformer-based decoder, decoupling scene representation learning from action-conditioned reasoning about task progression. The encoder operates solely on temporal scene graphs to learn structured representations, while the decoder conditions on action-context to predict future action sequences, associated objects, and object motions over extended time horizons. Through extensive evaluation on human demonstration datasets, we show that semantic-geometric task graph-representations are particularly beneficial for tasks with high action and object variability, where simpler sequence-based models struggle to capture task progression. Finally, we demonstrate that task graph representations can be transferred to a physical bimanual robot and used for online action selection, highlighting their potential as reusable task abstractions for downstream decision-making in manipulation systems.


### The power-spectrum tensor in steady-state systems and its role in quantum friction
**Authors**: F. Intravaia, K. Busch

**Published Date**: 2024-02-24

**Updated Date**: 2026-01-16

**PDF Url**: [2402.15777v2](https://arxiv.org/pdf/2402.15777v2)

**Abstract**: We derive and classify properties of the power-spectrum tensor for systems in general steady-states, including stationary states not necessarily corresponding to equilibrium configurations. We establish a rigorous connection between the power-spectrum tensor and other quantities that characterize these systems, providing a systematic comparison with their equilibrium counterparts. As a physical application, we investigate the problem of quantum friction, describing the contactless quantum-electrodynamic drag acting on a particle moving in close proximity to material bodies at zero temperature. Specifically, we demonstrate how including additional information about the system's physical properties facilitates the derivation of more precise constraints on the power spectrum and its functional dependencies.


### Principles of Client Enrichment in Multicomponent Biomolecular Condensates
**Authors**: Aishani Ghosal, Nicholas E. Lea, Lindsay B. Case, Trevor GrandPre

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11450v1](https://arxiv.org/pdf/2601.11450v1)

**Abstract**: Biomolecular condensates are commonly organized by a small number of scaffold molecules that drive phase separation together with client molecules that do not condense on their own but become selectively recruited into the dense phase. A central open question is how client recruitment feeds back on scaffold interactions to determine condensate composition. Here we address this problem in a reconstituted focal adhesion system composed of focal adhesion kinase (FAK) and phosphorylated p130Cas (Cas) as scaffolds and the adaptor protein paxillin (PXN) as a client. We show that both FAK phosphorylation and PXN recruitment produce a common compositional response in which FAK becomes enriched while Cas is depleted within the condensate. To interpret these observations, we develop two complementary theoretical descriptions. First, within a two-component Flory-Huggins framework, we show that phosphorylation can be captured by either strengthening heterotypic FAK-Cas interactions or increasing the effective number of interaction-relevant segments on FAK, both of which bias partitioning toward FAK-rich condensates. Second, we introduce a minimal three-component Flory-Huggins theory without an explicit solvent and map it onto an effective two-component description, demonstrating that client recruitment renormalizes homotypic and heterotypic scaffold interactions. Analytical predictions for the location of the critical point are tested in reconstituted multicomponent systems through PXN addition, showing that client recruitment alone tunes proximity to criticality and reshapes condensate composition. Together, our results reveal distinct yet convergent physical routes by which post-translational modification and client recruitment control scaffold composition in multicomponent condensates.


### Entropy Production in Machine Learning Under Fokker-Planck Probability Flow
**Authors**: Lennon Shikhman

**Published Date**: 2026-01-02

**Updated Date**: 2026-01-16

**PDF Url**: [2601.00554v3](https://arxiv.org/pdf/2601.00554v3)

**Abstract**: Machine learning models deployed in nonstationary environments inevitably experience performance degradation due to data drift. While numerous drift detection heuristics exist, most lack a dynamical interpretation and provide limited guidance on how retraining decisions should be balanced against operational cost. In this work, we propose an entropy-based retraining framework grounded in nonequilibrium statistical physics. Interpreting drift as probability flow governed by a Fokker-Planck equation, we quantify model-data mismatch using relative entropy and show that its time derivative admits an entropy-balance decomposition featuring a nonnegative entropy production term driven by probability currents. Guided by this theory, we implement an entropy-triggered retraining policy using an exponentially weighted moving-average (EWMA) control statistic applied to a streaming kernel density estimator of the Kullback-Leibler divergence. We evaluate this approach across multiple nonstationary data streams. In synthetic, financial, and web-traffic domains, entropy-based retraining achieves predictive performance comparable to frequent retraining while reducing retraining frequency by one to two orders of magnitude. However, in a challenging biomedical ECG setting, the entropy-based trigger underperforms the maximum-frequency baseline, highlighting limitations of feature-space entropy monitoring under complex label-conditional drift.


### Simulation of Self-Assembled Monolayers of Polyalanine $α$-Helices: Development and Application of an Effective Potential for Film Structure Predictions
**Authors**: Hadis Ghodrati Saeini, Kevin Preis, Thi Ngoc Ha, Christoph Tegenkamp, Sibylle Gemming, Jeffrey Kelling, Florian Günther

**Published Date**: 2025-11-03

**Updated Date**: 2026-01-16

**PDF Url**: [2511.01596v2](https://arxiv.org/pdf/2511.01596v2)

**Abstract**: Self-assembled monolayers of polyalanine $α$-helices exhibit distinct structural phases with implications for chiral-induced spin selectivity. We combine scanning tunneling microscopy and theoretical modeling to reveal how chiral composition governs supramolecular organization. Enantiopure systems form hexagonal lattices, while racemic mixtures organize into rectangular phases with stripe-like features. Our interaction potentials derived from density-functional based tight binding calculations show that opposite-handed helix pairs exhibit stronger binding and closer packing, explaining the denser racemic structures. Crucially, we demonstrate that the observed STM contrast arises from anti-parallel alignment of opposite-handed helices rather than physical height variations. These findings establish fundamental structure-property relationships for designing peptide-based spintronic materials.


### Deterministic Theories
**Authors**: Hans Halvorson, JB Manchak, James Owen Weatherall

**Published Date**: 2025-03-07

**Updated Date**: 2026-01-16

**PDF Url**: [2503.05681v2](https://arxiv.org/pdf/2503.05681v2)

**Abstract**: Determinism is (roughly) the thesis that the past determines the future. But efforts to define it precisely have exposed deep methodological disagreements. Standard possible-worlds formulations of determinism presuppose an "agreement" relation between worlds,but this relation can be understood in multiple ways, none of which is particularly clear. We critically examine the proliferation of definitions of determinism in the recent literature, arguing that these definitions fail to deliver clear verdicts about actual scientific theories. We advocate a return to a formal approach, in the logical tradition of Carnap, that treats determinism as a property of scientific theories, rather than an elusive metaphysical doctrine.
  We highlight two key distinctions: (1) the difference between qualitative and "full" determinism, as emphasized in recent discussions of physics and metaphysics, and (2) the distinction between weak and strong formal conditions on the uniqueness of world extensions. We argue that defining determinism in terms of metaphysical notions such as haecceities is unhelpful, whereas rigorous formal criteria such as Belot's D1 and D3 offer a tractable and scientifically relevant account. By clarifying what it means for a theory to be deterministic, we set the stage for a fruitful interaction between physics and metaphysics.


## Diffusion
### When Are Two Scores Better Than One? Investigating Ensembles of Diffusion Models
**Authors**: Raphaël Razafindralambo, Rémy Sun, Frédéric Precioso, Damien Garreau, Pierre-Alexandre Mattei

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11444v1](https://arxiv.org/pdf/2601.11444v1)

**Abstract**: Diffusion models now generate high-quality, diverse samples, with an increasing focus on more powerful models. Although ensembling is a well-known way to improve supervised models, its application to unconditional score-based diffusion models remains largely unexplored. In this work we investigate whether it provides tangible benefits for generative modelling. We find that while ensembling the scores generally improves the score-matching loss and model likelihood, it fails to consistently enhance perceptual quality metrics such as FID on image datasets. We confirm this observation across a breadth of aggregation rules using Deep Ensembles, Monte Carlo Dropout, on CIFAR-10 and FFHQ. We attempt to explain this discrepancy by investigating possible explanations, such as the link between score estimation and image quality. We also look into tabular data through random forests, and find that one aggregation strategy outperforms the others. Finally, we provide theoretical insights into the summing of score models, which shed light not only on ensembling but also on several model composition techniques (e.g. guidance).


### GenDA: Generative Data Assimilation on Complex Urban Areas via Classifier-Free Diffusion Guidance
**Authors**: Francisco Giral, Álvaro Manzano, Ignacio Gómez, Ricardo Vinuesa, Soledad Le Clainche

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11440v1](https://arxiv.org/pdf/2601.11440v1)

**Abstract**: Urban wind flow reconstruction is essential for assessing air quality, heat dispersion, and pedestrian comfort, yet remains challenging when only sparse sensor data are available. We propose GenDA, a generative data assimilation framework that reconstructs high-resolution wind fields on unstructured meshes from limited observations. The model employs a multiscale graph-based diffusion architecture trained on computational fluid dynamics (CFD) simulations and interprets classifier-free guidance as a learned posterior reconstruction mechanism: the unconditional branch learns a geometry-aware flow prior, while the sensor-conditioned branch injects observational constraints during sampling. This formulation enables obstacle-aware reconstruction and generalization across unseen geometries, wind directions, and mesh resolutions without retraining. We consider both sparse fixed sensors and trajectory-based observations using the same reconstruction procedure. When evaluated against supervised graph neural network (GNN) baselines and classical reduced-order data assimilation methods, GenDA reduces the relative root-mean-square error (RRMSE) by 25-57% and increases the structural similarity index (SSIM) by 23-33% across the tested meshes. Experiments are conducted on Reynolds-averaged Navier-Stokes (RANS) simulations of a real urban neighbourhood in Bristol, United Kingdom, at a characteristic Reynolds number of $\mathrm{Re}\approx2\times10^{7}$, featuring complex building geometry and irregular terrain. The proposed framework provides a scalable path toward generative, geometry-aware data assimilation for environmental monitoring in complex domains.


### Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning
**Authors**: Ahmed Rashwan, Keith Briggs, Chris Budd, Lisa Kreusser

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11401v1](https://arxiv.org/pdf/2601.11401v1)

**Abstract**: Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constructions can be difficult to estimate and ill-behaved in infinite-horizon settings. We introduce the Diffusion Value Function (DVF), a factored value function for GMDPs that assigns to each agent a value component by diffusing rewards over the influence graph with temporal discounting and spatial attenuation. We show that DVF is well-defined, admits a Bellman fixed point, and decomposes the global discounted value via an averaging property. DVF can be used as a drop-in critic in standard RL algorithms and estimated scalably with graph neural networks. Building on DVF, we propose Diffusion A2C (DA2C) and a sparse message-passing actor, Learned DropEdge GNN (LD-GNN), for learning decentralised algorithms under communication costs. Across the firefighting benchmark and three distributed computation tasks (vector graph colouring and two transmit power optimisation problems), DA2C consistently outperforms local and global critic baselines, improving average reward by up to 11%.


### Unlocking the Potentials of Retrieval-Augmented Generation for Diffusion Language Models
**Authors**: Chuanyue Yu, Jiahui Wang, Yuhan Li, Heng Chang, Ge Lan, Qingyun Sun, Jia Li, Jianxin Li, Ziwei Zhang

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11342v1](https://arxiv.org/pdf/2601.11342v1)

**Abstract**: Diffusion Language Models (DLMs) have recently demonstrated remarkable capabilities in natural language processing tasks. However, the potential of Retrieval-Augmented Generation (RAG), which shows great successes for enhancing large language models (LLMs), has not been well explored, due to the fundamental difference between LLM and DLM decoding. To fill this critical gap, we systematically test the performance of DLMs within the RAG framework. Our findings reveal that DLMs coupled with RAG show promising potentials with stronger dependency on contextual information, but suffer from limited generation precision. We identify a key underlying issue: Response Semantic Drift (RSD), where the generated answer progressively deviates from the query's original semantics, leading to low precision content. We trace this problem to the denoising strategies in DLMs, which fail to maintain semantic alignment with the query throughout the iterative denoising process. To address this, we propose Semantic-Preserving REtrieval-Augmented Diffusion (SPREAD), a novel framework that introduces a query-relevance-guided denoising strategy. By actively guiding the denoising trajectory, SPREAD ensures the generation remains anchored to the query's semantics and effectively suppresses drift. Experimental results demonstrate that SPREAD significantly enhances the precision and effectively mitigates RSD of generated answers within the RAG framework.


### X-Distill: Cross-Architecture Vision Distillation for Visuomotor Learning
**Authors**: Maanping Shao, Feihong Zhang, Gu Zhang, Baiye Cheng, Zhengrong Xue, Huazhe Xu

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11269v1](https://arxiv.org/pdf/2601.11269v1)

**Abstract**: Visuomotor policies often leverage large pre-trained Vision Transformers (ViTs) for their powerful generalization capabilities. However, their significant data requirements present a major challenge in the data-scarce context of most robotic learning settings, where compact CNNs with strong inductive biases can be more easily optimized. To address this trade-off, we introduce X-Distill, a simple yet highly effective method that synergizes the strengths of both architectures. Our approach involves an offline, cross-architecture knowledge distillation, transferring the rich visual representations of a large, frozen DINOv2 teacher to a compact ResNet-18 student on the general-purpose ImageNet dataset. This distilled encoder, now endowed with powerful visual priors, is then jointly fine-tuned with a diffusion policy head on the target manipulation tasks. Extensive experiments on $34$ simulated benchmarks and $5$ challenging real-world tasks demonstrate that our method consistently outperforms policies equipped with from-scratch ResNet or fine-tuned DINOv2 encoders. Notably, X-Distill also surpasses 3D encoders that utilize privileged point cloud observations or much larger Vision-Language Models. Our work highlights the efficacy of a simple, well-founded distillation strategy for achieving state-of-the-art performance in data-efficient robotic manipulation.


## Quantitative Finance
### KANHedge: Efficient Hedging of High-Dimensional Options Using Kolmogorov-Arnold Network-Based BSDE Solver
**Authors**: Rushikesh Handal, Masanori Hirano

**Published Date**: 2026-01-16

**Updated Date**: 2026-01-16

**PDF Url**: [2601.11097v1](https://arxiv.org/pdf/2601.11097v1)

**Abstract**: High-dimensional option pricing and hedging present significant challenges in quantitative finance, where traditional PDE-based methods struggle with the curse of dimensionality. The BSDE framework offers a computationally efficient alternative to PDE-based methods, and recently proposed deep BSDE solvers, generally utilizing conventional Multi-Layer Perceptrons (MLPs), build upon this framework to provide a scalable alternative to numerical BSDE solvers. In this research, we show that although such MLP-based deep BSDEs demonstrate promising results in option pricing, there remains room for improvement regarding hedging performance. To address this issue, we introduce KANHedge, a novel BSDE-based hedger that leverages Kolmogorov-Arnold Networks (KANs) within the BSDE framework. Unlike conventional MLP approaches that use fixed activation functions, KANs employ learnable B-spline activation functions that provide enhanced function approximation capabilities for continuous derivatives. We comprehensively evaluate KANHedge on both European and American basket options across multiple dimensions and market conditions. Our experimental results demonstrate that while KANHedge and MLP achieve comparable pricing accuracy, KANHedge provides improved hedging performance. Specifically, KANHedge achieves considerable reductions in hedging cost metrics, demonstrating enhanced risk control capabilities.


