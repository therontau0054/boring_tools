# Abstracts of Papers

## Physics
### Learning Physically Consistent Lagrangian Control Models Without Acceleration Measurements
**Authors**: Ibrahim Laiche, Mokrane Boudaoud, Patrick Gallinari, Pascal Morin

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03035v1](https://arxiv.org/pdf/2512.03035v1)

**Abstract**: This article investigates the modeling and control of Lagrangian systems involving non-conservative forces using a hybrid method that does not require acceleration calculations. It focuses in particular on the derivation and identification of physically consistent models, which are essential for model-based control synthesis. Lagrangian or Hamiltonian neural networks provide useful structural guarantees but the learning of such models often leads to inconsistent models, especially on real physical systems where training data are limited, partial and noisy. Motivated by this observation and the objective to exploit these models for model-based nonlinear control, a learning algorithm relying on an original loss function is proposed to improve the physical consistency of Lagrangian systems. A comparative analysis of different learning-based modeling approaches with the proposed solution shows significant improvements in terms of physical consistency of the learned models, on both simulated and experimental systems. The model's consistency is then exploited to demonstrate, on an experimental benchmark, the practical relevance of the proposed methodology for feedback linearization and energy-based control techniques.


### The Gamma-disordered Aztec diamond
**Authors**: Maurice Duits, Roger Van Peski

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03033v1](https://arxiv.org/pdf/2512.03033v1)

**Abstract**: We introduce a multi-parameter family of random edge weights on the Aztec diamond graph, given by certain Gamma variables, and prove several results about the corresponding random dimer measures.
  Firstly, we show there is no phase transition at the level of the free energy. This provides rigorous backing for the physics predictions of Zeng-Leath-Hwa and later works that dimer models with random weights are in the glassy `super-rough' phase at all temperatures with no phase transition.
  Secondly, we show that the random dimer covers themselves enjoy exact distributional equalities of certain marginals with path locations in new `hybrid' integrable polymers. These reduce to the stationary log-Gamma, strict-weak, and Beta polymer in random environment in certain cases, allowing transfer of known results from integrable polymers to dimers with random weights. As an example application, we prove that the turning points at the boundaries of the Aztec diamond exhibit fluctuations of order $n^{2/3}$, in contrast to the $n^{1/2}$ fluctuations for deterministic weights.
  Underlying all these is a key integrability property of the weights: they are the unique family for which independence is preserved under the shuffling algorithm.


### The Hilbert space of gauge theories: group averaging and the quantization of Jackiw-Teitelboim gravity
**Authors**: Elba Alonso-Monsalve

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03030v1](https://arxiv.org/pdf/2512.03030v1)

**Abstract**: When the gauge group of a theory has infinite volume, defining the inner product on physical states becomes subtle. This is the case for gravity, even in exactly solvable models such as minisuperspace or low-dimensional theories: the physical states do not inherit an inner product in a straightforward manner, and different quantization procedures yield a priori inequivalent prescriptions. This is one of the main challenges when constructing gravitational Hilbert spaces. In this paper we study a quantization procedure known as group averaging, which is a special case of the BRST/BV formalism and has gained popularity as a promising connection between Dirac quantization and gravitational path integrals. We identify a large class of theories for which group averaging is ill-defined due to isometry groups with infinite volume, which includes Jackiw-Teitelboim gravity. We propose a modification of group averaging to renormalize these infinite volumes and use it to quantize Jackiw-Teitelboim gravity with a positive cosmological constant in closed universes. The resulting Hilbert space naturally splits into infinite-dimensional superselection sectors and has a positive-definite inner product. This is the first complete Dirac quantization of this theory, as we are able to capture all the physical states for the first time.


### Combinatorial foundations for solvable chaotic local Euclidean quantum circuits in two dimensions
**Authors**: Fredy Yip

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03029v1](https://arxiv.org/pdf/2512.03029v1)

**Abstract**: We investigate a graph-theoretic problem motivated by questions in quantum computing concerning the propagation of information in quantum circuits. A graph $G$ is said to be a bounded extension of its subgraph $L$ if they share the same vertex set, and the graph distance $d_L(u, v)$ is uniformly bounded for edges $uv\in G$. Given vertices $u, v$ in $G$ and an integer $k$, the geodesic slice $S(u, v, k)$ denotes the subset of vertices $w$ lying on a geodesic in $G$ between $u$ and $v$ with $d_G(u, w) = k$. We say that $G$ has bounded geodesic slices if $|S(u, v, k)|$ is uniformly bounded over all $u, v, k$. We call a graph $L$ geodesically directable if it has a bounded extension $G$ with bounded geodesic slices.
  Contrary to previous expectations, we prove that $\mathbb{Z}^2$ is geodesically directable. Physically, this provides a setting in which one could devise exactly-solvable chaotic local quantum circuits with non-trivial correlation patterns on 2D Euclidean lattices. In fact, we show that any bounded extension of $\mathbb{Z}^2$ is geodesically directable. This further implies that all two-dimensional regular tilings are geodesically directable.


### SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control
**Authors**: Yuxuan Mu, Ziyu Zhang, Yi Shi, Minami Matsumoto, Kotaro Imamura, Guy Tevet, Chuan Guo, Michael Taylor, Chang Shu, Pengcheng Xi, Xue Bin Peng

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03028v1](https://arxiv.org/pdf/2512.03028v1)

**Abstract**: Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at https://youtu.be/ravlZJteS20


### Theory of coherent interaction-free detection of pulses
**Authors**: John J. McCord, Shruti Dogra, Gheorghe Sorin Paraoanu

**Published Date**: 2023-07-11

**Updated Date**: 2025-12-02

**PDF Url**: [2307.05214v2](https://arxiv.org/pdf/2307.05214v2)

**Abstract**: Quantum physics allows an object to be detected even in the absence of photon absorption by the use of so-called interaction-free measurements. We provide a formulation of this protocol using a three-level system, where the object to be detected is a pulse coupled resonantly to the second transition. In the original formulation of interaction-free measurements, the absorption is associated with a projection operator onto the third state. We perform an in-depth analytical and numerical analysis of the coherent protocol, where coherent interaction between the object and the detector replaces the projective operators, resulting in higher detection efficiencies. We provide approximate asymptotic analytical results to support this finding. We find that our protocol reaches the Heisenberg limit when evaluating the Fisher information at small strengths of the pulses we aim to detect -- in contrast to the projective protocol that can only reach the standard quantum limit. We also demonstrate that the coherent protocol remains remarkably robust under errors such as pulse-rotation phases and strengths, the effects of relaxation rates and detunings, as well as different thermalized initial states.


### Trade-off between complexity and energy in quantum phase estimation
**Authors**: Yukuan Tao, Madalin Guta, Gerardo Adesso

**Published Date**: 2025-11-07

**Updated Date**: 2025-12-02

**PDF Url**: [2511.05458v2](https://arxiv.org/pdf/2511.05458v2)

**Abstract**: Driven by the desire to make quantum technologies more sustainable, in this work we introduce a framework for analysing the interplay between complexity and energy cost of quantum procedures. In particular, we study a sequential quantum phase estimation protocol, where a phase of physical significance is encoded in a quantum channel. The channel is applied to a probe state repetitively until the probe is measured and the outcome leads to an estimate on the phase. We establish a trade-off relation between the implementation energy of the channel and the number of times it is applied (complexity), while reaching a desired estimation precision. The principles of our analysis can be adapted to optimise the energy consumption in other quantum protocols and devices.


### IOTA Experiment for Proton Pulse Compression at Extreme Space-Charge
**Authors**: Benjamin Simons, Nilanjan Banerjee, Jeffrey Eldred, Vladimir Shiltsev

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03002v1](https://arxiv.org/pdf/2512.03002v1)

**Abstract**: The longitudinal compression of high-intensity, space-charge-dominated proton bunches is a critical requirement for future proton-driven muon colliders. We propose a proton bunch compression experiment at the Integrable Optics Test Accelerator (IOTA) storage ring at Fermilab to investigate optimal radio-frequency (RF) cavity parameters and lattice configurations. IOTA is a compact, fixed-energy storage ring dedicated to beam physics Research and Development and capable of circulating a 2.5 MeV proton beam under extreme space-charge conditions. Using the ImpactX code with its 3D space-charge solver, simulations indicate that the bunch length can be rapidly reduced by at least a factor of two without appreciable degradation of transverse beam quality--even in the strong space-charge regime. However, longitudinal defocusing due to the space-charge remains a significant challenge in short-pulsed intense proton bunches, and the optimization of compression under these conditions is discussed.


### Characterisation of the LAPPD, a large area microchannel-plate PMT
**Authors**: S. Korpar, R. Dolenec, F. Grijalva, A. Lozar, A. Kodrič, P. Križan, S. Parashari, R. Pestotnik, A. Seljak, D. Žontar

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.02990v1](https://arxiv.org/pdf/2512.02990v1)

**Abstract**: We present a comprehensive characterization of the LAPPD Gen-II, a large-area microchannel-plate photomultiplier tube (MCP-PMT) equipped with a capacitively coupled sensing (readout) electrode. Two detector variants with different geometries and materials were investigated using a picosecond pulsed laser system. We measured the single-photon timing response and spatial charge distribution on segmented readout electrodes. The prompt timing peak exhibits a resolution of approximately 30 ps, with the overall timing structure explained by photoelectron propagation and back-scattering effects from the MCP input surface. We developed analytical models that describe the propagation of photoelectrons and the induced charge spread on the sensing electrodes, including secondary electron backscattering from the resistive anode. The model accurately reproduces the measured device properties and enables performance extrapolations for various detector geometries and dielectric properties. These results provide a predictive framework for optimizing MCP-PMTs for timing- and imaging-critical applications such as RICH detectors in high-energy physics and TOF-PET systems for medical imaging.


### Flexible Gravitational-Wave Parameter Estimation with Transformers
**Authors**: Annalena Kofler, Maximilian Dax, Stephen R. Green, Jonas Wildberger, Nihar Gupte, Jakob H. Macke, Jonathan Gair, Alessandra Buonanno, Bernhard Schölkopf

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.02968v1](https://arxiv.org/pdf/2512.02968v1)

**Abstract**: Gravitational-wave data analysis relies on accurate and efficient methods to extract physical information from noisy detector signals, yet the increasing rate and complexity of observations represent a growing challenge. Deep learning provides a powerful alternative to traditional inference, but existing neural models typically lack the flexibility to handle variations in data analysis settings. Such variations accommodate imperfect observations or are required for specialized tests, and could include changes in detector configurations, overall frequency ranges, or localized cuts. We introduce a flexible transformer-based architecture paired with a training strategy that enables adaptation to diverse analysis settings at inference time. Applied to parameter estimation, we demonstrate that a single flexible model -- called Dingo-T1 -- can (i) analyze 48 gravitational-wave events from the third LIGO-Virgo-KAGRA Observing Run under a wide range of analysis configurations, (ii) enable systematic studies of how detector and frequency configurations impact inferred posteriors, and (iii) perform inspiral-merger-ringdown consistency tests probing general relativity. Dingo-T1 also improves median sample efficiency on real events from a baseline of 1.4% to 4.2%. Our approach thus demonstrates flexible and scalable inference with a principled framework for handling missing or incomplete data -- key capabilities for current and next-generation observatories.


## Diffusion
### Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation
**Authors**: Zeqi Xiao, Yiwei Zhao, Lingxiao Li, Yushi Lan, Yu Ning, Rahul Garg, Roshni Cooper, Mohammad H. Taghavi, Xingang Pan

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03040v1](https://arxiv.org/pdf/2512.03040v1)

**Abstract**: We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning. Both tasks use video-only inputs, without auxiliary modalities such as depth or poses. With simple yet effective design choices in the framework and data curation, Video4Spatial demonstrates strong spatial understanding from video context: it plans navigation and grounds target objects end-to-end, follows camera-pose instructions while maintaining spatial consistency, and generalizes to long contexts and out-of-domain environments. Taken together, these results advance video generative models toward general visuospatial reasoning.


### In-Context Sync-LoRA for Portrait Video Editing
**Authors**: Sagi Polaczek, Or Patashnik, Ali Mahdavi-Amiri, Daniel Cohen-Or

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.03013v1](https://arxiv.org/pdf/2512.03013v1)

**Abstract**: Editing portrait videos is a challenging task that requires flexible yet precise control over a wide range of modifications, such as appearance changes, expression edits, or the addition of objects. The key difficulty lies in preserving the subject's original temporal behavior, demanding that every edited frame remains precisely synchronized with the corresponding source frame. We present Sync-LoRA, a method for editing portrait videos that achieves high-quality visual modifications while maintaining frame-accurate synchronization and identity consistency. Our approach uses an image-to-video diffusion model, where the edit is defined by modifying the first frame and then propagated to the entire sequence. To enable accurate synchronization, we train an in-context LoRA using paired videos that depict identical motion trajectories but differ in appearance. These pairs are automatically generated and curated through a synchronization-based filtering process that selects only the most temporally aligned examples for training. This training setup teaches the model to combine motion cues from the source video with the visual changes introduced in the edited first frame. Trained on a compact, highly curated set of synchronized human portraits, Sync-LoRA generalizes to unseen identities and diverse edits (e.g., modifying appearance, adding objects, or changing backgrounds), robustly handling variations in pose and expression. Our results demonstrate high visual fidelity and strong temporal coherence, achieving a robust balance between edit fidelity and precise motion preservation.


### Instruction-based Time Series Editing
**Authors**: Jiaxing Qiu, Dongliang Guo, Brynne Sullivan, Teague R. Henry, Tom Hartvigsen

**Published Date**: 2025-08-02

**Updated Date**: 2025-12-02

**PDF Url**: [2508.01504v2](https://arxiv.org/pdf/2508.01504v2)

**Abstract**: In time series editing, we aim to modify some properties of a given time series without altering others. For example, when analyzing a hospital patient's blood pressure, we may add a sudden early drop and observe how it impacts their future while preserving other conditions. Existing diffusion-based editors rely on rigid, predefined attribute vectors as conditions and produce all-or-nothing edits through sampling. This attribute- and sampling-based approach limits flexibility in condition format and lacks customizable control over editing strength. To overcome these limitations, we introduce Instruction-based Time Series Editing, where users specify intended edits using natural language. This allows users to express a wider range of edits in a more accessible format. We then introduce InstructTime, the first instruction-based time series editor. InstructTime takes in time series and instructions, embeds them into a shared multi-modal representation space, then decodes their embeddings to generate edited time series. By learning a structured multi-modal representation space, we can easily interpolate between embeddings to achieve varying degrees of edit. To handle local and global edits together, we propose multi-resolution encoders. In our experiments, we use synthetic and real datasets and find that InstructTime is a state-of-the-art time series editor: InstructTime achieves high-quality edits with controllable strength, can generalize to unseen instructions, and can be easily adapted to unseen conditions through few-shot learning.


### Forecasting in Offline Reinforcement Learning for Non-stationary Environments
**Authors**: Suzan Ece Ada, Georg Martius, Emre Ugur, Erhan Oztop

**Published Date**: 2025-12-01

**Updated Date**: 2025-12-02

**PDF Url**: [2512.01987v2](https://arxiv.org/pdf/2512.01987v2)

**Abstract**: Offline Reinforcement Learning (RL) provides a promising avenue for training policies from pre-collected datasets when gathering additional interaction data is infeasible. However, existing offline RL methods often assume stationarity or only consider synthetic perturbations at test time, assumptions that often fail in real-world scenarios characterized by abrupt, time-varying offsets. These offsets can lead to partial observability, causing agents to misperceive their true state and degrade performance. To overcome this challenge, we introduce Forecasting in Non-stationary Offline RL (FORL), a framework that unifies (i) conditional diffusion-based candidate state generation, trained without presupposing any specific pattern of future non-stationarity, and (ii) zero-shot time-series foundation models. FORL targets environments prone to unexpected, potentially non-Markovian offsets, requiring robust agent performance from the onset of each episode. Empirical evaluations on offline RL benchmarks, augmented with real-world time-series data to simulate realistic non-stationarity, demonstrate that FORL consistently improves performance compared to competitive baselines. By integrating zero-shot forecasting with the agent's experience, we aim to bridge the gap between offline RL and the complexities of real-world, non-stationary environments.


## Quantitative Finance
### Leveraging Large Language Models to Bridge On-chain and Off-chain Transparency in Stablecoins
**Authors**: Yuexin Xiang, Yuchen Lei, SM Mahir Shazeed Rish, Yuanzhe Zhang, Qin Wang, Tsz Hon Yuen, Jiangshan Yu

**Published Date**: 2025-12-02

**Updated Date**: 2025-12-02

**PDF Url**: [2512.02418v1](https://arxiv.org/pdf/2512.02418v1)

**Abstract**: Stablecoins such as USDT and USDC aspire to peg stability by coupling issuance controls with reserve attestations. In practice, however, the transparency is split across two worlds: verifiable on-chain traces and off-chain disclosures locked in unstructured text that are unconnected. We introduce a large language model (LLM)-based automated framework that bridges these two dimensions by aligning on-chain issuance data with off-chain disclosure statements. First, we propose an integrative framework using LLMs to capture and analyze on- and off-chain data through document parsing and semantic alignment, extracting key financial indicators from issuer attestations and mapping them to corresponding on-chain metrics. Second, we integrate multi-chain issuance records and disclosure documents within a model context protocol (MCP) framework that standardizes LLMs access to both quantitative market data and qualitative disclosure narratives. This framework enables unified retrieval and contextual alignment across heterogeneous stablecoin information sources and facilitates consistent analysis. Third, we demonstrate the capability of LLMs to operate across heterogeneous data modalities in blockchain analytics, quantifying discrepancies between reported and observed circulation and examining their implications for cross-chain transparency and price dynamics. Our findings reveal systematic gaps between disclosed and verifiable data, showing that LLM-assisted analysis enhances cross-modal transparency and supports automated, data-driven auditing in decentralized finance (DeFi).


