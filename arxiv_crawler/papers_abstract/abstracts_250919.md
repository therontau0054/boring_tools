# Abstracts of Papers

## Physics
### A mathematical model for Nordic skiing
**Authors**: Jane Shaw MacDonald, Rafael Ordoñez Cardales, John M. Stockie

**Published Date**: 2024-09-17

**Updated Date**: 2025-09-18

**PDF Url**: [2410.02767v2](http://arxiv.org/pdf/2410.02767v2)

**Abstract**: Nordic skiing provides fascinating opportunities for mathematical modelling
studies that exploit methods and insights from physics, applied mathematics,
data analysis, scientific computing and sports science. A typical ski course
winds over varied terrain with frequent changes in elevation and direction, and
so its geometry is naturally described by a three-dimensional space curve. The
skier travels along a course under the influence of various forces, and their
dynamics can be described using a nonlinear system of ordinary differential
equations (ODEs) that are derived from Newton's laws of motion. We develop an
algorithm for solving the governing equations that combines Hermite spline
interpolation, numerical quadrature and a high-order ODE solver. Numerical
simulations are compared with measurements of skiers on actual courses to
demonstrate the effectiveness of the model. Throughout, we aim to illustrate
how elementary concepts from undergraduate courses in calculus and scientific
computing can be applied to study real problems in sport, which we hope will
provide stimulating examples for both instructors and students. At the same
time, we demonstrate how these concepts are capable of providing novel insights
into skiing that should also be of interest to sport scientists.


### Top- and bottom-heavy vertical velocity structures: physical modes of layered atmospheric models
**Authors**: Fiaz Ahmed, J. David Neelin

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15166v1](http://arxiv.org/pdf/2509.15166v1)

**Abstract**: Tropical East and West Pacific Oceans display differences in their vertical
velocity (or omega) profiles. The East Pacific is characterized by bottom-heavy
profiles, while the West Pacific is characterized by top-heavy profiles.
Although inter-basin differences in the horizontal SST gradient are known to be
important, physical reasons for why these omega structure variants exist are
not fully understood. This question is addressed using a steady, linear model
on an $f$-plane with $n$ atmospheric layers. Convection and radiation are
parameterized as linear responses to thermodynamic perturbations with
convective nonlinearity approximated by convection on/off regimes. The free (or
eigen) modes of the model yield vertical structures resembling the observed
baroclinic modes of the tropical atmosphere, with each mode associated with a
characteristic horizontal scale (the eigenvalue). In the standard parameter
regime, the first-baroclinic mode has a large spatial scale ($\sim$ 1500 km)
while the second-baroclinic mode has a smaller spatial scale ($\sim$ 250 km).
When the model is forced with a strong- and weak-gradient surface temperature
($T_s$) patterns, the resulting omega profiles assume bottom- and top-heavy
structures respectively -- mimicking the observed differences between East and
West Pacific Oceans. Additional dependence on the magnitude of the Coriolis
force is also observed. The connection between the vertical structure and the
horizontal scale of the baroclinic modes explains why a strong-gradient $T_s$
profile projects strongly onto the second-baroclinic mode yielding bottom-heavy
omega profiles in the eastern Pacific, while a weak-gradient $T_s$ profile
projects strongly onto the first-baroclinic mode, yielding top-heavy omega
profiles typical of the Western Pacific.


### Super resonance: Breaking the bandwidth limit of resonant modes and its application to flow control
**Authors**: Adam R. Harris, Armin Kianfar, David Roca, Daniel Yago, Christoph Brehm, Mahmoud I. Hussein

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15142v1](http://arxiv.org/pdf/2509.15142v1)

**Abstract**: We report the discovery of super resonance--a new regime of resonant behavior
in which a mode's out-of-phase response persists far beyond its classical
bandwidth. This effect emerges from a coiled phononic structure composed of a
locally resonant elastic metamaterial and architected to support multiple
internal energy pathways. These pathways converge at a single structural point,
enabling extended modal dominance and significantly broadening the frequency
range over which a resonant phase is sustained. We demonstrate by direct
numerical simulations the implications of this mechanism in the context of flow
instability control, where current approaches are inherently constrained by the
characteristically narrow spectral bandwidth of conventional resonances. Using
a super-resonant phononic subsurface structure interfacing with a channel flow,
we show passive simultaneous suppression of four unstable flow perturbations
across a frequency range more than five times wider than that is achievable
with a standard resonance in an equivalent uncoiled structure. By enabling
broadband, passive control of flow instabilities, super resonance overcomes a
longstanding limitation in laminar flow control strategies. More broadly, it
introduces a powerful new tool for phase-engineered wave-matter interaction.
The ability to preserve out-of-phase modal response across wide spectral ranges
establishes a fundamental advance in the physics of resonance, with
far-reaching implications for suppressing fully developed turbulent flows and
beyond.


### Learning Mechanistic Subtypes of Neurodegeneration with a Physics-Informed Variational Autoencoder Mixture Model
**Authors**: Sanduni Pinnawala, Annabelle Hartanto, Ivor J. A. Simpson, Peter A. Wijeratne

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15124v1](http://arxiv.org/pdf/2509.15124v1)

**Abstract**: Modelling the underlying mechanisms of neurodegenerative diseases demands
methods that capture heterogeneous and spatially varying dynamics from sparse,
high-dimensional neuroimaging data. Integrating partial differential equation
(PDE) based physics knowledge with machine learning provides enhanced
interpretability and utility over classic numerical methods. However, current
physics-integrated machine learning methods are limited to considering a single
PDE, severely limiting their application to diseases where multiple mechanisms
are responsible for different groups (i.e., subtypes) and aggravating problems
with model misspecification and degeneracy. Here, we present a deep generative
model for learning mixtures of latent dynamic models governed by physics-based
PDEs, going beyond traditional approaches that assume a single PDE structure.
Our method integrates reaction-diffusion PDEs within a variational autoencoder
(VAE) mixture model framework, supporting inference of subtypes of
interpretable latent variables (e.g. diffusivity and reaction rates) from
neuroimaging data. We evaluate our method on synthetic benchmarks and
demonstrate its potential for uncovering mechanistic subtypes of Alzheimer's
disease progression from positron emission tomography (PET) data.


### Shedding Light on Dark Matter at the LHC with Machine Learning
**Authors**: Ernesto Arganda, Martín de los Rios, Andres D. Perez, Subhojit Roy, Rosa M. Sandá Seoane, Carlos E. M. Wagner

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15121v1](http://arxiv.org/pdf/2509.15121v1)

**Abstract**: We investigate a WIMP dark matter (DM) candidate in the form of a
singlino-dominated lightest supersymmetric particle (LSP) within the
$Z_3$-symmetric Next-to-Minimal Supersymmetric Standard Model. This framework
gives rise to regions of parameter space where DM is obtained via
co-annihilation with nearby higgsino-like electroweakinos and DM direct
detection~signals are suppressed, the so-called ``blind spots". On the other
hand, collider signatures remain promising due to enhanced radiative decay
modes of higgsinos into the singlino-dominated LSP and a photon, rather than
into leptons or hadrons. This motivates searches for radiatively decaying
neutralinos, however, these signals face substantial background challenges, as
the decay products are typically soft due to the small mass-splits ($\Delta m$)
between the LSP and the higgsino-like coannihilation partners. We apply a
data-driven Machine Learning (ML) analysis that improves sensitivity to these
subtle signals, offering a powerful complement to traditional search strategies
to discover a new physics scenario. Using an LHC integrated luminosity of
$100~\mathrm{fb}^{-1}$ at $14~\mathrm{TeV}$, the method achieves a $5\sigma$
discovery reach for higgsino masses up to $225~\mathrm{GeV}$ with $\Delta
m\!\lesssim\!12~\mathrm{GeV}$, and a $2\sigma$ exclusion up to
$285~\mathrm{GeV}$ with $\Delta m\!\lesssim\!20~\mathrm{GeV}$. These results
highlight the power of collider searches to probe DM candidates that remain
hidden from current direct detection experiments, and provide a motivation for
a search by the LHC collaborations using ML methods.


### Low-rank surrogate modeling and stochastic zero-order optimization for training of neural networks with black-box layers
**Authors**: Andrei Chertkov, Artem Basharin, Mikhail Saygin, Evgeny Frolov, Stanislav Straupe, Ivan Oseledets

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15113v1](http://arxiv.org/pdf/2509.15113v1)

**Abstract**: The growing demand for energy-efficient, high-performance AI systems has led
to increased attention on alternative computing platforms (e.g., photonic,
neuromorphic) due to their potential to accelerate learning and inference.
However, integrating such physical components into deep learning pipelines
remains challenging, as physical devices often offer limited expressiveness,
and their non-differentiable nature renders on-device backpropagation difficult
or infeasible. This motivates the development of hybrid architectures that
combine digital neural networks with reconfigurable physical layers, which
effectively behave as black boxes. In this work, we present a framework for the
end-to-end training of such hybrid networks. This framework integrates
stochastic zeroth-order optimization for updating the physical layer's internal
parameters with a dynamic low-rank surrogate model that enables gradient
propagation through the physical layer. A key component of our approach is the
implicit projector-splitting integrator algorithm, which updates the
lightweight surrogate model after each forward pass with minimal hardware
queries, thereby avoiding costly full matrix reconstruction. We demonstrate our
method across diverse deep learning tasks, including: computer vision, audio
classification, and language modeling. Notably, across all modalities, the
proposed approach achieves near-digital baseline accuracy and consistently
enables effective end-to-end training of hybrid models incorporating various
non-differentiable physical components (spatial light modulators, microring
resonators, and Mach-Zehnder interferometers). This work bridges hardware-aware
deep learning and gradient-free optimization, thereby offering a practical
pathway for integrating non-differentiable physical components into scalable,
end-to-end trainable AI systems.


### Zero Indirect Band Gap in Non-Hermitian Systems
**Authors**: Rahul S, Giandomenico Palumbo

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15102v1](http://arxiv.org/pdf/2509.15102v1)

**Abstract**: Zero indirect gaps in band models are typically viewed as unstable and
achievable only through fine-tuning. Recent works, however, have revealed
robust semimetallic phases in Hermitian systems where the indirect gap remains
pinned at zero over a finite parameter range. Here, we extend this paradigm to
non-Hermitian lattice models by studying a one-dimensional diamond-like system
with gain and loss. We show that a zero indirect band gap can remain stable
against non-Hermitian perturbations and identify the regimes where this
robustness persists. Remarkably, we find that the zero indirect gap induces a
suppression of the non-Hermitian skin effect distinct from other physical
mechanics already discussed in the literature. Our results reveal new
connections between indirect gaps, exceptional points and non-Hermitian skin
effect, opening avenues for experimental realizations.


### A zero-dead-time strontium lattice clock with a stability at $10^{-19}$ level
**Authors**: Xiao-Yong Liu, Peng Liu, Jie Li, Yu-Chen Zhang, Yuan-Bo Wang, Zhi-Peng Jia, Xiang Zhang, Xian-Qing Zhu, De-Quan Kong, Wen-Lan Song, Guo-Zhen Niu, Yu-Meng Yang, Pei-Jun Feng, Xiang-Pei Liu, Xing-Yang Cui, Ping Xu, Xiao Jiang, Juan Yin, Sheng-Kai Liao, Cheng-Zhi Peng, Han-Ning Dai, Yu-Ao Chen, Jian-Wei Pan

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15100v1](http://arxiv.org/pdf/2509.15100v1)

**Abstract**: Optical atomic clocks play a crucial role in fundamental physics,
relativistic geodesy, and the future redefinition of the SI second. Standard
operation relies on cyclic interrogation sequences, which alternate between
atomic interrogation and dead time used for state preparation and readout. This
approach introduces the Dick effect, where laser frequency noise aliases onto
the atomic transition frequency. Although reducing laser noise improves clock
stability, the Dick effect remains a key limitation. In this work, we
demonstrate a zero-dead-time optical clock based on two interleaved ensembles
of cold $^{87}\text{Sr}$ atoms. Our system significantly suppresses this noise
and achieves a fractional frequency instability at the $10^{-19}$ level between
10,000 and 20,000 seconds over repeated measurements, with a best value of $2.9
\times 10^{-19}$ at $\tau = 20,000$ seconds. The estimated long-term stability
based on the combined data of these measurements reaches $2.5 \times 10^{-19}$
at one day. These results represent a more than ninefold improvement over a
conventional single-ensemble clock, highlighting its potential for
next-generation timekeeping applications.


### Precise measurement of the $t\bar{t}$ production cross-section and lepton differential distributions in $eμ$ dilepton events from $\sqrt{s}=13$ TeV $pp$ collisions with the ATLAS detector
**Authors**: ATLAS Collaboration

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15066v1](http://arxiv.org/pdf/2509.15066v1)

**Abstract**: The inclusive top quark pair ($t\bar{t}$) cross-section $\sigma_{t\bar{t}}$
has been measured in $\sqrt{s}=13$ TeV proton-proton collisions, using 140
fb$^{-1}$ of data collected by the ATLAS experiment at the Large Hadron
Collider. Using events with an opposite-charge $e\mu$ pair and $b$-tagged jets,
the cross-section is measured to be: $\sigma_{t\bar{t}} = 829.3 \pm
1.3\,\mathrm{(stat)}\ \pm 8.0\,\mathrm{(syst)}\ \pm 7.3\,\mathrm{(lumi)}\ \pm
1.9\,\mathrm{(beam)}\,\mathrm{pb},$ where the uncertainties reflect the limited
size of the data sample, experimental and theoretical systematic effects, the
integrated luminosity, and the proton beam energy, giving a total uncertainty
of 1.3%. The result is used to determine the top quark pole mass via the
dependence of the predicted cross-section on $m_t^\mathrm{pole}$, giving
$m_t^\mathrm{pole}=172.8^{+1.5}_{-1.7}$ GeV. The same event sample is used to
measure absolute and normalised differential cross-sections for the
$t\bar{t}\rightarrow e\mu\nu\bar{\nu}b\bar{b}$ process as a function of
single-lepton and dilepton kinematic variables. Complementary measurements of
$e\mu b\bar{b}$ production, treating both $t\bar{t}$ and $Wt$ events as signal,
are also provided. Both sets of differential cross-sections are compared to the
predictions of various Monte Carlo event generators, demonstrating that the
state-of-the-art generators Powheg MiNNLO and Powheg $bb4l$ describe the data
better than Powheg hvq.


### Advanced Physics-Informed Neural Network with Residuals for Solving Complex Integral Equations
**Authors**: Mahdi Movahedian Moghaddam, Kourosh Parand, Saeed Reza Kheradpisheh

**Published Date**: 2025-01-22

**Updated Date**: 2025-09-18

**PDF Url**: [2501.16370v3](http://arxiv.org/pdf/2501.16370v3)

**Abstract**: In this paper, we present the Residual Integral Solver Network (RISN), a
novel neural network architecture designed to solve a wide range of integral
and integro-differential equations, including one-dimensional,
multi-dimensional, ordinary and partial integro-differential, systems,
fractional types, and Helmholtz-type integral equations involving oscillatory
kernels. RISN integrates residual connections with high-accuracy numerical
methods such as Gaussian quadrature and fractional derivative operational
matrices, enabling it to achieve higher accuracy and stability than traditional
Physics-Informed Neural Networks (PINN). The residual connections help mitigate
vanishing gradient issues, allowing RISN to handle deeper networks and more
complex kernels, particularly in multi-dimensional problems. Through extensive
experiments, we demonstrate that RISN consistently outperforms not only
classical PINNs but also advanced variants such as Auxiliary PINN (A-PINN) and
Self-Adaptive PINN (SA-PINN), achieving significantly lower Mean Absolute
Errors (MAE) across various types of equations. These results highlight RISN's
robustness and efficiency in solving challenging integral and
integro-differential problems, making it a valuable tool for real-world
applications where traditional methods often struggle.


## Diffusion
### Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning
**Authors**: Yeongbin Seo, Dongha Lee, Jaehyung Kim, Jinyoung Yeo

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15188v1](http://arxiv.org/pdf/2509.15188v1)

**Abstract**: Autoregressive (AR) language models generate text one token at a time, which
limits their inference speed. Diffusion-based language models offer a promising
alternative, as they can decode multiple tokens in parallel. However, we
identify a key bottleneck in current diffusion LMs: the long decoding-window
problem, where tokens generated far from the input context often become
irrelevant or repetitive. Previous solutions like semi-autoregressive address
this issue by splitting windows into blocks, but this sacrifices speed and
bidirectionality, eliminating the main advantage of diffusion models. To
overcome this, we propose Convolutional decoding (Conv), a normalization-based
method that narrows the decoding window without hard segmentation, leading to
better fluency and flexibility. Additionally, we introduce Rejecting Rule-based
Fine-Tuning (R2FT), a post-hoc training scheme that better aligns tokens at
positions far from context. Our methods achieve state-of-the-art results on
open-ended generation benchmarks (e.g., AlpacaEval) among diffusion LM
baselines, with significantly lower step size than previous works,
demonstrating both speed and quality improvements.


### AnoF-Diff: One-Step Diffusion-Based Anomaly Detection for Forceful Tool Use
**Authors**: Yating Lin, Zixuan Huang, Fan Yang, Dmitry Berenson

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15153v1](http://arxiv.org/pdf/2509.15153v1)

**Abstract**: Multivariate time-series anomaly detection, which is critical for identifying
unexpected events, has been explored in the field of machine learning for
several decades. However, directly applying these methods to data from forceful
tool use tasks is challenging because streaming sensor data in the real world
tends to be inherently noisy, exhibits non-stationary behavior, and varies
across different tasks and tools. To address these challenges, we propose a
method, AnoF-Diff, based on the diffusion model to extract force-torque
features from time-series data and use force-torque features to detect
anomalies. We compare our method with other state-of-the-art methods in terms
of F1-score and Area Under the Receiver Operating Characteristic curve (AUROC)
on four forceful tool-use tasks, demonstrating that our method has better
performance and is more robust to a noisy dataset. We also propose the method
of parallel anomaly score evaluation based on one-step diffusion and
demonstrate how our method can be used for online anomaly detection in several
forceful tool use experiments.


### Probing the Representational Power of Sparse Autoencoders in Vision Models
**Authors**: Matthew Lyle Olson, Musashi Hinck, Neale Ratzlaff, Changbai Li, Phillip Howard, Vasudev Lal, Shao-Yen Tseng

**Published Date**: 2025-08-15

**Updated Date**: 2025-09-18

**PDF Url**: [2508.11277v2](http://arxiv.org/pdf/2508.11277v2)

**Abstract**: Sparse Autoencoders (SAEs) have emerged as a popular tool for interpreting
the hidden states of large language models (LLMs). By learning to reconstruct
activations from a sparse bottleneck layer, SAEs discover interpretable
features from the high-dimensional internal representations of LLMs. Despite
their popularity with language models, SAEs remain understudied in the visual
domain. In this work, we provide an extensive evaluation the representational
power of SAEs for vision models using a broad range of image-based tasks. Our
experimental results demonstrate that SAE features are semantically meaningful,
improve out-of-distribution generalization, and enable controllable generation
across three vision model architectures: vision embedding models, multi-modal
LMMs and diffusion models. In vision embedding models, we find that learned SAE
features can be used for OOD detection and provide evidence that they recover
the ontological structure of the underlying model. For diffusion models, we
demonstrate that SAEs enable semantic steering through text encoder
manipulation and develop an automated pipeline for discovering
human-interpretable attributes. Finally, we conduct exploratory experiments on
multi-modal LLMs, finding evidence that SAE features reveal shared
representations across vision and language modalities. Our study provides a
foundation for SAE evaluation in vision models, highlighting their strong
potential improving interpretability, generalization, and steerability in the
visual domain.


### WorldForge: Unlocking Emergent 3D/4D Generation in Video Diffusion Model via Training-Free Guidance
**Authors**: Chenxi Song, Yanming Yang, Tong Zhao, Ruibo Li, Chi Zhang

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.15130v1](http://arxiv.org/pdf/2509.15130v1)

**Abstract**: Recent video diffusion models demonstrate strong potential in spatial
intelligence tasks due to their rich latent world priors. However, this
potential is hindered by their limited controllability and geometric
inconsistency, creating a gap between their strong priors and their practical
use in 3D/4D tasks. As a result, current approaches often rely on retraining or
fine-tuning, which risks degrading pretrained knowledge and incurs high
computational costs. To address this, we propose WorldForge, a training-free,
inference-time framework composed of three tightly coupled modules. Intra-Step
Recursive Refinement introduces a recursive refinement mechanism during
inference, which repeatedly optimizes network predictions within each denoising
step to enable precise trajectory injection. Flow-Gated Latent Fusion leverages
optical flow similarity to decouple motion from appearance in the latent space
and selectively inject trajectory guidance into motion-related channels.
Dual-Path Self-Corrective Guidance compares guided and unguided denoising paths
to adaptively correct trajectory drift caused by noisy or misaligned structural
signals. Together, these components inject fine-grained, trajectory-aligned
guidance without training, achieving both accurate motion control and
photorealistic content generation. Extensive experiments across diverse
benchmarks validate our method's superiority in realism, trajectory
consistency, and visual fidelity. This work introduces a novel plug-and-play
paradigm for controllable video synthesis, offering a new perspective on
leveraging generative priors for spatial intelligence.


### M4Diffuser: Multi-View Diffusion Policy with Manipulability-Aware Control for Robust Mobile Manipulation
**Authors**: Ju Dong, Lei Zhang, Liding Zhang, Yao Ling, Yu Fu, Kaixin Bai, Zoltán-Csaba Márton, Zhenshan Bing, Zhaopeng Chen, Alois Christian Knoll, Jianwei Zhang

**Published Date**: 2025-09-18

**Updated Date**: 2025-09-18

**PDF Url**: [2509.14980v1](http://arxiv.org/pdf/2509.14980v1)

**Abstract**: Mobile manipulation requires the coordinated control of a mobile base and a
robotic arm while simultaneously perceiving both global scene context and
fine-grained object details. Existing single-view approaches often fail in
unstructured environments due to limited fields of view, exploration, and
generalization abilities. Moreover, classical controllers, although stable,
struggle with efficiency and manipulability near singularities. To address
these challenges, we propose M4Diffuser, a hybrid framework that integrates a
Multi-View Diffusion Policy with a novel Reduced and Manipulability-aware QP
(ReM-QP) controller for mobile manipulation. The diffusion policy leverages
proprioceptive states and complementary camera perspectives with both
close-range object details and global scene context to generate task-relevant
end-effector goals in the world frame. These high-level goals are then executed
by the ReM-QP controller, which eliminates slack variables for computational
efficiency and incorporates manipulability-aware preferences for robustness
near singularities. Comprehensive experiments in simulation and real-world
environments show that M4Diffuser achieves 7 to 56 percent higher success rates
and reduces collisions by 3 to 31 percent over baselines. Our approach
demonstrates robust performance for smooth whole-body coordination, and strong
generalization to unseen tasks, paving the way for reliable mobile manipulation
in unstructured environments. Details of the demo and supplemental material are
available on our project website https://sites.google.com/view/m4diffuser.


