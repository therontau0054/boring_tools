# Abstracts of Papers

## Physics
### On the relation between perspective-neutral, algebraic, and effective quantum reference frames
**Authors**: Philipp A. Hoehn, Julian De Vuyst, Artur Tsobanjan

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14131v1](http://arxiv.org/pdf/2507.14131v1)

**Abstract**: The framework of internal quantum reference frames (QRFs) constitutes a
universal toolset for dealing with symmetries in quantum theory and has led to
new revelations in quantum gravity, gauge theories and foundational physics.
Multiple approaches have emerged, sometimes differing in scope and the way
symmetries are implemented, raising the question as to their relation. Here, we
investigate the relation between three approaches to QRFs for gauge symmetries,
namely the effective semiclassical, algebraic, and perspective-neutral (PN)
approaches. Rather than constructing Hilbert spaces, as the PN approach, the
effective approach is based on a quantum phase space parametrized by
expectation values and fluctuations, while the emphasis of the algebraic
approach is on the state space of complex linear functionals on a kinematical
algebra. Nevertheless, external frame information is treated as gauge in all
three formalisms, manifested in constraints on states and algebra. We show that
these three approaches are, in fact, equivalent for ideal QRFs, distinguished
by sharp orientations, which is the previous setting of the first two
approaches. Our demonstration pertains to single constraints, including
relativistic ones, and encompasses QRF changes. In particular, the QRF
transformations of the PN framework agree semiclassically with those of the
older effective approach, by which it was inspired. As a physical application,
we explore the QRF covariance of uncertainties and fluctuations, which turn out
to be frame-dependent. This is particularly well-suited for the effective and
algebraic approaches, for which these quantities form a natural basis. Finally,
we pave the way towards extending these two approaches to non-ideal QRFs by
studying the projection and gauge-fixing operations of the Page-Wootters
formalism, built into the PN framework, on algebraic states.


### NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining
**Authors**: Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh, Georgii Fedorov, Bulat Suleimanov, Vladimir Dokholyan, Aleksandr Gordeev

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14119v1](http://arxiv.org/pdf/2507.14119v1)

**Abstract**: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.


### Spatiotemporal Order and Parametric Instabilities from First-Principles
**Authors**: Daniel Kaplan, Pavel A. Volkov, Jennifer Coulter, Shiwei Zhang, Premala Chandra

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14110v1](http://arxiv.org/pdf/2507.14110v1)

**Abstract**: Shaping crystal structure with light is an enduring goal of physics and
materials engineering. Here we present calculations in candidate materials
selected by symmetry that allow light-induced spatiotemporal parametric
instabilities. We demonstrate a theoretical framework that includes a complete
symmetry analysis of phonon modes that contribute to parametric instabilities
across all non-centrosymmetric point groups, a detailed survey of the materials
landscape and finally the computation of nonlinear couplings from first
principles. We then showcase detailed results for chiral crystals,
ferroelectrics, and layered van der Waals materials. Our results pave the way
towards realizing designer time-crystalline order in quantum materials,
detectable with time-resolved diffractive probes.


### An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting
**Authors**: Xinyu Cao, Bimal Adhikari, Shangqing Zhao, Jingxian Wu, Yanjun Pan

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14109v1](http://arxiv.org/pdf/2507.14109v1)

**Abstract**: Radio frequency (RF) fingerprinting, which extracts unique hardware
imperfections of radio devices, has emerged as a promising physical-layer
device identification mechanism in zero trust architectures and beyond 5G
networks. In particular, deep learning (DL) methods have demonstrated
state-of-the-art performance in this domain. However, existing approaches have
primarily focused on enhancing system robustness against temporal and spatial
variations in wireless environments, while the security vulnerabilities of
these DL-based approaches have often been overlooked. In this work, we
systematically investigate the security risks of DL-based RF fingerprinting
systems through an adversarial-driven experimental analysis. We observe a
consistent misclassification behavior for DL models under domain shifts, where
a device is frequently misclassified as another specific one. Our analysis
based on extensive real-world experiments demonstrates that this behavior can
be exploited as an effective backdoor to enable external attackers to intrude
into the system. Furthermore, we show that training DL models on raw received
signals causes the models to entangle RF fingerprints with environmental and
signal-pattern features, creating additional attack vectors that cannot be
mitigated solely through post-processing security methods such as confidence
thresholds.


### Ultrafast thermal boundary conductance under large temperature discontinuities of ultrathin epitaxial Pb films on Si(111)
**Authors**: Christian Brand, Tobias Witte, Mohammad Tajik, Jonas D. Fortmann, Birk Finke, Michael Horn-von Hoegen

**Published Date**: 2025-07-17

**Updated Date**: 2025-07-18

**PDF Url**: [2507.13109v2](http://arxiv.org/pdf/2507.13109v2)

**Abstract**: Heat transfer is a critical aspect of modern electronics, and a deeper
understanding of the underlying physics is essential for building faster,
smaller, and more powerful devices with an improved performance and efficiency.
In such nanoscale structures the heat transfer between two materials is limited
by the finite thermal boundary conductance across their interface. Using
ultrafast electron diffraction under grazing incidence we investigated the heat
transfer from ultrathin epitaxial Pb films to an Si(111) substrate under strong
non-equilibrium conditions. Applying an intense femtosecond laser pulse, the
5-7 ML thin Pb film experiences a strong heat up by 10-120 K while the Si
substrate remains cold at $\approx$ 10 K. At such large temperature
discontinuities we observe a significantly faster cooling for stronger excited
Pb films. The decrease of the corresponding cooling time constant is explained
through the thermal boundary conductance in the framework of the diffuse
mismatch model. The thermal boundary conductance is reduced by more than a
factor of three in comparison with Pb films grown on H-terminated substrates,
pointing out the importance of the morphology of substrate, film and their
interface.


### Generative AI-Driven High-Fidelity Human Motion Simulation
**Authors**: Hari Iyer, Neel Macwan, Atharva Jitendra Hude, Heejin Jeong, Shenghan Guo

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14097v1](http://arxiv.org/pdf/2507.14097v1)

**Abstract**: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.


### Machine Learning-aided Optimal Control of a noisy qubit
**Authors**: Riccardo Cantone, Shreyasi Mukherjee, Luigi Giannelli, Elisabetta Paladino, Giuseppe Falci

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.14085v1](http://arxiv.org/pdf/2507.14085v1)

**Abstract**: We apply a graybox machine-learning framework to model and control a qubit
undergoing Markovian and non-Markovian dynamics from environmental noise. The
approach combines physics-informed equations with a lightweight transformer
neural network based on the self-attention mechanism. The model is trained on
simulated data and learns an effective operator that predicts observables
accurately, even in the presence of memory effects. We benchmark both
non-Gaussian random-telegraph noise and Gaussian Ornstein-Uhlenbeck noise and
achieve low prediction errors even in challenging noise coupling regimes. Using
the model as a dynamics emulator, we perform gradient-based optimal control to
identify pulse sequences implementing a universal set of single-qubit gates,
achieving fidelities above 99% for the lowest considered value of the coupling
and remaining above 90% for the highest.


### Constraining scalars of $16_H$ through proton decays in non-renormalisable $SO(10)$ models
**Authors**: Saurabh K. Shukla

**Published Date**: 2024-03-21

**Updated Date**: 2025-07-18

**PDF Url**: [2403.14331v2](http://arxiv.org/pdf/2403.14331v2)

**Abstract**: Non-renormalisable versions of $SO(10)$\, based on irreducible
representations with lesser degrees of freedom, are free of running into the
catastrophe of non-perturbativity of standard model gauge couplings in contrast
to the renormalisable versions having tensors with many degrees of freedom.
$16_H$ is the smallest representation, participates in Yukawa Lagrangian at the
non-renormalisable level, contributing to the charged and neutral fermion
masses, and has six distinct scalars with different $B-L$ charges. We computed
the leptoquark and diquark couplings of different pairs of scalars stemming
from all possible decomposition of the term resulting from the coupling of
$16_{H}$ with the ${\mathbf{16}}$ dimensional fermion multiplet of $SO(10)$,\,
i.e. $\frac{{\mathbf{16}}\,{\mathbf{16}}\,16_{H}\,16_{H}}{\Lambda}$. Computing
the tree and loop level contribution of different pairs to the effective
dimension six, $B-L$ conserving operators, it turns out only three pairs, viz
$\sigma\big(1,1,0\big)- T\big(3,1,\frac{1}{3}\big)$, and
$H\big(1,2,-\frac{1}{2}\big)-\Delta\big(3,2,\frac{1}{6}\big)$, and $H-T$ can
induce proton decay at tree level. Assuming that the Yukawa couplings of the
$16_{H}$ are comparable to those of the $\overline{126}_{H}$ of a realistic
$SO(10)$ model and setting the cutoff scale to the Planck scale typically
constrains the $B-L$ breaking scale to be $4\sim 5$ orders of magnitude less
than the cutoff scale $(\Lambda)$. Moreover, analysing the branching pattern of
the leading two-body decay modes of the proton, we observed a preference for
the proton to decay into second-generation mesons due to the hierarchical
nature of Yukawa couplings. In a realistic $SO(10)$\, scenario, we find that
$M_T >10^{8}$ TeV, while $M_\Delta$ could be as light as a few TeV$s$.


### Critiques of World Models
**Authors**: Eric Xing, Mingkai Deng, Jinyu Hou, Zhiting Hu

**Published Date**: 2025-07-07

**Updated Date**: 2025-07-18

**PDF Url**: [2507.05169v2](http://arxiv.org/pdf/2507.05169v2)

**Abstract**: World Model, the supposed algorithmic surrogate of the real-world environment
which biological agents experience with and act upon, has been an emerging
topic in recent years because of the rising needs to develop virtual agents
with artificial (general) intelligence. There has been much debate on what a
world model really is, how to build it, how to use it, and how to evaluate it.
In this essay, starting from the imagination in the famed Sci-Fi classic Dune,
and drawing inspiration from the concept of "hypothetical thinking" in
psychology literature, we offer critiques of several schools of thoughts on
world modeling, and argue the primary goal of a world model to be simulating
all actionable possibilities of the real world for purposeful reasoning and
acting. Building on the critiques, we propose a new architecture for a
general-purpose world model, based on hierarchical, multi-level, and mixed
continuous/discrete representations, and a generative and self-supervision
learning framework, with an outlook of a Physical, Agentic, and Nested (PAN)
AGI system enabled by such a model.


### High stakes exams inflate a gender gap and contribute to systematic grading errors in introductory physics
**Authors**: David J. Webb, Cassandra A. Paul

**Published Date**: 2025-04-13

**Updated Date**: 2025-07-18

**PDF Url**: [2504.09418v2](http://arxiv.org/pdf/2504.09418v2)

**Abstract**: Previous research has suggested that changing the percentage of the course
grade associated with exam grades in STEM courses can change the gender gap in
the course. It has also been shown that assessments with the highest stakes
have the lowest (relative) scores for female students. Previous research by the
authors has shown that the implementation of retake exams can eliminate the
gender gap in introductory physics courses. This paper explores several
different hypotheses for why retake exams are associated with a zeroed gender
gap. Two independent measurements comparing exams with different stakes are
used in support of the argument that the entire gender gap on introductory
physics exams may be due to the stakes associated with those exams. In other
words, these data support the idea that a gender grade gap on exams is not
measuring a gender difference in the physics knowledge or physics ability of
these students. Implications suggest that instructors should choose lower
stakes assessment options if they are interested in exam measurements that are
not influenced by differences in students' performance related to exam stakes.


## Diffusion
### A General Framework for Inference-time Scaling and Steering of Diffusion Models
**Authors**: Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath

**Published Date**: 2025-01-12

**Updated Date**: 2025-07-18

**PDF Url**: [2501.06848v5](http://arxiv.org/pdf/2501.06848v5)

**Abstract**: Diffusion models produce impressive results in modalities ranging from images
and video to protein design and text. However, generating samples with
user-specified properties remains a challenge. Recent research proposes
fine-tuning models to maximize rewards that capture desired properties, but
these methods require expensive training and are prone to mode collapse. In
this work, we present Feynman-Kac (FK) steering, an inference-time framework
for steering diffusion models with reward functions. FK steering works by
sampling a system of multiple interacting diffusion processes, called
particles, and resampling particles at intermediate steps based on scores
computed using functions called potentials. Potentials are defined using
rewards for intermediate states and are selected such that a high value
indicates that the particle will yield a high-reward sample. We explore various
choices of potentials, intermediate rewards, and samplers. We evaluate FK
steering on text-to-image and text diffusion models. For steering text-to-image
models with a human preference reward, we find that FK steering a 0.8B
parameter model outperforms a 2.6B parameter fine-tuned model on prompt
fidelity, with faster sampling and no training. For steering text diffusion
models with rewards for text quality and specific text attributes, we find that
FK steering generates lower perplexity, more linguistically acceptable outputs
and enables gradient-free control of attributes like toxicity. Our results
demonstrate that inference-time scaling and steering of diffusion models - even
with off-the-shelf rewards - can provide significant sample quality gains and
controllability benefits. Code is available at
https://github.com/zacharyhorvitz/Fk-Diffusion-Steering .


### CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models
**Authors**: Quang-Binh Nguyen, Minh Luu, Quang Nguyen, Anh Tran, Khoi Nguyen

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.13984v1](http://arxiv.org/pdf/2507.13984v1)

**Abstract**: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.


### Generalist Forecasting with Frozen Video Models via Latent Diffusion
**Authors**: Jacob C Walker, Pedro Vélez, Luisa Polania Cabrera, Guangyao Zhou, Rishabh Kabra, Carl Doersch, Maks Ovsjanikov, João Carreira, Shiry Ginosar

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.13942v1](http://arxiv.org/pdf/2507.13942v1)

**Abstract**: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.


### Improved DDIM Sampling with Moment Matching Gaussian Mixtures
**Authors**: Prasad Gabbur

**Published Date**: 2023-11-08

**Updated Date**: 2025-07-18

**PDF Url**: [2311.04938v3](http://arxiv.org/pdf/2311.04938v3)

**Abstract**: We propose using a Gaussian Mixture Model (GMM) as reverse transition
operator (kernel) within the Denoising Diffusion Implicit Models (DDIM)
framework, which is one of the most widely used approaches for accelerated
sampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).
Specifically we match the first and second order central moments of the DDPM
forward marginals by constraining the parameters of the GMM. We see that moment
matching is sufficient to obtain samples with equal or better quality than the
original DDIM with Gaussian kernels. We provide experimental results with
unconditional models trained on CelebAHQ and FFHQ and class-conditional models
trained on ImageNet datasets respectively. Our results suggest that using the
GMM kernel leads to significant improvements in the quality of the generated
samples when the number of sampling steps is small, as measured by FID and IS
metrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a
FID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73
respectively with a Gaussian kernel.


### Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction
**Authors**: Mingyang Yu, Zhijian Wu, Dingjiang Huang

**Published Date**: 2025-07-18

**Updated Date**: 2025-07-18

**PDF Url**: [2507.13769v1](http://arxiv.org/pdf/2507.13769v1)

**Abstract**: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.


## Quantitative Finance
### Machine-learning regression methods for American-style path-dependent contracts
**Authors**: Matteo Gambara, Giulia Livieri, Andrea Pallavicini

**Published Date**: 2023-11-28

**Updated Date**: 2025-07-18

**PDF Url**: [2311.16762v2](http://arxiv.org/pdf/2311.16762v2)

**Abstract**: Evaluating financial products with early-termination clauses, in particular
those with path-dependent structures, is challenging. This paper focuses on
Asian options, look-back options, and callable certificates. We will compare
regression methods for pricing and computing sensitivities, highlighting modern
machine learning techniques against traditional polynomial basis functions.
Specifically, we will analyze randomized recurrent and feed-forward neural
networks, along with a novel approach using signatures of the underlying price
process. For option sensitivities like Delta and Gamma, we will incorporate
Chebyshev interpolation. Our findings show that machine learning algorithms
often match the accuracy and efficiency of traditional methods for Asian and
look-back options, while randomized neural networks are best for callable
certificates. Furthermore, we apply Chebyshev interpolation for Delta and Gamma
calculations for the first time in Asian options and callable certificates.


