# Abstracts of Papers

## Physics
### Optimal-order Trotter-Suzuki decomposition for quantum simulation on noisy quantum computers
**Authors**: A. A. Avtandilyan, W. V. Pogosov

**Published Date**: 2024-05-02

**Updated Date**: 2024-12-30

**PDF Url**: [2405.01131v3](http://arxiv.org/pdf/2405.01131v3)

**Abstract**: The potential of employing higher orders of the Trotter-Suzuki decomposition
of the evolution operator for more effective simulations of quantum systems on
a noisy quantum computer is explored. By examining the transverse-field Ising
model and the XY model, it is demonstrated that when the gate error is
decreased by approximately an order of magnitude relative to typical modern
values, higher-order Trotterization becomes advantageous. This form of
Trotterization yields a global minimum of the overall simulation error,
comprising both the mathematical error of Trotterization and the physical error
arising from gate execution.


### Cut-Out Wedges in $H_{3}$ and the Borel-Resurgent Chern-Simons Matrix Integrals
**Authors**: Tuo Jia, Zhaojie Xu

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21190v1](http://arxiv.org/pdf/2412.21190v1)

**Abstract**: In this paper, we present a systematic study of the Chern--Simons theory with
gauge group \(\mathrm{SL}(2,\mathbb{R})\times\mathrm{SL}(2,\mathbb{R})\)
restricted to a wedge-identified manifold in the hyperbolic upper-half-space.
The wedge geometry is created by imposing an angular cutoff in the \((x,y)\)
plane and identifying two boundary lines, which introduces a single
noncontractible loop in the manifold. By imposing the flat-connection condition
of the Chern--Simons gauge fields, the path integral reduces to a
finite-dimensional matrix integral in
\(\mathrm{SL}(2,\mathbb{R})\times\mathrm{SL}(2,\mathbb{R})\) . Although
Chern-Simons theory is a topological theory, the resulting matrix integral
remains nontrivial due to noncompact directions and boundary constraints.
  The large-\(k\) expansion of the matrix integral is carried out by selecting
a classical configuration in the space of holonomies and expanding around it in
inverse powers of \(k\). The resulting coefficients of the asymptotic series
exhibit factorial growth, enabling us to apply the Borel resummation
techniques. Summation over these subleading sectors removes potential
ambiguities in the Borel integral and clarifies the emergence of a resurgent
transseries structure. In the Borel-resurgent analysis, we show that, despite
the apparent simplicity of the reduced action, the wedge geometry yields a rich
interplay of perturbative and non-perturbative phenomena. This work presents an
explicit example of how a finite-dimensional matrix integral in its expansions
is physically meaningful through Borel resummation.


### Quantum algorithms for the simulation of QCD processes in the perturbative regime
**Authors**: Herschel A. Chawdhry, Mathieu Pellen

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21177v1](http://arxiv.org/pdf/2412.21177v1)

**Abstract**: Theoretical predictions for high-energy collision processes at particle
colliders, such as the Large Hadron Collider (LHC), rely on calculations in
perturbative Quantum Chromodynamics (QCD), which are often computationally
challenging. In these conference proceedings, we explore the possibility of
using quantum computers to simulate QCD processes in the perturbative QCD
regime. In particular, as a first step towards that goal, we present quantum
circuits to simulate the colour part of perturbative QCD. The circuits are
validated by implementing them on a simulated quantum computer and verifying
the colour factors for several example Feynman diagrams.


### Hint at an axion-like particle from GRB 221009A
**Authors**: Giorgio Galanti, Lara Nava, Marco Roncadelli, Fabrizio Tavecchio, Giacomo Bonnoli

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21175v1](http://arxiv.org/pdf/2412.21175v1)

**Abstract**: The detection by the LHAASO Collaboration of the gamma-ray burst GRB 221009A
at redshift $z = 0.151$ with energies up to $(13-18) \, \rm TeV$ challenges
conventional physics. Photons emitted with energies above $10 \, \rm TeV$ at
this redshift can hardly be observed on Earth due to their interaction with the
extragalactic background light (EBL). We show that indeed the LHAASO
Collaboration should not have observed photons with energies above $10 \, \rm
TeV$ if the state-of-the-art EBL model by Saldana-Lopez et al. is taken into
account. A problem therefore arises: the Universe should be more transparent
than currently believed. We also show that the issue is solved if we introduce
the interaction of photons with axion-like particles (ALPs). ALPs are predicted
by String Theory, are among the best candidates for dark matter and can produce
spectral and polarization effects on astrophysical sources in the presence of
external magnetic fields. In particular, for GRB 221009A, photon-ALP
oscillations occur within the crossed magnetized media, i.e. the host galaxy,
the extragalactic space, the Milky Way, partially reducing the EBL absorption
to a level that explains the LHAASO detection of GRB 221009A and its observed
spectrum without the need of contrived choices of parameter values, which are
instead compulsory within proposed emission models within conventional physics.
This fact regarding GRB 221009A represents a strong hint at the ALP existence,
which adds to two other indications coming from blazars, a class of active
galactic nuclei.


### Quantum Error Correction near the Coding Theoretical Bound
**Authors**: Daiki Komoto, Kenta Kasai

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21171v1](http://arxiv.org/pdf/2412.21171v1)

**Abstract**: Recent advancements in quantum computing have led to the realization of
systems comprising tens of reliable logical qubits, constructed from thousands
of noisy physical qubits. However, many of the critical applications that
quantum computers aim to solve require quantum computations involving millions
or more logical qubits. This necessitates highly efficient quantum error
correction capable of handling large numbers of logical qubits. Classical error
correction theory is well-developed, with low-density parity-check (LDPC) codes
achieving performance limits by encoding large classical bits. Despite more
than two decades of effort, no efficiently decodable quantum error-correcting
code that approaches the hashing bound, which is a fundamental lower bound on
quantum capacity, had been discovered. Here, we present quantum
error-correcting codes constructed from classical LDPC codes that approach the
hashing bound while maintaining linear computational complexity in the number
of physical qubits. This result establishes a pathway toward realizing
large-scale, fault-tolerant quantum computers. By integrating our quantum error
correction scheme with devices capable of managing vast numbers of qubits, the
prospect of solving critical real-world problems through quantum computation is
brought significantly closer.


### Causality and Stability from Acoustic Geometry
**Authors**: Ignacy Sawicki, Georg Trenkler, Alexander Vikman

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21169v1](http://arxiv.org/pdf/2412.21169v1)

**Abstract**: Scalar-tensor theories with derivative interactions form backgrounds which
spontaneously break Lorentz invariance. We investigate the dynamics of free
scalar perturbations on general anisotropic backgrounds. We demonstrate that
the phonons move on null geodesics of an acoustic spacetime described by its
own metric and own connection featuring nonmetricity with respect to the usual
spacetime metric. We give distinct physical interpretations to the acoustic
metric and its inverse. The first defines rays and their phase velocities. The
latter defines momenta and the dispersion relation. We classify possible
acoustic geometries and provide a physical interpretation for them.
  We discuss the phonon properties that moving observers, inequivalent owing to
the breaking of Lorentz invariance, would measure. Ghosts and true gradient
instabilities are to be read off from invariant properties of the acoustic
metric - its signature and determinant. However, the choice of the observer's
frame can cause some confusion and paradoxes, including apparent instabilities.
For instance, complex phonon energies can appear entirely due to the
ill-posedness of the Cauchy problem in the frame chosen. On the other hand,
unbounded negative phonon energies can appear, without ghosts or gradient
instabilities, for observers moving supersonically, when phonon Cherenkov
radiation can be emitted.
  The action for phonons also gives an acoustically covariantly conserved
energy-momentum tensor (EMT) which is, however, not conserved in the usual
spacetime. Nonetheless, in the presence of an acoustic timelike Killing vector,
the acoustic Hamiltonian functional is a conserved charge in both the acoustic
and in the usual spacetimes, and even has the same value in both. Thus, the
acoustic Hamiltonian can be used to bound the motion of phonons interacting
with other species living in the usual spacetime.


### Measuring Quantum Discord at the LHC
**Authors**: Tao Han, Matthew Low, Navin McGinnis, Shufang Su

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21158v1](http://arxiv.org/pdf/2412.21158v1)

**Abstract**: There has been an increasing interest in exploring quantities associated with
quantum information at colliders. We perform a detailed analysis describing how
to measure the quantum discord in the top anti-top quantum state at the Large
Hadron Collider (LHC). While for pure states, quantum discord, entanglement,
and Bell nonlocality all probe the same correlations, for mixed states they
probe different aspects of quantum correlations. The quantum discord, in
particular, is interesting because it aims to encapsulate all correlations
between systems that cannot have a classical origin. We employ two
complementary approaches for the study of the top anti-top system, namely the
decay method and the kinematic method. We highlight subtleties associated with
measuring discord for reconstructed quantum states at colliders. Usually
quantum discord is difficult to compute due to an extremization that must be
performed. We show, however, that for the $t\bar{t}$ system this extremization
can be performed analytically and we provide closed-form formulas for the
quantum discord. We demonstrate that at the high luminosity LHC, discord is
projected to be measurable with a precision of approximately 5% using the decay
method and sub-percent levels using the kinematic method. Even with current LHC
datasets, discord can be measured with 1-2% precision with the kinematic
method. By systematically investigating quantum discord for the first time
through a detailed collider analysis, this work expands the toolkit for quantum
information studies in particle physics and lays the groundwork for deeper
insights into the quantum properties in high-energy collisions.


### Systematic Benchmarking of Macrosegregation: The Performance of a Modified Hybrid Model
**Authors**: Ali Moeinirad, Ehsan Amani

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21143v1](http://arxiv.org/pdf/2412.21143v1)

**Abstract**: Recently, a new alloy solidification benchmark, called AFRODITE, with
well-defined setups and state-of-the-art measurements has emerged, enabling a
thorough assessment of MacroSegregation (MS) solvers, particularly in terms of
their ability to predict different features of MS maps. In this research, we
first develop an analytical solution for the alloy-solidification Stefan
problem, which involves melt, solid, and mushy regions. This new analytical
solution extends a previous solution (S. Cho and J. Sunderland,
"Heat-conduction problems with melting or freezing", J. Heat Transfer, vol. 91,
pp. 421-426, 1969) by incorporating a linear microsegregation law as a function
of temperature in place of spatial coordinate. Then, we adopt this solution to
verify an OpenFOAM MS solver in a limiting condition, where only heat diffusion
is present. Subsequently, to capture the MS map of the Sn-3%Pb AFRODITE
benchmark, the solver is incorporated using the standard Blake-Kozeny-Carman
permeability law and one of its hybrid variants, slightly modified in this work
to better align with physics by ensuring a continuous transition of
characteristics from the slurry to the porous regions of the mush. It is
demonstrated that the hybrid model predicts the main features of the MS map,
including the channel segregates morphology and peak segregation degree due to
the pile-up effect, in much finer agreement with the experimental observation.
Careful analyses of the results reveal that these improved predictions stem
from the hybrid model's more accurate estimation of the re-melting, melt flow
advection parallel, and advection normal to the solidification front.


### DeepF-fNet: a physics-informed neural network for vibration isolation optimization
**Authors**: A. Tollardo, F. Cadini, M. Giglio, L. Lomazzi

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21132v1](http://arxiv.org/pdf/2412.21132v1)

**Abstract**: Structural optimization is essential for designing safe, efficient, and
durable components with minimal material usage. Traditional methods for
vibration control often rely on active systems to mitigate unpredictable
vibrations, which may lead to resonance and potential structural failure.
However, these methods face significant challenges when addressing the
nonlinear inverse eigenvalue problems required for optimizing structures
subjected to a wide range of frequencies. As a result, no existing approach has
effectively addressed the need for real-time vibration suppression within this
context, particularly in high-performance environments such as automotive
noise, vibration and harshness, where computational efficiency is crucial.
  This study introduces DeepF-fNet, a novel neural network framework designed
to replace traditional active systems in vibration-based structural
optimization. Leveraging DeepONets within the context of physics-informed
neural networks, DeepF-fNet integrates both data and the governing physical
laws. This enables rapid identification of optimal parameters to suppress
critical vibrations at specific frequencies, offering a more efficient and
real-time alternative to conventional methods.
  The proposed framework is validated through a case study involving a locally
resonant metamaterial used to isolate structures from user-defined frequency
ranges. The results demonstrate that DeepF-fNet outperforms traditional genetic
algorithms in terms of computational speed while achieving comparable results,
making it a promising tool for vibration-sensitive applications. By replacing
active systems with machine learning techniques, DeepF-fNet paves the way for
more efficient and cost-effective structural optimization in real-world
scenarios.


### High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces
**Authors**: Shihao Shao, Yikang Li, Zhouchen Lin, Qinghua Cui

**Published Date**: 2024-12-24

**Updated Date**: 2024-12-30

**PDF Url**: [2412.18263v2](http://arxiv.org/pdf/2412.18263v2)

**Abstract**: Irreducible Cartesian tensors (ICTs) play a crucial role in the design of
equivariant graph neural networks, as well as in theoretical chemistry and
chemical physics. Meanwhile, the design space of available linear operations on
tensors that preserve symmetry presents a significant challenge. The ICT
decomposition and a basis of this equivariant space are difficult to obtain for
high-order tensors. After decades of research, we recently achieve an explicit
ICT decomposition for $n=5$ \citep{bonvicini2024irreducible} with factorial
time/space complexity. This work, for the first time, obtains decomposition
matrices for ICTs up to rank $n=9$ with reduced and affordable complexity, by
constructing what we call path matrices. The path matrices are obtained via
performing chain-like contraction with Clebsch-Gordan matrices following the
parentage scheme. We prove and leverage that the concatenation of path matrices
is an orthonormal change-of-basis matrix between the Cartesian tensor product
space and the spherical direct sum spaces. Furthermore, we identify a complete
orthogonal basis for the equivariant space, rather than a spanning set
\citep{pearce2023brauer}, through this path matrices technique. We further
extend our result to the arbitrary tensor product and direct sum spaces,
enabling free design between different spaces while keeping symmetry. The
Python code is available in
https://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases where
the $n=6,\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and
4m32s, respectively.


## Diffusion
### Sparse chaos in cortical circuits
**Authors**: Rainer Engelken, Michael Monteforte, Fred Wolf

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21188v1](http://arxiv.org/pdf/2412.21188v1)

**Abstract**: Nerve impulses, the currency of information flow in the brain, are generated
by an instability of the neuronal membrane potential dynamics. Neuronal
circuits exhibit collective chaos that appears essential for learning, memory,
sensory processing, and motor control. However, the factors controlling the
nature and intensity of collective chaos in neuronal circuits are not well
understood. Here we use computational ergodic theory to demonstrate that basic
features of nerve impulse generation profoundly affect collective chaos in
neuronal circuits. Numerically exact calculations of Lyapunov spectra,
Kolmogorov-Sinai-entropy, and upper and lower bounds on attractor dimension
show that changes in nerve impulse generation in individual neurons moderately
impact information encoding rates but qualitatively transform phase space
structure. Specifically, we find a drastic reduction in the number of unstable
manifolds, Kolmogorov-Sinai entropy, and attractor dimension. Beyond a critical
point, marked by the simultaneous breakdown of the diffusion approximation, a
peak in the largest Lyapunov exponent, and a localization transition of the
leading covariant Lyapunov vector, networks exhibit sparse chaos: prolonged
periods of near stable dynamics interrupted by short bursts of intense chaos.
Analysis of large, more realistically structured networks supports the
generality of these findings. In cortical circuits, biophysical properties
appear tuned to this regime of sparse chaos. Our results reveal a close link
between fundamental aspects of single-neuron biophysics and the collective
dynamics of cortical circuits, suggesting that nerve impulse generation
mechanisms are adapted to enhance circuit controllability and information flow.


### Quantum Diffusion Model for Quark and Gluon Jet Generation
**Authors**: Mariia Baidachna, Rey Guadarrama, Gopal Ramesh Dahale, Tom Magorsch, Isabel Pedraza, Konstantin T. Matchev, Katia Matcheva, Kyoungchul Kong, Sergei Gleyzer

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21082v1](http://arxiv.org/pdf/2412.21082v1)

**Abstract**: Diffusion models have demonstrated remarkable success in image generation,
but they are computationally intensive and time-consuming to train. In this
paper, we introduce a novel diffusion model that benefits from quantum
computing techniques in order to mitigate computational challenges and enhance
generative performance within high energy physics data. The fully quantum
diffusion model replaces Gaussian noise with random unitary matrices in the
forward process and incorporates a variational quantum circuit within the U-Net
in the denoising architecture. We run evaluations on the structurally complex
quark and gluon jets dataset from the Large Hadron Collider. The results
demonstrate that the fully quantum and hybrid models are competitive with a
similar classical model for jet generation, highlighting the potential of using
quantum techniques for machine learning problems.


### PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion
**Authors**: Sophia Tang, Yinuo Zhang, Pranam Chatterjee

**Published Date**: 2024-12-23

**Updated Date**: 2024-12-30

**PDF Url**: [2412.17780v2](http://arxiv.org/pdf/2412.17780v2)

**Abstract**: Peptide therapeutics, a major class of medicines, have achieved remarkable
success across diseases such as diabetes and cancer, with landmark examples
such as GLP-1 receptor agonists revolutionizing the treatment of type-2
diabetes and obesity. Despite their success, designing peptides that satisfy
multiple conflicting objectives, such as target binding affinity, solubility,
and membrane permeability, remains a major challenge. Classical drug
development and structure-based design are ineffective for such tasks, as they
fail to optimize global functional properties critical for therapeutic
efficacy. Existing generative frameworks are largely limited to continuous
spaces, unconditioned outputs, or single-objective guidance, making them
unsuitable for discrete sequence optimization across multiple properties. To
address this, we present PepTune, a multi-objective discrete diffusion model
for the simultaneous generation and optimization of therapeutic peptide SMILES.
Built on the Masked Discrete Language Model (MDLM) framework, PepTune ensures
valid peptide structures with state-dependent masking schedules and
penalty-based objectives. To guide the diffusion process, we propose a Monte
Carlo Tree Search (MCTS)-based strategy that balances exploration and
exploitation to iteratively refine Pareto-optimal sequences. MCTS integrates
classifier-based rewards with search-tree expansion, overcoming gradient
estimation challenges and data sparsity inherent to discrete spaces. Using
PepTune, we generate diverse, chemically-modified peptides optimized for
multiple therapeutic properties, including target binding affinity, membrane
permeability, solubility, hemolysis, and non-fouling characteristics on various
disease-relevant targets. In total, our results demonstrate that MCTS-guided
discrete diffusion is a powerful and modular approach for multi-objective
sequence design in discrete state spaces.


### BridgePure: Revealing the Fragility of Black-box Data Protection
**Authors**: Yihan Wang, Yiwei Lu, Xiao-Shan Gao, Gautam Kamath, Yaoliang Yu

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.21061v1](http://arxiv.org/pdf/2412.21061v1)

**Abstract**: Availability attacks, or unlearnable examples, are defensive techniques that
allow data owners to modify their datasets in ways that prevent unauthorized
machine learning models from learning effectively while maintaining the data's
intended functionality. It has led to the release of popular black-box tools
for users to upload personal data and receive protected counterparts. In this
work, we show such black-box protections can be substantially bypassed if a
small set of unprotected in-distribution data is available. Specifically, an
adversary can (1) easily acquire (unprotected, protected) pairs by querying the
black-box protections with the unprotected dataset; and (2) train a diffusion
bridge model to build a mapping. This mapping, termed BridgePure, can
effectively remove the protection from any previously unseen data within the
same distribution. Under this threat model, our method demonstrates superior
purification performance on classification and style mimicry tasks, exposing
critical vulnerabilities in black-box data protection.


### AlignAb: Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies
**Authors**: Yibo Wen, Chenwei Xu, Jerry Yao-Chieh Hu, Han Liu

**Published Date**: 2024-12-30

**Updated Date**: 2024-12-30

**PDF Url**: [2412.20984v1](http://arxiv.org/pdf/2412.20984v1)

**Abstract**: We present a three-stage framework for training deep learning models
specializing in antibody sequence-structure co-design. We first pre-train a
language model using millions of antibody sequence data. Then, we employ the
learned representations to guide the training of a diffusion model for joint
optimization over both sequence and structure of antibodies. During the final
alignment stage, we optimize the model to favor antibodies with low repulsion
and high attraction to the antigen binding site, enhancing the rationality and
functionality of the designs. To mitigate conflicting energy preferences, we
extend AbDPO (Antibody Direct Preference Optimization) to guide the model
towards Pareto optimality under multiple energy-based alignment objectives.
Furthermore, we adopt an iterative learning paradigm with temperature scaling,
enabling the model to benefit from diverse online datasets without requiring
additional data. In practice, our proposed methods achieve high stability and
efficiency in producing a better Pareto front of antibody designs compared to
top samples generated by baselines and previous alignment techniques. Through
extensive experiments, we showcase the superior performance of our methods in
generating nature-like antibodies with high binding affinity consistently.


## Quantitative Finance
### GISExplainer: On Explainability of Graph Neural Networks via Game-theoretic Interaction Subgraphs
**Authors**: Xingping Xian, Jianlu Liu, Chao Wang, Tao Wu, Shaojie Qiao, Xiaochuan Tang, Qun Liu

**Published Date**: 2024-09-24

**Updated Date**: 2024-12-30

**PDF Url**: [2409.15698v2](http://arxiv.org/pdf/2409.15698v2)

**Abstract**: Explainability is crucial for the application of black-box Graph Neural
Networks (GNNs) in critical fields such as healthcare, finance, cybersecurity,
and more. Various feature attribution methods, especially the
perturbation-based methods, have been proposed to indicate how much each
node/edge contributes to the model predictions. However, these methods fail to
generate connected explanatory subgraphs that consider the causal interaction
between edges within different coalition scales, which will result in
unfaithful explanations. In our study, we propose GISExplainer, a novel
game-theoretic interaction based explanation method that uncovers what the
underlying GNNs have learned for node classification by discovering
human-interpretable causal explanatory subgraphs. First, GISExplainer defines a
causal attribution mechanism that considers the game-theoretic interaction of
multi-granularity coalitions in candidate explanatory subgraph to quantify the
causal effect of an edge on the prediction. Second, GISExplainer assumes that
the coalitions with negative effects on the predictions are also significant
for model interpretation, and the contribution of the computation graph stems
from the combined influence of both positive and negative interactions within
the coalitions. Then, GISExplainer regards the explanation task as a sequential
decision process, in which a salient edges is successively selected and
connected to the previously selected subgraph based on its causal effect to
form an explanatory subgraph, ultimately striving for better explanations.
Additionally, an efficiency optimization scheme is proposed for the causal
attribution mechanism through coalition sampling. Extensive experiments
demonstrate that GISExplainer achieves better performance than state-of-the-art
approaches w.r.t. two quantitative metrics: Fidelity and Sparsity.


### Digital transformation: A systematic review and bibliometric analysis from the corporate finance perspective
**Authors**: Ping Zhang, Yiru Wang

**Published Date**: 2024-12-13

**Updated Date**: 2024-12-13

**PDF Url**: [2412.19817v1](http://arxiv.org/pdf/2412.19817v1)

**Abstract**: Digital transformation significantly impacts firm investment, financing, and
value enhancement. A systematic investigation from the corporate finance
perspective has not yet been formed. This paper combines bibliometric and
content analysis methods to systematically review the evolutionary trend,
status quo, hotspots and overall structure of research in digital
transformation from 2011 to 2024. The study reveals an emerging and rapidly
growing focus on digital transformation research, particularly in developed
countries. We categorize the literature into three areas according to
bibliometric clustering: the measurements (qualitative and quantitative),
impact factors (internal and external), and the economic consequences
(investment, financing, and firm value). These areas are divided into ten
sub-branches, with a detailed literature review. We also review the existing
theories related to digital transformation, identify the current gaps in these
papers, and provide directions for future research on each sub-branches.


