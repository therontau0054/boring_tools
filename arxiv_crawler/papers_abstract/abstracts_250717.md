# Abstracts of Papers

## Physics
### Fault-tolerant fermionic quantum computing
**Authors**: Alexander Schuckert, Eleanor Crane, Alexey V. Gorshkov, Mohammad Hafezi, Michael J. Gullans

**Published Date**: 2024-11-13

**Updated Date**: 2025-07-16

**PDF Url**: [2411.08955v2](http://arxiv.org/pdf/2411.08955v2)

**Abstract**: Simulating the dynamics of electrons and other fermionic particles in quantum
chemistry, materials science, and high-energy physics is one of the most
promising applications of fault-tolerant quantum computers. However, the
overhead in mapping time evolution under fermionic Hamiltonians to qubit gates
renders this endeavor challenging. We introduce fermionic fault-tolerant
quantum computing, a framework which removes this overhead altogether. Using
native fermionic operations we first construct a repetition code which corrects
phase errors only. Within a fermionic color code, which corrects for both phase
and loss errors, we then realize a universal fermionic gate set, including
transversal fermionic Clifford gates. Interfacing with qubit color codes we
introduce qubit-fermion fault-tolerant computation, which allows for
qubit-controlled fermionic time evolution, a crucial subroutine in
state-of-the-art quantum algorithms. As an application, we consider simulating
crystalline materials, finding an exponential improvement in circuit depth for
a single time step from $\mathcal{O}(N)$ to $\mathcal{O}(\log(N))$ with respect
to lattice site number $N$ while retaining a site count of
$\tilde{\mathcal{O}}(N)$, implying a linear-in-$N$ end-to-end gate depth for
simulating materials, as opposed to quadratic in previous approaches. We also
introduce a fermion-inspired qubit algorithm with $O(\mathrm{log}(N)$ depth,
but a prohibitive number of additional ancilla qubits. We show how our
framework can be implemented in neutral atoms, overcoming the apparent
inability of neutral atoms to implement non-number-conserving gates. Our work
opens the door to fermion-qubit fault-tolerant quantum computation in platforms
with native fermions such as neutral atoms, quantum dots and donors in silicon,
with applications in quantum chemistry, material science, and high-energy
physics.


### The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data
**Authors**: Fakrul Islam Tushar, Lavsen Dahal, Saman Sotoudeh-Paima, Ehsan Abadi, W. Paul Segars, Ehsan Samei, Joseph Y. Lo

**Published Date**: 2023-08-17

**Updated Date**: 2025-07-16

**PDF Url**: [2308.09730v5](http://arxiv.org/pdf/2308.09730v5)

**Abstract**: Purpose: The credibility of Artificial Intelligence (AI) models for medical
imaging continues to be a challenge, affected by the diversity of models, the
data used to train the models, and applicability of their combination to
produce reproducible results for new data. Approach: In this work we aimed to
explore if the emerging Virtual Imaging Trials (VIT) methodologies can provide
an objective resource to approach this challenge. The study was conducted for
the case example of COVID-19 diagnosis using clinical and virtual computed
tomography (CT) and chest radiography (CXR) processed with convolutional neural
networks. Multiple AI models were developed and tested using 3D ResNet-like and
2D EfficientNetv2 architectures across diverse datasets. Results: The
performance differences were evaluated in terms of the area under the curve
(AUC) and the DeLong method for AUC confidence intervals. The models trained on
the most diverse datasets showed the highest external testing performance, with
AUC values ranging from 0.73-0.76 for CT and 0.70-0.73 for CXR. Internal
testing yielded higher AUC values (0.77 -0.85 for CT and 0.77-1.0 for CXR),
highlighting a substantial drop in performance during external validation,
which underscores the importance of diverse and comprehensive training and
testing data. Most notably, VIT approach provided objective assessment of the
utility of diverse models and datasets while further providing insight into the
influence of dataset characteristics, patient factors, and imaging physics on
AI efficacy. Conclusions: The VIT approach can be used to enhance model
transparency and reliability, offering nuanced insights into the factors
driving AI performance and bridging the gap between experimental and clinical
settings.


### Radiation-Reaction on the Straight-Line Motion of a Point Charge accelerated by a constant applied Electric Field in an Electromagnetic Bopp-Landé-Thomas-Podolsky vacuum
**Authors**: Ryan J. McGuigan, Michael K. -H. Kiessling

**Published Date**: 2025-06-10

**Updated Date**: 2025-07-16

**PDF Url**: [2506.08799v2](http://arxiv.org/pdf/2506.08799v2)

**Abstract**: The radiation-reaction problem of standard Lorentz electrodynamics with point
charges is pathological, standing in contrast to
Bopp--Land\'e--Thomas--Podolsky (BLTP) electrodynamics where it is in fact
well-defined and calculable, as reported in a previous publication. To
demonstrate the viability of BLTP electrodynamics, we consider the BLTP
analogue of the radiation reaction of a classical point charge accelerated from
rest by a static homogeneous capacitor plate field, and calculate it up to
$O(\varkappa^4)$ in a formal expansion about $\varkappa=0$ in powers of
$\varkappa$, Bopp's reciprocal length, a new electrodynamics parameter
introduced by BLTP theory. In a paper by Carley and Kiessling (arXiv:2303.01720
[physics.class-ph]) the radiation-reaction corrections to test-particle motion
were explicitly computed to $O(\varkappa^3)$, the first non-vanishing order. In
this article a crucial question regarding this ``small-$\varkappa$'' expansion,
raised by Carley and Kiessling, is answered as follows: The motions computed
with terms $O(\varkappa^3)$ included are mathematically accurate approximations
to {physically reasonable} solutions of the actual BLTP initial value problem
for short times $t$, viz. when $\varkappa c t \ll 1$, where $c$ is the speed of
light in vacuo, but their unphysical behavior over {much} longer times does not
accurately approximate the actual BLTP solutions even when the dimensionless
parameter $\varkappa e^2 / |m_b| c^2 \ll 1$, where $e$ is the elementary charge
and $m_b$ the bare rest mass of the electron. This has the important
implication that BLTP electrodynamics remains a viable contender for an
accurate classical electrodynamics with point charges that does not suffer from
the infinite self-interaction problems of textbook Lorentz electrodynamics with
point charges.


### "Is it always watching? Is it always listening?" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots
**Authors**: Henry Bell, Jabari Kwesi, Hiba Laabadli, Pardis Emami-Naeini

**Published Date**: 2025-07-14

**Updated Date**: 2025-07-16

**PDF Url**: [2507.10786v2](http://arxiv.org/pdf/2507.10786v2)

**Abstract**: Equipped with artificial intelligence (AI) and advanced sensing capabilities,
social robots are gaining interest among consumers in the United States. These
robots seem like a natural evolution of traditional smart home devices.
However, their extensive data collection capabilities, anthropomorphic
features, and capacity to interact with their environment make social robots a
more significant security and privacy threat. Increased risks include data
linkage, unauthorized data sharing, and the physical safety of users and their
homes. It is critical to investigate U.S. users' security and privacy needs and
concerns to guide the design of social robots while these devices are still in
the early stages of commercialization in the U.S. market. Through 19
semi-structured interviews, we identified significant security and privacy
concerns, highlighting the need for transparency, usability, and robust privacy
controls to support adoption. For educational applications, participants
worried most about misinformation, and in medical use cases, they worried about
the reliability of these devices. Participants were also concerned with the
data inference that social robots could enable. We found that participants
expect tangible privacy controls, indicators of data collection, and
context-appropriate functionality.


### Bounding the asymptotic quantum value of all multipartite compiled non-local games
**Authors**: Matilde Baroni, Dominik Leichtle, Siniša Janković, Ivan Šupić

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12408v1](http://arxiv.org/pdf/2507.12408v1)

**Abstract**: Non-local games are a powerful tool to distinguish between correlations
possible in classical and quantum worlds. Kalai et al. (STOC'23) proposed a
compiler that converts multipartite non-local games into interactive protocols
with a single prover, relying on cryptographic tools to remove the assumption
of physical separation of the players. While quantum completeness and classical
soundness of the construction have been established for all multipartite games,
quantum soundness is known only in the special case of bipartite games.
  In this paper, we prove that the Kalai et al.'s compiler indeed achieves
quantum soundness for all multipartite compiled non-local games, by showing
that any correlations that can be generated in the asymptotic case correspond
to quantum commuting strategies.
  Our proof uses techniques from the theory of operator algebras, and relies on
a characterisation of sequential operationally no-signalling strategies as
quantum commuting operator strategies in the multipartite case, thereby
generalising several previous results. On the way, we construct universal
C*-algebras of sequential PVMs and prove a new chain rule for Radon-Nikodym
derivatives of completely positive maps on C*-algebras which may be of
independent interest.


### Light Scalars in the Extended Georgi-Machacek Model
**Authors**: Poulami Mondal, Subrata Samanta

**Published Date**: 2025-06-06

**Updated Date**: 2025-07-16

**PDF Url**: [2506.06427v2](http://arxiv.org/pdf/2506.06427v2)

**Abstract**: We perform global fits of the CP-conserving Georgi-Machacek (GM) and extended
Georgi-Machacek (eGM) models, incorporating a light CP-even beyond the Standard
Model (BSM) scalar within the mass range of $90$ GeV to $100$ GeV. These fits
combine the Higgs signal strengths and direct search limits from ATLAS and CMS
at $\sqrt{s} = 8$ and $13$ TeV, $B$-physics observables, and theoretical
constraints arising from next-to-leading order (NLO) unitarity and BFB
constraints. From the global fit, we show that the LHC diphoton and LEP
$b\bar{b}$ excesses around $95$ GeV are well compatible with the $125$ GeV
Higgs data. Whereas the CMS ditau excess is incompatible with the $125$ GeV
Higgs signal strength data in both the CP-conserving GM and eGM models. We
present the results from the combined fit, including the $95$ GeV Higgs signal
strength data. In the eGM model, the triplet VEV cannot exceed $12$ GeV for
additional BSM scalar masses below $160$ GeV and approximately $20$ GeV for
additional BSM scalar masses above $160$ GeV. The masses of additional BSM
scalars cannot exceed $600$ GeV. The maximum mass splitting is of around $120$
GeV within the members of each custodial multiplet, and up to $250$ GeV between
the members of different multiplets. In the GM model, these constraints become
more stringent: the triplet VEV is limited to below $15$ GeV, which tightens to
$4$ GeV once the BSM scalar masses are below $160$ GeV. Masses of the quintet
$m_5$ and the triplet $m_3$ are restricted to be below $530$ GeV and $320$ GeV,
respectively. A mass hierarchy, $m_5 > m_3$, is favoured in the high-mass
region, with the mass splitting constrained to be less than $210$ GeV.


### Deep Learning-Assisted Fourier Analysis for High-Efficiency Structural Design: A Case Study on Three-Dimensional Photonic Crystals Enumeration
**Authors**: Congcong Cui, Guangfeng Wei, Matthias Saba, Yuanyuan Cao, Lu Han

**Published Date**: 2025-01-30

**Updated Date**: 2025-07-16

**PDF Url**: [2501.18495v2](http://arxiv.org/pdf/2501.18495v2)

**Abstract**: The geometric design of structures with optimized physical and chemical
properties is one of the core topics in materials science. However, designing
new functional materials is challenging due to the vast number of existing and
the possible unknown structures to be enumerated and difficulties in mining the
underlying correlations between structures and their properties. Here, we
propose a universal method for periodic structural design and property
optimization. The key in our approach is a deep-learning assisted inverse
Fourier transform, which enables the creation of arbitrary geometries within
crystallographic space groups. It effectively explores extensive parameter
spaces to identify ideal structures with desired properties. Taking the
research of three-dimensional (3D) photonic structures as a case study, this
method is capable of modelling numerous structures and identifying their
photonic bandgaps in just a few hours. We confirmed the established knowledge
that the widest photonic bandgaps exist in network morphologies, among which
the single diamond (dia net) reigns supreme. Additionally, this method
identified a rarely-known lcs topology with excellent photonic properties,
highlighting the infinitely extensible application boundaries of our approach.
This work demonstrates the high efficiency and effectiveness of the
Fourier-based method, advancing material design and providing insights for
next-generation functional materials.


### Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts
**Authors**: Yeming Xian, Xiaoming Wang, Yanfa Yan

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12404v1](http://arxiv.org/pdf/2507.12404v1)

**Abstract**: Understanding and predicting the activity of oxide perovskite catalysts for
the oxygen evolution reaction (OER) requires descriptors that are both accurate
and physically interpretable. While symbolic regression (SR) offers a path to
discover such formulas, its performance degrades with high-dimensional inputs
and small datasets. We present a two-phase framework that combines neural
networks (NN), feature importance analysis, and symbolic regression (SR) to
discover interpretable descriptors for OER activity in oxide perovskites. In
Phase I, using a small dataset and seven structural features, we reproduce and
improve the known {\mu}/t descriptor by engineering composite features and
applying symbolic regression, achieving training and validation MAEs of 22.8
and 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce
dimensionality, and identify LUMO energy as a key electronic descriptor. A
final formula using {\mu}/t, {\mu}/RA, and LUMO energy achieves improved
accuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong
physical interpretability. Our results demonstrate that NN-guided symbolic
regression enables accurate, interpretable, and physically meaningful
descriptor discovery in data-scarce regimes, indicating interpretability need
not sacrifice accuracy for materials informatics.


### Beyond Ground States: Physics-Inspired Optimization of Excited States of Classical Hamiltonians
**Authors**: Erik Altelarrea-Ferré, Júlia Barberà-Rodríguez, David Jansen, Antonio Acín

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12394v1](http://arxiv.org/pdf/2507.12394v1)

**Abstract**: We introduce excited local quantum annealing (ExcLQA), a classical,
physics-inspired algorithm that extends local quantum annealing (LQA) to
identify excited states of classical Ising Hamiltonians. LQA simulates quantum
annealing while constraining the quantum state to remain in a product state and
uses a gradient-based approach to find approximate solutions to large-scale
quadratic unconstrained binary optimization problems. ExcLQA extends this
framework by adding a penalty term in the cost function to target excited
states, with a single hyperparameter that can be tuned via binary search to set
the desired penalization level. We benchmark ExcLQA on the shortest vector
problem (SVP), a fundamental lattice problem underlying the security of many
postquantum cryptographic schemes. Solving an SVP instance can be mapped to
identifying the first excited state of a Hamiltonian, with approximate
solutions located among nearby excited states. Our results show that ExcLQA
manages to solve SVP instances up to rank 46, and outperforms the
Metropolis-Hastings algorithm in solved ratio, number of shots, and
approximation factor in the tested instances.


### Derivation of the time-dependent Hartree equations for strongly interacting dense fermionic systems
**Authors**: Duc Viet Hoang, David Mitrouskas, Peter Pickl

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12390v1](http://arxiv.org/pdf/2507.12390v1)

**Abstract**: The time-dependent Hartree and Hartree-Fock equations provide effective
mean-field descriptions for the dynamics of large fermionic systems and play a
fundamental role in many areas of physics. In this work, we rigorously derive
the time-dependent Hartree equations as the large-$N$ limit of the microscopic
Schr\"odinger dynamics of $N$ fermions confined to a volume of order one and
interacting via strong pair potentials. A central step in our analysis is the
implementation of time-dependent gauge transformations, which eliminate the
dominant contribution from the interaction potential in both the Schr\"odinger
and Hartree evolutions.


## Diffusion
### Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models
**Authors**: Samuel Lavoie, Michael Noukhovitch, Aaron Courville

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12318v1](http://arxiv.org/pdf/2507.12318v1)

**Abstract**: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.


### RadioDiff-3D: A 3D$\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication
**Authors**: Xiucheng Wang, Qiming Zhang, Nan Cheng, Junting Chen, Zezhong Zhang, Zan Li, Shuguang Cui, Xuemin Shen

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12166v1](http://arxiv.org/pdf/2507.12166v1)

**Abstract**: Radio maps (RMs) serve as a critical foundation for enabling
environment-aware wireless communication, as they provide the spatial
distribution of wireless channel characteristics. Despite recent progress in RM
construction using data-driven approaches, most existing methods focus solely
on pathloss prediction in a fixed 2D plane, neglecting key parameters such as
direction of arrival (DoA), time of arrival (ToA), and vertical spatial
variations. Such a limitation is primarily due to the reliance on static
learning paradigms, which hinder generalization beyond the training data
distribution. To address these challenges, we propose UrbanRadio3D, a
large-scale, high-resolution 3D RM dataset constructed via ray tracing in
realistic urban environments. UrbanRadio3D is over 37$\times$3 larger than
previous datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,
forming a novel 3D$\times$33D dataset with 7$\times$3 more height layers than
prior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet
with 3D convolutional operators is proposed. Moreover, we further introduce
RadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D
convolutional architecture. RadioDiff-3D supports both radiation-aware
scenarios with known transmitter locations and radiation-unaware settings based
on sparse spatial observations. Extensive evaluations on UrbanRadio3D validate
that RadioDiff-3D achieves superior performance in constructing rich,
high-dimensional radio maps under diverse environmental dynamics. This work
provides a foundational dataset and benchmark for future research in 3D
environment-aware communication. The dataset is available at
https://github.com/UNIC-Lab/UrbanRadio3D.


### FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale
**Authors**: Boris Bonev, Thorsten Kurth, Ankur Mahesh, Mauro Bisson, Jean Kossaifi, Karthik Kashinath, Anima Anandkumar, William D. Collins, Michael S. Pritchard, Alexander Keller

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12144v1](http://arxiv.org/pdf/2507.12144v1)

**Abstract**: FourCastNet 3 advances global weather modeling by implementing a scalable,
geometric machine learning (ML) approach to probabilistic ensemble forecasting.
The approach is designed to respect spherical geometry and to accurately model
the spatially correlated probabilistic nature of the problem, resulting in
stable spectra and realistic dynamics across multiple scales. FourCastNet 3
delivers forecasting accuracy that surpasses leading conventional ensemble
models and rivals the best diffusion-based methods, while producing forecasts 8
to 60 times faster than these approaches. In contrast to other ML approaches,
FourCastNet 3 demonstrates excellent probabilistic calibration and retains
realistic spectra, even at extended lead times of up to 60 days. All of these
advances are realized using a purely convolutional neural network architecture
tailored for spherical geometry. Scalable and efficient large-scale training on
1024 GPUs and more is enabled by a novel training paradigm for combined model-
and data-parallelism, inspired by domain decomposition methods in classical
numerical models. Additionally, FourCastNet 3 enables rapid inference on a
single GPU, producing a 90-day global forecast at 0.25{\deg}, 6-hourly
resolution in under 20 seconds. Its computational efficiency, medium-range
probabilistic skill, spectral fidelity, and rollout stability at subseasonal
timescales make it a strong candidate for improving meteorological forecasting
and early warning systems through large ensemble predictions.


### RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization
**Authors**: Vladimir Bogachev, Vladimir Aletov, Alexander Molozhavenko, Denis Bobkov, Vera Soboleva, Aibek Alanov, Maxim Rakhuba

**Published Date**: 2025-07-16

**Updated Date**: 2025-07-16

**PDF Url**: [2507.12142v1](http://arxiv.org/pdf/2507.12142v1)

**Abstract**: Low-Rank Adaptation (LoRA) has become a widely adopted standard for
parameter-efficient fine-tuning of large language models (LLMs), significantly
reducing memory and computational demands. However, challenges remain,
including finding optimal initialization strategies or mitigating
overparametrization in low-rank matrix factorization. In this work, we propose
a novel approach that addresses both of the challenges simultaneously within a
unified framework. Our method treats a set of fixed-rank LoRA matrices as a
smooth manifold. Considering adapters as elements on this manifold removes
overparametrization, while determining the direction of the fastest loss
decrease along the manifold provides initialization. Special care is taken to
obtain numerically stable and computationally efficient implementation of our
method, using best practices from numerical linear algebra and Riemannian
optimization. Experimental results on LLM and diffusion model architectures
demonstrate that RiemannLoRA consistently improves both convergence speed and
final performance over standard LoRA and its state-of-the-art modifications.


### Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction
**Authors**: Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li

**Published Date**: 2025-03-14

**Updated Date**: 2025-07-16

**PDF Url**: [2503.11167v3](http://arxiv.org/pdf/2503.11167v3)

**Abstract**: Decoding visual stimuli from neural activity is essential for understanding
the human brain. While fMRI methods have successfully reconstructed static
images, fMRI-to-video reconstruction faces challenges due to the need for
capturing spatiotemporal dynamics like motion and scene transitions. Recent
approaches have improved semantic and perceptual alignment but struggle to
integrate coarse fMRI data with detailed visual features. Inspired by the
hierarchical organization of the visual system, we propose NEURONS, a novel
framework that decouples learning into four correlated sub-tasks: key object
segmentation, concept recognition, scene description, and blurry video
reconstruction. This approach simulates the visual cortex's functional
specialization, allowing the model to capture diverse video content. In the
inference stage, NEURONS generates robust conditioning signals for a
pre-trained text-to-video diffusion model to reconstruct the videos. Extensive
experiments demonstrate that NEURONS outperforms state-of-the-art baselines,
achieving solid improvements in video consistency (26.6%) and semantic-level
accuracy (19.1%). Notably, NEURONS shows a strong functional correlation with
the visual cortex, highlighting its potential for brain-computer interfaces and
clinical applications. Code and model weights are available at:
https://github.com/xmed-lab/NEURONS.


