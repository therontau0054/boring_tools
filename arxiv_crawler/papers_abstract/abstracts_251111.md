# Abstracts of Papers

## Physics
### Robot Learning from a Physical World Model
**Authors**: Jiageng Mao, Sicheng He, Hao-Ning Wu, Yang You, Shuyang Sun, Zhicheng Wang, Yanan Bao, Huizhong Chen, Leonidas Guibas, Vitor Guizilini, Howard Zhou, Yue Wang

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07416v1](http://arxiv.org/pdf/2511.07416v1)

**Abstract**: We introduce PhysWorld, a framework that enables robot learning from video
generation through physical world modeling. Recent video generation models can
synthesize photorealistic visual demonstrations from language commands and
images, offering a powerful yet underexplored source of training signals for
robotics. However, directly retargeting pixel motions from generated videos to
robots neglects physics, often resulting in inaccurate manipulations. PhysWorld
addresses this limitation by coupling video generation with physical world
reconstruction. Given a single image and a task command, our method generates
task-conditioned videos and reconstructs the underlying physical world from the
videos, and the generated video motions are grounded into physically accurate
actions through object-centric residual reinforcement learning with the
physical world model. This synergy transforms implicit visual guidance into
physically executable robotic trajectories, eliminating the need for real robot
data collection and enabling zero-shot generalizable robotic manipulation.
Experiments on diverse real-world tasks demonstrate that PhysWorld
substantially improves manipulation accuracy compared to previous approaches.
Visit \href{https://pointscoder.github.io/PhysWorld_Web/}{the project webpage}
for details.


### Higher Spins, Holography and Exotic Matter
**Authors**: Carlo Iazeolla, Per Sundell

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07408v1](http://arxiv.org/pdf/2511.07408v1)

**Abstract**: We review a new perspective on higher-spin holography, whereby Vasiliev's 4D
higher-spin gravity emerges together with a 3D counterpart, consisting of
coloured conformal matter fields coupled to topological conformal higher-spin
and colour gauge fields, as two distinct reductions, characterised by dual
structure groups, of a common parent model. The latter is given by a
non-commutative AKSZ sigma model consisting on-shell of a flat superconnection
valued in a fractional-spin extension of Fradkin-Vasiliev's higher-spin
algebra. In particular, we highlight an intermediate 4D reduction, referred to
fractional-spin gravity, consisting of exotic matter, in the form of coloured
singletons, coupled to higher-spin and colour gauge fields.


### The ideal limit of rhombohedral graphene: Interaction-induced layer-skyrmion lattices and their collective excitations
**Authors**: Tixuan Tan, Patrick J. Ledwith, Trithep Devakul

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07402v1](http://arxiv.org/pdf/2511.07402v1)

**Abstract**: We introduce an ideal limit of rhombohedral graphene multilayers. In this
limit, we show analytically how short-range repulsion stabilizes a
layer-pseudospin skyrmion lattice, which generates an effective magnetic field
and gives rise to a Chern band. This establishes the real-space origin of
interaction-driven topology in moir\'e rhombohedral graphene. The resulting
interaction-induced skyrmion lattice is physically analogous to magnetic
skyrmion crystals and hosts a hierarchy of collective excitations naturally
described within the framework of skyrmion-lattice dynamics.


### Lagrangian neural ODEs: Measuring the existence of a Lagrangian with Helmholtz metrics
**Authors**: Luca Wolf, Tobias Buck, Bjoern Malte Schaefer

**Published Date**: 2025-10-07

**Updated Date**: 2025-11-10

**PDF Url**: [2510.06367v2](http://arxiv.org/pdf/2510.06367v2)

**Abstract**: Neural ODEs are a widely used, powerful machine learning technique in
particular for physics. However, not every solution is physical in that it is
an Euler-Lagrange equation. We present Helmholtz metrics to quantify this
resemblance for a given ODE and demonstrate their capabilities on several
fundamental systems with noise. We combine them with a second order neural ODE
to form a Lagrangian neural ODE, which allows to learn Euler-Lagrange equations
in a direct fashion and with zero additional inference cost. We demonstrate
that, using only positional data, they can distinguish Lagrangian and
non-Lagrangian systems and improve the neural ODE solutions.


### Machine-Learning Accelerated Calculations of Reduced Density Matrices
**Authors**: Awwab A. Azam, Lexu Zhao, Jiabin Yu

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07367v1](http://arxiv.org/pdf/2511.07367v1)

**Abstract**: $n$-particle reduced density matrices ($n$-RDMs) play a central role in
understanding correlated phases of matter. Yet the calculation of $n$-RDMs is
often computationally inefficient for strongly-correlated states, particularly
when the system sizes are large. In this work, we propose to use neural network
(NN) architectures to accelerate the calculation of, and even predict, the
$n$-RDMs for large-size systems. The underlying intuition is that $n$-RDMs are
often smooth functions over the Brillouin zone (BZ) (certainly true for gapped
states) and are thus interpolable, allowing NNs trained on small-size $n$-RDMs
to predict large-size ones. Building on this intuition, we devise two NNs: (i)
a self-attention NN that maps random RDMs to physical ones, and (ii) a
Sinusoidal Representation Network (SIREN) that directly maps momentum-space
coordinates to RDM values. We test the NNs in three 2D models: the pair-pair
correlation functions of the Richardson model of superconductivity, the
translationally-invariant 1-RDM in a four-band model with short-range
repulsion, and the translation-breaking 1-RDM in the half-filled Hubbard model.
We find that a SIREN trained on a $6\times 6$ momentum mesh can predict the
$18\times 18$ pair-pair correlation function with a relative accuracy of
$0.839$. The NNs trained on $6\times 6 \sim 8\times 8$ meshes can provide
high-quality initial guesses for $50\times 50$ translation-invariant
Hartree-Fock (HF) and $30\times 30$ fully translation-breaking-allowed HF,
reducing the number of iterations required for convergence by up to $91.63\%$
and $92.78\%$, respectively, compared to random initializations. Our results
illustrate the potential of using NN-based methods for interpolable $n$-RDMs,
which might open a new avenue for future research on strongly correlated
phases.


### Some of the many uses of scalar fields: kinks, lumps, and geometric constraints
**Authors**: D. Bazeia, R. Menezes

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07360v1](http://arxiv.org/pdf/2511.07360v1)

**Abstract**: This perspective deals with real scalar fields in two-dimensional spacetime.
We focus on models described by one and two real scalar fields, paying closer
attention to kinks and lumps, which are localized structures of current
interest in high energy physics and in other areas of nonlinear science. We
briefly review some of the main results presented in the literature and then
focus on some new issues concerning the compact and long-range behavior of
solutions and the presence of geometric constraints, suggesting how they can be
used in applications in other areas of nonlinear science.


### The algebraic structure of the gradient expansion in linearised classical hydrodynamics
**Authors**: Sa≈°o Grozdanov, Mile Vrbica

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07357v1](http://arxiv.org/pdf/2511.07357v1)

**Abstract**: In this work, we systematically treat the ambiguities that generically arise
in the gradient expansion of any hydrodynamic theory. While these ambiguities
do not affect the physical content of the equations, they induce two types of
transformations in the space of transport coefficients. The first type is known
as the 'frame' transformations, and amounts to field redefinitions. The second
type, which we introduce and formalise here, we term the 'on-shell'
transformations. This identifies equivalence classes of hydrodynamic theories
that provide an equally valid low-energy description of the underlying
microscopic theory. We show that in any (classical) theory of hydrodynamics (at
arbitrary order in derivatives), the action of such transformations on the
dispersion relations and two-point correlation functions is universal. We
explicitly construct invariants which can then be matched to a microscopic
theory. Among them are, expectedly, the low-momentum expansions of the
hydrodynamic modes. The (unphysical) gapped modes can, however, be added or
removed at will. Finally, we show that such transformations assign a nilpotent
Lie group to every hydrodynamic theory, and discuss the related algebraic
properties underlying classical hydrodynamics.


### Sensitivity Analysis for Climate Science with Generative Flow Models
**Authors**: Alex Dobra, Jakiw Pidstrigach, Tim Reichelt, Christian Schroeder de Witt, Philip Torr, Philip Stier

**Published Date**: 2025-11-01

**Updated Date**: 2025-11-10

**PDF Url**: [2511.00663v2](http://arxiv.org/pdf/2511.00663v2)

**Abstract**: Sensitivity analysis is a cornerstone of climate science, essential for
understanding phenomena ranging from storm intensity to long-term climate
feedbacks. However, computing these sensitivities using traditional physical
models is often prohibitively expensive in terms of both computation and
development time. While modern AI-based generative models are orders of
magnitude faster to evaluate, computing sensitivities with them remains a
significant bottleneck. This work addresses this challenge by applying the
adjoint state method for calculating gradients in generative flow models. We
apply this method to the cBottle generative model, trained on ERA5 and ICON
data, to perform sensitivity analysis of any atmospheric variable with respect
to sea surface temperatures. We quantitatively validate the computed
sensitivities against the model's own outputs. Our results provide initial
evidence that this approach can produce reliable gradients, reducing the
computational cost of sensitivity analysis from weeks on a supercomputer with a
physical model to hours on a GPU, thereby simplifying a critical workflow in
climate science. The code can be found at
https://github.com/Kwartzl8/cbottle_adjoint_sensitivity.


### Defect Fusion and Casimir Energy in Higher Dimensions
**Authors**: Oleksandr Diatlyk, Himanshu Khanchandani, Fedor K. Popov, Yifan Wang

**Published Date**: 2024-04-08

**Updated Date**: 2025-11-10

**PDF Url**: [2404.05815v4](http://arxiv.org/pdf/2404.05815v4)

**Abstract**: We study the operator algebra of extended conformal defects in more than two
spacetime dimensions. Such algebra structure encodes the combined effect of
multiple impurities on physical observables at long distances as well as the
interactions among the impurities. These features are formalized by a fusion
product which we define for a pair of defects, after isolating divergences that
capture the effective potential between the defects, which generalizes the
usual Casimir energy. We discuss general properties of the corresponding fusion
algebra and contrast with the more familiar cases that involve topological
defects. We also describe the relation to a different defect setup in the shape
of a wedge. We provide explicit examples to illustrate these properties using
line defects and interfaces in the Wilson-Fisher CFT and the
Gross-Neveu(-Yukawa) CFT and determine the defect fusion data thereof.


### NOWS: Neural Operator Warm Starts for Accelerating Iterative Solvers
**Authors**: Mohammad Sadegh Eshaghi, Cosmin Anitescu, Navid Valizadeh, Yizheng Wang, Xiaoying Zhuang, Timon Rabczuk

**Published Date**: 2025-11-04

**Updated Date**: 2025-11-10

**PDF Url**: [2511.02481v3](http://arxiv.org/pdf/2511.02481v3)

**Abstract**: Partial differential equations (PDEs) underpin quantitative descriptions
across the physical sciences and engineering, yet high-fidelity simulation
remains a major computational bottleneck for many-query, real-time, and design
tasks. Data-driven surrogates can be strikingly fast but are often unreliable
when applied outside their training distribution. Here we introduce Neural
Operator Warm Starts (NOWS), a hybrid strategy that harnesses learned solution
operators to accelerate classical iterative solvers by producing high-quality
initial guesses for Krylov methods such as conjugate gradient and GMRES. NOWS
leaves existing discretizations and solver infrastructures intact, integrating
seamlessly with finite-difference, finite-element, isogeometric analysis,
finite volume method, etc. Across our benchmarks, the learned initialization
consistently reduces iteration counts and end-to-end runtime, resulting in a
reduction of the computational time of up to 90 %, while preserving the
stability and convergence guarantees of the underlying numerical algorithms. By
combining the rapid inference of neural operators with the rigor of traditional
solvers, NOWS provides a practical and trustworthy approach to accelerate
high-fidelity PDE simulations.


## Diffusion
### StreamDiffusionV2: A Streaming System for Dynamic and Interactive Video Generation
**Authors**: Tianrui Feng, Zhi Li, Shuo Yang, Haocheng Xi, Muyang Li, Xiuyu Li, Lvmin Zhang, Keting Yang, Kelly Peng, Song Han, Maneesh Agrawala, Kurt Keutzer, Akio Kodaira, Chenfeng Xu

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07399v1](http://arxiv.org/pdf/2511.07399v1)

**Abstract**: Generative models are reshaping the live-streaming industry by redefining how
content is created, styled, and delivered. Previous image-based streaming
diffusion models have powered efficient and creative live streaming products
but have hit limits on temporal consistency due to the foundation of
image-based designs. Recent advances in video diffusion have markedly improved
temporal consistency and sampling efficiency for offline generation. However,
offline generation systems primarily optimize throughput by batching large
workloads. In contrast, live online streaming operates under strict
service-level objectives (SLOs): time-to-first-frame must be minimal, and every
frame must meet a per-frame deadline with low jitter. Besides, scalable
multi-GPU serving for real-time streams remains largely unresolved so far. To
address this, we present StreamDiffusionV2, a training-free pipeline for
interactive live streaming with video diffusion models. StreamDiffusionV2
integrates an SLO-aware batching scheduler and a block scheduler, together with
a sink-token--guided rolling KV cache, a motion-aware noise controller, and
other system-level optimizations. Moreover, we introduce a scalable pipeline
orchestration that parallelizes the diffusion process across denoising steps
and network layers, achieving near-linear FPS scaling without violating latency
guarantees. The system scales seamlessly across heterogeneous GPU environments
and supports flexible denoising steps (e.g., 1--4), enabling both
ultra-low-latency and higher-quality modes. Without TensorRT or quantization,
StreamDiffusionV2 renders the first frame within 0.5s and attains 58.28 FPS
with a 14B-parameter model and 64.52 FPS with a 1.3B-parameter model on four
H100 GPUs, making state-of-the-art generative live streaming practical and
accessible--from individual creators to enterprise-scale platforms.


### A Diffusion Model to Shrink Proteins While Maintaining Their Function
**Authors**: Ethan Baron, Alan N. Amin, Ruben Weitzman, Debora Marks, Andrew Gordon Wilson

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07390v1](http://arxiv.org/pdf/2511.07390v1)

**Abstract**: Many proteins useful in modern medicine or bioengineering are challenging to
make in the lab, fuse with other proteins in cells, or deliver to tissues in
the body, because their sequences are too long. Shortening these sequences
typically involves costly, time-consuming experimental campaigns. Ideally, we
could instead use modern models of massive databases of sequences from nature
to learn how to propose shrunken proteins that resemble sequences found in
nature. Unfortunately, these models struggle to efficiently search the
combinatorial space of all deletions, and are not trained with inductive biases
to learn how to delete. To address this gap, we propose SCISOR, a novel
discrete diffusion model that deletes letters from sequences to generate
protein samples that resemble those found in nature. To do so, SCISOR trains a
de-noiser to reverse a forward noising process that adds random insertions to
natural sequences. As a generative model, SCISOR fits evolutionary sequence
data competitively with previous large models. In evaluation, SCISOR achieves
state-of-the-art predictions of the functional effects of deletions on
ProteinGym. Finally, we use the SCISOR de-noiser to shrink long protein
sequences, and show that its suggested deletions result in significantly more
realistic proteins and more often preserve functional motifs than previous
models of evolutionary sequences.


### Inference-Time Scaling of Diffusion Models for Infrared Data Generation
**Authors**: Kai A. Horstmann, Maxim Clouser, Kia Khezeli

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07362v1](http://arxiv.org/pdf/2511.07362v1)

**Abstract**: Infrared imagery enables temperature-based scene understanding using passive
sensors, particularly under conditions of low visibility where traditional RGB
imaging fails. Yet, developing downstream vision models for infrared
applications is hindered by the scarcity of high-quality annotated data, due to
the specialized expertise required for infrared annotation. While synthetic
infrared image generation has the potential to accelerate model development by
providing large-scale, diverse training data, training foundation-level
generative diffusion models in the infrared domain has remained elusive due to
limited datasets. In light of such data constraints, we explore an
inference-time scaling approach using a domain-adapted CLIP-based verifier for
enhanced infrared image generation quality. We adapt FLUX.1-dev, a
state-of-the-art text-to-image diffusion model, to the infrared domain by
finetuning it on a small sample of infrared images using parameter-efficient
techniques. The trained verifier is then employed during inference to guide the
diffusion sampling process toward higher quality infrared generations that
better align with input text prompts. Empirically, we find that our approach
leads to consistent improvements in generation quality, reducing FID scores on
the KAIST Multispectral Pedestrian Detection Benchmark dataset by 10% compared
to unguided baseline samples. Our results suggest that inference-time guidance
offers a promising direction for bridging the domain gap in low-data infrared
settings.


### PADiff: Predictive and Adaptive Diffusion Policies for Ad Hoc Teamwork
**Authors**: Hohei Chan, Xinzhi Zhang, Antao Xiang, Weinan Zhang, Mengchen Zhao

**Published Date**: 2025-11-10

**Updated Date**: 2025-11-10

**PDF Url**: [2511.07260v1](http://arxiv.org/pdf/2511.07260v1)

**Abstract**: Ad hoc teamwork (AHT) requires agents to collaborate with previously unseen
teammates, which is crucial for many real-world applications. The core
challenge of AHT is to develop an ego agent that can predict and adapt to
unknown teammates on the fly. Conventional RL-based approaches optimize a
single expected return, which often causes policies to collapse into a single
dominant behavior, thus failing to capture the multimodal cooperation patterns
inherent in AHT. In this work, we introduce PADiff, a diffusion-based approach
that captures agent's multimodal behaviors, unlocking its diverse cooperation
modes with teammates. However, standard diffusion models lack the ability to
predict and adapt in highly non-stationary AHT scenarios. To address this
limitation, we propose a novel diffusion-based policy that integrates critical
predictive information about teammates into the denoising process. Extensive
experiments across three cooperation environments demonstrate that PADiff
outperforms existing AHT methods significantly.


### Mitigating Sexual Content Generation via Embedding Distortion in Text-conditioned Diffusion Models
**Authors**: Jaesin Ahn, Heechul Jung

**Published Date**: 2025-01-31

**Updated Date**: 2025-11-10

**PDF Url**: [2501.18877v2](http://arxiv.org/pdf/2501.18877v2)

**Abstract**: Diffusion models show remarkable image generation performance following text
prompts, but risk generating sexual contents. Existing approaches, such as
prompt filtering, concept removal, and even sexual contents mitigation methods,
struggle to defend against adversarial attacks while maintaining benign image
quality. In this paper, we propose a novel approach called Distorting Embedding
Space (DES), a text encoder-based defense mechanism that effectively tackles
these issues through innovative embedding space control. DES transforms unsafe
embeddings, extracted from a text encoder using unsafe prompts, toward
carefully calculated safe embedding regions to prevent unsafe contents
generation, while reproducing the original safe embeddings. DES also
neutralizes the ``nudity'' embedding, by aligning it with neutral embedding to
enhance robustness against adversarial attacks. As a result, extensive
experiments on explicit content mitigation and adaptive attack defense show
that DES achieves state-of-the-art (SOTA) defense, with attack success rate
(ASR) of 9.47% on FLUX.1, a recent popular model, and 0.52% on the widely
adopted Stable Diffusion v1.5. These correspond to ASR reductions of 76.5% and
63.9% compared to previous SOTA methods, EraseAnything and AdvUnlearn,
respectively. Furthermore, DES maintains benign image quality, achieving
Frechet Inception Distance and CLIP score comparable to those of the original
FLUX.1 and Stable Diffusion v1.5.


