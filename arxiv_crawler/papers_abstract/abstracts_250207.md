# Abstracts of Papers

## Physics
### Magnetic Reconnection in a Compact Magnetic Dome: Peculiar Emissions and High-velocity Plasma Flows
**Authors**: J. M. da Silva Santos, E. Dunnington, R. Jarolim, S. Danilovic, S. Criscuoli

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04292v1](http://arxiv.org/pdf/2502.04292v1)

**Abstract**: Magnetic reconnection at small spatial scales is a fundamental driver of
energy release and plasma dynamics in the lower solar atmosphere. We present
novel observations of a brightening in an active region, captured in
high-resolution data from the Daniel K. Inouye Solar Telescope (DKIST) using
the Visible Broadband Imager (VBI) and the Visible Spectro-Polarimeter (ViSP).
The event exhibits Ellerman bomb-like morphology in the H$\beta$ filter,
associated with flux cancellation between a small negative polarity patch
adjacent to opposite-polarity plage. Additionally, it displays a distinct
annular emission pattern in Ca II K, hot jet-like structures containing
Alfv\'enic plasma flows, and cooler surges. We employ multi-line, non-local
thermodynamic equilibrium (non-LTE) inversions of the spectropolarimetric data
to infer the stratification of the physical parameters of the atmosphere.
Furthermore, we use the photospheric vector magnetogram inferred from the ViSP
spectra as a boundary condition for nonlinear force-free field extrapolations,
revealing the three-dimensional distribution of squashing factors. We find
significant enhancements in temperature, velocity, and microturbulence confined
to the upper photosphere and low chromosphere. Our findings provide
observational evidence of low-altitude magnetic reconnection along
quasi-separatrix layers in a compact fan-spine-type configuration, highlighting
the complex interplay between magnetic topology, energy release, and plasma
flows. Finally, we discuss the potential role of nonthermal particles in the
distinct emissions at different wavelengths.


### Exponentially Better Bounds for Quantum Optimization via Dynamical Simulation
**Authors**: Ahmet Burak Catli, Sophia Simon, Nathan Wiebe

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04285v1](http://arxiv.org/pdf/2502.04285v1)

**Abstract**: We provide several quantum algorithms for continuous optimization that do not
require any gradient estimation. Instead, we encode the optimization problem
into the dynamics of a physical system and coherently simulate the time
evolution. This allows us, in certain cases, to obtain exponentially better
query upper bounds relative to the best known upper bounds for gradient-based
optimization schemes which utilize quantum computers only for the evaluation of
gradients. Our first two algorithms can find local optima of a differentiable
function $f: \mathbb{R}^N \rightarrow \mathbb{R}$ by simulating either
classical or quantum dynamics with friction via a time-dependent Hamiltonian.
We show that these methods require $O(N\kappa^2/h_x^2\epsilon)$ queries to a
phase oracle to find an $\epsilon$-approximate local optimum of a locally
quadratic objective function, where $\kappa$ is the condition number of the
Hessian matrix and $h_x$ is the discretization spacing. In contrast, we show
that gradient-based methods require $O(N(1/\epsilon)^{\kappa \log(3)/4})$
queries. Our third algorithm can find the global optimum of $f$ by preparing a
classical low-temperature thermal state via simulation of the classical
Liouvillian operator associated with the Nos\'e Hamiltonian. We use results
from the quantum thermodynamics literature to bound the thermalization time for
the discrete system. Additionally, we analyze barren plateau effects that
commonly plague quantum optimization algorithms and observe that our approach
is vastly less sensitive to this problem than standard gradient-based
optimization. Our results suggests that these dynamical optimization approaches
may be far more scalable for future quantum machine learning, optimization and
variational experiments than was widely believed.


### Gaussian Process Regression for Inverse Problems in Linear PDEs
**Authors**: Xin Li, Markus Lange-Hegermann, Bogdan Raiţă

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04276v1](http://arxiv.org/pdf/2502.04276v1)

**Abstract**: This paper introduces a computationally efficient algorithm in system theory
for solving inverse problems governed by linear partial differential equations
(PDEs). We model solutions of linear PDEs using Gaussian processes with priors
defined based on advanced commutative algebra and algebraic analysis. The
implementation of these priors is algorithmic and achieved using the Macaulay2
computer algebra software. An example application includes identifying the wave
speed from noisy data for classical wave equations, which are widely used in
physics. The method achieves high accuracy while enhancing computational
efficiency.


### Fermion Dark Matter Effect on Electroweak Phase Transition
**Authors**: Soudeh Mirzaie, Karim Ghorbani, Parsa Ghorbani

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04265v1](http://arxiv.org/pdf/2502.04265v1)

**Abstract**: The addition of extra scalars to the Standard Model (SM) of particle physics
enriches the vacuum structure and consequently gives rise to strong first-order
phase transitions (EWPT) in the early universe. We raise the question that how
the EWPT is affected by the addition of fermions in models beyond the SM, and
address this question by studying the EWPT in a dark matter model comprising a
singlet scalar and two Dirac fermions. The singlet scalar develops a nonzero
vacuum expectation value (VEV), and the lighter fermion plays the role of the
dark matter. The model evades the stringent direct detection bounds due to the
presence of two fermions. We first show that applying the high-temperature
approximation, no first-order phase transition is found. Then we demonstrate
that when including the full finite temperature corrections to the effective
potential, the first-order phase transition becomes possible, nevertheless, all
the phase transitions will be weak. We therefore deduce that the addition of
fermions reduces the strength of the EWPT.


### Nelson-Barr ultralight dark matter
**Authors**: Michael Dine, Gilad Perez, Wolfram Ratzinger, Inbar Savoray

**Published Date**: 2024-05-10

**Updated Date**: 2025-02-06

**PDF Url**: [2405.06744v2](http://arxiv.org/pdf/2405.06744v2)

**Abstract**: We show that, in the Nelson-Barr solution to the strong CP-problem, a
naturally light scalar can arise. It gives rise to a completely new
phenomenology beyond that of the celebrated QCD axion, if this field
constitutes dark matter, as the CKM elements vary periodically in time. We also
discuss how the model can be tested using quantum sensors, in particular using
nuclear clocks, which leads to an interesting synergy between different
frontiers of physics.


### Black Hole Evaporation in Loop Quantum Gravity
**Authors**: Abhay Ashtekar

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04252v1](http://arxiv.org/pdf/2502.04252v1)

**Abstract**: The conference \emph{Black Holes Inside and Out} marked the 50th anniversary
of Hawking's seminal paper on black hole radiance. It was clear already from
Hawking's analysis that a proper quantum gravity theory would be essential for
a more complete understanding of the evaporation process. This task was
undertaken in Loop Quantum Gravity (LQG) two decades ago and by now the
literature on the subject is quite rich. The goal of this contribution is to
summarize a mainstream perspective that has emerged. The intended audience is
the broader gravitational physics community, rather than quantum gravity
experts. Therefore, the emphasis is on conceptual issues, especially on the key
features that distinguish the LQG approach, and on concrete results that
underlie the paradigm that has emerged. This is \emph{not} meant to be an
exhaustive review. Rather, it is a broad-brush stroke portrait of the present
status. Further details can be found in the references listed.


### VideoSAM: A Large Vision Foundation Model for High-Speed Video Segmentation
**Authors**: Chika Maduabuchi, Ericmoore Jossou, Matteo Bucci

**Published Date**: 2024-10-22

**Updated Date**: 2025-02-06

**PDF Url**: [2410.21304v3](http://arxiv.org/pdf/2410.21304v3)

**Abstract**: High-speed video (HSV) segmentation is essential for analyzing dynamic
physical processes in scientific and industrial applications, such as boiling
heat transfer. Existing models like U-Net struggle with generalization and
accurately segmenting complex bubble formations. We present VideoSAM, a
specialized adaptation of the Segment Anything Model (SAM), fine-tuned on a
diverse HSV dataset for phase detection. Through diverse experiments, VideoSAM
demonstrates superior performance across four fluid environments -- Water,
FC-72, Nitrogen, and Argon -- significantly outperforming U-Net in complex
segmentation tasks. In addition to introducing VideoSAM, we contribute an
open-source HSV segmentation dataset designed for phase detection, enabling
future research in this domain. Our findings underscore VideoSAM's potential to
set new standards in robust and accurate HSV segmentation. The code and dataset
used in this study are available online at
https://github.com/chikap421/videosam.


### Search for hadronic decays of feebly-interacting particles at NA62
**Authors**: NA62 Collaboration

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04241v1](http://arxiv.org/pdf/2502.04241v1)

**Abstract**: The NA62 experiment at CERN has the capability to collect data in a beam-dump
mode, where 400 GeV protons are dumped on an absorber. In this configuration,
New Physics particles, including dark photons, dark scalars, and axion-like
particles, may be produced in the absorber and decay in the instrumented volume
beginning approximately 80 m downstream of the dump. A search for these
particles decaying in flight to hadronic final states is reported, based on an
analysis of a sample of $1.4 \times 10^{17}$ protons on dump collected in 2021.
No evidence of a New Physics signal is observed, excluding new regions of
parameter spaces of multiple models.


### The Equation of State of QCD up to very high temperatures
**Authors**: Matteo Bresciani, Mattia Dalla Brida, Leonardo Giusti, Michele Pepe

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04239v1](http://arxiv.org/pdf/2502.04239v1)

**Abstract**: We present the non-perturbative computation of the entropy density in QCD for
temperatures ranging from 3 GeV up to the electro-weak scale, using $N_f=3$
flavours of massless O$(a)$-improved Wilson fermions. We adopt a new strategy
designed to be computationally efficient and based on formulating thermal QCD
in a moving reference frame, where the fields satisfy shifted boundary
conditions in the temporal direction and periodic boundary conditions along the
spatial ones. In this setup the entropy density can be computed as the
derivative of the free-energy density with respect to the shift parameter. For
each physical temperature, we perform Monte Carlo simulations at four values of
the lattice spacing in order to extrapolate the numerical data of the entropy
density to the continuum limit. We achieve a final accuracy of approximatively
$0.5$-$1.0\%$ and our results are compared with predictions from
high-temperature perturbation theory.


### A Modern Look at the Oscillation Physics Case for a Neutrino Factory
**Authors**: Peter B. Denton, Julia Gehrlein

**Published Date**: 2024-07-02

**Updated Date**: 2025-02-06

**PDF Url**: [2407.02572v3](http://arxiv.org/pdf/2407.02572v3)

**Abstract**: The next generation of neutrino oscillation experiments, JUNO, DUNE, and HK,
are under construction now and will collect data over the next decade and
beyond. As there are no approved plans to follow up this program with more
advanced neutrino oscillation experiments, we consider here one option that had
gained considerable interest more than a decade ago: a neutrino factory. Such
an experiment uses stored muons in a racetrack configuration with extremely
well characterized decays reducing systematic uncertainties and providing for
more oscillation channels. Such a machine could also be one step towards a high
energy muon collider program. We consider a long-baseline configuration to SURF
using the DUNE far detectors or modifications thereof, and compare the expected
sensitivities of the three-flavor oscillation parameters to the anticipated
results from DUNE and HK. We show optimal beam configurations, the impact of
charge identification, the role of statistics and systematics, and the expected
precision to the relevant standard oscillation parameters in different DUNE
vs.~neutrino factory configurations.


## Diffusion
### ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features
**Authors**: Alec Helbling, Tuna Han Salih Meral, Ben Hoover, Pinar Yanardag, Duen Horng Chau

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04320v1](http://arxiv.org/pdf/2502.04320v1)

**Abstract**: Do the rich representations of multi-modal diffusion transformers (DiTs)
exhibit unique properties that enhance their interpretability? We introduce
ConceptAttention, a novel method that leverages the expressive power of DiT
attention layers to generate high-quality saliency maps that precisely locate
textual concepts within images. Without requiring additional training,
ConceptAttention repurposes the parameters of DiT attention layers to produce
highly contextualized concept embeddings, contributing the major discovery that
performing linear projections in the output space of DiT attention layers
yields significantly sharper saliency maps compared to commonly used
cross-attention mechanisms. Remarkably, ConceptAttention even achieves
state-of-the-art performance on zero-shot image segmentation benchmarks,
outperforming 11 other zero-shot interpretability methods on the
ImageNet-Segmentation dataset and on a single-class subset of PascalVOC. Our
work contributes the first evidence that the representations of multi-modal DiT
models like Flux are highly transferable to vision tasks like segmentation,
even outperforming multi-modal foundation models like CLIP.


### HOG-Diff: Higher-Order Guided Diffusion for Graph Generation
**Authors**: Yiming Huang, Tolga Birdal

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04308v1](http://arxiv.org/pdf/2502.04308v1)

**Abstract**: Graph generation is a critical yet challenging task as empirical analyses
require a deep understanding of complex, non-Euclidean structures. Although
diffusion models have recently made significant achievements in graph
generation, these models typically adapt from the frameworks designed for image
generation, making them ill-suited for capturing the topological properties of
graphs. In this work, we propose a novel Higher-order Guided Diffusion
(HOG-Diff) model that follows a coarse-to-fine generation curriculum and is
guided by higher-order information, enabling the progressive generation of
plausible graphs with inherent topological structures. We further prove that
our model exhibits a stronger theoretical guarantee than classical diffusion
frameworks. Extensive experiments on both molecular and generic graph
generation tasks demonstrate that our method consistently outperforms or
remains competitive with state-of-the-art baselines. Our code is available at
https://github.com/Yiminghh/HOG-Diff.


### Statistical guarantees for continuous-time policy evaluation: blessing of ellipticity and new tradeoffs
**Authors**: Wenlong Mou

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04297v1](http://arxiv.org/pdf/2502.04297v1)

**Abstract**: We study the estimation of the value function for continuous-time Markov
diffusion processes using a single, discretely observed ergodic trajectory. Our
work provides non-asymptotic statistical guarantees for the least-squares
temporal-difference (LSTD) method, with performance measured in the first-order
Sobolev norm. Specifically, the estimator attains an $O(1 / \sqrt{T})$
convergence rate when using a trajectory of length $T$; notably, this rate is
achieved as long as $T$ scales nearly linearly with both the mixing time of the
diffusion and the number of basis functions employed.
  A key insight of our approach is that the ellipticity inherent in the
diffusion process ensures robust performance even as the effective horizon
diverges to infinity. Moreover, we demonstrate that the Markovian component of
the statistical error can be controlled by the approximation error, while the
martingale component grows at a slower rate relative to the number of basis
functions. By carefully balancing these two sources of error, our analysis
reveals novel trade-offs between approximation and statistical errors.


### Unpicking Data at the Seams: Understanding Disentanglement in VAEs
**Authors**: Carl Allen

**Published Date**: 2024-10-29

**Updated Date**: 2025-02-06

**PDF Url**: [2410.22559v4](http://arxiv.org/pdf/2410.22559v4)

**Abstract**: Disentanglement, or identifying statistically independent factors of the
data, is relevant to much of machine learning, from controlled data generation
and robust classification to efficient encoding and improving our understanding
of the data itself. Disentanglement arises in several generative paradigms
including Variational Autoencoders (VAEs), Generative Adversarial Networks and
diffusion models. Recent progress has been made in understanding
disentanglement in VAEs, where a choice of diagonal posterior covariance
matrices is shown to promote mutual orthogonality between columns of the
decoder's Jacobian. We build on this to show how such orthogonality, a
geometric property, translates to disentanglement, a statistical property,
furthering our understanding of how a VAE identifies independent components of,
or disentangles, the data.


### Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis
**Authors**: Zhen Ye, Xinfa Zhu, Chi-Min Chan, Xinsheng Wang, Xu Tan, Jiahe Lei, Yi Peng, Haohe Liu, Yizhu Jin, Zheqi DAI, Hongzhan Lin, Jianyi Chen, Xingjian Du, Liumeng Xue, Yunlin Chen, Zhifei Li, Lei Xie, Qiuqiang Kong, Yike Guo, Wei Xue

**Published Date**: 2025-02-06

**Updated Date**: 2025-02-06

**PDF Url**: [2502.04128v1](http://arxiv.org/pdf/2502.04128v1)

**Abstract**: Recent advances in text-based large language models (LLMs), particularly in
the GPT series and the o1 model, have demonstrated the effectiveness of scaling
both training-time and inference-time compute. However, current
state-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring
separate models (e.g., diffusion models after LLM), complicating the decision
of whether to scale a particular model during training or testing. This work
makes the following contributions: First, we explore the scaling of train-time
and inference-time compute for speech synthesis. Second, we propose a simple
framework Llasa for speech synthesis that employs a single-layer vector
quantizer (VQ) codec and a single Transformer architecture to fully align with
standard LLMs such as Llama. Our experiments reveal that scaling train-time
compute for Llasa consistently improves the naturalness of synthesized speech
and enables the generation of more complex and accurate prosody patterns.
Furthermore, from the perspective of scaling inference-time compute, we employ
speech understanding models as verifiers during the search, finding that
scaling inference-time compute shifts the sampling modes toward the preferences
of specific verifiers, thereby improving emotional expressiveness, timbre
consistency, and content accuracy. In addition, we released the checkpoint and
training code for our TTS model (1B, 3B, 8B) and codec model publicly
available.


## Quantitative Finance
### Chaos into Order: Neural Framework for Expected Value Estimation of Stochastic Partial Differential Equations
**Authors**: Ísak Pétursson, María Óskarsdóttir

**Published Date**: 2025-02-05

**Updated Date**: 2025-02-05

**PDF Url**: [2502.03670v1](http://arxiv.org/pdf/2502.03670v1)

**Abstract**: Stochastic Partial Differential Equations (SPDEs) are fundamental to modeling
complex systems in physics, finance, and engineering, yet their numerical
estimation remains a formidable challenge. Traditional methods rely on
discretization, introducing computational inefficiencies, and limiting
applicability in high-dimensional settings. In this work, we introduce a novel
neural framework for SPDE estimation that eliminates the need for
discretization, enabling direct estimation of expected values across arbitrary
spatio-temporal points. We develop and compare two distinct neural
architectures: Loss Enforced Conditions (LEC), which integrates physical
constraints into the loss function, and Model Enforced Conditions (MEC), which
embeds these constraints directly into the network structure. Through extensive
experiments on the stochastic heat equation, Burgers' equation, and
Kardar-Parisi-Zhang (KPZ) equation, we reveal a trade-off: While LEC achieves
superior residual minimization and generalization, MEC enforces initial
conditions with absolute precision and exceptionally high accuracy in boundary
condition enforcement. Our findings highlight the immense potential of
neural-based SPDE solvers, particularly for high-dimensional problems where
conventional techniques falter. By circumventing discretization and explicitly
modeling uncertainty, our approach opens new avenues for solving SPDEs in
fields ranging from quantitative finance to turbulence modeling. To the best of
our knowledge, this is the first neural framework capable of directly
estimating the expected values of SPDEs in an entirely non-discretized manner,
offering a step forward in scientific computing.


