# Abstracts of Papers

## Physics
### Hardware-inspired Continuous Variables Quantum Optical Neural Networks
**Authors**: Todor Krasimirov-Ivanov, Alba Cervera-Lierta, Paolo Stornati, Federico Centrone

**Published Date**: 2025-12-04

**Updated Date**: 2026-01-14

**PDF Url**: [2512.05204v2](https://arxiv.org/pdf/2512.05204v2)

**Abstract**: Continuous-variables (CV) quantum optics is a natural formalism for neural networks (NNs) due to its ability to reproduce the information processing of such trainable interconnected systems. In quantum optics, Gaussian operators induce affine mappings on the quadratures of optical modes while non-Gaussian resources (the challenging piece for physical implementation) originate the nonlinear effects, unlocking quantum analogs of an artificial neuron. This work presents a novel experimentally-feasible framework for continuous-variable quantum optical neural networks (QONNs) developed with available photonic components: coherent states as input encoding, a general Gaussian transformation followed by multi-mode photon subtractions as the processing layer, and homodyne detection as outputs readout. The closed-form expressions of such architecture are derived demonstrating the family of adaptive activations and the quantum-optical neurons that emerge from the amount of photon-subtracted modes, proving that the proposed design satisfies the Universal Approximation Theorem within a single layer. To classically simulate the QONN training, the high-performance QuaNNTO library has been developed based on Wick-Isserlis expansion and Bogoliubov transformations, allowing multi-layer exact expectation values of non-Gaussian states without truncating the infinite-dimensional Hilbert space. Experiments on supervised learning and state-preparation tasks show balanced-resource efficiency with strong expressivity and generalization capabilities, illustrating the potential of the architecture for scalable photonic quantum machine learning and for quantum applications such as complex non-Gaussian gate synthesis.


### Development & Characterization of Electrodes for large-scale Xenon Time Projection Chambers
**Authors**: A. Elykov, S. Vetter, V. H. S. Wu, A. Deisting, K. Eitel, R. Gumbsheimer, M. Kara, S. Lichter, S. Lindemann, T. Luce, Y. Ma, J. Müller, K. Müller, K. Ni, U. Oberlack, M. Schumann, P. Shagin, K. Valerius, M. Zhong

**Published Date**: 2025-11-20

**Updated Date**: 2026-01-14

**PDF Url**: [2511.16408v2](https://arxiv.org/pdf/2511.16408v2)

**Abstract**: Dual-phase liquid xenon time projection chambers are the core detector elements of many experiments that conduct searches for Dark Matter and rare events, as well as in neutrino and high-energy physics. As part of this detector technology, high-voltage electrodes are instrumental for the generation of observable signals and their physical interpretation. Thus, electrode design and manufacturing has to fulfill stringent requirements, and their production is associated with significant engineering challenges. In this work we describe the successful development of electrodes on the 1.5 m-scale, from their design and simulation to subsequent assembly and high-voltage testing in a gaseous argon environment. The produced electrodes were recently installed as an anode and a cathode during an upgrade to the XENONnT experiment.


### Cyclotron Radiation Signal Characterization in Resonant Cavities for the Project 8 Neutrino Mass Experiment
**Authors**: A. Ashtari Esfahani, S. Bhagvati, H. P. Binney, S. Böser, M. J. Brandsema, N. Buzinsky, R. Cabral, M. C. Carmona-Benitez, C. Claessens, L. de Viveiros, A. El Boustani, M. G. Elliott, S. Enomoto, M. Fertl, J. A. Formaggio, B. T. Foust, J. K. Gaison, P. Harmston, K. M. Heeger, B. J. P. Jones, E. Karim, K. Kazkaz, P. T. Kolbeck, A. Kurmus, M. Li, A. Lindman, C. -Y. Liu, T. Luo, C. Matthé, R. Mohiuddin, B. Monreal, B. Mucogllava, R. Mueller, A. Negi, J. A. Nikkel, E. Novitski, N. S. Oblath, M. Oueslati, J. I. Peña, W. Pettus, A. W. P. Poon, V. S. Ranatunga, R. Reimann, A. L. Reine, R. G. H. Robertson, G. Rybka, L. Saldaña, V. Sharma, P. L. Slocum, F. Spanier, J. Stachurska, Y. -H. Sun, P. T. Surukuchi, A. B. Telles, F. Thomas, L. A. Thorne, T. Thümmler, M. Turqueti, W. Van De Pontseele, B. A. VanDevender, T. E. Weiss, M. Wynne, A. Ziegler

**Published Date**: 2026-01-07

**Updated Date**: 2026-01-14

**PDF Url**: [2601.07848v2](https://arxiv.org/pdf/2601.07848v2)

**Abstract**: Many experimental methods in physics require understanding radiation from single particles into non-trivial electromagnetic mode structures. Such characterization is critical for Cyclotron Radiation Emission Spectroscopy (CRES), an advancing new measurement technique that has the potential to greatly benefit fundamental physics measurements. In CRES, charged particles emit cyclotron radiation at frequencies that provide their energy measurement. As a notable example, the Project 8 experiment aims to kinematically infer the neutrino mass by measuring the energies of electrons emitted in tritium beta decay using CRES. In near-term realizations of Project 8, resonant cylindrical cavities will be used for CRES readout, in a configuration with a magnetic field oriented along the symmetry axis, and electrons following helical cyclotron trajectories confined to the cavity interior. The physics of electromagnetic radiation in these environments is complicated, since it involves both the motion of the emitting particle and the mode structure imposed by the cavity. In this work, we derive and validate an analytic model for how an oscillating, trapped electron radiates into cavity modes, and the power and frequency content of the radiation that can be read out from these events. These results can be used to guide the design of cavities for future CRES and other experiments.


### Constitutive parameter inference using physics-based data-driven modeling in full volume datasets of intact and torn rotator cuff tendons
**Authors**: Carla Nathaly Villacís Núñez, Siddhartha Srivastava, Ulrich Scheven, Asheesh Bedi, Krishna Garikipati, Ellen M. Arruda

**Published Date**: 2026-01-14

**Updated Date**: 2026-01-14

**PDF Url**: [2601.09660v1](https://arxiv.org/pdf/2601.09660v1)

**Abstract**: In this work, we characterized the material properties of an animal model of the rotator cuff tendon using full volume datasets of both its intact and injured states by capturing internal strain behavior throughout the tendon. Our experimental setup, involving tension along the fiber direction, activated volumetric, tensile, and shear mechanisms due to the tendon's complex geometry. We implemented an approach to model inference that we refer to as variational system identification (VSI) to solve the weak form of the stress equilibrium equation using these full volume displacements. Three constitutive models were used for parameter inference: a neo-Hookean model, a modified Holzapfel-Gasser-Ogden (HGO) model with higher-order terms in the first and second invariants, and a reduced polynomial model consisting of terms based on the first, second, and fiber-related invariants. Inferred parameters were further refined using an adjoint-based partial differential equation (PDE)-constrained optimization framework. Our results show that the modified HGO model captures the tendon's deformation mechanisms with reasonable accuracy, while the neo-Hookean model fails to reproduce key internal features, particularly the shear behavior in the injured tendon. Surprisingly, the simplified polynomial model performed comparably to the modified HGO formulation using only three terms. These findings suggest that while current constitutive models do not fully replicate the complex internal mechanics of the tendon, they are capable of capturing key trends in both intact and damaged tissue, using a homogeneous modeling approach. Continued model development is needed to bridge this gap and enable clinical-grade, predictive simulations of tendon injury and repair.


### Dynamics-Aligned Latent Imagination in Contextual World Models for Zero-Shot Generalization
**Authors**: Frank Röder, Jan Benad, Manfred Eppe, Pradeep Kr. Banerjee

**Published Date**: 2025-08-27

**Updated Date**: 2026-01-14

**PDF Url**: [2508.20294v2](https://arxiv.org/pdf/2508.20294v2)

**Abstract**: Real-world reinforcement learning demands adaptation to unseen environmental conditions without costly retraining. Contextual Markov Decision Processes (cMDP) model this challenge, but existing methods often require explicit context variables (e.g., friction, gravity), limiting their use when contexts are latent or hard to measure. We introduce Dynamics-Aligned Latent Imagination (DALI), a framework integrated within the Dreamer architecture that infers latent context representations from agent-environment interactions. By training a self-supervised encoder to predict forward dynamics, DALI generates actionable representations conditioning the world model and policy, bridging perception and control. We theoretically prove this encoder is essential for efficient context inference and robust generalization. DALI's latent space enables counterfactual consistency: Perturbing a gravity-encoding dimension alters imagined rollouts in physically plausible ways. On challenging cMDP benchmarks, DALI achieves significant gains over context-unaware baselines, often surpassing context-aware baselines in extrapolation tasks, enabling zero-shot generalization to unseen contextual variations.


### Constraint-Induced Effective Mass in Massless Field Propagation
**Authors**: Charles Wood

**Published Date**: 2026-01-14

**Updated Date**: 2026-01-14

**PDF Url**: [2601.09642v1](https://arxiv.org/pdf/2601.09642v1)

**Abstract**: Constrained propagation of massless fields is ubiquitous in physical systems, arising from boundaries, material structure, or other restrictions on admissible modes. This paper shows that such constraints generically induce mass-like terms in the effective dispersion relation, without modifying the underlying field equations or introducing new degrees of freedom. Working at an abstract level, constraints are represented as linear operators acting on the field's mode space. Restriction of the admissible mode manifold produces a spectral gap whose magnitude is set by the smallest non-zero eigenvalue of an associated positive semidefinite operator. This gap may be identified with an effective mass parameter, yielding a Proca-like dispersion relation in the long-wavelength limit. The resulting Mass Induction Principle identifies rank reduction of the accessible mode space as the structural mechanism responsible for effective mass generation in constrained massless fields. Familiar systems such as plasmas, superconductors, and periodic media realise this structure as special cases, without introducing new dynamics. The analysis is deliberately dispersion-level and non-phenomenological: it does not assert a field-theoretic mass term, does not address vacuum propagation, and does not make claims about bounds on intrinsic particle masses.


### Quirk SUEP
**Authors**: David Curtin, Sascha Dreyer, Max Fusté Costa, Sarah Heim, Gregor Kasieczka, Louis Moureaux, David Rousso, David Shih, Manuel Sommerhalder

**Published Date**: 2025-06-12

**Updated Date**: 2026-01-14

**PDF Url**: [2506.11192v2](https://arxiv.org/pdf/2506.11192v2)

**Abstract**: We propose searching for physics beyond the Standard Model in the low-transverse-momentum tracks accompanying hard-scatter events at the LHC. TeV-scale resonances connected to a dark QCD sector could be enhanced by selecting events with anomalies in the track distributions. As a benchmark, a quirk model with microscopic string lengths is developed, including a setup for event simulation. For this model, strategies are presented to enhance the sensitivity compared to inclusive resonance searches: a simple cut-based selection, a supervised search, and a model-agnostic weakly supervised anomaly search with the CATHODE method. Expected discovery potentials and exclusion limits are shown for 140 fb$^{-1}$ of 13 TeV proton-proton collisions at the LHC.


### Physically Plausible Multi-System Trajectory Generation and Symmetry Discovery
**Authors**: Jiayin Liu, Yulong Yang, Vineet Bansal, Christine Allen-Blanchette

**Published Date**: 2025-09-26

**Updated Date**: 2026-01-14

**PDF Url**: [2509.23003v2](https://arxiv.org/pdf/2509.23003v2)

**Abstract**: From metronomes to celestial bodies, mechanics underpins how the world evolves in time and space. With consideration of this, a number of recent neural network models leverage inductive biases from classical mechanics to encourage model interpretability and ensure forecasted states are physical. However, in general, these models are designed to capture the dynamics of a single system with fixed physical parameters, from state-space measurements of a known configuration space. In this paper we introduce Symplectic Phase Space GAN (SPS-GAN) which can capture the dynamics of multiple systems, and generalize to unseen physical parameters from. Moreover, SPS-GAN does not require prior knowledge of the system configuration space. In fact, SPS-GAN can discover the configuration space structure of the system from arbitrary measurement types (e.g., state-space measurements, video frames). To achieve physically plausible generation, we introduce a novel architecture which embeds a Hamiltonian neural network recurrent module in a conditional GAN backbone. To discover the structure of the configuration space, we optimize the conditional time-series GAN objective with an additional physically motivated term to encourages a sparse representation of the configuration space. We demonstrate the utility of SPS-GAN for trajectory prediction, video generation and symmetry discovery. Our approach captures multiple systems and achieves performance on par with supervised models designed for single systems.


### Introduction to the Combination of Reduced Order Models and Domain Decomposition: State of the Art and Perspectives
**Authors**: Shenhui Ruan, Andreas G. Class, Gianluigi Rozza

**Published Date**: 2026-01-14

**Updated Date**: 2026-01-14

**PDF Url**: [2601.09623v1](https://arxiv.org/pdf/2601.09623v1)

**Abstract**: Reduced Order Models (ROMs) have been regarded as an efficient alternative to conventional high-fidelity Computational Fluid Dynamics (CFD) for accelerating the design and optimization processes in engineering applications. Many industrial geometries feature repeating subdomains or contain sub-regions governed by distinct physical phenomena, making them well-suited to Domain Decomposition (DD) techniques. The integration of ROM and DD is promising to further reduce computational costs by constructing local ROMs and assembling them into global solutions. Due to the complexity and necessity of coupling ROMs, many approaches have been proposed in recent years. This review provides a concise overview of existing methodologies combining ROM and DD. We categorize existing methods into intrusive (projection-based) and non-intrusive (data-driven) frameworks. Various strategies for generating local reduced bases and coupling them across subdomains are illustrated. Particular emphasis is placed on intrusive techniques, including equations, numerical algorithms, and practical implementations. The non-intrusive framework is also discussed, highlighting its general procedures, basic formulations, and underlying principles. Finally, we summarise the state of the literature, identify open challenges, and present perspectives on future implementation from an engineering viewpoint.


### Mechanical Impedance and the Physics of Faster-Than-the-Wind Travel
**Authors**: Karl Svozil

**Published Date**: 2025-07-26

**Updated Date**: 2026-01-14

**PDF Url**: [2507.22081v3](https://arxiv.org/pdf/2507.22081v3)

**Abstract**: It is a well-documented yet counterintuitive fact that wind-driven vehicles can travel directly downwind faster than the wind itself. This effect is not paradoxical once one recognizes that the vehicle is not pushed by the air alone but acts as a coupled mechanical system that taps the relative motion of two media -- the moving air and the (effectively) stationary ground or water -- and, through its drivetrain, can gear up this modest velocity difference into a larger vehicle speed. The ground provides the indispensable mechanical impedance, serving as a rigid foothold that allows the wheels to support reaction forces without doing work in the ideal limit. The drivetrain -- wheels, gears, and propeller -- then functions as a mechanical transformer: It trades increased vehicle speed against reduced thrust so that power is conserved in the ideal limit. Using the analogies of a gearbox, a lever, and a sliding-boat thought experiment, this work presents an explicitly Newtonian description showing how faster-than-the-wind travel arises from the geared-up relative motion of two media coupled through a high-impedance foothold.


## Diffusion
### Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling
**Authors**: Shayan Mohajer Hamidi, En-Hui Yang, Ben Liang

**Published Date**: 2025-10-08

**Updated Date**: 2026-01-14

**PDF Url**: [2510.09676v2](https://arxiv.org/pdf/2510.09676v2)

**Abstract**: Inverse problems, where the goal is to recover an unknown signal from noisy or incomplete measurements, are central to applications in medical imaging, remote sensing, and computational biology. Diffusion models have recently emerged as powerful priors for solving such problems. However, existing methods either rely on projection-based techniques that enforce measurement consistency through heuristic updates, or they approximate the likelihood $p(\boldsymbol{y} \mid \boldsymbol{x})$, often resulting in artifacts and instability under complex or high-noise conditions. To address these limitations, we propose a novel framework called \emph{coupled data and measurement space diffusion posterior sampling} (C-DPS), which eliminates the need for constraint tuning or likelihood approximation. C-DPS introduces a forward stochastic process in the measurement space $\{\boldsymbol{y}_t\}$, evolving in parallel with the data-space diffusion $\{\boldsymbol{x}_t\}$, which enables the derivation of a closed-form posterior $p(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive sampling based on a well-defined posterior distribution. Empirical results demonstrate that C-DPS consistently outperforms existing baselines, both qualitatively and quantitatively, across multiple inverse problem benchmarks.


### Can AI Dream of Unseen Galaxies? Conditional Diffusion Model for Galaxy Morphology Augmentation
**Authors**: Chenrui Ma, Zechang Sun, Tao Jing, Zheng Cai, Yuan-Sen Ting, Song Huang, Mingyu Li

**Published Date**: 2025-06-19

**Updated Date**: 2026-01-14

**PDF Url**: [2506.16233v2](https://arxiv.org/pdf/2506.16233v2)

**Abstract**: Observational astronomy relies on visual feature identification to detect critical astrophysical phenomena. While machine learning (ML) increasingly automates this process, models often struggle with generalization in large-scale surveys due to the limited representativeness of labeled datasets, whether from simulations or human annotation, a challenge pronounced for rare yet scientifically valuable objects. To address this, we propose a conditional diffusion model to synthesize realistic galaxy images for augmenting ML training data (hereafter GalaxySD). Leveraging the Galaxy Zoo 2 dataset which contains visual feature, galaxy image pairs from volunteer annotation, we demonstrate that GalaxySD generates diverse, high-fidelity galaxy images that closely adhere to the specified morphological feature conditions. Moreover, this model enables generative extrapolation to project well-annotated data into unseen domains and advancing rare object detection. Integrating synthesized images into ML pipelines improves performance in standard morphology classification, boosting completeness and purity by up to 30% across key metrics. For rare object detection, using early-type galaxies with prominent dust lane features (~0.1% in GZ2 dataset) as a test case, our approach doubled the number of detected instances, from 352 to 872, compared to previous studies based on visual inspection. This study highlights the power of generative models to bridge gaps between scarce labeled data and the vast, uncharted parameter space of observational astronomy and sheds insight for future astrophysical foundation model developments. Our project homepage is available at https://galaxysd-webpage.streamlit.app/.


### Content Accuracy and Quality Aware Resource Allocation Based on LP-Guided DRL for ISAC-Driven AIGC Networks
**Authors**: Ningzhe Shi, Yiqing Zhou, Ling Liu, Jinglin Shi, Yihao Wu, Haiwei Shi, Hanxiao Yu

**Published Date**: 2025-08-16

**Updated Date**: 2026-01-14

**PDF Url**: [2508.12079v2](https://arxiv.org/pdf/2508.12079v2)

**Abstract**: Integrated sensing and communication (ISAC) can enhance artificial intelligence-generated content (AIGC) networks by providing efficient sensing and transmission. Existing AIGC services usually assume that the accuracy of the generated content can be ensured, given accurate input data and prompt, thus only the content generation quality (CGQ) is concerned. However, it is not applicable in ISAC-based AIGC networks, where content generation is based on inaccurate sensed data. Moreover, the AIGC model itself introduces generation errors, which depend on the number of generating steps (i.e., computing resources). To assess the quality of experience of ISAC-based AIGC services, we propose a content accuracy and quality aware service assessment metric (CAQA). Since allocating more resources to sensing and generating improves content accuracy but may reduce communication quality, and vice versa, this sensing-generating (computing)-communication three-dimensional resource tradeoff must be optimized to maximize the average CAQA (AvgCAQA) across all users with AIGC (CAQA-AIGC). This problem is NP-hard, with a large solution space that grows exponentially with the number of users. To solve the CAQA-AIGC problem with low complexity, a linear programming (LP) guided deep reinforcement learning (DRL) algorithm with an action filter (LPDRL-F) is proposed. Through the LP-guided approach and the action filter, LPDRL-F can transform the original three-dimensional solution space to two dimensions, reducing complexity while improving the learning performance of DRL. Simulations show that compared to existing DRL and generative diffusion model (GDM) algorithms without LP, LPDRL-F converges faster and finds better resource allocation solutions, improving AvgCAQA by more than 10%. With LPDRL-F, CAQA-AIGC can achieve an improvement in AvgCAQA of more than 50% compared to existing schemes focusing solely on CGQ.


### Learning Whole-Body Human-Humanoid Interaction from Human-Human Demonstrations
**Authors**: Wei-Jin Huang, Yue-Yi Zhang, Yi-Lin Wei, Zhi-Wei Xia, Juantao Tan, Yuan-Ming Li, Zhilin Zhao, Wei-Shi Zheng

**Published Date**: 2026-01-14

**Updated Date**: 2026-01-14

**PDF Url**: [2601.09518v1](https://arxiv.org/pdf/2601.09518v1)

**Abstract**: Enabling humanoid robots to physically interact with humans is a critical frontier, but progress is hindered by the scarcity of high-quality Human-Humanoid Interaction (HHoI) data. While leveraging abundant Human-Human Interaction (HHI) data presents a scalable alternative, we first demonstrate that standard retargeting fails by breaking the essential contacts. We address this with PAIR (Physics-Aware Interaction Retargeting), a contact-centric, two-stage pipeline that preserves contact semantics across morphology differences to generate physically consistent HHoI data. This high-quality data, however, exposes a second failure: conventional imitation learning policies merely mimic trajectories and lack interactive understanding. We therefore introduce D-STAR (Decoupled Spatio-Temporal Action Reasoner), a hierarchical policy that disentangles when to act from where to act. In D-STAR, Phase Attention (when) and a Multi-Scale Spatial module (where) are fused by the diffusion head to produce synchronized whole-body behaviors beyond mimicry. By decoupling these reasoning streams, our model learns robust temporal phases without being distracted by spatial noise, leading to responsive, synchronized collaboration. We validate our framework through extensive and rigorous simulations, demonstrating significant performance gains over baseline approaches and a complete, effective pipeline for learning complex whole-body interactions from HHI data.


### VideoAR: Autoregressive Video Generation via Next-Frame & Scale Prediction
**Authors**: Longbin Ji, Xiaoxiong Liu, Junyuan Shang, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang

**Published Date**: 2026-01-09

**Updated Date**: 2026-01-14

**PDF Url**: [2601.05966v2](https://arxiv.org/pdf/2601.05966v2)

**Abstract**: Recent advances in video generation have been dominated by diffusion and flow-matching models, which produce high-quality results but remain computationally intensive and difficult to scale. In this work, we introduce VideoAR, the first large-scale Visual Autoregressive (VAR) framework for video generation that combines multi-scale next-frame prediction with autoregressive modeling. VideoAR disentangles spatial and temporal dependencies by integrating intra-frame VAR modeling with causal next-frame prediction, supported by a 3D multi-scale tokenizer that efficiently encodes spatio-temporal dynamics. To improve long-term consistency, we propose Multi-scale Temporal RoPE, Cross-Frame Error Correction, and Random Frame Mask, which collectively mitigate error propagation and stabilize temporal coherence. Our multi-stage pretraining pipeline progressively aligns spatial and temporal learning across increasing resolutions and durations. Empirically, VideoAR achieves new state-of-the-art results among autoregressive models, improving FVD on UCF-101 from 99.5 to 88.6 while reducing inference steps by over 10x, and reaching a VBench score of 81.74-competitive with diffusion-based models an order of magnitude larger. These results demonstrate that VideoAR narrows the performance gap between autoregressive and diffusion paradigms, offering a scalable, efficient, and temporally consistent foundation for future video generation research.


## Quantitative Finance
### Systemic Risk in DeFi: A Network-Based Fragility Analysis of TVL Dynamics
**Authors**: Shiyu Zhang, Zining Wang, Jin Zheng, John Cartlidge

**Published Date**: 2026-01-13

**Updated Date**: 2026-01-13

**PDF Url**: [2601.08540v1](https://arxiv.org/pdf/2601.08540v1)

**Abstract**: Systemic risk refers to the overall vulnerability arising from the high degree of interconnectedness and interdependence within the financial system. In the rapidly developing decentralized finance (DeFi) ecosystem, numerous studies have analyzed systemic risk through specific channels such as liquidity pressures, leverage mechanisms, smart contract risks, and historical risk events. However, these studies are mostly event-driven or focused on isolated risk channels, paying limited attention to the structural dimension of systemic risk. Overall, this study provides a unified quantitative framework for ecosystem-level analysis and continuous monitoring of systemic risk in DeFi. From a network-based perspective, this paper proposes the DeFi Correlation Fragility Indicator (CFI), constructed from time-varying correlation networks at the protocol category level. The CFI captures ecosystem-wide structural fragility associated with correlation concentration and increasing synchronicity. Furthermore, we define a Risk Contribution Score (RCS) to quantify the marginal contribution of different protocol types to overall systemic risk. By combining the CFI and RCS, the framework enables both the tracking of time-varying systemic risk and identification of structurally important functional modules in risk accumulation and amplification.


### A Blessing in Disguise: How DeFi Hacks Trigger Unintended Liquidity Injections into US Money Markets
**Authors**: Tingyi Lin

**Published Date**: 2026-01-13

**Updated Date**: 2026-01-13

**PDF Url**: [2601.08263v1](https://arxiv.org/pdf/2601.08263v1)

**Abstract**: Do vulnerabilities in Decentralized Finance (DeFi) destabilize traditional short-term funding markets? While the prevailing "Contagion Hypothesis" posits that the liquidation of stablecoin reserves triggers fire-sale spirals that transmit distress to traditional markets , we document a robust "Flight-to-Quality" effect to the contrary. In the wake of major DeFi exploits, spreads on 3-month AA-rated commercial paper (CP) exhibit a paradoxical narrowing. We identify a "liquidity recycling" mechanism driving this outcome: capital fleeing DeFi protocols is re-intermediated into the traditional financial system via Prime Money Market Funds (MMFs) , where strict regulatory constraints (e.g., SEC Rule 2a-7) compel these funds to purchase high-quality paper. Our estimates indicate that this institutional demand shock quantitatively overwhelms the supply shock driven by stablecoin issuer redemptions. Rather than acting as vectors of financial contagion , these crypto native shocks serve as an inadvertent "safety valve" in segmented markets , providing transient liquidity support and effectively subsidizing borrowing costs for high-grade issuers in the real economy.


### Non-Convex Portfolio Optimization via Energy-Based Models: A Comparative Analysis Using the Thermodynamic HypergRaphical Model Library (THRML) for Index Tracking
**Authors**: Javier Mancilla, Theodoros D. Bouloumis, Frederic Goguikian

**Published Date**: 2026-01-12

**Updated Date**: 2026-01-12

**PDF Url**: [2601.07792v1](https://arxiv.org/pdf/2601.07792v1)

**Abstract**: Portfolio optimization under cardinality constraints transforms the classical Markowitz mean-variance problem from a convex quadratic problem into an NP-hard combinatorial optimization problem. This paper introduces a novel approach using THRML (Thermodynamic HypergRaphical Model Library), a JAX-based library for building and sampling probabilistic graphical models that reformulates index tracking as probabilistic inference on an Ising Hamiltonian. Unlike traditional methods that seek a single optimal solution, THRML samples from the Boltzmann distribution of high-quality portfolios using GPU-accelerated block Gibbs sampling, providing natural regularization against overfitting.
  We implement three key innovations: (1) dynamic coupling strength that scales inversely with market volatility (VIX), adapting diversification pressure to market regimes; (2) rebalanced bias weights prioritizing tracking quality over momentum for index replication; and (3) sector-aware post-processing ensuring institutional-grade diversification. Backtesting on a 100-stock S and P 500 universe from 2023 to 2025 demonstrates that THRML achieves 4.31 percent annualized tracking error versus 5.66 to 6.30 percent for baselines, while simultaneously generating 128.63 percent total return against the index total return of 79.61 percent. The Diebold-Mariano test confirms statistical significance with p less than 0.0001 across all comparisons. These results position energy-based models as a promising paradigm for portfolio construction, bridging statistical mechanics and quantitative finance.


### FinForge: Semi-Synthetic Financial Benchmark Generation
**Authors**: Glenn Matlin, Akhil Theerthala, Anant Gupta, Anirudh JM, Rayan Castilla, Yi Mei Ng, Sudheer Chava

**Published Date**: 2026-01-11

**Updated Date**: 2026-01-11

**PDF Url**: [2601.06747v1](https://arxiv.org/pdf/2601.06747v1)

**Abstract**: Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.


