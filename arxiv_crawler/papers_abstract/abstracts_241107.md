# Abstracts of Papers

## Physics
### Second order cone relaxations for quantum Max Cut
**Authors**: Felix Huber, Kevin Thompson, Ojas Parekh, Sevag Gharibian

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.04120v1](http://arxiv.org/pdf/2411.04120v1)

**Abstract**: Quantum Max Cut (QMC), also known as the quantum anti-ferromagnetic
Heisenberg model, is a QMA-complete problem relevant to quantum many-body
physics and computer science. Semidefinite programming relaxations have been
fruitful in designing theoretical approximation algorithms for QMC, but are
computationally expensive for systems beyond tens of qubits. We give a second
order cone relaxation for QMC, which optimizes over the set of mutually
consistent three-qubit reduced density matrices. In combination with Pauli
level-$1$ of the quantum Lasserre hierarchy, the relaxation achieves an
approximation ratio of $0.526$ to the ground state energy. Our relaxation is
solvable on systems with hundreds of qubits and paves the way to
computationally efficient lower and upper bounds on the ground state energy of
large-scale quantum spin systems.


### Problem Space Transformations for Generalisation in Behavioural Cloning
**Authors**: Kiran Doshi, Marco Bagatella, Stelian Coros

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.04056v1](http://arxiv.org/pdf/2411.04056v1)

**Abstract**: The combination of behavioural cloning and neural networks has driven
significant progress in robotic manipulation. As these algorithms may require a
large number of demonstrations for each task of interest, they remain
fundamentally inefficient in complex scenarios. This issue is aggravated when
the system is treated as a black-box, ignoring its physical properties. This
work characterises widespread properties of robotic manipulation, such as pose
equivariance and locality. We empirically demonstrate that transformations
arising from each of these properties allow neural policies trained with
behavioural cloning to better generalise to out-of-distribution problem
instances.


### Corrections to adiabatic behavior for long paths
**Authors**: Thomas D. Cohen, Hyunwoo Oh

**Published Date**: 2024-05-16

**Updated Date**: 2024-11-06

**PDF Url**: [2405.10294v3](http://arxiv.org/pdf/2405.10294v3)

**Abstract**: The cost and the error of the adiabatic theorem for preparing the final
eigenstate are discussed in terms of path length. Previous studies in terms of
the norm of the Hamiltonian and its derivatives with the spectral gap are
limited in their ability to describe the cost of adiabatic state preparation
for certain physically large systems. We argue that total time is not a good
measure for determining the computational difficulty of adiabatic quantum
computation by developing a no-go theorem. From the result of time-periodic
Hamiltonian cases, we suggest that there are proxies for computational cost
which typically grow as path length increases when the error is kept fixed and
small and consider possible conjectures on how general the behavior is.


### The Quenched $g_A$ in Nuclei and Infrared Fixed-Point in QCD
**Authors**: Mannque Rho, Long-Qi Shao

**Published Date**: 2024-05-12

**Updated Date**: 2024-11-06

**PDF Url**: [2405.07339v4](http://arxiv.org/pdf/2405.07339v4)

**Abstract**: The possible consequence of an IR fixed point in QCD for $N_f=2, 3$ in
nuclear matter is discussed. It is shown in terms of d(ilaton)-$\chi$ effective
field theory (d$\chi$EFT) incorporated in a generalized effective field theory
(G$n$EFT) implemented with hidden local symmetry and hidden scale symmetry that
the recently measured superallowed Gamow-Teller transition in the
doubly-magic-shell nucleus $^{100}$Sn indicates a surprisingly large
anomaly-induced quenching (AIQ) of $g_A$ from the free-space value of 1.276 to
$\approx 0.8 $. Combined with the quenching expected from strong nuclear
correlations, the effective coupling in nuclei, $g_A^{\rm eff}$ would come to
$\sim 1/2$. If this result were reconfirmed, it would impact not only nuclear
structure and dense compact-star matter -- where $g_A$ figures in $\pi$-N
coupling via the Goldberger-Treiman relation -- but also in search for physics
Beyond the Standard Model (BSM), e.g. $0\nu\beta\beta$ decay, where 4th power
of $g_A$ figures.


### Gain-induced group delay in spontaneous parametric down-conversion
**Authors**: Guillaume Thekkadath, Martin Houde, Duncan England, Philip Bustard, Frédéric Bouchard, Nicolás Quesada, Ben Sussman

**Published Date**: 2024-05-13

**Updated Date**: 2024-11-06

**PDF Url**: [2405.07909v2](http://arxiv.org/pdf/2405.07909v2)

**Abstract**: Strongly-driven nonlinear optical processes such as spontaneous parametric
down-conversion and spontaneous four-wave mixing can produce multiphoton
nonclassical beams of light which have applications in quantum information
processing and sensing. In contrast to the low-gain regime, new physical
effects arise in a high-gain regime due to the interactions between the
nonclassical light and the strong pump driving the nonlinear process. Here, we
describe and experimentally observe a gain-induced group delay between the
multiphoton pulses generated in a high-gain type-II spontaneous parametric
down-conversion source. Since the group delay introduces distinguishability
between the generated photons, it will be important to compensate for it when
designing quantum interference devices in which strong optical nonlinearities
are required.


### Photon production in top quark events at ATLAS and CMS
**Authors**: Beatriz Ribeiro Lopes

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.03981v1](http://arxiv.org/pdf/2411.03981v1)

**Abstract**: Top quark production in association with a photon offers a unique test ground
for the standard model predictions, as it is sensitive to the top-photon
coupling. These processes are rare when compared to standard top pair
production, however the large amounts of data delivered by the LHC open the
window to precise measurements. This talk covered the recent inclusive and
differential measurements of top quark single and pair production in
association with a photon, by the ATLAS and CMS Collaborations. Potential
modifications to the top-photon couplings with respect to the standard model
predictions are also explored using the standard model effective field theory.


### Search for a heavy charged Higgs boson decaying into a $W$ boson and a Higgs boson in final states with leptons and $b$-jets in $\sqrt{s} = 13$ TeV $pp$ collisions with the ATLAS detector
**Authors**: ATLAS Collaboration

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.03969v1](http://arxiv.org/pdf/2411.03969v1)

**Abstract**: This article presents a search for a heavy charged Higgs boson produced in
association with a top quark and a bottom quark, and decaying into a $W$ boson
and a $125$ GeV Higgs boson $h$. The search is performed in final states with
one charged lepton, missing transverse momentum, and jets using proton-proton
collision data at $\sqrt{s} = 13$ TeV recorded with the ATLAS detector during
Run 2 of the LHC at CERN. This data set corresponds to a total integrated
luminosity of 140 fb$^{-1}$. The search is conducted by examining the
reconstructed invariant mass distribution of the $Wh$ candidates for evidence
of a localised excess in the charged Higgs boson mass range from $250$ GeV to
$3$ TeV. No significant excess is observed and 95% confidence-level upper
limits between $2.8$ pb and $1.2$ fb are placed on the production cross-section
times branching ratio for charged Higgs bosons decaying into $Wh$.


### Reconciling Kubo and Keldysh Approaches to Fermi-Sea-Dependent Nonequilibrium Observables: Application to Spin Hall Current and Spin-Orbit Torque in Spintronics
**Authors**: Simao M. Joao, Marko D. Petrovic, J. M. Viana Parente Lopes, Aires Ferreira, Branislav K. Nikolic

**Published Date**: 2024-08-29

**Updated Date**: 2024-11-06

**PDF Url**: [2408.16611v2](http://arxiv.org/pdf/2408.16611v2)

**Abstract**: Quantum transport studies of spin-dependent phenomena in solids commonly
employ the Kubo or Keldysh formulas for the nonequilibrium density operator in
the steady-state linear-response regime. Its trace with operators of interest,
such as the spin density, spin current density, etc., gives expectation values
of experimentally accessible observables. For local quantities, these formulas
require summing over the manifolds of {\em both} Fermi-surface and Fermi-sea
states. However, debates have been raging in the literature about the vastly
different physics the two formulations can apparently produce, even when
applied to the same system. Here, we revisit this problem using infinite-size
graphene with proximity-induced spin-orbit and magnetic exchange effects as a
testbed. By splitting this system into semi-infinite leads and central active
region, in the spirit of Landauer formulation of quantum transport, we prove
the {\em numerically exact equivalence} of the Kubo and Keldysh approaches via
the computation of spin Hall current density and spin-orbit torque in both
clean and disordered limits. The key to reconciling the two approaches are the
numerical frameworks we develop for: ({\em i}) evaluation of Kubo(-Bastin)
formula for a system attached to semi-infinite leads, which ensures continuous
energy spectrum and evades the need for commonly used phenomenological
broadening introducing ambiguity; and ({\em ii}) proper evaluation of Fermi-sea
term in the Keldysh approach, which {\em must} include the voltage drop across
the central active region even if it is disorder free.


### Generalized exchange operators for a system of spin-1 particles
**Authors**: Charlie Jeudy, Michel Rouleux

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.03952v1](http://arxiv.org/pdf/2411.03952v1)

**Abstract**: The irreps $(SU(2),{\cal H},U)$ of SU(2) of dimension $(2S+1)^N$, i.e.
operators acting on the space ${\cal H}={\cal H}_N={\bf C}^{(2S+1)^N}$ of $N$
identical particles with spin $S$, are described by Clebsch-Gordan
decomposition into inequivalent irreps. In the special case $S=1/2$, Dirac
\cite{Dir1} discovered that there is another rep given by $({\cal S}(N),{\cal
H},V)$ where ${\cal S}(N)$ is the permutation group, Thus, the standard
``linear'' Hamiltonian, or Heisenberg interaction Hamiltonian $H_0=\sum_{1\leq
i\leq N}\vec S_i\cdot\vec S_j$, where $\vec \sigma_i=2\vec S_i$ is the vector
of Pauli matrices, can be interpreted as the sum of the ``Exchange Operators''
$P_{ij}$ between particles $i$ and $j$. Schr\"odinger \cite{Sch} generalized to
higher spin numbers $S$ the Exchange Operator $P_{ij}=P_S(\vec S_i\cdot \vec
S_j)$ as a polynomial of degree $2S$ in $\vec S_i\cdot \vec S_j$. This we call
the $P$-representation. There is another rep induced by the one particle
permutation of states operators $\widetilde Q_\alpha$, which we call the
$Q$-rep. Our main purpose is to write some physical Hamiltonians for a few
particles in the $P$- or $Q$-rep and compute their spectrum. The simplest case
where there are as many particles as available states for the spin operator
along the $z$-axis, i.e. $N=2S+1=3$, see Weyl \cite{Wey} or Hamermesh
\cite{Ham}. Finally, we consider the relationship between permutations and
rotation invariance when $S=1/2$ and $S=1$.


### TabEBM: A Tabular Data Augmentation Method with Distinct Class-Specific Energy-Based Models
**Authors**: Andrei Margeloiu, Xiangjian Jiang, Nikola Simidjievski, Mateja Jamnik

**Published Date**: 2024-09-24

**Updated Date**: 2024-11-06

**PDF Url**: [2409.16118v3](http://arxiv.org/pdf/2409.16118v3)

**Abstract**: Data collection is often difficult in critical fields such as medicine,
physics, and chemistry. As a result, classification methods usually perform
poorly with these small datasets, leading to weak predictive performance.
Increasing the training set with additional synthetic data, similar to data
augmentation in images, is commonly believed to improve downstream
classification performance. However, current tabular generative methods that
learn either the joint distribution $ p(\mathbf{x}, y) $ or the
class-conditional distribution $ p(\mathbf{x} \mid y) $ often overfit on small
datasets, resulting in poor-quality synthetic data, usually worsening
classification performance compared to using real data alone. To solve these
challenges, we introduce TabEBM, a novel class-conditional generative method
using Energy-Based Models (EBMs). Unlike existing methods that use a shared
model to approximate all class-conditional densities, our key innovation is to
create distinct EBM generative models for each class, each modelling its
class-specific data distribution individually. This approach creates robust
energy landscapes, even in ambiguous class distributions. Our experiments show
that TabEBM generates synthetic data with higher quality and better statistical
fidelity than existing methods. When used for data augmentation, our synthetic
data consistently improves the classification performance across diverse
datasets of various sizes, especially small ones. Code is available at
https://github.com/andreimargeloiu/TabEBM.


## Diffusion
### DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion Models
**Authors**: Hengkang Wang, Xu Zhang, Taihui Li, Yuxiang Wan, Tiancong Chen, Ju Sun

**Published Date**: 2024-05-27

**Updated Date**: 2024-11-06

**PDF Url**: [2405.16749v2](http://arxiv.org/pdf/2405.16749v2)

**Abstract**: Pretrained diffusion models (DMs) have recently been popularly used in
solving inverse problems (IPs). The existing methods mostly interleave
iterative steps in the reverse diffusion process and iterative steps to bring
the iterates closer to satisfying the measurement constraint. However, such
interleaving methods struggle to produce final results that look like natural
objects of interest (i.e., manifold feasibility) and fit the measurement (i.e.,
measurement feasibility), especially for nonlinear IPs. Moreover, their
capabilities to deal with noisy IPs with unknown types and levels of
measurement noise are unknown. In this paper, we advocate viewing the reverse
process in DMs as a function and propose a novel plug-in method for solving IPs
using pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold
feasibility and measurement feasibility in a principled manner, and also shows
great potential for being robust to unknown types and levels of noise. Through
extensive experiments across various IP tasks, including two linear and three
nonlinear IPs, we demonstrate that DMPlug consistently outperforms
state-of-the-art methods, often by large margins especially for nonlinear IPs.
The code is available at https://github.com/sun-umn/DMPlug.


### DexDiffuser: Generating Dexterous Grasps with Diffusion Models
**Authors**: Zehang Weng, Haofei Lu, Danica Kragic, Jens Lundell

**Published Date**: 2024-02-05

**Updated Date**: 2024-11-06

**PDF Url**: [2402.02989v3](http://arxiv.org/pdf/2402.02989v3)

**Abstract**: We introduce DexDiffuser, a novel dexterous grasping method that generates,
evaluates, and refines grasps on partial object point clouds. DexDiffuser
includes the conditional diffusion-based grasp sampler DexSampler and the
dexterous grasp evaluator DexEvaluator. DexSampler generates high-quality
grasps conditioned on object point clouds by iterative denoising of randomly
sampled grasps. We also introduce two grasp refinement strategies:
Evaluator-Guided Diffusion (EGD) and Evaluator-based Sampling Refinement (ESR).
The experiment results demonstrate that DexDiffuser consistently outperforms
the state-of-the-art multi-finger grasp generation method FFHNet with an, on
average, 9.12% and 19.44% higher grasp success rate in simulation and real
robot experiments, respectively. Supplementary materials are available at
https://yulihn.github.io/DexDiffuser_page/


### ET-SEED: Efficient Trajectory-Level SE(3) Equivariant Diffusion Policy
**Authors**: Chenrui Tie, Yue Chen, Ruihai Wu, Boxuan Dong, Zeyi Li, Chongkai Gao, Hao Dong

**Published Date**: 2024-11-06

**Updated Date**: 2024-11-06

**PDF Url**: [2411.03990v1](http://arxiv.org/pdf/2411.03990v1)

**Abstract**: Imitation learning, e.g., diffusion policy, has been proven effective in
various robotic manipulation tasks. However, extensive demonstrations are
required for policy robustness and generalization. To reduce the demonstration
reliance, we leverage spatial symmetry and propose ET-SEED, an efficient
trajectory-level SE(3) equivariant diffusion model for generating action
sequences in complex robot manipulation tasks. Further, previous equivariant
diffusion models require the per-step equivariance in the Markov process,
making it difficult to learn policy under such strong constraints. We
theoretically extend equivariant Markov kernels and simplify the condition of
equivariant diffusion process, thereby significantly improving training
efficiency for trajectory-level SE(3) equivariant diffusion policy in an
end-to-end manner. We evaluate ET-SEED on representative robotic manipulation
tasks, involving rigid body, articulated and deformable object. Experiments
demonstrate superior data efficiency and manipulation proficiency of our
proposed method, as well as its ability to generalize to unseen configurations
with only a few demonstrations. Website: https://et-seed.github.io/


### Applying Guidance in a Limited Interval Improves Sample and Distribution Quality in Diffusion Models
**Authors**: Tuomas Kynkäänniemi, Miika Aittala, Tero Karras, Samuli Laine, Timo Aila, Jaakko Lehtinen

**Published Date**: 2024-04-11

**Updated Date**: 2024-11-06

**PDF Url**: [2404.07724v2](http://arxiv.org/pdf/2404.07724v2)

**Abstract**: Guidance is a crucial technique for extracting the best performance out of
image-generating diffusion models. Traditionally, a constant guidance weight
has been applied throughout the sampling chain of an image. We show that
guidance is clearly harmful toward the beginning of the chain (high noise
levels), largely unnecessary toward the end (low noise levels), and only
beneficial in the middle. We thus restrict it to a specific range of noise
levels, improving both the inference speed and result quality. This limited
guidance interval improves the record FID in ImageNet-512 significantly, from
1.81 to 1.40. We show that it is quantitatively and qualitatively beneficial
across different sampler parameters, network architectures, and datasets,
including the large-scale setting of Stable Diffusion XL. We thus suggest
exposing the guidance interval as a hyperparameter in all diffusion models that
use guidance.


### Copyright-Aware Incentive Scheme for Generative Art Models Using Hierarchical Reinforcement Learning
**Authors**: Zhuan Shi, Yifei Song, Xiaoli Tang, Lingjuan Lyu, Boi Faltings

**Published Date**: 2024-10-26

**Updated Date**: 2024-11-06

**PDF Url**: [2410.20180v2](http://arxiv.org/pdf/2410.20180v2)

**Abstract**: Generative art using Diffusion models has achieved remarkable performance in
image generation and text-to-image tasks. However, the increasing demand for
training data in generative art raises significant concerns about copyright
infringement, as models can produce images highly similar to copyrighted works.
Existing solutions attempt to mitigate this by perturbing Diffusion models to
reduce the likelihood of generating such images, but this often compromises
model performance. Another approach focuses on economically compensating data
holders for their contributions, yet it fails to address copyright loss
adequately. Our approach begin with the introduction of a novel copyright
metric grounded in copyright law and court precedents on infringement. We then
employ the TRAK method to estimate the contribution of data holders. To
accommodate the continuous data collection process, we divide the training into
multiple rounds. Finally, We designed a hierarchical budget allocation method
based on reinforcement learning to determine the budget for each round and the
remuneration of the data holder based on the data holder's contribution and
copyright loss in each round. Extensive experiments across three datasets show
that our method outperforms all eight benchmarks, demonstrating its
effectiveness in optimizing budget distribution in a copyright-aware manner. To
the best of our knowledge, this is the first technical work that introduces to
incentive contributors and protect their copyrights by compensating them.


