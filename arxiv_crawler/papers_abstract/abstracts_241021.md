# Abstracts of Papers

## Physics
### Generalization Error in Quantum Machine Learning in the Presence of Sampling Noise
**Authors**: Fangjun Hu, Xun Gao

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14654v1](http://arxiv.org/pdf/2410.14654v1)

**Abstract**: Tackling sampling noise due to finite shots of quantum measurement is an
unavoidable challenge when extracting information in machine learning with
physical systems. Eigentask Learning was developed in recent work as a
framework for learning in the presence of sampling noise. In that work,
numerical evidence was presented that extracting low-noise contributions of
features can improve performance for machine learning tasks, displaying
robustness to overfitting, and increasing generalization accuracy. The issue of
characterizing generalization errors in situations where the training dataset
is finite remains unresolved in the previous work. In this study, we use
methodologies from statistical mechanics to calculate the training and
generalization errors of a generic quantum machine learning system when the
input training dataset and output measurement sampling shots are both finite.
Our analytical findings, supported by numerical validation, offer solid
justification that Eigentask Learning provides optimal learning in the sense of
minimizing generalization errors.


### Bootstrapping Ground State Correlators in Matrix Theory, Part I
**Authors**: Henry W. Lin, Zechuan Zheng

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14647v1](http://arxiv.org/pdf/2410.14647v1)

**Abstract**: The D0-brane/Banks-Fischler-Shenker-Susskind matrix theory is a strongly
coupled quantum system with an interesting gravity dual. We develop a scheme to
derive bootstrap bounds on simple correlators in the matrix theory at infinite
$N$ at zero energy by imposing the supercharge equations of motion. By
exploiting SO(9) symmetry, we are able to consider single-trace operators
involving words of length up to 9 using very modest computational resources. We
interpret our initial results as strong evidence that the bootstrap method can
efficiently access physics in the strongly coupled, infinite $N$ regime.


### Displaced vertex signals of low temperature baryogenesis
**Authors**: Pedro Bittar, Gustavo Burdman

**Published Date**: 2024-10-01

**Updated Date**: 2024-10-18

**PDF Url**: [2410.00957v2](http://arxiv.org/pdf/2410.00957v2)

**Abstract**: We explore the connection of baryogenesis at temperatures below the
electroweak scale and signals for long-lived particles at the LHC. The model
features new SM singlets, with a long-lived fermion decaying to quarks to
generate the baryon asymmetry. The model avoids strong flavor physics bounds
while predicting a rich diquark phenomenology, monojet signals, and displaced
vertices. We show how the displaced vertex signals can be probed at the HL-LHC.
The large transverse production makes a strong physics case for constructing
far detector experiments such as MATHUSLA, ANUBIS, and CODEX-b, complementary
to the central and forward long-lived particle program.


### Asymptotically Optimal Change Detection for Unnormalized Pre- and Post-Change Distributions
**Authors**: Arman Adibi, Sanjeev Kulkarni, H. Vincent Poor, Taposh Banerjee, Vahid Tarokh

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14615v1](http://arxiv.org/pdf/2410.14615v1)

**Abstract**: This paper addresses the problem of detecting changes when only unnormalized
pre- and post-change distributions are accessible. This situation happens in
many scenarios in physics such as in ferromagnetism, crystallography,
magneto-hydrodynamics, and thermodynamics, where the energy models are
difficult to normalize.
  Our approach is based on the estimation of the Cumulative Sum (CUSUM)
statistics, which is known to produce optimal performance. We first present an
intuitively appealing approximation method. Unfortunately, this produces a
biased estimator of the CUSUM statistics and may cause performance degradation.
We then propose the Log-Partition Approximation Cumulative Sum (LPA-CUSUM)
algorithm based on thermodynamic integration (TI) in order to estimate the
log-ratio of normalizing constants of pre- and post-change distributions. It is
proved that this approach gives an unbiased estimate of the log-partition
function and the CUSUM statistics, and leads to an asymptotically optimal
performance. Moreover, we derive a relationship between the required sample
size for thermodynamic integration and the desired detection delay performance,
offering guidelines for practical parameter selection. Numerical studies are
provided demonstrating the efficacy of our approach.


### Bayesian Multi-wavelength Imaging of the LMC SN1987A with SRG/eROSITA
**Authors**: Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Michael Freyberg, Mara Salvato, Torsten Enßlin

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14599v1](http://arxiv.org/pdf/2410.14599v1)

**Abstract**: The EDR and eRASS1 data have already revealed a remarkable number of
undiscovered X-ray sources. Using Bayesian inference and generative modeling
techniques for X-ray imaging, we aim to increase the sensitivity and scientific
value of these observations by denoising, deconvolving, and decomposing the
X-ray sky. Leveraging information field theory, we can exploit the spatial and
spectral correlation structures of the different physical components of the sky
with non-parametric priors to enhance the image reconstruction. By
incorporating instrumental effects into the forward model, we develop a
comprehensive Bayesian imaging algorithm for eROSITA pointing observations.
Finally, we apply the developed algorithm to EDR data of the LMC SN1987A,
fusing data sets from observations made by five different telescope modules.
The final result is a denoised, deconvolved, and decomposed view of the LMC,
which enables the analysis of its fine-scale structures, the creation of point
source catalogues of this region, and enhanced calibration for future work.


### Circuit QED theory of direct and dual Shapiro steps with finite-size transmission line resonators
**Authors**: Federico Borletto, Luca Giacomelli, Cristiano Ciuti

**Published Date**: 2024-05-21

**Updated Date**: 2024-10-18

**PDF Url**: [2405.12935v2](http://arxiv.org/pdf/2405.12935v2)

**Abstract**: We investigate the occurrence of direct and dual Shapiro steps for a
Josephson junction coupled to a finite-size transmission line resonator. We
treat both problems through a circuit QED approach with a large, but finite
number of photon modes. For the dual case, we do not assume the (approximate)
charge-phase duality, but include the full multi-band dynamics for the
Josephson junction. Mean-field equations within such Hamiltonian approach
reproduce the result obtained through a dissipative classical equation when the
number of transmission line modes is large enough. To account for quantum and
thermal fluctuations, we go beyond the mean-field treatment within a truncated
Wigner approach. The fluctuations are shown to modify both the direct and the
dual steps. We show how the dual steps are very sensitive to these fluctuations
and identify the key physical parameters for the junction and the transmission
line controlling their robustness, which is essential for applications to close
the quantum metrological triangle.


### Fully charmed tetraquarks from LHC to FCC: Natural stability from fragmentation
**Authors**: Francesco Giovanni Celiberto, Gabriele Gatto, Alessandro papa

**Published Date**: 2024-05-23

**Updated Date**: 2024-10-18

**PDF Url**: [2405.14773v2](http://arxiv.org/pdf/2405.14773v2)

**Abstract**: We investigate the inclusive production of fully charmed tetraquarks,
$T_{4c}(0^{++})$ or $T_{4c}(2^{++})$ radial excitations, in high-energy proton
collisions. We build our study upon the collinear fragmentation of a single
parton in a variable-flavor number scheme, suited to describe the tetraquark
formation mechanism from moderate to large transverse-momentum regimes. To this
extent, we derive a novel set of DGLAP-evolving collinear fragmentation
functions, named TQ4Q1.0 determinations. They encode initial-scale inputs
corresponding to both gluon and heavy-quark fragmentation channels, defined
within the context of quark-potential and spin-physics inspired models,
respectively. We work within the NLL/NLO$^+$ hybrid factorization and make use
of the JETHAD numeric interface along with the symJETHAD symbolic calculation
plugin. With these tools, we provide predictions for high-energy observables
sensitive to $T_{4c}$ plus jet emissions at center-of-mass energies ranging
from 14 TeV at the LHC to the 100 TeV nominal energy of the FCC.


### Quantum Brownian motion induced by a scalar field in Einstein universe under Dirichlet and Neumann boundary conditions
**Authors**: E. J. B. Ferreira, H. F. Santana Mota

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14560v1](http://arxiv.org/pdf/2410.14560v1)

**Abstract**: In this paper, the Quantum Brownian motion of a point particle induced by the
quantum vacuum fluctuations of a real massless scalar field in Einstein
universe under Dirichlet and Neumann boundary conditions is studied. Using the
Wightman functions, general expressions for the renormalized dispersion of the
physical momentum are derived. Distinct expressions are found for the
dispersion associated with each component of the particle physical momentum,
indicating that the global properties of homogeneity and isotropy of space are
lost, as a consequence of the introduced boundary conditions. Divergences also
arise and are related to the compact nature of Einstein universe and the
introduced boundary conditions.


### Local Thermal Operations and Classical Communication
**Authors**: Rafał Bistroń, Jakub Czartowski

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14550v1](http://arxiv.org/pdf/2410.14550v1)

**Abstract**: Quantum mechanics and thermodynamics are foundational to modern physics. This
paper introduces a novel framework, based on local operations with classical
communication, fundamental paradigm in quantum information, incorporating the
preservation of thermal equilibrium: local thermal operations and classical
communication (LTOCC). We introduce a hierarchy of LTOCC, ordered according to
the amount of control and communication. Next, we provide a detailed analysis
of symmetric local thermal operations and classical communication
($\mathcal{S}$LTOCC), including majorization-based bounds on possible
transitions and properties such as generation of strong correlations from Gibbs
states.


### Responding to objections made by Sorin Coşofreţ concerning kinetic molecular theory: an illustration of how to teach physics students to evaluate pseudoscientific work
**Authors**: Marc Meléndez

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14534v1](http://arxiv.org/pdf/2410.14534v1)

**Abstract**: Sorin Co\c{s}ofre\c{t} has argued that kinetic molecular theory does not
correctly describe thermal equilibrium in ideal gases and has provided some
examples that purportedly show that the standard laws imply consequences that
contradict experimental results. This paper considers a few of the examples in
detail and concludes that Co\c{s}ofre\c{t}'s analysis is erroneous.
Furthermore, although it does not disprove any of the other claims made by
Co\c{s}ofre\c{t} in criticising thermodynamics and many other fields of
physics, it does call his whole project into question, as Co\c{s}ofre\c{t}
exhibits a lack of relevant training, limited knowledge of key facts and
previous research, and a disposition to favour his own intuitions above
theoretical and experimental checks. The exercise below illustrates some of the
problems commonly encountered in pseudoscientific approaches, and provides a
few tips on how to teach aspiring scientists about how to evaluate such works
for themselves.


## Diffusion
### Learning diffusion at lightspeed
**Authors**: Antonio Terpin, Nicolas Lanzetti, Martin Gadea, Florian Dörfler

**Published Date**: 2024-06-18

**Updated Date**: 2024-10-18

**PDF Url**: [2406.12616v2](http://arxiv.org/pdf/2406.12616v2)

**Abstract**: Diffusion regulates numerous natural processes and the dynamics of many
successful generative models. Existing models to learn the diffusion terms from
observational data rely on complex bilevel optimization problems and model only
the drift of the system. We propose a new simple model, JKOnet*, which bypasses
the complexity of existing architectures while presenting significantly
enhanced representational capabilities: JKOnet* recovers the potential,
interaction, and internal energy components of the underlying diffusion
process. JKOnet* minimizes a simple quadratic loss and outperforms other
baselines in terms of sample efficiency, computational complexity, and
accuracy. Additionally, JKOnet* provides a closed-form optimal solution for
linearly parametrized functionals, and, when applied to predict the evolution
of cellular processes from real-world data, it achieves state-of-the-art
accuracy at a fraction of the computational cost of all existing methods. Our
methodology is based on the interpretation of diffusion processes as
energy-minimizing trajectories in the probability space via the so-called JKO
scheme, which we study via its first-order optimality conditions.


### Diffusion-based Semi-supervised Spectral Algorithm for Regression on Manifolds
**Authors**: Weichun Xia, Jiaxin Jiang, Lei Shi

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14539v1](http://arxiv.org/pdf/2410.14539v1)

**Abstract**: We introduce a novel diffusion-based spectral algorithm to tackle regression
analysis on high-dimensional data, particularly data embedded within
lower-dimensional manifolds. Traditional spectral algorithms often fall short
in such contexts, primarily due to the reliance on predetermined kernel
functions, which inadequately address the complex structures inherent in
manifold-based data. By employing graph Laplacian approximation, our method
uses the local estimation property of heat kernel, offering an adaptive,
data-driven approach to overcome this obstacle. Another distinct advantage of
our algorithm lies in its semi-supervised learning framework, enabling it to
fully use the additional unlabeled data. This ability enhances the performance
by allowing the algorithm to dig the spectrum and curvature of the data
manifold, providing a more comprehensive understanding of the dataset.
Moreover, our algorithm performs in an entirely data-driven manner, operating
directly within the intrinsic manifold structure of the data, without requiring
any predefined manifold information. We provide a convergence analysis of our
algorithm. Our findings reveal that the algorithm achieves a convergence rate
that depends solely on the intrinsic dimension of the underlying manifold,
thereby avoiding the curse of dimensionality associated with the higher ambient
dimension.


### LEAD: Latent Realignment for Human Motion Diffusion
**Authors**: Nefeli Andreou, Xi Wang, Victoria Fernández Abrevaya, Marie-Paule Cani, Yiorgos Chrysanthou, Vicky Kalogeiton

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14508v1](http://arxiv.org/pdf/2410.14508v1)

**Abstract**: Our goal is to generate realistic human motion from natural language. Modern
methods often face a trade-off between model expressiveness and text-to-motion
alignment. Some align text and motion latent spaces but sacrifice
expressiveness; others rely on diffusion models producing impressive motions,
but lacking semantic meaning in their latent space. This may compromise
realism, diversity, and applicability. Here, we address this by combining
latent diffusion with a realignment mechanism, producing a novel, semantically
structured space that encodes the semantics of language. Leveraging this
capability, we introduce the task of textual motion inversion to capture novel
motion concepts from a few examples. For motion synthesis, we evaluate LEAD on
HumanML3D and KIT-ML and show comparable performance to the state-of-the-art in
terms of realism, diversity, and text-motion consistency. Our qualitative
analysis and user study reveal that our synthesized motions are sharper, more
human-like and comply better with the text compared to modern methods. For
motion textual inversion, our method demonstrates improved capacity in
capturing out-of-distribution characteristics in comparison to traditional
VAEs.


### ANT: Adaptive Noise Schedule for Time Series Diffusion Models
**Authors**: Seunghan Lee, Kibok Lee, Taeyoung Park

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14488v1](http://arxiv.org/pdf/2410.14488v1)

**Abstract**: Advances in diffusion models for generative artificial intelligence have
recently propagated to the time series (TS) domain, demonstrating
state-of-the-art performance on various tasks. However, prior works on TS
diffusion models often borrow the framework of existing works proposed in other
domains without considering the characteristics of TS data, leading to
suboptimal performance. In this work, we propose Adaptive Noise schedule for
Time series diffusion models (ANT), which automatically predetermines proper
noise schedules for given TS datasets based on their statistics representing
non-stationarity. Our intuition is that an optimal noise schedule should
satisfy the following desiderata: 1) It linearly reduces the non-stationarity
of TS data so that all diffusion steps are equally meaningful, 2) the data is
corrupted to the random noise at the final step, and 3) the number of steps is
sufficiently large. The proposed method is practical for use in that it
eliminates the necessity of finding the optimal noise schedule with a small
additional cost to compute the statistics for given datasets, which can be done
offline before training. We validate the effectiveness of our method across
various tasks, including TS forecasting, refinement, and generation, on
datasets from diverse domains. Code is available at this repository:
https://github.com/seunghan96/ANT.


### DRL Optimization Trajectory Generation via Wireless Network Intent-Guided Diffusion Models for Optimizing Resource Allocation
**Authors**: Junjie Wu, Xuming Fang, Dusit Niyato, Jiacheng Wang, Jingyu Wang

**Published Date**: 2024-10-18

**Updated Date**: 2024-10-18

**PDF Url**: [2410.14481v1](http://arxiv.org/pdf/2410.14481v1)

**Abstract**: With the rapid advancements in wireless communication fields, including
low-altitude economies, 6G, and Wi-Fi, the scale of wireless networks continues
to expand, accompanied by increasing service quality demands. Traditional deep
reinforcement learning (DRL)-based optimization models can improve network
performance by solving non-convex optimization problems intelligently. However,
they heavily rely on online deployment and often require extensive initial
training. Online DRL optimization models typically make accurate decisions
based on current channel state distributions. When these distributions change,
their generalization capability diminishes, which hinders the responsiveness
essential for real-time and high-reliability wireless communication networks.
Furthermore, different users have varying quality of service (QoS) requirements
across diverse scenarios, and conventional online DRL methods struggle to
accommodate this variability. Consequently, exploring flexible and customized
AI strategies is critical. We propose a wireless network intent (WNI)-guided
trajectory generation model based on a generative diffusion model (GDM). This
model can be generated and fine-tuned in real time to achieve the objective and
meet the constraints of target intent networks, significantly reducing state
information exposure during wireless communication. Moreover, The WNI-guided
optimization trajectory generation can be customized to address differentiated
QoS requirements, enhancing the overall quality of communication in future
intelligent networks. Extensive simulation results demonstrate that our
approach achieves greater stability in spectral efficiency variations and
outperforms traditional DRL optimization models in dynamic communication
systems.


