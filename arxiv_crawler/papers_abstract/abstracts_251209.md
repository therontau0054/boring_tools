# Abstracts of Papers

## Physics
### Comparing quantum channels using Hermitian-preserving trace-preserving linear maps: A physically meaningful approach
**Authors**: Arindam Mitra, Jatin Ghai

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07822v1](https://arxiv.org/pdf/2512.07822v1)

**Abstract**: In quantum technologies, quantum channels are essential elements for the transmission of quantum states. The action of a quantum channel usually introduces noise in the quantum state and thereby reduces the information contained in it. Concatenating a quantum channel with another quantum channel makes it more noisy and degrades its information and resource preservability. These are mathematically described by completely positive trace-preserving linear maps that represent the generic evolution of quantum systems. These are special cases of Hermitian-preserving trace-preserving linear maps. In this work, we demonstrate a physically meaningful way to compare a pair of quantum channels using Hermitian-preserving trace-preserving linear maps. More precisely, given a pair of quantum channels and an arbitrary unknown input state, we show that if the output state of one quantum channel from the pair can be obtained from the output statistics of the other channel from the pair using some quantum measurement, then the latter channel from the pair can be obtained from the former channel by concatenating it with a Hermitian-preserving trace-preserving linear map. This relation between these two channels is a preorder, and we try to study its characterization in this work. We also illustrate the implications of our results for the incompatibility of quantum devices through an example.


### Nonlinear Quantum Mechanics and Artificial Intelligence
**Authors**: Jonathan Oppenheim

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07809v1](https://arxiv.org/pdf/2512.07809v1)

**Abstract**: We examine a criterion for relativistic covariance of nonlinear quantum field theory recently proposed by GPT-5 and published in Physics Letters B. We show that this criterion inadvertently tests a different property -- locality of the Hamiltonian -- and is insensitive to whether the theory is nonlinear. We recall the correct criterion, identified by Gisin and Polchinski thirty-five years ago, and reformulate their result in field-theoretic language.


### Polylogarithmic-Depth Quantum Algorithm for Simulating the Extended Hubbard Model on a Two-Dimensional Lattice Using the Fast Multipole Method
**Authors**: Yu Wang, Martina Nibbi, Maxine Luo, Isabel Nha Minh Le, Yanbin Chen, J. Ignacio Cirac, Christian B. Mendl

**Published Date**: 2025-12-03

**Updated Date**: 2025-12-08

**PDF Url**: [2512.03898v3](https://arxiv.org/pdf/2512.03898v3)

**Abstract**: The extended Hubbard model on a two-dimensional lattice captures key physical phenomena, but is challenging to simulate due to the presence of long-range interactions. In this work, we present an efficient quantum algorithm for simulating the time evolution of this model. Our approach, inspired by the fast multipole method, approximates pairwise interactions by interactions between hierarchical levels of coarse-graining boxes. We discuss how to leverage recent advances in two-dimensional neutral atom quantum computing, supporting non-local operations such as long-range gates and shuttling. The resulting circuit depth for a single Trotter step scales polylogarithmically with system size.


### Strongly driven cavity quantum electrodynamical-optomechanical hybrid system
**Authors**: Xuxin Wang, Jiahe Pan, Tobias J. Kippenberg, Shingo Kono

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07788v1](https://arxiv.org/pdf/2512.07788v1)

**Abstract**: Hybrid quantum systems harness the distinct advantages of different physical platforms, yet their integration is not always trivial due to potential incompatibilities in operational principles. Here, we theoretically propose and demonstrate a scheme for generating non-Gaussian mechanical states using a strongly driven hybrid system that combines cavity quantum electrodynamics (QED) and cavity optomechanics. Our protocol prepares a non-Gaussian cavity state in the dispersive regime of cavity QED and subsequently transfers it to a mechanical oscillator using the optomechanical interaction enhanced by a coherent cavity drive. While non-Gaussian cavity state control in cavity QED is well established in the dispersive regime, its behavior under strong cavity drive, essential for cavity optomechanics, remains largely unexplored. To bridge this gap, we develop an efficient simulation framework to model cavity QED dynamics in the high-photon-number regime. We show that a strong cavity drive can coherently displace the cavity state with minimal perturbations, effectively decoupling it from the qubit. The resulting large coherent cavity field enhances the optomechanical coupling strength, enabling high-fidelity transfer of non-Gaussian cavity states to the mechanical mode. These results reveal new dynamical features of driven cavity QED and open a pathway toward realizing non-Gaussian mechanical quantum memories and sensors.


### Automating High Energy Physics Data Analysis with LLM-Powered Agents
**Authors**: Eli Gendreau-Distler, Joshua Ho, Dongwon Kim, Luc Tomas Le Pottier, Haichen Wang, Chengxi Yang

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07785v1](https://arxiv.org/pdf/2512.07785v1)

**Abstract**: We present a proof-of-principle study demonstrating the use of large language model (LLM) agents to automate a representative high energy physics (HEP) analysis. Using the Higgs boson diphoton cross-section measurement as a case study with ATLAS Open Data, we design a hybrid system that combines an LLM-based supervisor-coder agent with the Snakemake workflow manager. In this architecture, the workflow manager enforces reproducibility and determinism, while the agent autonomously generates, executes, and iteratively corrects analysis code in response to user instructions. We define quantitative evaluation metrics including success rate, error distribution, costs per specific task, and average number of API calls, to assess agent performance across multi-stage workflows. To characterize variability across architectures, we benchmark a representative selection of state-of-the-art LLMs spanning the Gemini and GPT-5 series, the Claude family, and leading open-weight models. While the workflow manager ensures deterministic execution of all analysis steps, the final outputs still show stochastic variation. Although we set the temperature to zero, other sampling parameters (e.g., top-p, top-k) remained at their defaults, and some reasoning-oriented models internally adjust these settings. Consequently, the models do not produce fully deterministic results. This study establishes the first LLM-agent-driven automated data-analysis framework in HEP, enabling systematic benchmarking of model capabilities, stability, and limitations in real-world scientific computing environments. The baseline code used in this work is available at https://huggingface.co/HWresearch/LLM4HEP. This work was accepted as a poster at the Machine Learning and the Physical Sciences (ML4PS) workshop at NeurIPS 2025. The initial submission was made on August 30, 2025.


### Spacetime boundaries do not break diffeomorphism and gauge symmetries
**Authors**: J. François, L. Ravera

**Published Date**: 2025-04-29

**Updated Date**: 2025-12-08

**PDF Url**: [2504.20945v2](https://arxiv.org/pdf/2504.20945v2)

**Abstract**: In General Relativity and gauge field theory, one often encounters a claim, which may be called the boundary problem, according to which "boundaries break diffeomorphism and gauge symmetries". We argue that this statement has the same conceptual structure as the hole argument, and is thus likewise defused by the point-coincidence argument: We show that the boundary problem dissolves once it is understood that a physical region, thus its boundary, is relationally and invariantly defined. This insight can be technically implemented via the Dressing Field Method, a systematic tool to exhibit the gauge-invariant content of general-relativistic gauge field theories, whereby physical field-theoretical degrees of freedom co-define each other and define, coordinatize, the physical spacetime. We illustrate our claim with a simple application to the case of General Relativity.


### Physics-Informed Neural Networks for Source Inversion and Parameters Estimation in Atmospheric Dispersion
**Authors**: Brenda Anague, Bamdad Hosseini, Issa Karambal, Jean Medard Ngnotchouye

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07755v1](https://arxiv.org/pdf/2512.07755v1)

**Abstract**: Recent studies have shown the success of deep learning in solving forward and inverse problems in engineering and scientific computing domains, such as physics-informed neural networks (PINNs). In the fields of atmospheric science and environmental monitoring, estimating emission source locations is a central task that further relies on multiple model parameters that dictate velocity profiles and diffusion parameters. Estimating these parameters at the same time as emission sources from scarce data is a difficult task. In this work, we achieve this by leveraging the flexibility and generality of PINNs. We use a weighted adaptive method based on the neural tangent kernels to solve a source inversion problem with parameter estimation on the 2D and 3D advection-diffusion equations with unknown velocity and diffusion coefficients that may vary in space and time. Our proposed weighted adaptive method is presented as an extension of PINNs for forward PDE problems to a highly ill-posed source inversion and parameter estimation problem. The key idea behind our methodology is to attempt the joint recovery of the solution, the sources along with the unknown parameters, thereby using the underlying partial differential equation as a constraint that couples multiple unknown functional parameters, leading to more efficient use of the limited information in the measurements. We present various numerical experiments, using different types of measurements that model practical engineering systems, to show that our proposed method is indeed successful and robust to additional noise in the measurements.


### The Ginsparg-Wilson relation and overlap fermions
**Authors**: Thomas DeGrand

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07743v1](https://arxiv.org/pdf/2512.07743v1)

**Abstract**: I review the physics of lattice fermions obeying the Ginsparg-Wilson relation. I describe their relation to domain wall fermions. I give a description of methodology for performing numerical simulations with overlap fermions. This is a chapter contributed to the on-line book ``Lattice QCD at 50 years,'' (LQCD@50), edited by Tanmoy Bhattacharya, Maarten Golterman, Rajan Gupta, Laurent Lellouch, and Steve Sharpe.


### A scalable and real-time neural decoder for topological quantum codes
**Authors**: Andrew W. Senior, Thomas Edlich, Francisco J. H. Heras, Lei M. Zhang, Oscar Higgott, James S. Spencer, Taylor Applebaum, Sam Blackwell, Justin Ledford, Akvilė Žemgulytė, Augustin Žídek, Noah Shutty, Andrew Cowie, Yin Li, George Holland, Peter Brooks, Charlie Beattie, Michael Newman, Alex Davies, Cody Jones, Sergio Boixo, Hartmut Neven, Pushmeet Kohli, Johannes Bausch

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07737v1](https://arxiv.org/pdf/2512.07737v1)

**Abstract**: Fault-tolerant quantum computing will require error rates far below those achievable with physical qubits. Quantum error correction (QEC) bridges this gap, but depends on decoders being simultaneously fast, accurate, and scalable. This combination of requirements has not yet been met by a machine-learning decoder, nor by any decoder for promising resource-efficient codes such as the colour code. Here we introduce AlphaQubit 2, a neural-network decoder that achieves near-optimal logical error rates for both surface and colour codes at large scales under realistic noise. For the colour code, it is orders of magnitude faster than other high-accuracy decoders. For the surface code, we demonstrate real-time decoding faster than 1 microsecond per cycle up to distance 11 on current commercial accelerators with better accuracy than leading real-time decoders. These results support the practical application of a wider class of promising QEC codes, and establish a credible path towards high-accuracy, real-time neural decoding at the scales required for fault-tolerant quantum computation.


### The Native Spiking Microarchitecture: From Iontronic Primitives to Bit-Exact FP8 Arithmetic
**Authors**: Zhengzheng Tang

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07724v1](https://arxiv.org/pdf/2512.07724v1)

**Abstract**: The 2025 Nobel Prize in Chemistry for Metal-Organic Frameworks (MOFs) and recent breakthroughs by Huanting Wang's team at Monash University establish angstrom-scale channels as promising post-silicon substrates with native integrate-and-fire (IF) dynamics. However, utilizing these stochastic, analog materials for deterministic, bit-exact AI workloads (e.g., FP8) remains a paradox. Existing neuromorphic methods often settle for approximation, failing Transformer precision standards. To traverse the gap "from stochastic ions to deterministic floats," we propose a Native Spiking Microarchitecture. Treating noisy neurons as logic primitives, we introduce a Spatial Combinational Pipeline and a Sticky-Extra Correction mechanism. Validation across all 16,129 FP8 pairs confirms 100% bit-exact alignment with PyTorch. Crucially, our architecture reduces Linear layer latency to O(log N), yielding a 17x speedup. Physical simulations further demonstrate robustness against extreme membrane leakage (beta approx 0.01), effectively immunizing the system against the stochastic nature of the hardware.


## Diffusion
### One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation
**Authors**: Yuan Gao, Chen Chen, Tianrong Chen, Jiatao Gu

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07829v1](https://arxiv.org/pdf/2512.07829v1)

**Abstract**: Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.


### The Adoption and Usage of AI Agents: Early Evidence from Perplexity
**Authors**: Jeremy Yang, Noah Yonack, Kate Zyskowski, Denis Yarats, Johnny Ho, Jerry Ma

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07828v1](https://arxiv.org/pdf/2512.07828v1)

**Abstract**: This paper presents the first large-scale field study of the adoption, usage intensity, and use cases of general-purpose AI agents operating in open-world web environments. Our analysis centers on Comet, an AI-powered browser developed by Perplexity, and its integrated agent, Comet Assistant. Drawing on hundreds of millions of anonymized user interactions, we address three fundamental questions: Who is using AI agents? How intensively are they using them? And what are they using them for? Our findings reveal substantial heterogeneity in adoption and usage across user segments. Earlier adopters, users in countries with higher GDP per capita and educational attainment, and individuals working in digital or knowledge-intensive sectors -- such as digital technology, academia, finance, marketing, and entrepreneurship -- are more likely to adopt or actively use the agent. To systematically characterize the substance of agent usage, we introduce a hierarchical agentic taxonomy that organizes use cases across three levels: topic, subtopic, and task. The two largest topics, Productivity & Workflow and Learning & Research, account for 57% of all agentic queries, while the two largest subtopics, Courses and Shopping for Goods, make up 22%. The top 10 out of 90 tasks represent 55% of queries. Personal use constitutes 55% of queries, while professional and educational contexts comprise 30% and 16%, respectively. In the short term, use cases exhibit strong stickiness, but over time users tend to shift toward more cognitively oriented topics. The diffusion of increasingly capable AI agents carries important implications for researchers, businesses, policymakers, and educators, inviting new lines of inquiry into this rapidly emerging class of AI capabilities.


### Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment
**Authors**: Sangha Park, Eunji Kim, Yeongtak Oh, Jooyoung Choi, Sungroh Yoon

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07702v1](https://arxiv.org/pdf/2512.07702v1)

**Abstract**: Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.


### Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks
**Authors**: Aileen Liao, Dong-Ki Kim, Max Olan Smith, Ali-akbar Agha-mohammadi, Shayegan Omidshafiei

**Published Date**: 2025-12-08

**Updated Date**: 2025-12-08

**PDF Url**: [2512.07697v1](https://arxiv.org/pdf/2512.07697v1)

**Abstract**: As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty.


## Quantitative Finance
### Quantum Temporal Convolutional Neural Networks for Cross-Sectional Equity Return Prediction: A Comparative Benchmark Study
**Authors**: Chi-Sheng Chen, Xinyu Zhang, Rong Fu, Qiuzhe Xie, Fan Zhang

**Published Date**: 2025-12-07

**Updated Date**: 2025-12-07

**PDF Url**: [2512.06630v1](https://arxiv.org/pdf/2512.06630v1)

**Abstract**: Quantum machine learning offers a promising pathway for enhancing stock market prediction, particularly under complex, noisy, and highly dynamic financial environments. However, many classical forecasting models struggle with noisy input, regime shifts, and limited generalization capacity. To address these challenges, we propose a Quantum Temporal Convolutional Neural Network (QTCNN) that combines a classical temporal encoder with parameter-efficient quantum convolution circuits for cross-sectional equity return prediction. The temporal encoder extracts multi-scale patterns from sequential technical indicators, while the quantum processing leverages superposition and entanglement to enhance feature representation and suppress overfitting. We conduct a comprehensive benchmarking study on the JPX Tokyo Stock Exchange dataset and evaluate predictions through long-short portfolio construction using out-of-sample Sharpe ratio as the primary performance metric. QTCNN achieves a Sharpe ratio of 0.538, outperforming the best classical baseline by approximately 72\%. These results highlight the practical potential of quantum-enhanced forecasting model, QTCNN, for robust decision-making in quantitative finance.


### Unveiling Hedge Funds: Topic Modeling and Sentiment Correlation with Fund Performance
**Authors**: Chang Liu

**Published Date**: 2025-12-07

**Updated Date**: 2025-12-07

**PDF Url**: [2512.06620v1](https://arxiv.org/pdf/2512.06620v1)

**Abstract**: The hedge fund industry presents significant challenges for investors due to its opacity and limited disclosure requirements. This pioneering study introduces two major innovations in financial text analysis. First, we apply topic modeling to hedge fund documents-an unexplored domain for automated text analysis-using a unique dataset of over 35,000 documents from 1,125 hedge fund managers. We compared three state-of-the-art methods: Latent Dirichlet Allocation (LDA), Top2Vec, and BERTopic. Our findings reveal that LDA with 20 topics produces the most interpretable results for human users and demonstrates higher robustness in topic assignments when the number of topics varies, while Top2Vec shows superior classification performance. Second, we establish a novel quantitative framework linking document sentiment to fund performance, transforming qualitative information traditionally requiring expert interpretation into systematic investment signals. In sentiment analysis, contrary to expectations, the general-purpose DistilBERT outperforms the finance-specific FinBERT in generating sentiment scores, demonstrating superior adaptability to diverse linguistic patterns found in hedge fund documents that extend beyond specialized financial news text. Furthermore, sentiment scores derived using DistilBERT in combination with Top2Vec show stronger correlations with subsequent fund performance compared to other model combinations. These results demonstrate that automated topic modeling and sentiment analysis can effectively process hedge fund documents, providing investors with new data-driven decision support tools.


