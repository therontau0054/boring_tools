# Abstracts of Papers

## Physics
### Probing scalar and pseudoscalar new physics using rare kaon decays
**Authors**: G. D'Ambrosio, A. M. Iyer, F. Mahmoudi, S. Neshatpour

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16903v1](https://arxiv.org/pdf/2512.16903v1)

**Abstract**: Rare kaon decays provide sensitive tests of new physics. In this work, we focus on scalar and pseudoscalar operators, analysing the $K\to π\ell^+\ell^-$ and $K\to \ell^+\ell^-$ decays. We highlight the complementary role of different modes: $K^+\toπ^+\ell^+\ell^-$, in particular the forward-backward asymmetry in the muon channel as a clean probe of scalar effects, the stringent constraints from $K_L\to μ^+μ^-$, and the discovery potential of future measurements of $K_S\to μ^+μ^-$ and $K_L\to π^0 \ell^+\ell^-$. The interplay between charged and neutral modes underscores the complementarity of NA62, the LHCb upgrade, and KOTO-II.


### Machine learning assisted high throughput prediction of moiré materials
**Authors**: Daniel Kaplan, Alexander C. Tyner, Eva Y. Andrei, J. H. Pixley

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16892v1](https://arxiv.org/pdf/2512.16892v1)

**Abstract**: The world of 2D materials is rapidly expanding with new discoveries of stackable and twistable layered systems composed of lattices of different symmetries, orbital character, and structural motifs. Often, however, it is not clear a priori whether a pair of monolayers twisted at a small angle will exhibit correlated or interaction-driven phenomena. The computational cost to make accurate predictions of the single particle states is significant, as small twists require very large unit cells, easily encompassing 10,000 atoms, and therefore implementing a high throughput prediction has been out of reach. Here we show a path to overcome this challenge by introducing a machine learning (ML) based methodology that efficiently estimates the twisted interlayer tunneling at arbitrarily low twist angles through the local-configuration based approach that enables interpolating the local stacking for a range of twist angles using a random forest regression algorithm. We leverage the kernel polynomial method to compute the density of states (DOS) on large real space graphs by reconstructing a lattice model of the twisted bilayer with the ML fitted hoppings. For twisted bilayer graphene (TBG), we show the ability of the method to resolve the magic angle DOS at a substantial improvement in computational time. We use this new technique to scan through the database of stable 2D monolayers (MC2D) and reveal new twistable candidates across the five possible points groups in two-dimensions with a large DOS near the Fermi energy, with potentially exciting interacting physics to be probed in future experiments.


### Anomalous Dimension of a General Effective Gauge Theory II: Fermionic Sector
**Authors**: Jason Aebischer, Luigi C. Bresciani, Nudzeim Selimovic

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16890v1](https://arxiv.org/pdf/2512.16890v1)

**Abstract**: The complete set of one-loop anomalous dimensions for general Effective Field Theories (EFTs) is derived using on-shell methods. Combined with previous findings for the bosonic sector, the obtained results conclude the computation of the complete set of leading order Renormalization Group Equations (RGEs) in arbitrary gauge EFTs containing scalar and fermion fields. Renormalization effects are consistently taken into account at the order $1/Λ^2$ in the new physics scale $Λ$ for all renormalizable and non-renormalizable couplings. The obtained template RGEs include operator mixing across different dimensions and are valid for arbitrary gauge groups.


### Many-body contextuality and self-testing quantum matter via nonlocal games
**Authors**: Oliver Hart, David T. Stephen, Evan Wickenden, Rahul Nandkishore

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16886v1](https://arxiv.org/pdf/2512.16886v1)

**Abstract**: Contextuality is arguably the fundamental property that makes quantum mechanics different from classical physics. It is responsible for quantum computational speedups in both magic-state-injection-based and measurement-based models of computation, and can be directly probed in a many-body setting by multiplayer nonlocal quantum games. Here, we discuss a family of games that can be won with certainty when performing single-site Pauli measurements on a state that is a codeword of a Calderbank-Shor-Steane (CSS) error-correcting quantum code. We show that these games require deterministic computation of a code-dependent Boolean function, and that the classical probability of success is upper bounded by a generalized notion of nonlinearity/nonquadraticity. This success probability quantifies the state's contextuality, and is computed via the function's (generalized) Walsh-Hadamard spectrum. To calculate this, we introduce an efficient, many-body-physics-inspired method that involves identifying the symmetries of an auxiliary hypergraph state. We compute the classical probability of success for several paradigmatic CSS codes and relate it to both classical statistical mechanics models and to strange correlators of symmetry-protected topological states. We also consider CSS submeasurement games, which can only be won with certainty by sharing the appropriate codeword up to local isometries. These games therefore enable self-testing, which we illustrate explicitly for the 2D toric code. We also discuss how submeasurement games enable an extensive notion of contextuality in many-body states.


### PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies
**Authors**: Arhan Jain, Mingtong Zhang, Kanav Arora, William Chen, Marcel Torne, Muhammad Zubair Irshad, Sergey Zakharov, Yue Wang, Sergey Levine, Chelsea Finn, Wei-Chiu Ma, Dhruv Shah, Abhishek Gupta, Karl Pertsch

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16881v1](https://arxiv.org/pdf/2512.16881v1)

**Abstract**: A significant challenge for robot learning research is our ability to accurately measure and compare the performance of robot policies. Benchmarking in robotics is historically challenging due to the stochasticity, reproducibility, and time-consuming nature of real-world rollouts. This challenge is exacerbated for recent generalist policies, which has to be evaluated across a wide variety of scenes and tasks. Evaluation in simulation offers a scalable complement to real world evaluations, but the visual and physical domain gap between existing simulation benchmarks and the real world has made them an unreliable signal for policy improvement. Furthermore, building realistic and diverse simulated environments has traditionally required significant human effort and expertise. To bridge the gap, we introduce Policy Evaluation and Environment Reconstruction in Simulation (PolaRiS), a scalable real-to-sim framework for high-fidelity simulated robot evaluation. PolaRiS utilizes neural reconstruction methods to turn short video scans of real-world scenes into interactive simulation environments. Additionally, we develop a simple simulation data co-training recipe that bridges remaining real-to-sim gaps and enables zero-shot evaluation in unseen simulation environments. Through extensive paired evaluations between simulation and the real world, we demonstrate that PolaRiS evaluations provide a much stronger correlation to real world generalist policy performance than existing simulated benchmarks. Its simplicity also enables rapid creation of diverse simulated environments. As such, this work takes a step towards distributed and democratized evaluation for the next generation of robotic foundation models.


### Advantage of Warm Starts for Electron-Phonon Systems on Quantum Computers
**Authors**: Arnab Adhikary, S. E. Skelton, Alberto Nocera, Mona Berciu

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16879v1](https://arxiv.org/pdf/2512.16879v1)

**Abstract**: Simulating electron-phonon interactions on quantum computers remains challenging, with most algorithmic effort focused on Hamiltonian simulation and circuit optimization. In this work, we study the single-electron Holstein model and propose an initial-state ansatz that substantially enhances ground state overlap in the strong coupling regime, thereby reducing the number of iterations required in standard quantum phase estimation. We further show that this ansatz can be implemented efficiently and yields an exponential reduction in overall circuit costs relative to conventional initial guesses. Our results highlight the practical value of incorporating physical intuition into initial state preparation for electron-phonon coupled systems.


### Structure of Chern-Simons Graviton Scattering Amplitudes from Topological Graviton Equivalence Theorem and Double Copy
**Authors**: Hong-Xu Liu, Zi-Xuan Yi, Hong-Jian He

**Published Date**: 2025-12-11

**Updated Date**: 2025-12-18

**PDF Url**: [2512.10870v2](https://arxiv.org/pdf/2512.10870v2)

**Abstract**: Gravitons naturally acquire topological masses in the 3d topologically massive gravity (TMG) theory that includes the gravitational Chern-Simons term. We present a covariant formulation of the TMG theory by introducing an unphysical dilaton field through the conformal transformation. We conduct the BRST quantization of the covariant TMG theory, which reduces to the conventional TMG in the unitary gauge. We demonstrate that this covariant TMG theory conserves the physical degrees of freedom (DoF) in the massless limit, under which the physical massive graviton becomes an unphysical massless graviton and its physical DoF is converted to the massless dilaton. With these, we newly establish a Topological Graviton Equivalence Theorem (TGRET), which connects each scattering amplitude of physical gravitons to the corresponding dilaton scattering amplitude in the high energy limit. The TGRET provides a general mechanism to guarantee all the large energy cancellations in any massive graviton scattering amplitudes. Applying the TGRET and using the generalized gravitational power counting rule, we prove that the $N$-point massive graviton amplitudes ($N\geqslant 4$) have striking energy cancellations by powers proportional to $\frac{5}{2}N$ ($\frac{7}{2}N$) in the Landau (unitary) gauge. This explains the large energy cancellations of $E^{11}\to E^1$ (Landau gauge) and $E^{12}\to E^1$ (unitary gauge) for the four graviton amplitudes. We compute the four-point graviton (dilaton) amplitudes and explicitly demonstrate the TGRET and these large energy cancellations. With the extended massive double-copy approach, we systematically construct the graviton (dilaton) scattering amplitudesin the TMG theory from the corresponding gauge boson (adjoint scalar) amplitudes in the topologically massive Yang-Mills theory.


### Developing Distance-Aware, and Evident Uncertainty Quantification in Dynamic Physics-Constrained Neural Networks for Robust Bearing Degradation Estimation
**Authors**: Waleed Razzaq, Yun-Bo Zhao

**Published Date**: 2025-12-09

**Updated Date**: 2025-12-18

**PDF Url**: [2512.08499v2](https://arxiv.org/pdf/2512.08499v2)

**Abstract**: Accurate and uncertainty-aware degradation estimation is essential for predictive maintenance in safety-critical systems like rotating machinery with rolling-element bearings. Many existing uncertainty methods lack confidence calibration, are costly to run, are not distance-aware, and fail to generalize under out-of-distribution data. We introduce two distance-aware uncertainty methods for deterministic physics-guided neural networks: PG-SNGP, based on Spectral Normalization Gaussian Process, and PG-SNER, based on Deep Evidential Regression. We apply spectral normalization to the hidden layers so the network preserves distances from input to latent space. PG-SNGP replaces the final dense layer with a Gaussian Process layer for distance-sensitive uncertainty, while PG-SNER outputs Normal Inverse Gamma parameters to model uncertainty in a coherent probabilistic form. We assess performance using standard accuracy metrics and a new distance-aware metric based on the Pearson Correlation Coefficient, which measures how well predicted uncertainty tracks the distance between test and training samples. We also design a dynamic weighting scheme in the loss to balance data fidelity and physical consistency. We test our methods on rolling-element bearing degradation using the PRONOSTIA, XJTU-SY and HUST datasets and compare them with Monte Carlo and Deep Ensemble PGNNs. Results show that PG-SNGP and PG-SNER improve prediction accuracy, generalize reliably under OOD conditions, and remain robust to adversarial attacks and noise.


### Extended regime of nematic order in an interacting monomer-dimer model of Heilmann and Lieb
**Authors**: Qidong He

**Published Date**: 2025-11-28

**Updated Date**: 2025-12-18

**PDF Url**: [2511.23437v2](https://arxiv.org/pdf/2511.23437v2)

**Abstract**: We revisit a two-dimensional model of liquid crystals introduced by Heilmann and Lieb (1979), which consists of a system of dimers on the square lattice at chemical potential $λ$, interacting via a hard-core repulsion and an attractive interaction of strength $-a<0$ between adjacent, colinear dimers. The model is conjectured to exhibit nematic order at low temperatures, in the sense of orientational symmetry breaking coupled with the absence of translational order, provided that $λ+a>0$. In this paper, we prove the conjecture under the additional condition that $3a>λ$, which corresponds physically to the regime where vacancies, as opposed to misaligned dimers, are the dominant mechanism for decorrelation, significantly extending the parameter regime under which the conjecture is known to hold. Our proof adapts the strategy of Hadas and Peled (2025) for proving the existence of a columnar phase in the hard-square model, combining a mesoscopic characterization of orientational order with the disagreement percolation method of van den Berg (1993) to prove the absence of translational order. To deal with the non-nearest neighbor interactions in the model, we also introduce an extension of the chessboard estimate applicable to finite products of periodic Gibbs measures.


### Exploring nuclear modification using one-point energy correlator at the electron-ion collider
**Authors**: Yu Fu, Zhong-Bo Kang, Jani Penttala, Yiyu Zhou

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16847v1](https://arxiv.org/pdf/2512.16847v1)

**Abstract**: We study the one-point energy correlator (OPEC) at both the back-to-back and collinear limits in electron-proton and electron-nucleus collisions. We provide the factorization formalism for the two types of OPEC and present phenomenological predictions in the kinematic region relevant for the future Electron-Ion Collider. Focusing on cold nuclear matter effects in electron-nucleus scattering, we demonstrate that the OPEC serves as a powerful probe of the transverse momentum dependent (TMD) physics and in characterizing the medium-induced transverse momentum broadening in cold nuclear matter.


## Diffusion
### Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather
**Authors**: Zhijian He, Feifei Liu, Yuwei Li, Zhanpeng Luo, Jintao Cheng, Xieyuanli Chen, Xiaoyu Tang

**Published Date**: 2025-12-15

**Updated Date**: 2025-12-18

**PDF Url**: [2512.13107v2](https://arxiv.org/pdf/2512.13107v2)

**Abstract**: Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.


### Yuan-TecSwin: A text conditioned Diffusion model with Swin-transformer blocks
**Authors**: Shaohua Wu, Tong Yu, Shenling Wang, Xudong Zhao

**Published Date**: 2025-12-18

**Updated Date**: 2025-12-18

**PDF Url**: [2512.16586v1](https://arxiv.org/pdf/2512.16586v1)

**Abstract**: Diffusion models have shown remarkable capacity in image synthesis based on their U-shaped architecture and convolutional neural networks (CNN) as basic blocks. The locality of the convolution operation in CNN may limit the model's ability to understand long-range semantic information. To address this issue, we propose Yuan-TecSwin, a text-conditioned diffusion model with Swin-transformer in this work. The Swin-transformer blocks take the place of CNN blocks in the encoder and decoder, to improve the non-local modeling ability in feature extraction and image restoration. The text-image alignment is improved with a well-chosen text encoder, effective utilization of text embedding, and careful design in the incorporation of text condition. Using an adapted time step to search in different diffusion stages, inference performance is further improved by 10%. Yuan-TecSwin achieves the state-of-the-art FID score of 1.37 on ImageNet generation benchmark, without any additional models at different denoising stages. In a side-by-side comparison, we find it difficult for human interviewees to tell the model-generated images from the human-painted ones.


### Cornserve: Efficiently Serving Any-to-Any Multimodal Models
**Authors**: Jeff J. Ma, Jae-Won Chung, Jisang Ahn, Yizhuo Liang, Akshay Jajoo, Myungjin Lee, Mosharaf Chowdhury

**Published Date**: 2025-12-16

**Updated Date**: 2025-12-18

**PDF Url**: [2512.14098v2](https://arxiv.org/pdf/2512.14098v2)

**Abstract**: We present Cornserve, an efficient online serving system for an emerging class of multimodal models called Any-to-Any models. Any-to-Any models accept combinations of text and multimodal data (e.g., image, video, audio) as input and also generate combinations of text and multimodal data as output, introducing request type, computation path, and computation scaling heterogeneity in model serving.
  Cornserve allows model developers to describe the computation graph of generic Any-to-Any models, which consists of heterogeneous components such as multimodal encoders, autoregressive models like Large Language Models (LLMs), and multimodal generators like Diffusion Transformers (DiTs). Given this, Cornserve's planner automatically finds an optimized deployment plan for the model, including whether and how to disaggregate the model into smaller components based on model and workload characteristics. Cornserve's distributed runtime then executes the model per the plan, efficiently handling Any-to-Any model heterogeneity during online serving. Evaluations show that Cornserve can efficiently serve diverse Any-to-Any models and workloads, delivering up to 3.81$\times$ throughput improvement and up to 5.79$\times$ tail latency reduction over existing solutions.


### Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling
**Authors**: Aihua Zhu, Rui Su, Qinglin Zhao, Li Feng, Meng Shen, Shibo He

**Published Date**: 2025-11-12

**Updated Date**: 2025-12-18

**PDF Url**: [2511.11688v2](https://arxiv.org/pdf/2511.11688v2)

**Abstract**: Diffusion probabilistic models have set a new standard for generative fidelity but are hindered by a slow iterative sampling process. A powerful training-free strategy to accelerate this process is Schedule Optimization, which aims to find an optimal distribution of timesteps for a fixed and small Number of Function Evaluations (NFE) to maximize sample quality. To this end, a successful schedule optimization method must adhere to four core principles: effectiveness, adaptivity, practical robustness, and computational efficiency. However, existing paradigms struggle to satisfy these principles simultaneously, motivating the need for a more advanced solution. To overcome these limitations, we propose the Hierarchical-Schedule-Optimizer (HSO), a novel and efficient bi-level optimization framework. HSO reframes the search for a globally optimal schedule into a more tractable problem by iteratively alternating between two synergistic levels: an upper-level global search for an optimal initialization strategy and a lower-level local optimization for schedule refinement. This process is guided by two key innovations: the Midpoint Error Proxy (MEP), a solver-agnostic and numerically stable objective for effective local optimization, and the Spacing-Penalized Fitness (SPF) function, which ensures practical robustness by penalizing pathologically close timesteps. Extensive experiments show that HSO sets a new state-of-the-art for training-free sampling in the extremely low-NFE regime. For instance, with an NFE of just 5, HSO achieves a remarkable FID of 11.94 on LAION-Aesthetics with Stable Diffusion v2.1. Crucially, this level of performance is attained not through costly retraining, but with a one-time optimization cost of less than 8 seconds, presenting a highly practical and efficient paradigm for diffusion model acceleration.


## Quantitative Finance
### SigMA: Path Signatures and Multi-head Attention for Learning Parameters in fBm-driven SDEs
**Authors**: Xianglin Wu, Chiheb Ben Hammouda, Cornelis W. Oosterlee

**Published Date**: 2025-12-17

**Updated Date**: 2025-12-17

**PDF Url**: [2512.15088v1](https://arxiv.org/pdf/2512.15088v1)

**Abstract**: Stochastic differential equations (SDEs) driven by fractional Brownian motion (fBm) are increasingly used to model systems with rough dynamics and long-range dependence, such as those arising in quantitative finance and reliability engineering. However, these processes are non-Markovian and lack a semimartingale structure, rendering many classical parameter estimation techniques inapplicable or computationally intractable beyond very specific cases. This work investigates two central questions: (i) whether integrating path signatures into deep learning architectures can improve the trade-off between estimation accuracy and model complexity, and (ii) what constitutes an effective architecture for leveraging signatures as feature maps. We introduce SigMA (Signature Multi-head Attention), a neural architecture that integrates path signatures with multi-head self-attention, supported by a convolutional preprocessing layer and a multilayer perceptron for effective feature encoding. SigMA learns model parameters from synthetically generated paths of fBm-driven SDEs, including fractional Brownian motion, fractional Ornstein-Uhlenbeck, and rough Heston models, with a particular focus on estimating the Hurst parameter and on joint multi-parameter inference, and it generalizes robustly to unseen trajectories. Extensive experiments on synthetic data and two real-world datasets (i.e., equity-index realized volatility and Li-ion battery degradation) show that SigMA consistently outperforms CNN, LSTM, vanilla Transformer, and Deep Signature baselines in accuracy, robustness, and model compactness. These results demonstrate that combining signature transforms with attention-based architectures provides an effective and scalable framework for parameter inference in stochastic systems with rough or persistent temporal structure.


