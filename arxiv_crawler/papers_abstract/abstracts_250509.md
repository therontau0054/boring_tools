# Abstracts of Papers

## Physics
### Primordial black-hole formation and heavy r-process element synthesis from the cosmological QCD transition. Two aspects of an inhomogeneous early Universe
**Authors**: M. Gonin, G. Hasinger, D. Blaschke, O. Ivanytskyi, G. Röpke

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05463v1](http://arxiv.org/pdf/2505.05463v1)

**Abstract**: We review the role of primordial black holes (PBHs) for illuminating the dark
ages of the cosmological evolution and as dark matter candidates. We elucidate
the role of phase transitions for primordial black hole formation in the early
Universe and focus our attention to the cosmological QCD phase transition
within a recent microscopical model. We explore the impact of physics beyond
the Standard Model on the cosmic equation of state and the probability
distribution for the formation of primordial black holes which serve as dark
matter (DM) candidates. We argue that besides primordial black holes also
droplet-like quark-gluon plasma inhomogeneities may become gravitationally
stabilized for a sufficiently long epoch to distill baryon number and form
nuclear matter droplets which upon their evaporation may enrich the cosmos
locally with heavy $r$-process elements already in the early Universe.


### Marsden--Meyer--Weinstein reduction for $k$-contact field theories
**Authors**: J. de Lucas, X. Rivas, S. Vilarino, B. M. Zawora

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05462v1](http://arxiv.org/pdf/2505.05462v1)

**Abstract**: This work devises a Marsden--Meyer--Weinstein $k$-contact reduction. Our
techniques are illustrated with several examples of mathematical and physical
relevance. As a byproduct, we review the previous contact reduction literature
so as to clarify and to solve some inaccuracies.


### RL-DAUNCE: Reinforcement Learning-Driven Data Assimilation with Uncertainty-Aware Constrained Ensembles
**Authors**: Pouria Behnoudfar, Nan Chen

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05452v1](http://arxiv.org/pdf/2505.05452v1)

**Abstract**: Machine learning has become a powerful tool for enhancing data assimilation.
While supervised learning remains the standard method, reinforcement learning
(RL) offers unique advantages through its sequential decision-making framework,
which naturally fits the iterative nature of data assimilation by dynamically
balancing model forecasts with observations. We develop RL-DAUNCE, a new
RL-based method that enhances data assimilation with physical constraints
through three key aspects. First, RL-DAUNCE inherits the computational
efficiency of machine learning while it uniquely structures its agents to
mirror ensemble members in conventional data assimilation methods. Second,
RL-DAUNCE emphasizes uncertainty quantification by advancing multiple ensemble
members, moving beyond simple mean-state optimization. Third, RL-DAUNCE's
ensemble-as-agents design facilitates the enforcement of physical constraints
during the assimilation process, which is crucial to improving the state
estimation and subsequent forecasting. A primal-dual optimization strategy is
developed to enforce constraints, which dynamically penalizes the reward
function to ensure constraint satisfaction throughout the learning process.
Also, state variable bounds are respected by constraining the RL action space.
Together, these features ensure physical consistency without sacrificing
efficiency. RL-DAUNCE is applied to the Madden-Julian Oscillation, an
intermittent atmospheric phenomenon characterized by strongly non-Gaussian
features and multiple physical constraints. RL-DAUNCE outperforms the standard
ensemble Kalman filter (EnKF), which fails catastrophically due to the
violation of physical constraints. Notably, RL-DAUNCE matches the performance
of constrained EnKF, particularly in recovering intermittent signals, capturing
extreme events, and quantifying uncertainties, while requiring substantially
less computational effort.


### Screened Axio-dilaton Cosmology: Novel Forms of Early Dark Energy
**Authors**: Adam Smith, Philippe Brax, Carsten van de Bruck, C. P. Burgess, Anne-Christine Davis

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05450v1](http://arxiv.org/pdf/2505.05450v1)

**Abstract**: We study the cosmology of multi-field Dark Energy, using a well-motivated
axio-dilaton model that contains the minimal number of fields to have the
2-derivative sigma-model interactions that power-counting arguments show
naturally compete with General Relativity at low energies. Our analysis differs
from earlier, related, studies by treating the case where the dilaton's
couplings to matter are large enough to require screening to avoid unacceptable
dilaton-mediated forces in the solar system. We use a recently proposed
screening mechanism that exploits the interplay between
stronger-than-gravitational axion-matter couplings with the 2-derivative
axion-dilaton interactions to suppress the couplings of the dilaton to bulk
matter. The required axion-matter couplings also modify cosmology, with the
axion's background energy density turning out to resemble early dark energy. We
compute the properties of the axion fluid describing the rapid oscillations of
the axion field around the time-dependent minimum of its matter-dependent
effective potential, extending the usual formalism to include nontrivial
kinetic sigma-model interactions. We explore the implications of these models
for the Cosmic Microwave Background and the growth of structure and find that
for dilaton potentials of the Albrecht-Skordis form (itself well-motivated by
UV physics), successful screening can be consistent with the early dark energy
temporarily comprising as much as 10% of the total density in the past. We find
that increasing the dilaton-matter coupling decreases the growth of structure
due to enhanced Hubble friction, an effect that dominates the usual fifth-force
effects that amplify structure growth.


### Manifest Gauge Invariance for Structure Dependent Radiative Corrections to Processes Involving Atoms and Nuclei
**Authors**: Ryan Plestid, Mark B. Wise

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05449v1](http://arxiv.org/pdf/2505.05449v1)

**Abstract**: Radiative corrections to reactions involving atoms or nuclei can become
sensitive to the structure of the bound state. Generically, one encounters
correlation functions of multiple currents which must satisfy Ward identities.
At intermediate steps, however the Ward identities are obscured, and often
violated by physically motivated approximation schemes. In this paper we
outline a method to construct a representation of the aforementioned
correlators that manifests gauge invariance in the limit of a heavy target
(i.e., when recoil energy can be neglected). This representation then enables
manifestly gauge invariant approximation schemes. Furthermore, the proposed
representation naturally separates the largest contributions that dominate
scattering amplitudes in the limit of a heavy constituent (e.g., proton) mass.
We analyze elastic electron scattering from nuclei in detail, and also discuss
radiative corrections to processes mediated by the weak interaction.


### The effective energy of a lattice metamaterial
**Authors**: Xuenan Li, Robert V. Kohn

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05436v1](http://arxiv.org/pdf/2505.05436v1)

**Abstract**: We study the sense in which the continuum limit of a broad class of discrete
materials with periodic structures can be viewed as a nonlinear elastic
material. While we are not the first to consider this question, our treatment
is more general and more physical than those in the literature. Indeed, it
applies to a broad class of systems, including ones that possess mechanisms;
and we discuss how the degeneracy that plagues prior work in this area can be
avoided by penalizing change of orientation. A key motivation for this work is
its relevance to mechanism-based mechanical metamaterials. Such systems often
have ``soft modes'', achieved in typical examples by modulating mechanisms. Our
results permit the following more general definition of a soft mode: it is a
macroscopic deformation whose effective energy vanishes -- in other words, one
whose spatially-averaged elastic energy tends to zero in the continuum limit.


### Barren Plateaus in Variational Quantum Computing
**Authors**: Martin Larocca, Supanut Thanasilp, Samson Wang, Kunal Sharma, Jacob Biamonte, Patrick J. Coles, Lukasz Cincio, Jarrod R. McClean, Zoë Holmes, M. Cerezo

**Published Date**: 2024-05-01

**Updated Date**: 2025-05-08

**PDF Url**: [2405.00781v2](http://arxiv.org/pdf/2405.00781v2)

**Abstract**: Variational quantum computing offers a flexible computational paradigm with
applications in diverse areas. However, a key obstacle to realizing their
potential is the Barren Plateau (BP) phenomenon. When a model exhibits a BP,
its parameter optimization landscape becomes exponentially flat and featureless
as the problem size increases. Importantly, all the moving pieces of an
algorithm -- choices of ansatz, initial state, observable, loss function and
hardware noise -- can lead to BPs when ill-suited. Due to the significant
impact of BPs on trainability, researchers have dedicated considerable effort
to develop theoretical and heuristic methods to understand and mitigate their
effects. As a result, the study of BPs has become a thriving area of research,
influencing and cross-fertilizing other fields such as quantum optimal control,
tensor networks, and learning theory. This article provides a comprehensive
review of the current understanding of the BP phenomenon.


### Robustly optimal dynamics for active matter reservoir computing
**Authors**: Mario U. Gaimann, Miriam Klopotek

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05420v1](http://arxiv.org/pdf/2505.05420v1)

**Abstract**: We study the information processing abilities of active matter in the
reservoir computing (RC) paradigm, using a model that is externally driven to
infer the future state of a chaotic signal. The simulated system closely
follows a previously reported model. We uncover an exceptional dynamical regime
of agent dynamics that has been overlooked heretofore. It appears robustly
optimal across varying physical parameters and inference tasks, thus providing
valuable insights into computation and inference with physical systems more
generally. The ability to form effective mechanisms for information processing
are primarily determined by the system's own intrinsic relaxation abilities.
These are identifiable when probing the system without a specific inference
goal and manifest when testing minimalistic single-particle reservoirs. The
regime that achieves optimal computation is situated just below the critical
damping threshold, involving a microscopic dynamical relaxation with multiple
stages. The optimal system is adaptable under chaotic external driving, due to
a diversity in response mechanisms that emerge like rapid alternations between
quasi-stationary and highly nonlinear dynamical states. Both coherent and
incoherent dynamics contribute to their operation, partly at dissimilar scales
of space and delay time. Correlations on agent dynamics can indicate the
best-performing regimes and onsets of tight relationships between the
responding system and the fluctuating driver. As this model of computation is
interpretable in physical terms, it facilitates re-framing inquiries regarding
learning and unconventional computing with a fresh rationale for many-body
physics out of equilibrium.


### Quantum Simulation of Dynamical Response Functions of Equilibrium States
**Authors**: Esther Cruz, Dominik S. Wild, Mari Carmen Bañuls, J. Ignacio Cirac

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05411v1](http://arxiv.org/pdf/2505.05411v1)

**Abstract**: The computation of dynamical response functions is central to many problems
in condensed matter physics. Owing to the rapid growth of quantum correlations
following a quench, classical methods face significant challenges even if an
efficient description of the equilibrium state is available. Quantum computing
offers a promising alternative. However, existing approaches often assume
access to the equilibrium state, which may be difficult to prepare in practice.
In this work, we present a method that circumvents this by using energy filter
techniques, enabling the computation of response functions and other dynamical
properties in both microcanonical and canonical ensembles. Our approach only
requires the preparation of states that have significant weight at the desired
energy. The dynamical response functions are then reconstructed from
measurements after quenches of varying duration by classical postprocessing. We
illustrate the algorithm numerically by applying it to compute the dynamical
conductivity of a free-fermion model, which unveils the energy-dependent
localization properties of the model.


### Testing an unstable cosmic neutrino background
**Authors**: Pasquale Di Bari

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05405v1](http://arxiv.org/pdf/2505.05405v1)

**Abstract**: I discuss how different cosmological observations can test the possibility
that neutrinos might be unstable on cosmological times, resulting into an
unstable cosmic neutrino background. I also discuss out how actually there are
different independent anomalies intriguingly hint to such a possibility that
would clearly point to new physics. I first focus on how the new DESI results
place an upper bound on the sum of neutrino masses that starts to be in tension
with the lower bound from neutrino oscillation experiments and how this tension
could be easily solved assuming unstable relic neutrinos. Then I show how 21 cm
cosmology allows to test radiative relic neutrino decays and how these could
explain the controversial EDGES anomaly. I also discuss how the excess radio
background and in particular the ARCADE 2 data can also be nicely explained by
relic neutrino radiative decays. Finally, I point out the difficulties in
building a model that does not clash with the upper limits on the effective
magnetic moment coming from neutrino-electron scattering experiments and
globular cluster stars.


## Diffusion
### Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models
**Authors**: Zhanpeng He, Yifeng Cao, Matei Ciocarlie

**Published Date**: 2025-02-26

**Updated Date**: 2025-05-08

**PDF Url**: [2503.01876v2](http://arxiv.org/pdf/2503.01876v2)

**Abstract**: Human-in-the-loop (HitL) robot deployment has gained significant attention in
both academia and industry as a semi-autonomous paradigm that enables human
operators to intervene and adjust robot behaviors at deployment time, improving
success rates. However, continuous human monitoring and intervention can be
highly labor-intensive and impractical when deploying a large number of robots.
To address this limitation, we propose a method that allows diffusion policies
to actively seek human assistance only when necessary, reducing reliance on
constant human oversight. To achieve this, we leverage the generative process
of diffusion policies to compute an uncertainty-based metric based on which the
autonomous agent can decide to request operator assistance at deployment time,
without requiring any operator interaction during training. Additionally, we
show that the same method can be used for efficient data collection for
fine-tuning diffusion policies in order to improve their autonomous
performance. Experimental results from simulated and real-world environments
demonstrate that our approach enhances policy performance during deployment for
a variety of scenarios.


### Denoising Diffusion Probabilistic Models for Coastal Inundation Forecasting
**Authors**: Kazi Ashik Islam, Zakaria Mehrab, Mahantesh Halappanavar, Henning Mortveit, Sridhar Katragadda, Jon Derek Loftis, Madhav Marathe

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05381v1](http://arxiv.org/pdf/2505.05381v1)

**Abstract**: Coastal flooding poses significant risks to communities, necessitating fast
and accurate forecasting methods to mitigate potential damage. To approach this
problem, we present DIFF-FLOOD, a probabilistic spatiotemporal forecasting
method designed based on denoising diffusion models. DIFF-FLOOD predicts
inundation level at a location by taking both spatial and temporal context into
account. It utilizes inundation levels at neighboring locations and digital
elevation data as spatial context. Inundation history from a context time
window, together with additional co-variates are used as temporal context.
Convolutional neural networks and cross-attention mechanism are then employed
to capture the spatiotemporal dynamics in the data. We trained and tested
DIFF-FLOOD on coastal inundation data from the Eastern Shore of Virginia, a
region highly impacted by coastal flooding. Our results show that, DIFF-FLOOD
outperforms existing forecasting methods in terms of prediction performance (6%
to 64% improvement in terms of two performance metrics) and scalability.


### Operator-Level Quantum Acceleration of Non-Logconcave Sampling
**Authors**: Jiaqi Leng, Zhiyan Ding, Zherui Chen, Lin Lin

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05301v1](http://arxiv.org/pdf/2505.05301v1)

**Abstract**: Sampling from probability distributions of the form $\sigma \propto e^{-\beta
V}$, where $V$ is a continuous potential, is a fundamental task across physics,
chemistry, biology, computer science, and statistics. However, when $V$ is
non-convex, the resulting distribution becomes non-logconcave, and classical
methods such as Langevin dynamics often exhibit poor performance. We introduce
the first quantum algorithm that provably accelerates a broad class of
continuous-time sampling dynamics. For Langevin dynamics, our method encodes
the target Gibbs measure into the amplitudes of a quantum state, identified as
the kernel of a block matrix derived from a factorization of the Witten
Laplacian operator. This connection enables Gibbs sampling via singular value
thresholding and yields the first provable quantum advantage with respect to
the Poincar\'e constant in the non-logconcave setting. Building on this
framework, we further develop the first quantum algorithm that accelerates
replica exchange Langevin diffusion, a widely used method for sampling from
complex, rugged energy landscapes.


### Linear combinations of latents in generative models: subspaces and beyond
**Authors**: Erik Bodin, Alexandru Stere, Dragos D. Margineantu, Carl Henrik Ek, Henry Moss

**Published Date**: 2024-08-16

**Updated Date**: 2025-05-08

**PDF Url**: [2408.08558v6](http://arxiv.org/pdf/2408.08558v6)

**Abstract**: Sampling from generative models has become a crucial tool for applications
like data synthesis and augmentation. Diffusion, Flow Matching and Continuous
Normalizing Flows have shown effectiveness across various modalities, and rely
on latent variables for generation. For experimental design or creative
applications that require more control over the generation process, it has
become common to manipulate the latent variable directly. However, existing
approaches for performing such manipulations (e.g. interpolation or forming
low-dimensional representations) only work well in special cases or are network
or data-modality specific. We propose Linear combinations of Latent variables
(LOL) as a general-purpose method to form linear combinations of latent
variables that adhere to the assumptions of the generative model. As LOL is
easy to implement and naturally addresses the broader task of forming any
linear combinations, e.g. the construction of subspaces of the latent space,
LOL dramatically simplifies the creation of expressive low-dimensional
representations of high-dimensional objects.


### Overcoming Dimensional Factorization Limits in Discrete Diffusion Models through Quantum Joint Distribution Learning
**Authors**: Chuangtao Chen, Qinglin Zhao, MengChu Zhou, Zhimin He, Haozhen Situ

**Published Date**: 2025-05-08

**Updated Date**: 2025-05-08

**PDF Url**: [2505.05151v1](http://arxiv.org/pdf/2505.05151v1)

**Abstract**: This study explores quantum-enhanced discrete diffusion models to overcome
classical limitations in learning high-dimensional distributions. We rigorously
prove that classical discrete diffusion models, which calculate per-dimension
transition probabilities to avoid exponential computational cost, exhibit
worst-case linear scaling of Kullback-Leibler (KL) divergence with data
dimension. To address this, we propose a Quantum Discrete Denoising Diffusion
Probabilistic Model (QD3PM), which enables joint probability learning through
diffusion and denoising in exponentially large Hilbert spaces. By deriving
posterior states through quantum Bayes' theorem, similar to the crucial role of
posterior probabilities in classical diffusion models, and by learning the
joint probability, we establish a solid theoretical foundation for
quantum-enhanced diffusion models. For denoising, we design a quantum circuit
using temporal information for parameter sharing and learnable
classical-data-controlled rotations for encoding. Exploiting joint distribution
learning, our approach enables single-step sampling from pure noise,
eliminating iterative requirements of existing models. Simulations demonstrate
the proposed model's superior accuracy in modeling complex distributions
compared to factorization methods. Hence, this paper establishes a new
theoretical paradigm in generative models by leveraging the quantum advantage
in joint distribution learning.


