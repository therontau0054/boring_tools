# Abstracts of Papers

## Physics
### A Localized Burst of Relativistic Electrons in Earth's Plasma Sheet: Low- and High-Altitude Signatures During a Substorm
**Authors**: M. Shumko, D. L. Turner, A. Y. Ukhorskiy, I. J. Cohen, G. K. Stephens, A. Artemyev, X. Zhang, C. Wilkins, E. Tsai, C. Gabrielse, S. Raptis, M. Sitnov, V. Angelopoulos

**Published Date**: 2024-10-21

**Updated Date**: 2024-11-18

**PDF Url**: [2410.16412v2](http://arxiv.org/pdf/2410.16412v2)

**Abstract**: Earth's magnetotail, and the plasma sheet embedded in it, is a highly dynamic
region that is coupled to both the solar wind and to the inner magnetosphere.
As a consequence of this coupling, the plasma sheet undergoes explosive energy
releases in the form of substorms. One consequence of this energy release is
heating of thermal electrons and acceleration of energetic (non-thermal)
electrons. The upper-energy limit as well as the spatial scale size of the
electron acceleration regions remain mysteries in magnetotail physics because
current missions can effectively only offer us a single-point glimpse into the
numerous magnetotail phenomena ranging from electron- to global-scales. These
energetic electrons can provide a significant source of seed electrons for the
Van Allen Radiation belts. Here we use a unique approach to study relativistic
plasma sheet electron acceleration. We combine high-altitude Magnetospheric
Multiscale (MMS) mission observations with low-altitude Electron Losses and
Fields Investigation (ELFIN) observations, to quantify the upper-energy extent
and radial scale of a burst of plasma sheet electrons that mapped to 33 Earth
radii. The plasma sheet locally accelerated an intense mesoscale burst of 3 MeV
electrons -- far higher and more intense than the outer Van Allen radiation
belt -- and scattered them into the atmospheric loss cone. High-altitude
observations Earthward of the burst at 17 Earth radii showed only the usual
substorm activity signatures -- demonstrating that this burst was 1) intense,
2) localized to the far magnetotail, and 3) likely accelerated by a very
efficient and rapid mechanism.


### Logical computation demonstrated with a neutral atom quantum processor
**Authors**: Ben W. Reichardt, Adam Paetznick, David Aasen, Ivan Basov, Juan M. Bello-Rivas, Parsa Bonderson, Rui Chao, Wim van Dam, Matthew B. Hastings, Andres Paz, Marcus P. da Silva, Aarthi Sundaram, Krysta M. Svore, Alexander Vaschillo, Zhenghan Wang, Matt Zanner, William B. Cairncross, Cheng-An Chen, Daniel Crow, Hyosub Kim, Jonathan M. Kindem, Jonathan King, Michael McDonald, Matthew A. Norcia, Albert Ryou, Mark Stone, Laura Wadleigh, Katrina Barnes, Peter Battaglino, Thomas C. Bohdanowicz, Graham Booth, Andrew Brown, Mark O. Brown, Kayleigh Cassella, Robin Coxe, Jeffrey M. Epstein, Max Feldkamp, Christopher Griger, Eli Halperin, Andre Heinz, Frederic Hummel, Matthew Jaffe, Antonia M. W. Jones, Eliot Kapit, Krish Kotru, Joseph Lauigan, Ming Li, Jan Marjanovic, Eli Megidish, Matthew Meredith, Ryan Morshead, Juan A. Muniz, Sandeep Narayanaswami, Ciro Nishiguchi, Timothy Paule, Kelly A. Pawlak, Kristen L. Pudenz, David Rodríguez Pérez, Jon Simon, Aaron Smull, Daniel Stack, Miroslav Urbanek, René J. M. van de Veerdonk, Zachary Vendeiro, Robert T. Weverka, Thomas Wilkason, Tsung-Yao Wu, Xin Xie, Evan Zalys-Geller, Xiaogang Zhang, Benjamin J. Bloom

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11822v1](http://arxiv.org/pdf/2411.11822v1)

**Abstract**: Transitioning from quantum computation on physical qubits to quantum
computation on encoded, logical qubits can improve the error rate of
operations, and will be essential for realizing valuable quantum computational
advantages. Using a neutral atom quantum processor with 256 qubits, each an
individual Ytterbium atom, we demonstrate the entanglement of 24 logical qubits
using the distance-two [[4,2,2]] code, simultaneously detecting errors and
correcting for lost qubits. We also implement the Bernstein-Vazirani algorithm
with up to 28 logical qubits encoded in the [[4,1,2]] code, showing
better-than-physical error rates. We demonstrate fault-tolerant quantum
computation in our approach, guided by the proposal of Gottesman (2016), by
performing repeated loss correction for both structured and random circuits
encoded in the [[4,2,2]] code. Finally, since distance-two codes can correct
qubit loss, but not other errors, we show repeated loss and error correction
using the distance-three [[9,1,3]] Bacon-Shor code. These results begin to
clear a path for achieving scientific quantum advantage with a programmable
neutral atom quantum processor.


### Angular analysis of the B$^0$ $\to$ K$^*$(892)$^0μ^+μ^-$ decay in proton-proton collisions at $\sqrt{s}$ = 13 TeV
**Authors**: CMS Collaboration

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11820v1](http://arxiv.org/pdf/2411.11820v1)

**Abstract**: A full set of optimized observables is measured in an angular analysis of the
decay B$^0$ $\to$ K$^*$(892)$^0\mu^+\mu^-$ using a sample of proton-proton
collisions at $\sqrt{s}$ = 13 TeV, collected with the CMS detector at the LHC,
corresponding to an integrated luminosity of 140 fb$^{-1}$. The analysis is
performed in six bins of the squared invariant mass of the dimuon system,
$q^2$, over the range 1.1 $\lt$ $q^2$ $\lt$ 16 GeV$^2$. The results are among
the most precise experimental measurements of the angular observables for this
decay and are compared to a variety of predictions based on the standard model.


### In-Silico Analysis of Curve Fitting in Angiographic Parametric Imaging in Intracranial Aneurysms
**Authors**: Parmita Mondal, Allison Shields, Mohammad Mahdi Shiraz Bhurwani, Kyle A Williams, Ciprian N Ionita

**Published Date**: 2024-11-08

**Updated Date**: 2024-11-18

**PDF Url**: [2411.05287v2](http://arxiv.org/pdf/2411.05287v2)

**Abstract**: In Angiographic Parametric Imaging (API), accurate estimation of parameters
from Time Density Curves (TDC) is crucial. However, these estimations are often
marred by errors arising from factors such as patient motion, procedural
preferences, image noise, and injection variability. While fitting methods like
gamma-variate fitting offer a solution to recover incomplete or corrupted TDC
data, they might also introduce unforeseen biases. This study investigates the
trade-offs and benefits of employing gamma-variate fitting on virtual
angiograms to enhance the precision of API biomarkers. Utilizing Computational
Fluid Dynamics (CFD) in patient specific 3D geometries, we generated a series
of high-definition virtual angiograms at distinct inlet velocities: 0.25m/s,
0.35m/s, and 0.45m/s. These velocities were investigated across injection
durations ranging from 0.5s to 2.0s. From these angiograms, TDCs for aneurysms
and their corresponding inlets were constructed. To emulate typical clinical
challenges, we introduced noise, simulated patient motion, and generated
temporally incomplete data sets. These modified TDCs underwent gamma-variate
fitting. We quantified both the original and fitted TDC curves using standard
angiography metrics such as Cross-Correlation (Cor), Time to Peak (TTP), Mean
Transit Time (MTT), Peak Height (PH), Area Under the Curve (AUC), and Maximum
Gradient (Max-Gr) for a comprehensive comparison. TDCs enhanced by
gamma-variate fitting exhibited a robust correlation with vascular flow
dynamics. Our results affirm that gamma-variate fitting can adeptly restore
TDCs from fragmentary sequences, elevating the precision of derived API
parameters.


### KAN/MultKAN with Physics-Informed Spline fitting (KAN-PISF) for ordinary/partial differential equation discovery of nonlinear dynamic systems
**Authors**: Ashish Pal, Satish Nagarajaiah

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11801v1](http://arxiv.org/pdf/2411.11801v1)

**Abstract**: Machine learning for scientific discovery is increasingly becoming popular
because of its ability to extract and recognize the nonlinear characteristics
from the data. The black-box nature of deep learning methods poses difficulties
in interpreting the identified model. There is a dire need to interpret the
machine learning models to develop a physical understanding of dynamic systems.
An interpretable form of neural network called Kolmogorov-Arnold networks (KAN)
or Multiplicative KAN (MultKAN) offers critical features that help recognize
the nonlinearities in the governing ordinary/partial differential equations
(ODE/PDE) of various dynamic systems and find their equation structures. In
this study, an equation discovery framework is proposed that includes i)
sequentially regularized derivatives for denoising (SRDD) algorithm to denoise
the measure data to obtain accurate derivatives, ii) KAN to identify the
equation structure and suggest relevant nonlinear functions that are used to
create a small overcomplete library of functions, and iii) physics-informed
spline fitting (PISF) algorithm to filter the excess functions from the library
and converge to the correct equation. The framework was tested on the forced
Duffing oscillator, Van der Pol oscillator (stiff ODE), Burger's equation, and
Bouc-Wen model (coupled ODE). The proposed method converged to the true
equation for the first three systems. It provided an approximate model for the
Bouc-Wen model that could acceptably capture the hysteresis response. Using KAN
maintains low complexity, which helps the user interpret the results throughout
the process and avoid the black-box-type nature of machine learning methods.


### A Multi-Component, Multi-Physics Computational Model for Solving Coupled Cardiac Electromechanics and Vascular Haemodynamics
**Authors**: Sharp C. Y. Lo, Alberto Zingaro, Jon W. S. McCullough, Xiao Xue, Mariano Vázquez, Peter V. Coveney

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11797v1](http://arxiv.org/pdf/2411.11797v1)

**Abstract**: The circulatory system, comprising the heart and blood vessels, is vital for
nutrient transport, waste removal, and homeostasis. Traditional computational
models often isolate individual biophysical processes, such as cardiac
electromechanics and blood flow dynamics, failing to capture the system's
integrated nature. This paper presents an innovative approach that couples a 3D
electromechanical model of the heart with a 3D fluid mechanics model of
vascular blood flow. Our file-based partitioned coupling scheme allows these
models to run independently while sharing essential data through intermediate
files. We validate this approach using two solvers: one for cardiac
electromechanics and the other for vascular blood flow. Developed by separate
research groups, these solvers emphasise different dynamical scales and utilise
distinct discretisation schemes. Numerical simulations using idealised and
realistic anatomies show that the implemented coupling scheme is reliable and
requires minimal additional computation time relative to advancing individual
time steps in the heart and blood flow models. Notably, the coupled model
predicts muscle displacement differently than the standalone heart model,
highlighting the influence of detailed vascular blood flow on cardiac function.
This study presents a paradigm case of how to build virtual human models and
digital twins by productive collaboration between teams with complementary
expertise.


### Lorentz covariant physical Brownian motion: Classical and quantum
**Authors**: Henryk Gzyl

**Published Date**: 2024-07-12

**Updated Date**: 2024-11-18

**PDF Url**: [2407.08905v2](http://arxiv.org/pdf/2407.08905v2)

**Abstract**: In this work, we re-examine the Goldstein-Ka\c{c} velocity switching model
from two points of view. On the one hand, we prove that the forward and
backward Chapman-Kolmogorov equations of the stochastic process are Lorentz
covariant when the trajectories are parameterized by their proper time. On the
other hand, to recast the model as a quantum random evolution, we consider
restating the Goldstein-Ka\c{c} model as a Hamiltonian system, which can then
be quantized using the standard correspondence rules. It turns out that the
density for the random quantum evolution satisfies a Chapman-Kolmogorov
equation similar to that of the classical case, and therefore, it is also
Lorentz covariant. We compute the average quantum variance. To finish, we
verify that the quantum model is also consistent with special relativity and
that transitions outside the light cone, that is, transitions between states
with disjoint supports in space-time, cannot occur.


### A Puzzle About General Covariance and Gauge
**Authors**: Eleanor March, James Owen Weatherall

**Published Date**: 2024-05-06

**Updated Date**: 2024-11-18

**PDF Url**: [2405.03906v2](http://arxiv.org/pdf/2405.03906v2)

**Abstract**: We consider two simple criteria for when a physical theory should be said to
be "generally covariant", and we argue that these criteria are not met by
Yang-Mills theory, even on geometric formulations of that theory. The reason,
we show, is that the bundles encountered in Yang-Mills theory are not natural
bundles; instead, they are gauge-natural. We then show how these observations
relate to previous arguments about the significance of solder forms in
assessing disanalogies between general relativity and Yang-Mills theory. We
conclude by suggesting that general covariance is really about functoriality.


### Bounds on new neutrino interactions from the first CE$ν$NS data at direct detection experiments
**Authors**: Valentina De Romeri, Dimitrios K. Papoulias, Christoph A. Ternes

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11749v1](http://arxiv.org/pdf/2411.11749v1)

**Abstract**: Recently, two dark matter direct detection experiments have announced the
first indications of nuclear recoils from solar $^8$B neutrinos via coherent
elastic neutrino-nucleus scattering (CE$\nu$NS) with xenon nuclei. These
results constitute a turning point, not only for dark matter searches that are
now entering the \textit{neutrino fog}, but they also bring out new
opportunities to exploit dark matter facilities as neutrino detectors. We
investigate the implications of recent data from the PandaX-4T and XENONnT
experiments on both Standard Model physics and new neutrino interactions. We
first extract information on the weak mixing angle at low momentum transfer.
Then, following a phenomenological approach, we consider Lorentz-invariant
interactions (scalar, vector, axial-vector, and tensor) between neutrinos,
quarks and charged leptons. Furthermore, we study the $U(1)_\mathrm{B-L}$
scenario as a concrete example of a new anomaly-free vector interaction. We
find that despite the low statistics of these first experimental results, the
inferred bounds are in some cases already competitive. For the scope of this
work we also compute new bounds on some of the interactions using CE$\nu$NS
data from COHERENT and electron recoil data from XENONnT, LUX-ZEPLIN,
PandaX-4T, and TEXONO. It seems clear that while direct detection experiments
continue to take data, more precise measurements will be available, thus
allowing to test new neutrino interactions at the same level or even improving
over dedicated neutrino facilities.


### Lattice calculation of the $π^0$, $η$ and $η^{\prime}$ transition form factors and the hadronic light-by-light contribution to the muon $g-2$
**Authors**: Antoine Gérardin, Willem E. A. Verplanke, Gen Wang, Zoltan Fodor, Jana N. Guenther, Laurent Lellouch, Kalman K. Szabo, Lukas Varnhorst

**Published Date**: 2023-05-08

**Updated Date**: 2024-11-18

**PDF Url**: [2305.04570v2](http://arxiv.org/pdf/2305.04570v2)

**Abstract**: In this paper we present a first ab-initio calculation of the $\pi^0$, $\eta$
and $\eta^{\prime}$ transition form factors performed with physical light-quark
masses. We provide a complete parametrization of the form factors that includes
both single and double-virtual kinematics. Our results are compared with
experimental measurements of the form factors in the space-like region and with
the measured two-photon decay widths. In a second step, our parametrizations of
the transition form factors are used to compute the dominant pseudoscalar-pole
contributions to the hadronic light-by-light scattering in the muon $g-2$. Our
final result reads $a_{\mu}^{\rm hlbl, ps-pole} = (85.1 \pm 5.2) \times
10^{-11}$. Although the pion-pole is dominant, we confirm that, together, the
$\eta$ and $\eta^{\prime}$ provide roughly half of its contribution.


## Diffusion
### Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure
**Authors**: Xiang Li, Yixiang Dai, Qing Qu

**Published Date**: 2024-10-31

**Updated Date**: 2024-11-18

**PDF Url**: [2410.24060v3](http://arxiv.org/pdf/2410.24060v3)

**Abstract**: In this work, we study the generalizability of diffusion models by looking
into the hidden properties of the learned score functions, which are
essentially a series of deep denoisers trained on various noise levels. We
observe that as diffusion models transition from memorization to
generalization, their corresponding nonlinear diffusion denoisers exhibit
increasing linearity. This discovery leads us to investigate the linear
counterparts of the nonlinear diffusion models, which are a series of linear
models trained to match the function mappings of the nonlinear diffusion
denoisers. Surprisingly, these linear denoisers are approximately the optimal
denoisers for a multivariate Gaussian distribution characterized by the
empirical mean and covariance of the training dataset. This finding implies
that diffusion models have the inductive bias towards capturing and utilizing
the Gaussian structure (covariance information) of the training dataset for
data generation. We empirically demonstrate that this inductive bias is a
unique property of diffusion models in the generalization regime, which becomes
increasingly evident when the model's capacity is relatively small compared to
the training dataset size. In the case that the model is highly
overparameterized, this inductive bias emerges during the initial training
phases before the model fully memorizes its training data. Our study provides
crucial insights into understanding the notable strong generalization
phenomenon recently observed in real-world diffusion models.


### Aligning Few-Step Diffusion Models with Dense Reward Difference Learning
**Authors**: Ziyi Zhang, Li Shen, Sen Zhang, Deheng Ye, Yong Luo, Miaojing Shi, Bo Du, Dacheng Tao

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11727v1](http://arxiv.org/pdf/2411.11727v1)

**Abstract**: Aligning diffusion models with downstream objectives is essential for their
practical applications. However, standard alignment methods often struggle with
step generalization when directly applied to few-step diffusion models, leading
to inconsistent performance across different denoising step scenarios. To
address this, we introduce Stepwise Diffusion Policy Optimization (SDPO), a
novel alignment method tailored for few-step diffusion models. Unlike prior
approaches that rely on a single sparse reward from only the final step of each
denoising trajectory for trajectory-level optimization, SDPO incorporates dense
reward feedback at every intermediate step. By learning the differences in
dense rewards between paired samples, SDPO facilitates stepwise optimization of
few-step diffusion models, ensuring consistent alignment across all denoising
steps. To promote stable and efficient training, SDPO introduces an online
reinforcement learning framework featuring several novel strategies designed to
effectively exploit the stepwise granularity of dense rewards. Experimental
results demonstrate that SDPO consistently outperforms prior methods in
reward-based alignment across diverse step configurations, underscoring its
robust step generalization capabilities. Code is avaliable at
https://github.com/ZiyiZhang27/sdpo.


### Robust Reinforcement Learning under Diffusion Models for Data with Jumps
**Authors**: Chenyang Jiang, Donggyu Kim, Alejandra Quintos, Yazhen Wang

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11697v1](http://arxiv.org/pdf/2411.11697v1)

**Abstract**: Reinforcement Learning (RL) has proven effective in solving complex
decision-making tasks across various domains, but challenges remain in
continuous-time settings, particularly when state dynamics are governed by
stochastic differential equations (SDEs) with jump components. In this paper,
we address this challenge by introducing the Mean-Square Bipower Variation
Error (MSBVE) algorithm, which enhances robustness and convergence in scenarios
involving significant stochastic noise and jumps. We first revisit the
Mean-Square TD Error (MSTDE) algorithm, commonly used in continuous-time RL,
and highlight its limitations in handling jumps in state dynamics. The proposed
MSBVE algorithm minimizes the mean-square quadratic variation error, offering
improved performance over MSTDE in environments characterized by SDEs with
jumps. Simulations and formal proofs demonstrate that the MSBVE algorithm
reliably estimates the value function in complex settings, surpassing MSTDE's
performance when faced with jump processes. These findings underscore the
importance of alternative error metrics to improve the resilience and
effectiveness of RL algorithms in continuous-time frameworks.


### Conceptwm: A Diffusion Model Watermark for Concept Protection
**Authors**: Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu

**Published Date**: 2024-11-18

**Updated Date**: 2024-11-18

**PDF Url**: [2411.11688v1](http://arxiv.org/pdf/2411.11688v1)

**Abstract**: The personalization techniques of diffusion models succeed in generating
specific concepts but also pose threats to copyright protection and illegal
use. Model Watermarking is an effective method to prevent the unauthorized use
of subject-driven or style-driven image generation, safeguarding concept
copyrights. However, under the goal of concept-oriented protection, current
watermarking schemes typically add watermarks to all images rather than
applying them in a refined manner targeted at specific concepts. Additionally,
the personalization techniques of diffusion models can easily remove
watermarks. Existing watermarking methods struggle to achieve fine-grained
watermark embedding with a few images of specific concept and prevent removal
of watermarks through personalized fine-tuning. Therefore, we introduce a novel
concept-oriented watermarking framework that seamlessly embeds imperceptible
watermarks into the concept of diffusion models. We conduct extensive
experiments and ablation studies to verify our framework. Our code is available
at https://anonymous.4open.science/r/Conceptwm-4EB3/.


### Hierarchical Structure Enhances the Convergence and Generalizability of Linear Molecular Representation
**Authors**: Juan-Ni Wu, Tong Wang, Li-Juan Tang, Hai-Long Wu, Ru-Qin Yu

**Published Date**: 2024-02-03

**Updated Date**: 2024-11-18

**PDF Url**: [2402.02164v4](http://arxiv.org/pdf/2402.02164v4)

**Abstract**: Language models demonstrate fundamental abilities in syntax, semantics, and
reasoning, though their performance often depends significantly on the inputs
they process. This study introduces TSIS (Simplified TSID) and its
variants:TSISD (TSIS with Depth-First Search), TSISO (TSIS in Order), and TSISR
(TSIS in Random), as integral components of the t-SMILES framework. These
additions complete the framework's design, providing diverse approaches to
molecular representation. Through comprehensive analysis and experiments
employing deep generative models, including GPT, diffusion models, and
reinforcement learning, the findings reveal that the hierarchical structure of
t-SMILES is more straightforward to parse than initially anticipated.
Furthermore, t-SMILES consistently outperforms other linear representations
such as SMILES, SELFIES, and SAFE, demonstrating superior convergence speed and
enhanced generalization capabilities.


## Quantitative Finance
### Portfolio Optimization with Feedback Strategies Based on Artificial Neural Networks
**Authors**: Yaacov Kopeliovich, Michael Pokojovy

**Published Date**: 2024-11-15

**Updated Date**: 2024-11-15

**PDF Url**: [2411.09899v1](http://arxiv.org/pdf/2411.09899v1)

**Abstract**: With the recent advancements in machine learning (ML), artificial neural
networks (ANN) are starting to play an increasingly important role in
quantitative finance. Dynamic portfolio optimization is among many problems
that have significantly benefited from a wider adoption of deep learning (DL).
While most existing research has primarily focused on how DL can alleviate the
curse of dimensionality when solving the Hamilton-Jacobi-Bellman (HJB)
equation, some very recent developments propose to forego derivation and
solution of HJB in favor of empirical utility maximization over dynamic
allocation strategies expressed through ANN. In addition to being simple and
transparent, this approach is universally applicable, as it is essentially
agnostic about market dynamics. To showcase the method, we apply it to optimal
portfolio allocation between a cash account and the S&P 500 index modeled using
geometric Brownian motion or the Heston model. In both cases, the results are
demonstrated to be on par with those under the theoretical optimal weights
assuming isoelastic utility and real-time rebalancing. A set of R codes for a
broad class of stochastic volatility models are provided as a supplement.


