# Abstracts of Papers

## Physics
### Agentic Design of Compositional Machines
**Authors**: Wenqian Zhang, Weiyang Liu, Zhen Liu

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14980v1](http://arxiv.org/pdf/2510.14980v1)

**Abstract**: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.


### Terra: Explorable Native 3D World Model with Point Latents
**Authors**: Yuanhui Huang, Weiliang Chen, Wenzhao Zheng, Xin Tao, Pengfei Wan, Jie Zhou, Jiwen Lu

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14977v1](http://arxiv.org/pdf/2510.14977v1)

**Abstract**: World models have garnered increasing attention for comprehensive modeling of
the real world. However, most existing methods still rely on pixel-aligned
representations as the basis for world evolution, neglecting the inherent 3D
nature of the physical world. This could undermine the 3D consistency and
diminish the modeling efficiency of world models. In this paper, we present
Terra, a native 3D world model that represents and generates explorable
environments in an intrinsic 3D latent space. Specifically, we propose a novel
point-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into
a latent point representation, which is subsequently decoded as 3D Gaussian
primitives to jointly model geometry and appearance. We then introduce a sparse
point flow matching network (SPFlow) for generating the latent point
representation, which simultaneously denoises the positions and features of the
point latents. Our Terra enables exact multi-view consistency with native 3D
representation and architecture, and supports flexible rendering from any
viewpoint with only a single generation process. Furthermore, Terra achieves
explorable world modeling through progressive generation in the point latent
space. We conduct extensive experiments on the challenging indoor scenes from
ScanNet v2. Terra achieves state-of-the-art performance in both reconstruction
and generation with high 3D consistency.


### Astrophysical uncertainties challenge 21-cm forecasts: A primordial black hole case study
**Authors**: Dominic Agius, Rouven Essig, Daniele Gaggero, Sergio Palomares-Ruiz, Gregory Suczewski, Mauro Valli

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14877v1](http://arxiv.org/pdf/2510.14877v1)

**Abstract**: The 21-cm signal is a powerful probe of the early Universe's thermal history
and could provide a unique avenue for constraining exotic physics. Previous
studies have forecasted stringent constraints on energy injections from exotic
sources that heat, excite, and ionize the background gas and thereby modify the
21-cm signal. In this work, we quantify the substantial impact that
astrophysical uncertainties have on the projected sensitivity to exotic energy
injection. In particular, there are significant uncertainties in the minimum
star-forming dark matter halo mass, the Lyman-$\alpha$ emission, and the X-ray
emission, whose values characterize the fiducial astrophysical model when
projecting bounds. As a case study, we investigate the energy injection of
accreting primordial black holes of mass $\sim 1~M_\odot-10^3~M_\odot$, also
taking into account uncertainties in the accretion model. We show that,
depending on the chosen fiducial model and accretion uncertainties, the
sensitivity of future 21-cm data could constrain the abundance of primordial
black holes to be either slightly stronger, or significantly weaker, than
current limits from the Cosmic Microwave Background.


### LabOS: The AI-XR Co-Scientist That Sees and Works With Humans
**Authors**: Le Cong, Zaixi Zhang, Xiaotong Wang, Yin Di, Ruofan Jin, Michal Gerasimiuk, Yinkai Wang, Ravi K. Dinesh, David Smerkous, Alex Smerkous, Xuekun Wu, Shilong Liu, Peishan Li, Yi Zhu, Simran Serrao, Ning Zhao, Imran A. Mohammad, John B. Sunwoo, Joseph C. Wu, Mengdi Wang

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14861v1](http://arxiv.org/pdf/2510.14861v1)

**Abstract**: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.


### Exploiting Non-Diffracting Beams for Resilient Near-Field Millimeter-Wave Communications A Quantitative Roadmap
**Authors**: Yifeng Qin, Jing Chen, Zhi Hao Jiang, Zhining Chen, Yongming Huang, Lingyang Song

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14858v1](http://arxiv.org/pdf/2510.14858v1)

**Abstract**: Non diffracting (ND) beams are often cited as a promising solution to
mitigate blockage in millimeter wave (mmWave) systems. However, a quantitative
answer to the fundamental question, under what specific conditions do ND beams
actually outperform conventional pencil beams, has remained elusive, especially
in the emerging context of near-field communications. This paper provides the
first systematic answer by mapping the performance advantage regimes of ND
beams for blockage-resilient near-field links. We propose a unified holographic
generator that synthesizes various structured beams (e.g., Bessel, Mathieu)
under the physical constraints of a planar phased array, ensuring a fair
comparison against a boresight baseline with identical EIRP and aperture.
Through extensive, unbiased Monte Carlo simulations, we construct advantage
regime maps that delineate the specific regions where ND beams offer a tangible
link-level gain. Our key finding is that the advantage of ND beams is a
powerful but conditional near field phenomenon. While offering a positive
average gain, its performance is highly variable, with a 60-70% probability of
outperforming the baseline in its optimal range. Crucially, this performance is
strongly modulated by the obstacle's geometry, revealing a significant weakness
against large blockers. These findings provide not just a practical roadmap for
judiciously employing ND beams but also a clear motivation for future work in
environment-aware, adaptively shaped structured beams.


### RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning
**Authors**: Jinrui Liu, Bingyan Nie, Boyu Li, Yaran Chen, Yuze Wang, Shunsen He, Haoran Li

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14828v1](http://arxiv.org/pdf/2510.14828v1)

**Abstract**: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.


### Signatures of Topological Symmetries on a Noisy Quantum Simulator
**Authors**: Christopher Lamb, Robert M. Konik, Hubert Saleur, Ananda Roy

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14817v1](http://arxiv.org/pdf/2510.14817v1)

**Abstract**: Topological symmetries, invertible and otherwise, play a fundamental role in
the investigation of quantum field theories. Despite their ubiquitous
importance across a multitude of disciplines ranging from string theory to
condensed matter physics, controlled realizations of models exhibiting these
symmetries in physical systems are rare. Quantum simulators based on engineered
solid-state devices provide a novel alternative to conventional condensed
matter systems for realizing these models.
  In this work, eigenstates of impurity Hamiltonians and loop operators
associated with the topological symmetries for the Ising conformal field theory
in two space-time dimensions are realized on IBM's Kingston simulator. The
relevant states are created on the quantum device using a hybrid
quantum-classical algorithm. The latter is based on a variation of the quantum
approximate optimization algorithm ansatz combined with the quantum natural
gradient optimization method. Signatures of the topological symmetry are
captured by measuring correlation functions of different qubit operators with
results obtained from the quantum device in reasonable agreement with those
obtained from classical computations. The current work demonstrates the
viability of noisy quantum simulators as platforms for investigating
low-dimensional quantum field theories with direct access to observables that
are often difficult to probe in conventional condensed matter experiments.


### Reflections of quantum educators on strategies to diversify the second quantum revolution
**Authors**: Apekshya Ghimire, Chandralekha Singh

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14793v1](http://arxiv.org/pdf/2510.14793v1)

**Abstract**: We focus on reflections and suggestions of five college quantum educators
from four different institutions (two from same institution) regarding what can
be done to diversify the second quantum revolution. They are leading QIST
researchers, and very passionate about improving quantum education. The
educators were asked about their thoughts on whether the interdisciplinary
nature of the field, in which nobody can claim to be an expert in all aspects
of QIST, may make it easier to create a better culture from the beginning,
supportive of equitable participation of diverse groups unlike physics. This is
because disciplines such as physics have an ingrained inequitable culture based
on brilliance attribution that is a major impediment to diversity, equity and
inclusion. Educators were interviewed on Zoom using a semi-structured
think-aloud protocol about various issues related to QIST education including
those pertaining to how to diversify the second quantum revolution. Their
suggestions can be invaluable and can help other educators adapt and implement
strategies to diversify QIST.


### Flavor solitons in dense neutrino gases
**Authors**: Damiano F. G. Fiorillo, Georg Raffelt

**Published Date**: 2023-03-21

**Updated Date**: 2025-10-16

**PDF Url**: [2303.12143v2](http://arxiv.org/pdf/2303.12143v2)

**Abstract**: We consider a dense neutrino gas in the "fast-flavor limit" (vanishing
neutrino masses). For the first time, we identify exact solutions of the
nonlinear wave equation in the form of solitons. They can propagate with both
sub- or superluminal speed, the latter not violating causality. The soliton
with infinite speed is a homogeneous solution and coincides with the usual
fast-flavor pendulum except that it swings only once instead of being periodic.
The subluminal soliton in the static limit corresponds to a one-swing "spatial
pendulum". A necessary condition for such solutions to exist is a ``crossed''
neutrino angle distribution. Based on the Nyquist criterion, we derive a new
sufficient condition without solving the dispersion relation. The solitons are
very fragile: they are as unstable as the homogeneous neutrino gas alone.
Moreover, in the presence of matter, only the solution survives that is
homogeneous in a frame comoving with the matter current. Generally, the matter
effect cannot be eliminated by transformations in flavor space, but instead has
a real physical impact.


### Unifying Frictional Transients Reveals the Origin of Static Friction
**Authors**: Kasra Farain, Daniel Bonn

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14769v1](http://arxiv.org/pdf/2510.14769v1)

**Abstract**: Frictional motion is harder to initiate than to sustain, as evident when
pushing a heavy object. This disparity between static and kinetic friction
drives instabilities and stick-slip dynamics in systems ranging from
nanodevices and MEMS to squealing brakes, glaciers and tectonic faults, yet its
origin and the transition mechanism remain poorly understood. Empirical
rate-and-state friction laws predict that during the static-to-kinetic
transition, friction increases for nanometer-per-second slip rates, but
decreases for micrometers-per-second rates and above. These transients are
believed to be associated with contact strengthening (aging) at static
interfaces, although their physical basis is unclear and the crossover between
regimes has never been observed directly. Here we show, through
nanometer-resolution sliding experiments on macroscopic rough surfaces, that
these transients are segments of a single, universal non-monotonic response
whose peak defines static friction. We show that this behavior arises from
mechanical reorganization of interlocking surface asperities under shear,
fundamentally distinct from contact aging, which is governed by thermal
molecular processes. We derive, from first principles and without invoking any
empirical postulates, a differential equation that quantitatively captures the
friction peak. These results unify frictional transients across scales and
speeds, and establish a physics-based framework for understanding frictional
instabilities and failure processes in engineering and geosciences.


## Diffusion
### Coupled Diffusion Sampling for Training-Free Multi-View Image Editing
**Authors**: Hadi Alzayer, Yunzhi Zhang, Chen Geng, Jia-Bin Huang, Jiajun Wu

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14981v1](http://arxiv.org/pdf/2510.14981v1)

**Abstract**: We present an inference-time diffusion sampling method to perform multi-view
consistent image editing using pre-trained 2D image editing models. These
models can independently produce high-quality edits for each image in a set of
multi-view images of a 3D scene or object, but they do not maintain consistency
across views. Existing approaches typically address this by optimizing over
explicit 3D representations, but they suffer from a lengthy optimization
process and instability under sparse view settings. We propose an implicit 3D
regularization approach by constraining the generated 2D image sequences to
adhere to a pre-trained multi-view image distribution. This is achieved through
coupled diffusion sampling, a simple diffusion sampling technique that
concurrently samples two trajectories from both a multi-view image distribution
and a 2D edited image distribution, using a coupling term to enforce the
multi-view consistency among the generated images. We validate the
effectiveness and generality of this framework on three distinct multi-view
image editing tasks, demonstrating its applicability across various model
architectures and highlighting its potential as a general solution for
multi-view consistent editing.


### Learning an Image Editing Model without Image Editing Pairs
**Authors**: Nupur Kumari, Sheng-Yu Wang, Nanxuan Zhao, Yotam Nitzan, Yuheng Li, Krishna Kumar Singh, Richard Zhang, Eli Shechtman, Jun-Yan Zhu, Xun Huang

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14978v1](http://arxiv.org/pdf/2510.14978v1)

**Abstract**: Recent image editing models have achieved impressive results while following
natural language editing instructions, but they rely on supervised fine-tuning
with large datasets of input-target pairs. This is a critical bottleneck, as
such naturally occurring pairs are hard to curate at scale. Current workarounds
use synthetic training pairs that leverage the zero-shot capabilities of
existing models. However, this can propagate and magnify the artifacts of the
pretrained model into the final trained model. In this work, we present a new
training paradigm that eliminates the need for paired data entirely. Our
approach directly optimizes a few-step diffusion model by unrolling it during
training and leveraging feedback from vision-language models (VLMs). For each
input and editing instruction, the VLM evaluates if an edit follows the
instruction and preserves unchanged content, providing direct gradients for
end-to-end optimization. To ensure visual fidelity, we incorporate distribution
matching loss (DMD), which constrains generated images to remain within the
image manifold learned by pretrained models. We evaluate our method on standard
benchmarks and include an extensive ablation study. Without any paired data,
our method performs on par with various image editing diffusion models trained
on extensive supervised paired data, under the few-step setting. Given the same
VLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.


### WithAnyone: Towards Controllable and ID Consistent Image Generation
**Authors**: Hengyuan Xu, Wei Cheng, Peng Xing, Yixiao Fang, Shuhan Wu, Rui Wang, Xianfang Zeng, Daxin Jiang, Gang Yu, Xingjun Ma, Yu-Gang Jiang

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14975v1](http://arxiv.org/pdf/2510.14975v1)

**Abstract**: Identity-consistent generation has become an important focus in text-to-image
research, with recent models achieving notable success in producing images
aligned with a reference identity. Yet, the scarcity of large-scale paired
datasets containing multiple images of the same individual forces most
approaches to adopt reconstruction-based training. This reliance often leads to
a failure mode we term copy-paste, where the model directly replicates the
reference face rather than preserving identity across natural variations in
pose, expression, or lighting. Such over-similarity undermines controllability
and limits the expressive power of generation. To address these limitations, we
(1) construct a large-scale paired dataset MultiID-2M, tailored for
multi-person scenarios, providing diverse references for each identity; (2)
introduce a benchmark that quantifies both copy-paste artifacts and the
trade-off between identity fidelity and variation; and (3) propose a novel
training paradigm with a contrastive identity loss that leverages paired data
to balance fidelity with diversity. These contributions culminate in
WithAnyone, a diffusion-based model that effectively mitigates copy-paste while
preserving high identity similarity. Extensive qualitative and quantitative
experiments demonstrate that WithAnyone significantly reduces copy-paste
artifacts, improves controllability over pose and expression, and maintains
strong perceptual quality. User studies further validate that our method
achieves high identity fidelity while enabling expressive controllable
generation.


### pi-Flow: Policy-Based Few-Step Generation via Imitation Distillation
**Authors**: Hansheng Chen, Kai Zhang, Hao Tan, Leonidas Guibas, Gordon Wetzstein, Sai Bi

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14974v1](http://arxiv.org/pdf/2510.14974v1)

**Abstract**: Few-step diffusion or flow-based generative models typically distill a
velocity-predicting teacher into a student that predicts a shortcut towards
denoised data. This format mismatch has led to complex distillation procedures
that often suffer from a quality-diversity trade-off. To address this, we
propose policy-based flow models ($\pi$-Flow). $\pi$-Flow modifies the output
layer of a student flow model to predict a network-free policy at one timestep.
The policy then produces dynamic flow velocities at future substeps with
negligible overhead, enabling fast and accurate ODE integration on these
substeps without extra network evaluations. To match the policy's ODE
trajectory to the teacher's, we introduce a novel imitation distillation
approach, which matches the policy's velocity to the teacher's along the
policy's trajectory using a standard $\ell_2$ flow matching loss. By simply
mimicking the teacher's behavior, $\pi$-Flow enables stable and scalable
training and avoids the quality-diversity trade-off. On ImageNet 256$^2$, it
attains a 1-NFE FID of 2.85, outperforming MeanFlow of the same DiT
architecture. On FLUX.1-12B and Qwen-Image-20B at 4 NFEs, $\pi$-Flow achieves
substantially better diversity than state-of-the-art few-step methods, while
maintaining teacher-level quality.


### Attention Is All You Need for KV Cache in Diffusion LLMs
**Authors**: Quan Nguyen-Tri, Mukul Ranjan, Zhiqiang Shen

**Published Date**: 2025-10-16

**Updated Date**: 2025-10-16

**PDF Url**: [2510.14973v1](http://arxiv.org/pdf/2510.14973v1)

**Abstract**: This work studies how to adaptively recompute key-value (KV) caches for
diffusion large language models (DLMs) to maximize prediction accuracy while
minimizing decoding latency. Prior methods' decoders recompute QKV for all
tokens at every denoising step and layer, despite KV states changing little
across most steps, especially in shallow layers, leading to substantial
redundancy. We make three observations: (1) distant ${\bf MASK}$ tokens
primarily act as a length-bias and can be cached block-wise beyond the active
prediction window; (2) KV dynamics increase with depth, suggesting that
selective refresh starting from deeper layers is sufficient; and (3) the
most-attended token exhibits the smallest KV drift, providing a conservative
lower bound on cache change for other tokens. Building on these, we propose
${\bf Elastic-Cache}$, a training-free, architecture-agnostic strategy that
jointly decides ${when}$ to refresh (via an attention-aware drift test on the
most-attended token) and ${where}$ to refresh (via a depth-aware schedule that
recomputes from a chosen layer onward while reusing shallow-layer caches and
off-window MASK caches). Unlike fixed-period schemes, Elastic-Cache performs
adaptive, layer-aware cache updates for diffusion LLMs, reducing redundant
computation and accelerating decoding with negligible loss in generation
quality. Experiments on LLaDA-Instruct, LLaDA-1.5, and LLaDA-V across
mathematical reasoning and code generation tasks demonstrate consistent
speedups: $8.7\times$ on GSM8K (256 tokens), $45.1\times$ on longer sequences,
and $4.8\times$ on HumanEval, while consistently maintaining higher accuracy
than the baseline. Our method achieves significantly higher throughput
($6.8\times$ on GSM8K) than existing confidence-based approaches while
preserving generation quality, enabling practical deployment of diffusion LLMs.


