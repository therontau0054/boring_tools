# Abstracts of Papers

## Physics
### Suppression of errors in collectively coded information
**Authors**: Martin J. Falk, Leon Zhou, Yoshiya J. Matsubara, Kabir Husain, Jack W. Szostak, Arvind Murugan

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21806v1](http://arxiv.org/pdf/2508.21806v1)

**Abstract**: Modern life largely transmits genetic information from mother to daughter
through the duplication of single physically intact molecules that encode
information. However, copying an extended molecule requires highly processive
copying machinery and high fidelity that scales with the genome size to avoid
the error catastrophe. Here, we explore these fidelity requirements in an
alternative architecture, the virtual circular genome, in which no one physical
molecule encodes the full genetic information. Instead, information is encoded
and transmitted in a collective of overlapping and interacting segments. Using
a model experimental system of a complex mixture of DNA oligos that can partly
anneal and extend off each other, we find that mutant oligomers are suppressed
relative to a model without collective encoding. Through simulations and
theory, we show that this suppression of mutants can be explained by
competition for productive binding partners. As a consequence, information can
be propagated robustly in a virtual circular genome even if the mutation rate
is above the error catastrophe for a physically intact genome.


### DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers
**Authors**: Navid Aftabi, Abhishek Hanchate, Satish Bukkapatnam, Dan Li

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21797v1](http://arxiv.org/pdf/2508.21797v1)

**Abstract**: Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime
targets for replay attacks that use outdated sensor data to manipulate
actuators. Dynamic watermarking can reveal such tampering, but current schemes
assume linear-Gaussian dynamics and use constant watermark statistics, making
them vulnerable to the time-varying, partly proprietary behavior of MTCs. We
close this gap with DynaMark, a reinforcement learning framework that models
dynamic watermarking as a Markov decision process (MDP). It learns an adaptive
policy online that dynamically adapts the covariance of a zero-mean Gaussian
watermark using available measurements and detector feedback, without needing
system knowledge. DynaMark maximizes a unique reward function balancing control
performance, energy consumption, and detection confidence dynamically. We
develop a Bayesian belief updating mechanism for real-time detection confidence
in linear systems. This approach, independent of specific system assumptions,
underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D
controller digital twin, DynaMark achieves a reduction in watermark energy by
70% while preserving the nominal trajectory, compared to constant variance
baselines. It also maintains an average detection delay equivalent to one
sampling interval. A physical stepper-motor testbed validates these findings,
rapidly triggering alarms with less control performance decline and exceeding
existing benchmarks.


### Road map for the tuning of hadronic interaction models with accelerator-based and astroparticle data
**Authors**: Johannes Albrecht, Julia Becker Tjus, Noah Behling, Jiří Blažek, Marcus Bleicher, Julian Boelhauve, Lorenzo Cazon, Ruben Conceição, Hans Dembinski, Luca Dietrich, Jan Ebr, Jan Ellbracht, Ralph Engel, Anatoli Fedynitch, Max Fieg, Maria Garzelli, Chloé Gaudu, Giacomo Graziani, Pascal Gutjahr, Andreas Haungs, Tim Huege, Karolin Hymon, Karl-Heinz Kampert, Leonora Kardum, Lars Kolk, Natalia Korneeva, Kevin Kröninger, Antonin Maire, Hiroaki Menjo, Leonel Morejon, Sergey Ostapchenko, Petja Paakkinen, Tanguy Pierog, Pavlo Plotko, Anton Prosekin, Lilly Pyras, Thomas Pöschl, Maximilian Reininghaus, Wolfgang Rhode, Felix Riehn, Markus Roth, Alexander Sandrock, Ina Sarcevic, Michael Schmelling, Günter Sigl, Torbjorn Sjöstrand, Dennis Soldin, Michael Unger, Marius Utheim, Jakub Vícha, Klaus Werner, Michael Windau, Valery Zhukov

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21796v1](http://arxiv.org/pdf/2508.21796v1)

**Abstract**: In high-energy and astroparticle physics, event generators play an essential
role, even in the simplest data analyses. As analysis techniques become more
sophisticated, e.g. based on deep neural networks, their correct description of
the observed event characteristics becomes even more important. Physical
processes occurring in hadronic collisions are simulated within a Monte Carlo
framework. A major challenge is the modeling of hadron dynamics at low momentum
transfer, which includes the initial and final phases of every hadronic
collision. Phenomenological models inspired by Quantum Chromodynamics used for
these phases cannot guarantee completeness or correctness over the full phase
space. These models usually include parameters which must be tuned to suitable
experimental data. Until now, event generators have primarily been developed
and tuned based on data from high-energy physics experiments at accelerators.
However, in many cases they have been found to not satisfactorily describe data
from astroparticle experiments, which provide sensitivity especially to hadrons
produced nearly parallel to the collision axis and cover center-of-mass
energies up to several hundred TeV, well beyond those reached at colliders so
far. In this report, we address the complementarity of these two sets of data
and present a road map for exploiting, for the first time, their
complementarity by enabling a unified tuning of event generators with
accelerator-based and astroparticle data.


### Experimental measurement of quantum-first-passage-time distributions
**Authors**: Joseph M. Ryan, Simon Gorbaty, Thomas J. Kessler, Mitchell G. Peaks, Stephen W. Teitsworth, Crystal Noel

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21790v1](http://arxiv.org/pdf/2508.21790v1)

**Abstract**: Classical First-Passage-Time Distributions (FPTDs) have been extensively
studied both theoretically and experimentally. Their quantum counterparts,
Quantum First-Passage-Time Distributions (QFPTDs), remain largely unexplored
and have deep implications for both fundamental physics and the development of
emerging quantum technologies. We measure the first QFPTDs using a motional
mode of a single trapped ion. We develop a novel composite-phase laser pulse
sequence to perform tunable stroboscopic projective measurements of the
motional state of a trapped ion. We measure QFPTDs of the ion energy when
coupled to electric-field noise and establish a clear connection with its
classical counterpart. The measurement protocol developed here is broadly
applicable to other quantum systems and provides a powerful method for
exploring a broad range of QFPTD phenomena. With these results we open a new
field of experimental investigations of QFPT processes with potential future
relevance to quantum search algorithms, unraveling connections between
classical and quantum dynamics, and study of the quantum measurement problem.


### The Spontaneous Cascading Mechanism Behind Critical Phenomena in Self-Coupled Lasers
**Authors**: Jiaoqing Wang, Yael Kfir-Cohen, Chenni Xu, Bnaya Gross, Aswathy Sundaresan, Shlomo Havlin, Patrick Sebbah

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21786v1](http://arxiv.org/pdf/2508.21786v1)

**Abstract**: The basic physics of lasers is characterized by a second-order continuous
phase transition at the critical lasing threshold. Nevertheless, laser
bistability with abrupt transitions has been reported in some laser systems,
but its underlying mechanism has never been explored. Here we study
experimentally and theoretically a novel nonlinearly self-coupled laser system.
We show both experimentally and theoretically that this system experiences
spontaneous cascading that yields an abrupt mixed-order transition. At the
critical point, a long-lived cascading plateau is observed, characterized by a
critical branching factor equal to one. When deviating from criticality, the
branching factor departs monotonically from one. The critical scaling close to
and at the critical point resembles similar phenomena observed recently in
other interdependent systems, suggesting a common universal cascading origin
for abrupt transitions. Our results shed light on the cascading mechanism of
abrupt transitions in laser systems, which can be utilized for future research
and applications.


### Implications of computer science theory for the simulation hypothesis
**Authors**: David H. Wolpert

**Published Date**: 2024-04-09

**Updated Date**: 2025-08-29

**PDF Url**: [2404.16050v3](http://arxiv.org/pdf/2404.16050v3)

**Abstract**: The simulation hypothesis has recently excited renewed interest in the
physics and philosophy communities. However, the hypothesis specifically
concerns {\textit{computers}} that simulate physical universes. So to formally
investigate the hypothesis, we need to understand it in terms of computer
science (CS) theory. In addition we need a formal way to couple CS theory with
physics. Here I couple those fields by using the physical Church-Turing thesis.
This allow me to exploit Kleene's second recursion, to prove that not only is
it possible for {us} to be a simulation being run on a computer, but that we
might be in a simulation being run a computer \emph{by us}. In such a
``self-simulation'', there would be two identical instances of us, both equally
``real''. I then use Rice's theorem to derive impossibility results concerning
simulation and self-simulation; derive implications for (self-)simulation if we
are being simulated in a program using fully homomorphic encryption; and
briefly investigate the graphical structure of universes simulating other
universes which contain computers running their own simulations. I end by
describing some of the possible avenues for future research. While motivated in
terms of the simulation hypothesis, the results in this paper are direct
consequences of the Church-Turing thesis. So they apply far more broadly than
the simulation hypothesis.


### Probing $a_0(1450)$-meson leading-twist distribution amplitude and its effects to $D\to a_0(1450)\ell ν_{\ell}$
**Authors**: Ya-Lin Song, Yin-Long Yang, Ye Cao, Xue Zheng, Hai-Bing Fu

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21750v1](http://arxiv.org/pdf/2508.21750v1)

**Abstract**: In this paper, we investigate the semileptonic decay $D \to a_0(1450)\ell
\nu_{\ell}$ with $\ell=(e, \mu)$ using QCD light-cone sum rules. For the scalar
meson $a_0(1450)$, we treat it as a $q\bar{q}$ state and construct two
distributed distribution schemes based on the light-cone harmonic oscillator
model, then present their moments $\langle\xi^{n}_{2;a_0}\rangle |_{\mu}$ and
Gegenbauer moments $a_{n;a_0}(\mu)$ at $\mu_0=1~\mathrm{GeV}$ and $\mu_k=
1.4~\mathrm{GeV}$ for $n=(1,3,5)$. In the large recoil region, we obtain the
transition form factors (TFFs): $f_+^{D\to a_0({\rm
S1})}(0)=0.769_{-0.114}^{+0.103}$, $f_+^{D \to a_0 ({\rm
S2})}(0)=0.738_{-0.108}^{+0.106}$ and $f_{-}^{D \to
a_0}(0)=0.688_{-0.086}^{+0.081}$. A simplified $z(q^2, t)$-series expansion
parametrization is used to extrapolate the TFFs to the full physical
$q^2$-region. By taking $q^2=10^{-5} ~\mathrm{GeV}^2$, we calculate the angular
distribution of the differential decay width ${d\Gamma}/{d\cos\theta}$ over the
range $\cos\theta_{\ell}\in [-1,1]$. Subsequently, we obtained differential
decay widths and branching ratios for $D^0 \to a_0(1450)^- \ell^+ \nu_{\ell}$
and $D^- \to a_0(1450)^0 \ell^- \bar{\nu}_{\ell}$, with the branching ratios
being of order $10^{-6}$. Finally, we analyze the three angular observables for
the semileptonic decay process $D^- \to a_0(1450)^0 \ell^- \bar{\nu}_{\ell}$
with $\ell=(e,\mu)$, the forward-backward asymmetry $\mathcal{A}_{\rm{FB}}$,
lepton polarization asymmetry $\mathcal{A}_{\lambda_\ell}$ and the
$q^2$-differential flat term $\mathcal{F}_{\mathrm{H}}$.


### Factorization for Collider Dataspace Correlators
**Authors**: Andrew J. Larkoski

**Published Date**: 2025-04-16

**Updated Date**: 2025-08-29

**PDF Url**: [2504.12380v3](http://arxiv.org/pdf/2504.12380v3)

**Abstract**: A metric on the space of collider physics data enables analysis of its
geometrical properties, like dimensionality or curvature, as well as
quantifying the density with which a finite, discrete ensemble of data samples
the space. We provide the first systematically-improvable precision
calculations on this dataspace, presenting predictions resummed to
next-to-leading logarithmic accuracy, using the Spectral Energy Mover's
Distance (SEMD) as its metric. This is accomplished by demonstration of
factorization of soft and collinear contributions to the metric at leading
power and renormalization group evolution of the single-scale functions that
are present in the factorization theorem. As applications of this general
framework, we calculate the two-point correlator between pairs of jets on the
dataspace, and the measure of the non-Gaussian fluctuations in a finite
dataset. For the non-Gaussianities, our calculations validate the existence of
a universal structure that had been previously observed in simulated data. As
byproducts of this analysis, we also calculate the two-loop anomalous dimension
of the SEMD metric and show that the original Energy Mover's Distance metric is
identical to the SEMD through next-to-next-to-leading logarithmic accuracy.


### A lattice study of two dimensional SU(2) gauge theories with a single massless Majorana fermion
**Authors**: Rajamani Narayanan, Ray Romero

**Published Date**: 2025-08-08

**Updated Date**: 2025-08-29

**PDF Url**: [2508.05967v2](http://arxiv.org/pdf/2508.05967v2)

**Abstract**: Massless overlap fermions in the real representation of two dimensional
$SU(N_c)$ gauge theories exhibit a mod($2$) index due to the rigidity of its
spectrum when viewed as a function of the background gauge field - lattice
gauge fields on a periodic torus come under two classes; ones that have one set
of chirally paired zero modes and ones that do not. Focusing on $SU(2)$ and a
single Majorana fermion in an integer representation, $J$; we present numerical
evidence that shows only one of these classes survives the continuum limit and
this depends on the boundary conditions of the fermion and the gauge field. As
such, two of the four possible partition functions are zero in the continuum
limit. By defining modified partition functions which do not include the zero
modes of the overlap fermions in the fermion determinant, we are able to define
an expectation value for a fermion bilinear as ratios of two mixed partition
functions. This observable is referred to as the topological condensate and has
a non-zero expectation value on any finite physical torus and also has a
non-zero limit as the size of the torus is taken to infinity. We study the
spectral density of fermions and the scaling of the lowest eigenvalue with the
size of the torus to show the absence of any spontaneous symmetry breaking but
the emergence of zero modes in the infinite volume limit where it is prohibited
in finite volume. These results remain the same for $J = 1, 2, 3, 4$. These
results motivate us to propose an independent plaquette model which reproduces
the correct physics in the infinite volume limit using a single partition
function.


### Topological Magnon Frequency Combs
**Authors**: Zhixiong Li, Xuejuan Liu, Zhejunyu Jin, Guanghua Guo, Xingen Zheng, Peng Yan

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21743v1](http://arxiv.org/pdf/2508.21743v1)

**Abstract**: Exploring the synergy between topological physics and nonlinear dynamics
unveils profound insights into emergent states of matter. Inspired by recent
experimental demonstrations of topological frequency combs in photonics, we
theoretically introduce topological magnon frequency combs (MFCs) in a
two-dimensional triangular skyrmion lattice. Computing the Chern numbers of
magnon bands reveals robust chiral edge states. Strikingly, these topological
MFCs originate from nonlinear four-magnon scattering among the chiral edge
modes, activated by dual-frequency driving without an amplitude threshold. Comb
spacings are readily tunable through excitation frequency detuning.
Micromagnetic simulations validate our predictions with good concordance. This
work paves the way for defect-immune magnonic devices exploiting MFCs and
sparks investigations into topological-nonlinear phenomena in magnetic systems.


## Diffusion
### Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation
**Authors**: Tobias Hyrup, Emmanouil Panagiotou, Arjun Roy, Arthur Zimek, Eirini Ntoutsi, Peter Schneider-Kamp

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21815v1](http://arxiv.org/pdf/2508.21815v1)

**Abstract**: As privacy regulations such as the GDPR and HIPAA and responsibility
frameworks for artificial intelligence such as the AI Act gain traction, the
ethical and responsible use of real-world data faces increasing constraints.
Synthetic data generation has emerged as a promising solution to risk-aware
data sharing and model development, particularly for tabular datasets that are
foundational to sensitive domains such as healthcare. To address both privacy
and fairness concerns in this setting, we propose FLIP (Fair Latent
Intervention under Privacy guarantees), a transformer-based variational
autoencoder augmented with latent diffusion to generate heterogeneous tabular
data. Unlike the typical setup in fairness-aware data generation, we assume a
task-agnostic setup, not reliant on a fixed, defined downstream task, thus
offering broader applicability. To ensure privacy, FLIP employs R\'enyi
differential privacy (RDP) constraints during training and addresses fairness
in the input space with RDP-compatible balanced sampling that accounts for
group-specific noise levels across multiple sampling rates. In the latent
space, we promote fairness by aligning neuron activation patterns across
protected groups using Centered Kernel Alignment (CKA), a similarity measure
extending the Hilbert-Schmidt Independence Criterion (HSIC). This alignment
encourages statistical independence between latent representations and the
protected feature. Empirical results demonstrate that FLIP effectively provides
significant fairness improvements for task-agnostic fairness and across diverse
downstream tasks under differential privacy constraints.


### Tree-Guided Diffusion Planner
**Authors**: Hyeonseong Jeon, Cheolhong Min, Jaesik Park

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21800v1](http://arxiv.org/pdf/2508.21800v1)

**Abstract**: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.


### OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization
**Authors**: Jiazheng Xing, Hai Ci, Hongbin Xu, Hangjie Yuan, Yong Liu, Mike Zheng Shou

**Published Date**: 2025-08-29

**Updated Date**: 2025-08-29

**PDF Url**: [2508.21727v1](http://arxiv.org/pdf/2508.21727v1)

**Abstract**: Watermarking diffusion-generated images is crucial for copyright protection
and user tracking. However, current diffusion watermarking methods face
significant limitations: zero-bit watermarking systems lack the capacity for
large-scale user tracking, while multi-bit methods are highly sensitive to
certain image transformations or generative attacks, resulting in a lack of
comprehensive robustness. In this paper, we propose OptMark, an
optimization-based approach that embeds a robust multi-bit watermark into the
intermediate latents of the diffusion denoising process. OptMark strategically
inserts a structural watermark early to resist generative attacks and a detail
watermark late to withstand image transformations, with tailored regularization
terms to preserve image quality and ensure imperceptibility. To address the
challenge of memory consumption growing linearly with the number of denoising
steps during optimization, OptMark incorporates adjoint gradient methods,
reducing memory usage from O(N) to O(1). Experimental results demonstrate that
OptMark achieves invisible multi-bit watermarking while ensuring robust
resilience against valuemetric transformations, geometric transformations,
editing, and regeneration attacks.


### From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling
**Authors**: Marien Renaud, Valentin De Bortoli, Arthur Leclaire, Nicolas Papadakis

**Published Date**: 2025-05-20

**Updated Date**: 2025-08-29

**PDF Url**: [2505.14177v2](http://arxiv.org/pdf/2505.14177v2)

**Abstract**: We consider the problem of sampling distributions stemming from non-convex
potentials with Unadjusted Langevin Algorithm (ULA). We prove the stability of
the discrete-time ULA to drift approximations under the assumption that the
potential is strongly convex at infinity. In many context, e.g. imaging inverse
problems, potentials are non-convex and non-smooth. Proximal Stochastic
Gradient Langevin Algorithm (PSGLA) is a popular algorithm to handle such
potentials. It combines the forward-backward optimization algorithm with a ULA
step. Our main stability result combined with properties of the Moreau envelope
allows us to derive the first proof of convergence of the PSGLA for non-convex
potentials. We empirically validate our methodology on synthetic data and in
the context of imaging inverse problems. In particular, we observe that PSGLA
exhibits faster convergence rates than Stochastic Gradient Langevin Algorithm
for posterior sampling while preserving its restoration properties.


