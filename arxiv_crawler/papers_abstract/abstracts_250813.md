# Abstracts of Papers

## Physics
### Quantum Sensing Radiative Decays of Neutrinos and Dark Matter Particles
**Authors**: Zhongtian Dong, Doojin Kim, Kyoungchul Kong, Myeonghun Park, Miguel A. Soto Alcaraz

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09139v1](http://arxiv.org/pdf/2508.09139v1)

**Abstract**: We explore a novel strategy for detecting the radiative decay of very weakly
interacting particles by leveraging the extreme sensitivity of quantum devices,
such as superconducting transmon qubits and trapped ion systems, to faint
electromagnetic signals. By modeling the effective electric field induced by
the decay photons, we evaluate the response of quantum sensors across two
particle physics scenarios: the cosmic neutrino background and two-component
dark matter. We assess the discovery potential of these devices and outline the
parameter space accessible under current experimental capabilities. Our
analysis demonstrates that quantum sensors can probe radiative decays of dark
matter candidates using existing technology, while probing neutrino magnetic
moments beyond current limits will require scalable quantum architectures with
enhanced coherence.


### Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer
**Authors**: Zixin Yin, Xili Dai, Ling-Hao Chen, Deyu Zhou, Jianan Wang, Duomin Wang, Gang Yu, Lionel M. Ni, Heung-Yeung Shum

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09131v1](http://arxiv.org/pdf/2508.09131v1)

**Abstract**: Text-guided color editing in images and videos is a fundamental yet unsolved
problem, requiring fine-grained manipulation of color attributes, including
albedo, light source color, and ambient lighting, while preserving physical
consistency in geometry, material properties, and light-matter interactions.
Existing training-free methods offer broad applicability across editing tasks
but struggle with precise color control and often introduce visual
inconsistency in both edited and non-edited regions. In this work, we present
ColorCtrl, a training-free color editing method that leverages the attention
mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By
disentangling structure and color through targeted manipulation of attention
maps and value tokens, our method enables accurate and consistent color
editing, along with word-level control of attribute intensity. Our method
modifies only the intended regions specified by the prompt, leaving unrelated
areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate
that ColorCtrl outperforms existing training-free approaches and achieves
state-of-the-art performances in both edit quality and consistency.
Furthermore, our method surpasses strong commercial models such as FLUX.1
Kontext Max and GPT-4o Image Generation in terms of consistency. When extended
to video models like CogVideoX, our approach exhibits greater advantages,
particularly in maintaining temporal coherence and editing stability. Finally,
our method also generalizes to instruction-based editing diffusion models such
as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.


### Constrained free energy minimization for the design of thermal states and stabilizer thermodynamic systems
**Authors**: Michele Minervini, Madison Chin, Jacob Kupperman, Nana Liu, Ivy Luo, Meghan Ly, Soorya Rethinasamy, Kathie Wang, Mark M. Wilde

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09103v1](http://arxiv.org/pdf/2508.09103v1)

**Abstract**: A quantum thermodynamic system is described by a Hamiltonian and a list of
conserved, non-commuting charges, and a fundamental goal is to determine the
minimum energy of the system subject to constraints on the charges. Recently,
[Liu et al., arXiv:2505.04514] proposed first- and second-order classical and
hybrid quantum-classical algorithms for solving a dual chemical potential
maximization problem, and they proved that these algorithms converge to global
optima by means of gradient-ascent approaches. In this paper, we benchmark
these algorithms on several problems of interest in thermodynamics, including
one- and two-dimensional quantum Heisenberg models with nearest and
next-to-nearest neighbor interactions and with the charges set to the total
$x$, $y$, and $z$ magnetizations. We also offer an alternative compelling
interpretation of these algorithms as methods for designing ground and thermal
states of controllable Hamiltonians, with potential applications in molecular
and material design. Furthermore, we introduce stabilizer thermodynamic systems
as thermodynamic systems based on stabilizer codes, with the Hamiltonian
constructed from a given code's stabilizer operators and the charges
constructed from the code's logical operators. We benchmark the aforementioned
algorithms on several examples of stabilizer thermodynamic systems, including
those constructed from the one-to-three-qubit repetition code, the perfect
one-to-five-qubit code, and the two-to-four-qubit error-detecting code.
Finally, we observe that the aforementioned hybrid quantum-classical
algorithms, when applied to stabilizer thermodynamic systems, can serve as
alternative methods for encoding qubits into stabilizer codes at a fixed
temperature, and we provide an effective method for warm-starting these
encoding algorithms whenever a single qubit is encoded into multiple physical
qubits.


### A quantum computing approach to efficiently simulating correlated materials using impurity models and dynamical mean field theory
**Authors**: Norman Hogan, Efekan Kökcü, Thomas Steckmann, Liam P. Doak, Carlos Mejuto-Zaera, Daan Camps, Roel Van Beeumen, Wibe A. de Jong, A. F. Kemper

**Published Date**: 2025-08-07

**Updated Date**: 2025-08-12

**PDF Url**: [2508.05738v2](http://arxiv.org/pdf/2508.05738v2)

**Abstract**: The accurate theoretical description of materials with strongly correlated
electrons is a formidable challenge, at the forefront of condensed matter
physics and computational chemistry alike, and it is one of the targets for
quantum computing. Dynamical Mean Field Theory (DMFT) is a successful approach
that predicts behaviors of such systems by incorporating some correlated
behavior, but it is limited by the need to calculate the Green's function for
the impurity model. This work proposes a framework for DMFT calculations on
quantum computers, focusing on near-term applications. It leverages the
structure of the impurity problem, combining a low-rank Gaussian subspace
representation of the ground state and a compressed, short-depth quantum
circuit that joins the Gaussian state preparation with the time evolution to
compute the necessary Green's functions. We demonstrate the convergence of the
DMFT algorithm using the Gaussian subspace in a noise-free setting, and show
the hardware viability of the circuit compression by extracting the impurity
Green's function on IBM quantum processors for a single impurity coupled to
three bath orbitals (8 physical qubits and 1 ancilla). We discuss the potential
paths forward towards realizing this use case of quantum computing in materials
science.


### Simulating single-photon experiments with a quantum computer
**Authors**: Priyasheel Prasad, Marco Russo, Bartolomeo Montrucchio

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09095v1](http://arxiv.org/pdf/2508.09095v1)

**Abstract**: In this work, we simulate the behavior of photons in a laboratory experiment
using a quantum computer and examine how the simulation results compare with
the theoretical predictions. The experiment involves both protective and
non-protective measurements. While the latter involves complete wavefunction
collapse, the former combines weak interactions with a protective mechanism
thereby preserving the photon wave function coherence until its final
detection. The simulation gives insights as to how efficient quantum computers
can be in simulating actual physical systems as the amount of computation
increases.


### Anisotropic exciton-polaritons reveal non-Hermitian topology in van der Waals materials
**Authors**: Devarshi Chakrabarty, Avijit Dhara, Pritam Das, Kritika Ghosh, Ayan Roy Chaudhuri, Sajal Dhara

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09083v1](http://arxiv.org/pdf/2508.09083v1)

**Abstract**: Topological band theory has expanded into various domains in applied physics,
offering significant potential for future technologies. Recent developments
indicate that unique bulk band topology perceived for electrons can be realized
in a system of light-matter quasiparticles with reduced crystal symmetry
utilizing tunable light-matter interaction. In this work we realize
topologically non-trivial energy band dispersion of exciton-polaritons confined
in two-dimensional anisotropic materials inside an optical microcavity, and
show the emergence of exceptional points (EPs) due to non-Hermitian topology
arising from excitonic dipole oscillators with finite quasiparticle lifetime.
Fourier-plane imaging reveals two pairs of EPs connected by bulk Fermi arcs for
each of the transverse electric and magnetic polarized modes. An anisotropic
Lorentz oscillator model captures the exact band dispersion observed in our
experiment in two-dimensional momentum space. Our findings establish
anisotropic two-dimensional materials as a platform for exploring non-Hermitian
topological physics, with implications for polarization-controlled optical
technologies.


### Weak measurement in strong laser field physics
**Authors**: Philipp Stammer, Javier Rivera-Dean, Marcelo F. Ciappina, Maciej Lewenstein

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09048v1](http://arxiv.org/pdf/2508.09048v1)

**Abstract**: The advantage of attosecond measurements is the possibility of time-resolving
ultrafast quantum phenomena of electron dynamics. Many such measurements are of
interferometric nature, and therefore give access to the phase. Likewise, weak
measurements are intrinsically interferometric and specifically take advantage
of interfering probability amplitudes, therefore encoding the phase information
of the process. In this work, we show that attosecond interferometry
experiments can be seen as a weak measurement, which unveils how this notion is
connected to strong field physics and attosecond science. In particular, we
show how the electron trajectory picks up a new phase, which occurs due to the
weak measurement of the process. This phase can show significant contributions
in the presence of spectral features of the measured system. Furthermore,
extending this approach to include non-classical driving fields shows that the
generated harmonics exhibit non-trivial features in their quantum state and
photon statistics. This opens the path towards investigations of attosecond
quantum interferometry experiments.


### Finite-dimensional approximations of generalized squeezing
**Authors**: Sahel Ashhab, Felix Fischer, Davide Lonigro, Daniel Braak, Daniel Burgarth

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09041v1](http://arxiv.org/pdf/2508.09041v1)

**Abstract**: We show unexpected behaviour in simulations of generalized squeezing
performed with finite-dimensional truncations of the Fock space: even for
extremely large dimension of the state space, the results depend on whether the
truncation dimension is even or odd. This situation raises the question whether
the simulation results are physically meaningful. We demonstrate that, in fact,
the two truncation schemes correspond to two well-defined, distinct unitary
evolutions whose generators are defined on different subsets of the
infinite-dimensional Fock space. This is a consequence of the fact that the
generalized squeezing Hamiltonian is not self-adjoint on states with finite
excitations, but possesses multiple self-adjoint extensions. Furthermore, we
present results on the spectrum of the squeezing operators corresponding to
even and odd truncation size that elucidate the properties of the two different
self-adjoint extensions corresponding to the even and odd truncation scheme. To
make the squeezing operator applicable to a physical system, we must regularize
it by other terms that depend on the specifics of the experimental
implementation. We show that the addition of a Kerr interaction term in the
Hamiltonian leads to uniquely converging simulations, with no dependence on the
parity of the truncation size, and demonstrate that the Kerr term indeed
renders the Hamiltonian self-adjoint and thus physically interpretable.


### Characterization of the optical response from variant InGaN nanowires emitting within the green spectral gap
**Authors**: Mohsen Esmaeilzadeh, Pablo Tieben, Soumyadip Chatterjee, Apurba Laha, Andreas W. Schel

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.08977v1](http://arxiv.org/pdf/2508.08977v1)

**Abstract**: This study provides a comprehensive physical and optical investigation of
InGaN nanowires (NWs) designed to address the challenges posed by the green gap
region. We conduct a detailed analysis of the morphology, structure, and
optical characteristics of the NWs using characterization techniques such as
scanning electron microscopy, cathodoluminescence spectroscopy, and confocal
scanning microscopy. Notably, increasing the indium concentration causes a
redshift in emission and alters the luminescence properties across different
segments of NWs.
  Our findings provide valuable insight into the correlation between indium
compositional nonuniformity and the optical emission properties of NWs. These
insights contribute to optimizing the growth condition, color accuracy, and
enhancing optical efficiency of NWs, highlighting their potential for next
generation high-performance LEDs and optoelectronics devices.


### Virtual thermodynamic potential and black hole criticality
**Authors**: Dumitru Astefanesei, Gonzalo Casanova, Raul Rojas

**Published Date**: 2025-07-24

**Updated Date**: 2025-08-12

**PDF Url**: [2507.18719v2](http://arxiv.org/pdf/2507.18719v2)

**Abstract**: We propose a new way to relate the black hole thermodynamics and geometry by
generalizing the Euclidean formalism to include "virtual geometries", which do
not necessarily satisfy Einstein equations. This provides a physically well
motivated route to study black hole criticality and obtain the Landau Ginzburg
potential. We compute the "virtual thermodynamic potential" and show that it
satisfies a modified quantum statistical relation that is compatible with the
first law of black hole thermodynamics supplemented with an extra term,
interpreted as virtual work in previous literature. The novelty is that, within
our formalism, we can explicitly compute this term as the first derivative of
the virtual thermodynamic potential with respect to the horizon radius that is
considered as the order parameter. Imposing the physical condition that the
first derivative vanishes is at the basis of the matching between the first law
of black hole thermodynamics and (one of the) Einstein equations evaluated at
the horizon. Interestingly, imposing the physical conditions that the second
and third derivatives vanish, we can concretely study the criticality and
existence of swallow tails. As a specific example, we apply this formalism to
an exact four dimensional asymptotically flat hairy black hole, namely the
generalized Kaluza Klein (KK) black hole when the dilaton potential is
included, and show that it is thermodynamically stable and has a non-trivial
critical behaviour corresponding to an inverted swallowtail.


## Diffusion
### Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models
**Authors**: Wen Wang, Bozhen Fang, Chenchen Jing, Yongliang Shen, Yangyi Shen, Qiuyu Wang, Hao Ouyang, Hao Chen, Chunhua Shen

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.09138v1](http://arxiv.org/pdf/2508.09138v1)

**Abstract**: Diffusion large language models (dLLMs) generate text through iterative
denoising, yet current decoding strategies discard rich intermediate
predictions in favor of the final output. Our work here reveals a critical
phenomenon, temporal oscillation, where correct answers often emerge in the
middle process, but are overwritten in later denoising steps. To address this
issue, we introduce two complementary methods that exploit temporal
consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time
decoding strategy that aggregates predictions across denoising steps to select
the most consistent output; and 2) a post-training method termed Temporal
Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a
measure of semantic stability across intermediate predictions, as a reward
signal to encourage stable generations. Empirical results across multiple
benchmarks demonstrate the effectiveness of our approach. Using the negative
TSE reward alone, we observe a remarkable average improvement of 24.7% on the
Countdown dataset over an existing dLLM. Combined with the accuracy reward, we
achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and
25.3% on Countdown, respectively. Our findings underscore the untapped
potential of temporal dynamics in dLLMs and offer two simple yet effective
tools to harness them.


### TIDE : Temporal-Aware Sparse Autoencoders for Interpretable Diffusion Transformers in Image Generation
**Authors**: Victor Shea-Jay Huang, Le Zhuo, Yi Xin, Zhaokai Wang, Fu-Yun Wang, Yuchi Wang, Renrui Zhang, Peng Gao, Hongsheng Li

**Published Date**: 2025-03-10

**Updated Date**: 2025-08-12

**PDF Url**: [2503.07050v2](http://arxiv.org/pdf/2503.07050v2)

**Abstract**: Diffusion Transformers (DiTs) are a powerful yet underexplored class of
generative models compared to U-Net-based diffusion architectures. We propose
TIDE-Temporal-aware sparse autoencoders for Interpretable Diffusion
transformErs-a framework designed to extract sparse, interpretable activation
features across timesteps in DiTs. TIDE effectively captures temporally-varying
representations and reveals that DiTs naturally learn hierarchical semantics
(e.g., 3D structure, object class, and fine-grained concepts) during
large-scale pretraining. Experiments show that TIDE enhances interpretability
and controllability while maintaining reasonable generation quality, enabling
applications such as safe image editing and style transfer.


### Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change
**Authors**: Ziyi Guo, Yan Wang

**Published Date**: 2025-08-12

**Updated Date**: 2025-08-12

**PDF Url**: [2508.08976v1](http://arxiv.org/pdf/2508.08976v1)

**Abstract**: Natural disasters such as hurricanes and wildfires increasingly introduce
unusual disturbance on economic activities, which are especially likely to
reshape commercial land use pattern given their sensitive to customer
visitation. However, current modeling approaches are limited in capturing such
complex interplay between human activities and commercial land use change under
and following disturbances. Such interactions have been more effectively
captured in current resilient urban planning theories. This study designs and
calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for
Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict
both the yearly decline and expansion of commercial land use at census block
level under cumulative impact of disasters on human activities over two years.
Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal
attention mechanisms with three theory-informed modules. Resilience theory
guides a disaster-aware temporal attention module that captures visitation
dynamics. Spatial economic theory informs a multi-relational spatial attention
module for inter-block representation. Diffusion theory contributes a
regularization term that constrains land use transitions. The model performs
significantly better than non-theoretical baselines in predicting commercial
land use change under the scenario of recurrent hurricanes, with around 19%
improvement in F1 score (0.8763). The effectiveness of the theory-guided
modules was further validated through ablation studies. The research
demonstrates that embedding urban theory into commercial land use modeling
models may substantially enhance the capacity to capture its gains and losses.
These advances in commercial land use modeling contribute to land use research
that accounts for cumulative impacts of recurrent disasters and shifts in
economic activity patterns.


### 3DFacePolicy: Audio-Driven 3D Facial Animation Based on Action Control
**Authors**: Xuanmeng Sha, Liyun Zhang, Tomohiro Mashita, Naoya Chiba, Yuki Uranishi

**Published Date**: 2024-09-17

**Updated Date**: 2025-08-12

**PDF Url**: [2409.10848v2](http://arxiv.org/pdf/2409.10848v2)

**Abstract**: Audio-driven 3D facial animation has achieved significant progress in both
research and applications. While recent baselines struggle to generate natural
and continuous facial movements due to their frame-by-frame vertex generation
approach, we propose 3DFacePolicy, a pioneer work that introduces a novel
definition of vertex trajectory changes across consecutive frames through the
concept of "action". By predicting action sequences for each vertex that encode
frame-to-frame movements, we reformulate vertex generation approach into an
action-based control paradigm. Specifically, we leverage a robotic control
mechanism, diffusion policy, to predict action sequences conditioned on both
audio and vertex states. Extensive experiments on VOCASET and BIWI datasets
demonstrate that our approach significantly outperforms state-of-the-art
methods and is particularly expert in dynamic, expressive and naturally smooth
facial animations.


### Cut2Next: Generating Next Shot via In-Context Tuning
**Authors**: Jingwen He, Hongbo Liu, Jiajun Li, Ziqi Huang, Yu Qiao, Wanli Ouyang, Ziwei Liu

**Published Date**: 2025-08-11

**Updated Date**: 2025-08-12

**PDF Url**: [2508.08244v2](http://arxiv.org/pdf/2508.08244v2)

**Abstract**: Effective multi-shot generation demands purposeful, film-like transitions and
strict cinematic continuity. Current methods, however, often prioritize basic
visual consistency, neglecting crucial editing patterns (e.g., shot/reverse
shot, cutaways) that drive narrative flow for compelling storytelling. This
yields outputs that may be visually coherent but lack narrative sophistication
and true cinematic integrity. To bridge this, we introduce Next Shot Generation
(NSG): synthesizing a subsequent, high-quality shot that critically conforms to
professional editing patterns while upholding rigorous cinematic continuity.
Our framework, Cut2Next, leverages a Diffusion Transformer (DiT). It employs
in-context tuning guided by a novel Hierarchical Multi-Prompting strategy. This
strategy uses Relational Prompts to define overall context and inter-shot
editing styles. Individual Prompts then specify per-shot content and
cinematographic attributes. Together, these guide Cut2Next to generate
cinematically appropriate next shots. Architectural innovations, Context-Aware
Condition Injection (CACI) and Hierarchical Attention Mask (HAM), further
integrate these diverse signals without introducing new parameters. We
construct RawCuts (large-scale) and CuratedCuts (refined) datasets, both with
hierarchical prompts, and introduce CutBench for evaluation. Experiments show
Cut2Next excels in visual consistency and text fidelity. Crucially, user
studies reveal a strong preference for Cut2Next, particularly for its adherence
to intended editing patterns and overall cinematic continuity, validating its
ability to generate high-quality, narratively expressive, and cinematically
coherent subsequent shots.


## Quantitative Finance
### Technical Report: Full-Stack Fine-Tuning for the Q Programming Language
**Authors**: Brendan R. Hogan, Will Brown, Adel Boyarsky, Anderson Schneider, Yuriy Nevmyvaka

**Published Date**: 2025-08-09

**Updated Date**: 2025-08-12

**PDF Url**: [2508.06813v2](http://arxiv.org/pdf/2508.06813v2)

**Abstract**: Even though large language models are becoming increasingly capable, it is
still unreasonable to expect them to excel at tasks that are under-represented
on the Internet. Leveraging LLMs for specialized applications, particularly in
niche programming languages and private domains, remains challenging and
largely unsolved. In this work, we address this gap by presenting a
comprehensive, open-source approach for adapting LLMs to the Q programming
language, a popular tool in quantitative finance that is much less present on
the Internet compared to Python, C, Java, and other ``mainstream" languages and
is therefore not a strong suit of general-purpose AI models. We introduce a new
Leetcode style evaluation dataset for Q, benchmark major frontier models on the
dataset, then do pretraining, supervised fine tuning, and reinforcement
learning to train a suite of reasoning and non-reasoning models based on the
Qwen-2.5 series, spanning five parameter sizes (1.5B, 3B, 7B, 14B, 32B). Our
best model achieves a pass@1 accuracy of 59 percent on our Q benchmark,
surpassing the best-performing frontier model, Claude Opus-4 by 29.5 percent.
Additionally, all models, even our 1.5B model, outperform GPT-4.1 on this task.
In addition to releasing models, code, and data, we provide a detailed
blueprint for dataset construction, model pretraining, supervised fine-tuning,
and reinforcement learning. Our methodology is broadly applicable, and we
discuss how these techniques can be extended to other tasks, including those
where evaluation may rely on soft or subjective signals.


### Chimera: Harnessing Multi-Agent LLMs for Automatic Insider Threat Simulation
**Authors**: Jiongchi Yu, Xiaofei Xie, Qiang Hu, Yuhan Ma, Ziming Zhao

**Published Date**: 2025-08-11

**Updated Date**: 2025-08-12

**PDF Url**: [2508.07745v2](http://arxiv.org/pdf/2508.07745v2)

**Abstract**: Insider threats, which can lead to severe losses, remain a major security
concern. While machine learning-based insider threat detection (ITD) methods
have shown promising results, their progress is hindered by the scarcity of
high-quality data. Enterprise data is sensitive and rarely accessible, while
publicly available datasets, when limited in scale due to cost, lack sufficient
real-world coverage; and when purely synthetic, they fail to capture rich
semantics and realistic user behavior. To address this, we propose Chimera, the
first large language model (LLM)-based multi-agent framework that automatically
simulates both benign and malicious insider activities and collects diverse
logs across diverse enterprise environments. Chimera models each employee with
agents that have role-specific behavior and integrates modules for group
meetings, pairwise interactions, and autonomous scheduling, capturing realistic
organizational dynamics. It incorporates 15 types of insider attacks (e.g., IP
theft, system sabotage) and has been deployed to simulate activities in three
sensitive domains: technology company, finance corporation, and medical
institution, producing a new dataset, ChimeraLog. We assess ChimeraLog via
human studies and quantitative analysis, confirming its diversity, realism, and
presence of explainable threat patterns. Evaluations of existing ITD methods
show an average F1-score of 0.83, which is significantly lower than 0.99 on the
CERT dataset, demonstrating ChimeraLog's higher difficulty and utility for
advancing ITD research.


### Free Lunches with Vanishing Risks Most Likely Exist
**Authors**: Eckhard Platen, Kevin Fergusson

**Published Date**: 2025-08-09

**Updated Date**: 2025-08-09

**PDF Url**: [2508.07108v1](http://arxiv.org/pdf/2508.07108v1)

**Abstract**: The hypothesis that there do not exist free lunches with vanishing risk
(FLVRs) in the real market underpins the popular risk-neutral pricing and
hedging methodology in quantitative finance. The paper documents the fact that
this hypothesis can be safely rejected. It performs extremely accurately the
hedging of an extreme-maturity zero-coupon bond (ZCB). This hedge is part of a
portfolio that starts with zero initial wealth and invests dynamically in a
total return stock market index and the savings account to generate at the
maturity date of the extreme-maturity ZCB a strictly positive amount with
strictly positive probability, which represents an FLVR. The fact that FLVRs
naturally exist in the real market can be accommodated theoretically under the
benchmark approach.


