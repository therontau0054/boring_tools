{
    "Physics": [
        {
            "title": "LiDAR-RT: Gaussian-based Ray Tracing for Dynamic LiDAR Re-simulation",
            "authors": "Chenxu Zhou, Lvchang Fu, Sida Peng, Yunzhi Yan, Zhanhua Zhang, Yong Chen, Jiazhi Xia, Xiaowei Zhou",
            "summary": "This paper targets the challenge of real-time LiDAR re-simulation in dynamic\ndriving scenarios. Recent approaches utilize neural radiance fields combined\nwith the physical modeling of LiDAR sensors to achieve high-fidelity\nre-simulation results. Unfortunately, these methods face limitations due to\nhigh computational demands in large-scale scenes and cannot perform real-time\nLiDAR rendering. To overcome these constraints, we propose LiDAR-RT, a novel\nframework that supports real-time, physically accurate LiDAR re-simulation for\ndriving scenes. Our primary contribution is the development of an efficient and\neffective rendering pipeline, which integrates Gaussian primitives and\nhardware-accelerated ray tracing technology. Specifically, we model the\nphysical properties of LiDAR sensors using Gaussian primitives with learnable\nparameters and incorporate scene graphs to handle scene dynamics. Building upon\nthis scene representation, our framework first constructs a bounding volume\nhierarchy (BVH), then casts rays for each pixel and generates novel LiDAR views\nthrough a differentiable rendering algorithm. Importantly, our framework\nsupports realistic rendering with flexible scene editing operations and various\nsensor configurations. Extensive experiments across multiple public benchmarks\ndemonstrate that our method outperforms state-of-the-art methods in terms of\nrendering quality and efficiency. Our project page is at\nhttps://zju3dv.github.io/lidar-rt.",
            "pdf_url": "http://arxiv.org/pdf/2412.15199v1",
            "published": "2024-12-19 18:58:36+00:00",
            "updated": "2024-12-19 18:58:36+00:00"
        },
        {
            "title": "Flavor at FASER: Discovering Light Scalars Beyond Minimal Flavor Violation",
            "authors": "Reuven Balkin, Noam Burger, Jonathan L. Feng, Yael Shadmi",
            "summary": "We study a simple class of flavored scalar models, in which the couplings of\na new light scalar to standard-model fermions are controlled by the flavor\nsymmetry responsible for fermion masses and mixings. The scalar couplings are\nthen aligned with the Yukawa matrices, with small but nonzero flavor-violating\nentries. $D$-meson decays are an important source of scalar production in these\nmodels, in contrast to models assuming minimal flavor violation, in which $B$\nand $K$ decays dominate. We show that FASER2 can probe large portions of the\nparameter space of the models, with comparable numbers of scalars from $B$ and\n$D$ decays in some regions. If discovered, these particles will not only\nprovide evidence of new physics, but they may also shed new light on the\nstandard model flavor puzzle. Finally, the richness of theoretical models\nunderscores the importance of model-independent interpretations. We therefore\nanalyze the sensitivity of FASER and other experimental searches in terms of\nphysical parameters:~(i) the branching fractions of heavy mesons to the scalar,\nand (ii) $\\tau/m$, where $\\tau$ and $m$ are the scalar's lifetime and mass,\nrespectively. The results are largely independent of the new particle's spin\nand can be used to extract constraints on a wide variety of models.",
            "pdf_url": "http://arxiv.org/pdf/2412.15197v1",
            "published": "2024-12-19 18:58:34+00:00",
            "updated": "2024-12-19 18:58:34+00:00"
        },
        {
            "title": "Capturing the Page Curve and Entanglement Dynamics of Black Holes in Quantum Computers",
            "authors": "Talal Ahmed Chowdhury, Kwangmin Yu, Muhammad Asaduzzaman, Raza Sabbir Sufian",
            "summary": "Understanding the Page curve and resolving the black hole information puzzle\nin terms of the entanglement dynamics of black holes has been a key question in\nfundamental physics. In principle, the current quantum computing can provide\ninsights into the entanglement dynamics of black holes within some simplified\nmodels. In this regard, we utilize quantum computers to investigate the entropy\nof Hawking radiation using the qubit transport model, a toy qubit model of\nblack hole evaporation. Specifically, we implement the quantum simulation of\nthe scrambling dynamics in black holes using an efficient random unitary\ncircuit. Furthermore, we employ the swap-based many-body interference protocol\nfor the first time and the randomized measurement protocol to measure the\nentanglement entropy of Hawking radiation qubits in IBM's superconducting\nquantum computers. Our findings indicate that while both entanglement entropy\nmeasurement protocols accurately estimate the R\\'enyi entropy in numerical\nsimulation, the randomized measurement protocol has a particular advantage over\nthe swap-based many-body interference protocol in IBM's superconducting quantum\ncomputers. Finally, by incorporating quantum error mitigation techniques, we\nestablish that the current quantum computers are robust tools for measuring the\nentanglement entropy of complex quantum systems and can probe black hole\ndynamics within simplified toy qubit models.",
            "pdf_url": "http://arxiv.org/pdf/2412.15180v1",
            "published": "2024-12-19 18:53:05+00:00",
            "updated": "2024-12-19 18:53:05+00:00"
        },
        {
            "title": "Experimental Demonstration of Logical Magic State Distillation",
            "authors": "Pedro Sales Rodriguez, John M. Robinson, Paul Niklas Jepsen, Zhiyang He, Casey Duckering, Chen Zhao, Kai-Hsin Wu, Joseph Campo, Kevin Bagnall, Minho Kwon, Thomas Karolyshyn, Phillip Weinberg, Madelyn Cain, Simon J. Evered, Alexandra A. Geim, Marcin Kalinowski, Sophie H. Li, Tom Manovitz, Jesse Amato-Grill, James I. Basham, Liane Bernstein, Boris Braverman, Alexei Bylinskii, Adam Choukri, Robert DeAngelo, Fang Fang, Connor Fieweger, Paige Frederick, David Haines, Majd Hamdan, Julian Hammett, Ning Hsu, Ming-Guang Hu, Florian Huber, Ningyuan Jia, Dhruv Kedar, Milan Kornja\u010da, Fangli Liu, John Long, Jonathan Lopatin, Pedro L. S. Lopes, Xiu-Zhe Luo, Tommaso Macr\u00ec, Ognjen Markovi\u0107, Luis A. Mart\u00ednez-Mart\u00ednez, Xianmei Meng, Stefan Ostermann, Evgeny Ostroumov, David Paquette, Zexuan Qiang, Vadim Shofman, Anshuman Singh, Manuj Singh, Nandan Sinha, Henry Thoreen, Noel Wan, Yiping Wang, Daniel Waxman-Lenz, Tak Wong, Jonathan Wurtz, Andrii Zhdanov, Laurent Zheng, Markus Greiner, Alexander Keesling, Nathan Gemelke, Vladan Vuleti\u0107, Takuya Kitagawa, Sheng-Tao Wang, Dolev Bluvstein, Mikhail D. Lukin, Alexander Lukin, Hengyun Zhou, Sergio H. Cant\u00fa",
            "summary": "Realizing universal fault-tolerant quantum computation is a key goal in\nquantum information science. By encoding quantum information into logical\nqubits utilizing quantum error correcting codes, physical errors can be\ndetected and corrected, enabling substantial reduction in logical error rates.\nHowever, the set of logical operations that can be easily implemented on such\nencoded qubits is often constrained, necessitating the use of special resource\nstates known as 'magic states' to implement universal, classically hard\ncircuits. A key method to prepare high-fidelity magic states is to perform\n'distillation', creating them from multiple lower fidelity inputs. Here we\npresent the experimental realization of magic state distillation with logical\nqubits on a neutral-atom quantum computer. Our approach makes use of a\ndynamically reconfigurable architecture to encode and perform quantum\noperations on many logical qubits in parallel. We demonstrate the distillation\nof magic states encoded in d=3 and d=5 color codes, observing improvements of\nthe logical fidelity of the output magic states compared to the input logical\nmagic states. These experiments demonstrate a key building block of universal\nfault-tolerant quantum computation, and represent an important step towards\nlarge-scale logical quantum processors.",
            "pdf_url": "http://arxiv.org/pdf/2412.15165v1",
            "published": "2024-12-19 18:38:46+00:00",
            "updated": "2024-12-19 18:38:46+00:00"
        },
        {
            "title": "Primordial Gravitational Wave Probes of Non-Standard Thermal Histories",
            "authors": "Annet Konings, Mariia Marinichenko, Oleksii Mikulenko, Subodh P. Patil",
            "summary": "Primordial gravitational waves propagate almost unimpeded from the moment\nthey are generated to the present epoch. Nevertheless, they are subject to\nconvolution with a non-trivial transfer function. Within the standard thermal\nhistory, shifts in the temperature-redshift relation combine with damping\neffects by free streaming neutrinos to non-trivially process different\nwavelengths during radiation domination, with subsequently negligible effects\nat later times. Presuming a nearly scale invariant primordial spectrum, one\nobtains a characteristic late time spectrum, deviations from which would\nindicate departures from the standard thermal history. Given the paucity of\nprobes of the early universe physics before nucleosynthesis, it is useful to\nclassify how deviations from the standard thermal history of the early universe\ncan be constrained from observations of the late time stochastic background.\nThe late time spectral density has a plateau at high frequencies that can in\nprinciple be significantly enhanced or suppressed relative to the standard\nthermal history depending on the equation of state of the epoch intervening\nreheating and the terminal phase of radiation domination, imprinting additional\nfeatures from bursts of entropy production, and additional damping at\nintermediate scales via anisotropic stress production. In this paper, we survey\nphenomenologically motivated scenarios of early matter domination, kination,\nand late time decaying particles as representative non-standard thermal\nhistories, elaborate on their late time stochastic background, and discuss\nconstraints on different model scenarios.",
            "pdf_url": "http://arxiv.org/pdf/2412.15144v1",
            "published": "2024-12-19 18:26:40+00:00",
            "updated": "2024-12-19 18:26:40+00:00"
        },
        {
            "title": "On the perturbed Friedmann equations in Newtonian Gauge",
            "authors": "Jaume de Haro, Emilio Elizalde, Supriya Pan",
            "summary": "Based on the Newtonian mechanics, in this article, we present a heuristic\nderivation of the Friedmann equations, providing an intuitive foundation for\nthese fundamental relations in cosmology. Additionally, using the first law of\nthermodynamics and Euler's equation, we derive a set of equations that, at\nlinear order, coincide with those obtained from the conservation of the\nstress-energy tensor in General Relativity. This approach not only highlights\nthe consistency between Newtonian and relativistic frameworks in certain limits\nbut also serves as a pedagogical bridge, offering insights into the physical\nprinciples underlying the dynamics of the universe.",
            "pdf_url": "http://arxiv.org/pdf/2412.15139v1",
            "published": "2024-12-19 18:21:56+00:00",
            "updated": "2024-12-19 18:21:56+00:00"
        },
        {
            "title": "Observation of $VVZ$ production at $\\sqrt{s}=13$ TeV with the ATLAS detector",
            "authors": "ATLAS Collaboration",
            "summary": "A search for the production of three massive vector bosons, $VVZ (V=W, Z)$,\nin proton-proton collisions at $\\sqrt{s} = 13$ TeV is performed using data with\nan integrated luminosity of $140$ fb$^{-1}$ recorded by the ATLAS detector at\nthe Large Hadron Collider. Events produced in the leptonic final states $WWZ\n\\to \\ell\\nu \\ell\\nu \\ell \\ell$ ($\\ell=e, \\mu$), $WZZ \\to \\ell\\nu \\ell\\ell\n\\ell\\ell$, $ZZZ \\to \\ell\\ell \\ell\\ell \\ell\\ell$, and the semileptonic final\nstates $WWZ \\to qq \\ell\\nu \\ell \\ell$ and $WZZ \\to \\ell\\nu qq \\ell \\ell$, are\nanalysed. The measured cross section for the $pp \\rightarrow VVZ$ process is\n$660^{+93}_{-90}(\\text{stat.})^{+88}_{-81}(\\text{syst.})$ fb, and the observed\n(expected) significance is 6.4 (4.7) standard deviations, representing the\nobservation of $VVZ$ production. In addition, the measured cross section for\nthe $pp \\rightarrow WWZ$ process is $442 \\pm 94\n(\\text{stat.})^{+60}_{-52}(\\text{syst.})$ fb, and the observed (expected)\nsignificance is 4.4 (3.6) standard deviations, representing evidence of $WWZ$\nproduction. The measured cross sections are consistent with the Standard Model\npredictions. Constraints on physics beyond the Standard Model are also derived\nin the effective field theory framework by setting limits on Wilson\ncoefficients for dimension-8 operators describing anomalous quartic gauge boson\ncouplings.",
            "pdf_url": "http://arxiv.org/pdf/2412.15123v1",
            "published": "2024-12-19 18:02:55+00:00",
            "updated": "2024-12-19 18:02:55+00:00"
        },
        {
            "title": "Exploiting sparse structures and synergy designs to advance situational awareness of electrical power grid",
            "authors": "Shimiao Li",
            "summary": "The growing threats of uncertainties, anomalies, and cyberattacks on power\ngrids are driving a critical need to advance situational awareness which allows\nsystem operators to form a complete and accurate picture of the present and\nfuture state. Simulation and estimation are foundational tools in this process.\nHowever, existing tools lack the robustness and efficiency required to achieve\nthe level of situational awareness needed for the ever-evolving threat\nlandscape. Industry-standard (steady-state) simulators are not robust to\nblackouts, often leading to non-converging or non-actionable results.\nEstimation tools lack robustness to anomalous data, returning erroneous system\nstates. Efficiency is the other major concern as nonlinearities and scalability\nissues make large systems slow to converge.\n  This thesis addresses robustness and efficiency gaps through a dual-fold\ncontribution. We first address the inherent limitations in the existing\nphysics-based and data-driven worlds; and then transcend the boundaries of\nconventional algorithmic design in the direction of a new paradigm --\nPhysics-ML Synergy -- which integrates the strengths of the two worlds. Our\napproaches are built on circuit formulation which provides a unified framework\nthat applies to both transmission and distribution. Sparse optimization acts as\nthe key enabler to make these tools intrinsically robust and immune to random\nthreats, pinpointing dominant sources of (random) blackouts and data errors.\nFurther, we explore sparsity-exploiting optimizations to develop lightweight ML\nmodels whose prediction and detection capabilities are a complement to\nphysics-based tools; and whose lightweight designs advance generalization and\nscalability. Finally, Physics-ML Synergy brings robustness and efficiency\nfurther against targeted cyberthreats, by interconnecting our physics-based\ntools with lightweight ML.",
            "pdf_url": "http://arxiv.org/pdf/2412.15105v1",
            "published": "2024-12-19 17:51:43+00:00",
            "updated": "2024-12-19 17:51:43+00:00"
        },
        {
            "title": "Expected Tracking Performance of the ATLAS Inner Tracker at the High-Luminosity LHC",
            "authors": "ATLAS Collaboration",
            "summary": "The high-luminosity phase of LHC operations (HL-LHC), will feature a large\nincrease in simultaneous proton-proton interactions per bunch crossing up to\n200, compared with a typical leveling target of 64 in Run 3. Such an increase\nwill create a very challenging environment in which to perform charged particle\ntrajectory reconstruction, a task crucial for the success of the ATLAS physics\nprogram, and will exceed the capabilities of the current ATLAS Inner Detector\n(ID). A new all-silicon Inner Tracker (ITk) will replace the current ID in time\nfor the start of the HL-LHC. To ensure successful use of the ITk capabilities\nin Run 4 and beyond, the ATLAS tracking software has been successfully adapted\nto achieve state-of-the-art track reconstruction in challenging high-luminosity\nconditions with the ITk detector. This paper presents the expected tracking\nperformance of the ATLAS ITk based on the latest available developments since\nthe ITk technical design reports.",
            "pdf_url": "http://arxiv.org/pdf/2412.15090v1",
            "published": "2024-12-19 17:38:04+00:00",
            "updated": "2024-12-19 17:38:04+00:00"
        },
        {
            "title": "DroughtSet: Understanding Drought Through Spatial-Temporal Learning",
            "authors": "Xuwei Tan, Qian Zhao, Yanlan Liu, Xueru Zhang",
            "summary": "Drought is one of the most destructive and expensive natural disasters,\nseverely impacting natural resources and risks by depleting water resources and\ndiminishing agricultural yields. Under climate change, accurately predicting\ndrought is critical for mitigating drought-induced risks. However, the\nintricate interplay among the physical and biological drivers that regulate\ndroughts limits the predictability and understanding of drought, particularly\nat a subseasonal to seasonal (S2S) time scale. While deep learning has been\ndemonstrated with potential in addressing climate forecasting challenges, its\napplication to drought prediction has received relatively less attention. In\nthis work, we propose a new dataset, DroughtSet, which integrates relevant\npredictive features and three drought indices from multiple remote sensing and\nreanalysis datasets across the contiguous United States (CONUS). DroughtSet\nspecifically provides the machine learning community with a new real-world\ndataset to benchmark drought prediction models and more generally, time-series\nforecasting methods. Furthermore, we propose a spatial-temporal model SPDrought\nto predict and interpret S2S droughts. Our model learns from the spatial and\ntemporal information of physical and biological features to predict three types\nof droughts simultaneously. Multiple strategies are employed to quantify the\nimportance of physical and biological features for drought prediction. Our\nresults provide insights for researchers to better understand the\npredictability and sensitivity of drought to biological and physical\nconditions. We aim to contribute to the climate field by proposing a new tool\nto predict and understand the occurrence of droughts and provide the AI\ncommunity with a new benchmark to study deep learning applications in climate\nscience.",
            "pdf_url": "http://arxiv.org/pdf/2412.15075v1",
            "published": "2024-12-19 17:24:15+00:00",
            "updated": "2024-12-19 17:24:15+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "DI-PCG: Diffusion-based Efficient Inverse Procedural Content Generation for High-quality 3D Asset Creation",
            "authors": "Wang Zhao, Yan-Pei Cao, Jiale Xu, Yuejiang Dong, Ying Shan",
            "summary": "Procedural Content Generation (PCG) is powerful in creating high-quality 3D\ncontents, yet controlling it to produce desired shapes is difficult and often\nrequires extensive parameter tuning. Inverse Procedural Content Generation aims\nto automatically find the best parameters under the input condition. However,\nexisting sampling-based and neural network-based methods still suffer from\nnumerous sample iterations or limited controllability. In this work, we present\nDI-PCG, a novel and efficient method for Inverse PCG from general image\nconditions. At its core is a lightweight diffusion transformer model, where PCG\nparameters are directly treated as the denoising target and the observed images\nas conditions to control parameter generation. DI-PCG is efficient and\neffective. With only 7.6M network parameters and 30 GPU hours to train, it\ndemonstrates superior performance in recovering parameters accurately, and\ngeneralizing well to in-the-wild images. Quantitative and qualitative\nexperiment results validate the effectiveness of DI-PCG in inverse PCG and\nimage-to-3D generation tasks. DI-PCG offers a promising approach for efficient\ninverse PCG and represents a valuable exploration step towards a 3D generation\npath that models how to construct a 3D asset using parametric models.",
            "pdf_url": "http://arxiv.org/pdf/2412.15200v1",
            "published": "2024-12-19 18:58:46+00:00",
            "updated": "2024-12-19 18:58:46+00:00"
        },
        {
            "title": "AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal Audio-Video Generation",
            "authors": "Moayed Haji-Ali, Willi Menapace, Aliaksandr Siarohin, Ivan Skorokhodov, Alper Canberk, Kwot Sin Lee, Vicente Ordonez, Sergey Tulyakov",
            "summary": "We propose AV-Link, a unified framework for Video-to-Audio and Audio-to-Video\ngeneration that leverages the activations of frozen video and audio diffusion\nmodels for temporally-aligned cross-modal conditioning. The key to our\nframework is a Fusion Block that enables bidirectional information exchange\nbetween our backbone video and audio diffusion models through a\ntemporally-aligned self attention operation. Unlike prior work that uses\nfeature extractors pretrained for other tasks for the conditioning signal,\nAV-Link can directly leverage features obtained by the complementary modality\nin a single framework i.e. video features to generate audio, or audio features\nto generate video. We extensively evaluate our design choices and demonstrate\nthe ability of our method to achieve synchronized and high-quality audiovisual\ncontent, showcasing its potential for applications in immersive media\ngeneration. Project Page: snap-research.github.io/AVLink/",
            "pdf_url": "http://arxiv.org/pdf/2412.15191v1",
            "published": "2024-12-19 18:57:21+00:00",
            "updated": "2024-12-19 18:57:21+00:00"
        },
        {
            "title": "LlamaFusion: Adapting Pretrained Language Models for Multimodal Generation",
            "authors": "Weijia Shi, Xiaochuang Han, Chunting Zhou, Weixin Liang, Xi Victoria Lin, Luke Zettlemoyer, Lili Yu",
            "summary": "We present LlamaFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLlamaFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LlamaFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLlamaFusion improves image understanding by 20% and image generation by 3.6%\nusing only 50% of the FLOPs while maintaining Llama-3's language capabilities.\nWe also demonstrate that this framework can adapt existing vision-language\nmodels with multimodal generation ability. Overall, this framework not only\nleverages existing computational investments in text-only LLMs but also enables\nthe parallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.",
            "pdf_url": "http://arxiv.org/pdf/2412.15188v1",
            "published": "2024-12-19 18:56:24+00:00",
            "updated": "2024-12-19 18:56:24+00:00"
        },
        {
            "title": "Tiled Diffusion",
            "authors": "Or Madar, Ohad Fried",
            "summary": "Image tiling -- the seamless connection of disparate images to create a\ncoherent visual field -- is crucial for applications such as texture creation,\nvideo game asset development, and digital art. Traditionally, tiles have been\nconstructed manually, a method that poses significant limitations in\nscalability and flexibility. Recent research has attempted to automate this\nprocess using generative models. However, current approaches primarily focus on\ntiling textures and manipulating models for single-image generation, without\ninherently supporting the creation of multiple interconnected tiles across\ndiverse domains. This paper presents Tiled Diffusion, a novel approach that\nextends the capabilities of diffusion models to accommodate the generation of\ncohesive tiling patterns across various domains of image synthesis that require\ntiling. Our method supports a wide range of tiling scenarios, from self-tiling\nto complex many-to-many connections, enabling seamless integration of multiple\nimages. Tiled Diffusion automates the tiling process, eliminating the need for\nmanual intervention and enhancing creative possibilities in various\napplications, such as seamlessly tiling of existing images, tiled texture\ncreation, and 360{\\deg} synthesis.",
            "pdf_url": "http://arxiv.org/pdf/2412.15185v1",
            "published": "2024-12-19 18:55:25+00:00",
            "updated": "2024-12-19 18:55:25+00:00"
        },
        {
            "title": "Jet: A Modern Transformer-Based Normalizing Flow",
            "authors": "Alexander Kolesnikov, Andr\u00e9 Susano Pinto, Michael Tschannen",
            "summary": "In the past, normalizing generative flows have emerged as a promising class\nof generative models for natural images. This type of model has many modeling\nadvantages: the ability to efficiently compute log-likelihood of the input\ndata, fast generation and simple overall structure. Normalizing flows remained\na topic of active research but later fell out of favor, as visual quality of\nthe samples was not competitive with other model classes, such as GANs,\nVQ-VAE-based approaches or diffusion models. In this paper we revisit the\ndesign of the coupling-based normalizing flow models by carefully ablating\nprior design choices and using computational blocks based on the Vision\nTransformer architecture, not convolutional neural networks. As a result, we\nachieve state-of-the-art quantitative and qualitative performance with a much\nsimpler architecture. While the overall visual quality is still behind the\ncurrent state-of-the-art models, we argue that strong normalizing flow models\ncan help advancing research frontier by serving as building components of more\npowerful generative models.",
            "pdf_url": "http://arxiv.org/pdf/2412.15129v1",
            "published": "2024-12-19 18:09:42+00:00",
            "updated": "2024-12-19 18:09:42+00:00"
        }
    ]
}