{
    "Physics": [
        {
            "title": "Parton distributions confront LHC Run II data: a quantitative appraisal",
            "authors": "Amedeo Chiefa, Mark N. Costantini, Juan Cruz-Martinez, Emanuele R. Nocera, Tanjona R. Rabemananjara, Juan Rojo, Tanishq Sharma, Roy Stegeman, Maria Ubiali",
            "summary": "We present a systematic comparison of theoretical predictions and various\nhigh-precision experimental measurements, specifically of differential cross\nsections performed by the LHC run II for Drell-Yan gauge boson, top-quark pair,\nsingle-inclusive jet and di-jet production, and by HERA for single-inclusive\njet and di-jet production. Theoretical predictions are computed at\nnext-to-next-to-leading order (NNLO) accuracy in perturbative Quantum\nChromodynamics. The most widely employed sets of Parton Distribution Functions\n(PDFs) are used, and PDF, strong coupling, and missing higher order\nuncertainties are taken into account. We quantitatively assess the predictive\npower of each PDF set and the contribution of the different sources of\nexperimental and theoretical uncertainty to the agreement between data and\npredictions. We show that control over all of these aspects is crucial to\nprecision physics studies, such as the determination of Standard Model\nparameters at the LHC.",
            "pdf_url": "http://arxiv.org/pdf/2501.10359v1",
            "published": "2025-01-17 18:59:50+00:00",
            "updated": "2025-01-17 18:59:50+00:00"
        },
        {
            "title": "Exploring the Standard Model and Beyond from the Evidence of CE$\u03bd$NS with Reactor Antineutrinos in CONUS+",
            "authors": "M. Alp\u00edzar-Venegas, L. J. Flores, Eduardo Peinado, E. V\u00e1zquez-J\u00e1uregui",
            "summary": "The observation of the Coherent Elastic Neutrino-Nucleus Scattering\n(CE$\\nu$NS) process using reactor antineutrinos offers a unique opportunity to\nprobe the Standard Model and explore Beyond the Standard Model scenarios. This\nstudy reports on the latest results from the CONUS+ experiment conducted at the\nLeibstadt nuclear power plant (KKL), Switzerland. The CONUS collaboration\nreports $395 \\pm 106$ events detected from reactor antineutrinos with an\nexposure of 347 kg$\\cdot$days, utilizing high-purity germanium detectors\noperated at sub-keV thresholds. A $\\chi^2$-based statistical analysis was\nperformed on these results, incorporating systematic uncertainties. This\nanalysis was used to extract the weak mixing angle, establish a limit on the\nneutrino magnetic moment, and impose constraints on neutrino non-standard\ninteractions using reactor antineutrinos. The results confirm the potential of\nCE$\\nu$NS experiments in the study of fundamental neutrino properties and\nprobing new physics.",
            "pdf_url": "http://arxiv.org/pdf/2501.10355v1",
            "published": "2025-01-17 18:55:51+00:00",
            "updated": "2025-01-17 18:55:51+00:00"
        },
        {
            "title": "Resolving discrepancies in bang-time predictions for ICF experiments on the NIF: Insights from the Build-A-Hohlraum Campaign",
            "authors": "G. F. Swadling, W. A. Farmer, H. Chen, N. Aybar, M. S. Rubery, M. B. Schneider, D. A. Liedahl, N. C. Lemos, E. Tubman, J. S. Ross, D. E. Hinkel, O. L. Landen, M. D. Rosen, S. Rogers K. Newman, D. Yanagisawa, N. Roskopf, S. Vonhof, L. Aghaian, M. Mauldin, B. L. Reichelt, J. Kunimune",
            "summary": "This study investigated discrepancies between measured and simulated x-ray\ndrive in Inertial Confinement Fusion (ICF) hohlraums at the National Ignition\nFacility (NIF). Despite advances in radiation-hydrodynamic simulations, a\nconsistent \"drive deficit\" remains. Experimentally measured ICF capsule\nbang-times are systematically 400-700 ps later than simulations predict. The\nBuild-A-Hohlraum (BAH) campaign explored potential causes for this discrepancy\nby systematically varying hohlraum features, including laser entrance hole\n(LEH) windows, capsules, and gas fills. Overall, the agreement between\nsimulated and experimental x-ray drive was found to be largely unaffected by\nthese changes. The data allows us to exclude some hypotheses put forward to\npotentially explain the discrepancy. Errors in the local thermodynamic\nequilibrium (LTE) atomic modeling, errors in the modeling of LEH closure and\nerrors due to a lack of plasma species mix physics in simulations are shown to\nbe inconsistent with our measurements. Instead, the data supports the\nhypothesis that errors in NLTE emission modeling are a significant contributor\nto the discrepancy. X-ray emission in the 2 - 4 keV range is found to be\napproximately 30% lower than in simulations. This is accompanied by higher than\npredicted electron temperatures in the gold bubble region, pointing to errors\nin non-LTE modeling. Introducing an opacity multiplier of 0.87 on energy groups\nabove 1.8 keV improves agreement with experimental data, reducing the bang-time\ndiscrepancy from 300 ps to 100 ps. These results underscore the need for\nrefined NLTE opacity models to enhance the predictive power of hohlraum\nsimulations.",
            "pdf_url": "http://arxiv.org/pdf/2501.10350v1",
            "published": "2025-01-17 18:45:51+00:00",
            "updated": "2025-01-17 18:45:51+00:00"
        },
        {
            "title": "Top observables as precise probes of the ALP",
            "authors": "Anh Vu Phan",
            "summary": "Measurements of the top quark by the ATLAS and CMS experiments go beyond\ntesting the Standard Model (SM) with high precision. Axion-like particles\n(ALPs), a potential SM extension involving new pseudoscalar particles, exhibit\nstrong interactions with heavy SM fermions. Consequently, they can\nsignificantly affect the kinematic distributions of top quarks in top-antitop\npair production. Moreover, such strong interactions can induce other ALP\ncouplings at low energies, leading to a rich phenomenology. We summarize recent\ndevelopments in probing the ALP-top coupling and use LHC data from run 2 to\nconstrain the ALP parameter space.",
            "pdf_url": "http://arxiv.org/pdf/2412.06506v2",
            "published": "2024-12-09 14:09:37+00:00",
            "updated": "2025-01-17 17:54:51+00:00"
        },
        {
            "title": "Mass and wind luminosity of young Galactic open clusters in Gaia DR2",
            "authors": "Silvia Celli, Andreas Specovius, Stefano Menchiari, Alison Mitchell, Giovanni Morlino",
            "summary": "Context. Star clusters constitute a significant part of the stellar\npopulation in our Galaxy. The feedback processes they exert on the interstellar\nmedium impact multiple physical processes from the chemical to the dynamical\nevolution of the Galaxy. In addition, young and massive stellar clusters might\nact as efficient particle accelerators and contribute to the production of\ncosmic rays. Aims. We aim at evaluating the wind luminosity driven by the young\n(< 30 Myr) Galactic open stellar clusters observed by the Gaia space mission.\nThis is crucial for determining the energy channeled into accelerated\nparticles. Methods. To do this, we developed a method relying on the number,\nmagnitude, and line-of-sight extinction of the stars observed per cluster.\nAssuming that the stellar mass function follows a Kroupa mass distribution and\naccounting for the maximum stellar mass allowed by the age and mass of the\nparent cluster, we conservatively estimated the mass and wind luminosity of 387\nlocal clusters within the second data release of Gaia. Results. We compared the\nresults of our computation with recent estimates of young cluster masses. With\nrespect to these, our sample is three times more abundant, particularly above a\nfew thousand solar masses. This is of the utmost relevance for predicting the\ngamma-ray emission resulting from the interaction of accelerated particles. The\ncluster wind luminosity distribution we obtained extends up to 3x10^38 erg/s.\nThis is a promising feature in terms of potential particle acceleration\nscenarios.",
            "pdf_url": "http://arxiv.org/pdf/2311.09089v3",
            "published": "2023-11-15 16:34:12+00:00",
            "updated": "2025-01-17 17:42:43+00:00"
        },
        {
            "title": "Elucidating the high compliance mechanism by which the urinary bladder fills under low pressures",
            "authors": "Fatemeh Azari, Anne M. Robertson, Yasutaka Tobe, Paul N. Watton, Lori A. Birder, Naoki Yoshimura, Kanako Matsuoka, Christopher Hardin, Simon Watkins",
            "summary": "The high compliance of the urinary bladder during filling is essential for\nits proper function, enabling it to accommodate significant volumetric\nincreases with minimal rise in transmural pressure. This study aimed to\nelucidate the physical mechanisms underlying this phenomenon by analyzing the\nex vivo filling process in rat from a fully voided state to complete\ndistension, without preconditioning, using three complementary imaging\nmodalities. High-resolution micro-CT at 10.8 {\\mu}m resolution was used to\ngenerate detailed 3D reconstructions of the bladder lumen, revealing a 62 fold\nincrease in bladder volume during filling. Pressure-volume studies of whole\nbladder delineated three mechanical filling regimes: an initial high-compliance\nphase, a transitional phase, and a final high-pressure phase. While prior\nstudies conjectured small mucosal rugae (450 {\\mu}m) are responsible for the\nhigh compliance phase, multiphoton microscopy (MPM) of the dome of the voided\nbladder revealed large folds an order of magnitude larger than these rugae.\nBladder imaging during the inflation process demonstrated flattening of these\nlarge scale folds is responsible for volume increases in the initial high\ncompliance phase. The 3D reconstructions of the bladder lumen in the filled and\nvoided state revealed a high voiding efficiency of 97.13%. The MPM imaging\nresults suggest the large scale folds in the dome enable this high voiding\nfraction by driving urine toward the bladder outlet. These insights are vital\nfor computational models of bladder biomechanics and understanding changes to\nbladder function due to pathological conditions such as bladder outlet\nobstruction and age-related dysfunction.",
            "pdf_url": "http://arxiv.org/pdf/2501.10312v1",
            "published": "2025-01-17 17:34:48+00:00",
            "updated": "2025-01-17 17:34:48+00:00"
        },
        {
            "title": "The Auger-Meitner Radioisotope Microscope: an instrument for characterization of Auger electron multiplicities and energy distributions",
            "authors": "Patrick R. Stollenwerk, Stephen H. Southworth, Francesco Granato, Amy Renne, Brahim Mustapha, Kevin G. Bailey, Peter Mueller, Jerry Nolen, Thomas P. O'Connor, Junqi Xie, Linda Young, Matthew R. Dietrich",
            "summary": "We describe a new instrument, the Argonne Auger Radioisotope Microscope\n(ARM), capable of characterizing the Auger electron emission of radionuclides,\nincluding candidates relevant in nuclear medicine. Our approach relies on\nevent-by-event ion-electron coincidence, time-of-flight, and spatial readout\nmeasurement to determine correlated electron multiplicity and energy\ndistributions of Auger decays. We present a proof-of-principle measurement with\nthe ARM using X-ray photoionization of stable krypton beyond the K-edge and\nidentify a bifurcation in the electron multiplicity distribution depending on\nthe emission of K-LX electrons. Extension of the ARM to the characterization of\nradioactive sources of Auger electron emissions is enabled by the combination\nof two recent developments: (1) cryogenic buffer gas beam technology to\nintroduce Auger emitters into the detection region with well-defined initial\nconditions, and (2) large-area micro-channel plate detectors with multi-hit\ndetection capabilities to simultaneously detect multiple electrons emitted in a\nsingle decay.\n  The ARM will generate new experimental data on Auger multiplicities that can\nbe used to benchmark atomic relaxation and decay models. This data will provide\ninsight into the low-energy regime of Auger electrons where intensity\ncalculations are most challenging and experimental data is limited. In\nparticular, accurate multiplicity data of the low-energy regime can be used to\ninform oncological dosimetry models, where electron energies less than 500 eV\nare known to be most effective in damaging DNA and cell membranes.",
            "pdf_url": "http://arxiv.org/pdf/2410.23103v2",
            "published": "2024-10-30 15:13:18+00:00",
            "updated": "2025-01-17 17:16:23+00:00"
        },
        {
            "title": "Matrix Product Density Operators: Renormalization Fixed Points and Boundary Theories",
            "authors": "J. I. Cirac, D. Perez-Garcia, N. Schuch, F. Verstraete",
            "summary": "We consider the tensors generating matrix product states and density\noperators in a spin chain. For pure states, we revise the renormalization\nprocedure introduced by F. Verstraete et al. in 2005 and characterize the\ntensors corresponding to the fixed points. We relate them to the states\npossessing zero correlation length, saturation of the area law, as well as to\nthose which generate ground states of local and commuting Hamiltonians. For\nmixed states, we introduce the concept of renormalization fixed points and\ncharacterize the corresponding tensors. We also relate them to concepts like\nfinite correlation length, saturation of the area law, as well as to those\nwhich generate Gibbs states of local and commuting Hamiltonians. One of the\nmain result of this work is that the resulting fixed points can be associated\nto the boundary theories of two-dimensional topological states, through the\nbulk-boundary correspondence introduced by Cirac et al. in 2011.",
            "pdf_url": "http://arxiv.org/pdf/1606.00608v4",
            "published": "2016-06-02 10:20:42+00:00",
            "updated": "2025-01-17 16:56:05+00:00"
        },
        {
            "title": "Intense Laser-Driven Phenomena In Weyl Semimetals",
            "authors": "Amar Bharti",
            "summary": "Condensed-matter provides attractive platforms to realize exotic particles,\noriginally proposed in high-energy physics. Weyl semimetal (WSM) is a material\nin which low-energy collective excitations are governed by massless Weyl\nfermions, which appear in pairs of opposite chirality and are topologically\nprotected. Thus, the discovery of topological materials such as WSM has\nheralded a new era in contemporary physics. Moreover, these materials offer\nexciting opportunities in next-generation signal processing and\noptoelectronics. This thesis explores different facets of the intense\nlaser-driven phenomena in WSM for applications in emerging lightwave-driven\nPetahertz electronics and quantum technologies.",
            "pdf_url": "http://arxiv.org/pdf/2501.10293v1",
            "published": "2025-01-17 16:37:42+00:00",
            "updated": "2025-01-17 16:37:42+00:00"
        },
        {
            "title": "A precise study of the SU(3) Yang-Mills theory across the deconfinement transition",
            "authors": "Leonardo Giusti, Mitsuaki Hirasawa, Michele Pepe, Luca Virz\u00ec",
            "summary": "We perform a detailed computation of key quantities across the first-order\ndeconfinement phase transition of the SU(3) Yang-Mills theory. Specifically, we\ncalculate the entropy density, $s(T_c)/T_c^3$, on both sides of the transition\nand determine the latent heat $h$. The calculations are carried out in the\nlattice regularization with the Wilson action, employing shifted boundary\nconditions in the temporal direction. Our simulations are performed at five\ndifferent values of the lattice spacing in order to extrapolate the results to\nthe continuum limit. The latent heat can be measured also as the discontinuity\nin the trace anomaly of the energy-momentum tensor: our result using the\nentropy density is compatible with the one obtained from the trace anomaly,\ngiving a combined estimate $h=1.175(10)$. Additionally, we determine the\ncritical temperature $T_c$ in physical units with permille accuracy, yielding\n$T_c \\sqrt{t_0} = 0.24915(29)$. These results allow to connect with precision\nthe confined and the deconfined phases and we present an improved computation\nof the Equation of State across the deconfinement transition for $T$ between 0\nand $3.4 T_c$.",
            "pdf_url": "http://arxiv.org/pdf/2501.10284v1",
            "published": "2025-01-17 16:26:47+00:00",
            "updated": "2025-01-17 16:26:47+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Moonshine: Distilling Game Content Generators into Steerable Generative Models",
            "authors": "Yuhe Nie, Michael Middleton, Tim Merino, Nidhushan Kanagaraja, Ashutosh Kumar, Zhan Zhuang, Julian Togelius",
            "summary": "Procedural Content Generation via Machine Learning (PCGML) has enhanced game\ncontent creation, yet challenges in controllability and limited training data\npersist. This study addresses these issues by distilling a constructive PCG\nalgorithm into a controllable PCGML model. We first generate a large amount of\ncontent with a constructive algorithm and label it using a Large Language Model\n(LLM). We use these synthetic labels to condition two PCGML models for\ncontent-specific generation, a diffusion model and the five-dollar model. This\nneural network distillation process ensures that the generation aligns with the\noriginal algorithm while introducing controllability through plain text. We\ndefine this text-conditioned PCGML as a Text-to-game-Map (T2M) task, offering\nan alternative to prevalent text-to-image multi-modal tasks. We compare our\ndistilled models with the baseline constructive algorithm. Our analysis of the\nvariety, accuracy, and quality of our generation demonstrates the efficacy of\ndistilling constructive methods into controllable text-conditioned PCGML\nmodels.",
            "pdf_url": "http://arxiv.org/pdf/2408.09594v2",
            "published": "2024-08-18 20:59:59+00:00",
            "updated": "2025-01-17 16:44:35+00:00"
        },
        {
            "title": "DPCL-Diff: The Temporal Knowledge Graph Reasoning Based on Graph Node Diffusion Model with Dual-Domain Periodic Contrastive Learning",
            "authors": "Yukun Cao, Lisheng Wang, Luobin Huang",
            "summary": "Temporal knowledge graph (TKG) reasoning that infers future missing facts is\nan essential and challenging task. Predicting future events typically relies on\nclosely related historical facts, yielding more accurate results for repetitive\nor periodic events. However, for future events with sparse historical\ninteractions, the effectiveness of this method, which focuses on leveraging\nhigh-frequency historical information, diminishes. Recently, the capabilities\nof diffusion models in image generation have opened new opportunities for TKG\nreasoning. Therefore, we propose a graph node diffusion model with dual-domain\nperiodic contrastive learning (DPCL-Diff). Graph node diffusion model (GNDiff)\nintroduces noise into sparsely related events to simulate new events,\ngenerating high-quality data that better conforms to the actual distribution.\nThis generative mechanism significantly enhances the model's ability to reason\nabout new events. Additionally, the dual-domain periodic contrastive learning\n(DPCL) maps periodic and non-periodic event entities to Poincar\\'e and\nEuclidean spaces, leveraging their characteristics to distinguish similar\nperiodic events effectively. Experimental results on four public datasets\ndemonstrate that DPCL-Diff significantly outperforms state-of-the-art TKG\nmodels in event prediction, demonstrating our approach's effectiveness. This\nstudy also investigates the combined effectiveness of GNDiff and DPCL in TKG\ntasks.",
            "pdf_url": "http://arxiv.org/pdf/2411.01477v2",
            "published": "2024-11-03 08:30:29+00:00",
            "updated": "2025-01-17 14:10:15+00:00"
        },
        {
            "title": "Generate E-commerce Product Background by Integrating Category Commonality and Personalized Style",
            "authors": "Haohan Wang, Wei Feng, Yaoyu Li, Zheng Zhang, Jingjing Lv, Junjie Shen, Zhangang Lin, Jingping Shao",
            "summary": "The state-of-the-art methods for e-commerce product background generation\nsuffer from the inefficiency of designing product-wise prompts when scaling up\nthe production, as well as the ineffectiveness of describing fine-grained\nstyles when customizing personalized backgrounds for some specific brands. To\naddress these obstacles, we integrate the category commonality and personalized\nstyle into diffusion models. Concretely, we propose a Category-Wise Generator\nto enable large-scale background generation with only one model for the first\ntime. A unique identifier in the prompt is assigned to each category, whose\nattention is located on the background by a mask-guided cross attention layer\nto learn the category-wise style. Furthermore, for products with specific and\nfine-grained requirements in layout, elements, etc, a Personality-Wise\nGenerator is devised to learn such personalized style directly from a reference\nimage to resolve textual ambiguities, and is trained in a self-supervised\nmanner for more efficient training data usage. To advance research in this\nfield, the first large-scale e-commerce product background generation dataset\nBG60k is constructed, which covers more than 60k product images from over 2k\ncategories. Experiments demonstrate that our method could generate high-quality\nbackgrounds for different categories, and maintain the personalized background\nstyle of reference images. BG60k will be available at\n\\url{https://github.com/Whileherham/BG60k}.",
            "pdf_url": "http://arxiv.org/pdf/2312.13309v2",
            "published": "2023-12-20 04:35:00+00:00",
            "updated": "2025-01-17 13:28:01+00:00"
        },
        {
            "title": "Mitigating analytical variability in fMRI results with style transfer",
            "authors": "Elodie Germani, Camille Maumet, Elisa Fromont",
            "summary": "We propose a novel approach to improve the reproducibility of neuroimaging\nresults by converting statistic maps across different functional MRI pipelines.\nWe make the assumption that pipelines used to compute fMRI statistic maps can\nbe considered as a style component and we propose to use different generative\nmodels, among which, Generative Adversarial Networks (GAN) and Diffusion Models\n(DM) to convert statistic maps across different pipelines. We explore the\nperformance of multiple GAN frameworks, and design a new DM framework for\nunsupervised multi-domain styletransfer. We constrain the generation of 3D fMRI\nstatistic maps using the latent space of an auxiliary classifier that\ndistinguishes statistic maps from different pipelines and extend traditional\nsampling techniques used in DM to improve the transition performance. Our\nexperiments demonstrate that our proposed methods aresuccessful: pipelines can\nindeed be transferred as a style component, providing animportant source of\ndata augmentation for future medical studies.",
            "pdf_url": "http://arxiv.org/pdf/2404.03703v3",
            "published": "2024-04-04 07:49:39+00:00",
            "updated": "2025-01-17 09:03:57+00:00"
        },
        {
            "title": "Enhancing Crash Frequency Modeling Based on Augmented Multi-Type Data by Hybrid VAE-Diffusion-Based Generative Neural Networks",
            "authors": "Junlan Chen, Qijie He, Pei Liu, Wei Ma, Ziyuan Pu",
            "summary": "Crash frequency modelling analyzes the impact of factors like traffic volume,\nroad geometry, and environmental conditions on crash occurrences. Inaccurate\npredictions can distort our understanding of these factors, leading to\nmisguided policies and wasted resources, which jeopardize traffic safety. A key\nchallenge in crash frequency modelling is the prevalence of excessive zero\nobservations, caused by underreporting, the low probability of crashes, and\nhigh data collection costs. These zero observations often reduce model accuracy\nand introduce bias, complicating safety decision making. While existing\napproaches, such as statistical methods, data aggregation, and resampling,\nattempt to address this issue, they either rely on restrictive assumptions or\nresult in significant information loss, distorting crash data. To overcome\nthese limitations, we propose a hybrid VAE-Diffusion neural network, designed\nto reduce zero observations and handle the complexities of multi-type tabular\ncrash data (count, ordinal, nominal, and real-valued variables). We assess the\nsynthetic data quality generated by this model through metrics like similarity,\naccuracy, diversity, and structural consistency, and compare its predictive\nperformance against traditional statistical models. Our findings demonstrate\nthat the hybrid VAE-Diffusion model outperforms baseline models across all\nmetrics, offering a more effective approach to augmenting crash data and\nimproving the accuracy of crash frequency predictions. This study highlights\nthe potential of synthetic data to enhance traffic safety by improving crash\nfrequency modelling and informing better policy decisions.",
            "pdf_url": "http://arxiv.org/pdf/2501.10017v1",
            "published": "2025-01-17 07:53:27+00:00",
            "updated": "2025-01-17 07:53:27+00:00"
        }
    ]
}