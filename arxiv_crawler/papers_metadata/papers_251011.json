{
    "Physics": [
        {
            "title": "The Complexity of Thermalization in Finite Quantum Systems",
            "authors": "Dhruv Devulapalli, T. C. Mooney, James D. Watson",
            "summary": "Thermalization is the process through which a physical system evolves toward\na state of thermal equilibrium. Determining whether or not a physical system\nwill thermalize from an initial state has been a key question in condensed\nmatter physics. Closely related questions are determining whether observables\nin these systems relax to stationary values, and what those values are. Using\ntools from computational complexity theory, we demonstrate that given a\nHamiltonian on a finite-sized system, determining whether or not it thermalizes\nor relaxes to a given stationary value is computationally intractable, even for\na quantum computer. In particular, we show that the problem of determining\nwhether an observable of a finite-sized quantum system relaxes to a given value\nis PSPACE-complete, and so no efficient algorithm for determining the value is\nexpected to exist. Further, we show the existence of Hamiltonians for which the\nproblem of determining whether the system thermalizes to the Gibbs expectation\nvalue is PSPACE-complete. We also show that the related problem of determining\nwhether the system thermalizes to the microcanonical expectation value is\ncontained in PSPACE and is PSPACE-hard under quantum polynomial time\nreductions. In light of recent results demonstrating undecidability of\nthermalization in the thermodynamic limit, our work shows that the\nintractability of the problem is due to inherent difficulties in many-body\nphysics rather than particularities of infinite systems.",
            "pdf_url": "http://arxiv.org/pdf/2507.00405v2",
            "published": "2025-07-01 03:45:08+00:00",
            "updated": "2025-10-09 17:56:14+00:00"
        },
        {
            "title": "Energy, Bosons and Computational Complexity",
            "authors": "Ulysse Chabaud, Sevag Gharibian, Saeed Mehraban, Arsalan Motamedi, Hamid Reza Naeij, Dorian Rudolph, Dhruva Sambrani",
            "summary": "We investigate the role of energy, i.e. average photon number, as a resource\nin the computational complexity of bosonic systems. We show three sets of\nresults: (1. Energy growth rates) There exist bosonic gate sets which increase\nenergy incredibly rapidly, obtaining e.g. infinite energy in finite/constant\ntime. We prove these high energies can make computing properties of bosonic\ncomputations, such as deciding whether a given computation will attain infinite\nenergy, extremely difficult, formally undecidable. (2. Lower bounds on\ncomputational power) More energy ``='' more computational power. For example,\ncertain gate sets allow poly-time bosonic computations to simulate PTOWER, the\nset of deterministic computations whose runtime scales as a tower of\nexponentials with polynomial height. Even just exponential energy and $O(1)$\nmodes suffice to simulate NP, which, importantly, is a setup similar to that of\nthe recent bosonic factoring algorithm of [Brenner, Caha, Coiteux-Roy and\nKoenig (2024)]. For simpler gate sets, we show an energy hierarchy theorem. (3.\nUpper bounds on computational power) Bosonic computations with polynomial\nenergy can be simulated in BQP, ``physical'' bosonic computations with\narbitrary finite energy are decidable, and the gate set consisting of Gaussian\ngates and the cubic phase gate can be simulated in PP, with exponential bound\non energy, improving upon the previous PSPACE upper bound. Finally, combining\nupper and lower bounds yields no-go theorems for a continuous-variable\nSolovay--Kitaev theorem for gate sets such as the Gaussian and cubic phase\ngates.",
            "pdf_url": "http://arxiv.org/pdf/2510.08545v1",
            "published": "2025-10-09 17:55:10+00:00",
            "updated": "2025-10-09 17:55:10+00:00"
        },
        {
            "title": "A Dobrushin condition for quantum Markov chains: Rapid mixing and conditional mutual information at high temperature",
            "authors": "Ainesh Bakshi, Allen Liu, Ankur Moitra, Ewin Tang",
            "summary": "A central challenge in quantum physics is to understand the structural\nproperties of many-body systems, both in equilibrium and out of equilibrium.\nFor classical systems, we have a unified perspective which connects structural\nproperties of systems at thermal equilibrium to the Markov chain dynamics that\nmix to them. We lack such a perspective for quantum systems: there is no\nframework to translate the quantitative convergence of the Markovian evolution\ninto strong structural consequences.\n  We develop a general framework that brings the breadth and flexibility of the\nclassical theory to quantum Gibbs states at high temperature. At its core is a\nnatural quantum analog of a Dobrushin condition; whenever this condition holds,\na concise path-coupling argument proves rapid mixing for the corresponding\nMarkovian evolution. The same machinery bridges dynamic and structural\nproperties: rapid mixing yields exponential decay of conditional mutual\ninformation (CMI) without restrictions on the size of the probed subsystems,\nresolving a central question in the theory of open quantum systems. Our key\ntechnical insight is an optimal transport viewpoint which couples quantum\ndynamics to a linear differential equation, enabling precise control over how\nlocal deviations from equilibrium propagate to distant sites.",
            "pdf_url": "http://arxiv.org/pdf/2510.08542v1",
            "published": "2025-10-09 17:54:41+00:00",
            "updated": "2025-10-09 17:54:41+00:00"
        },
        {
            "title": "On anomalous dissipation induced by transport noise",
            "authors": "Antonio Agresti",
            "summary": "In this paper, we show that suitable transport noises produce anomalous\ndissipation of both enstrophy of solutions to 2D Navier-Stokes equations and of\nenergy of solutions to diffusion equations in all dimensions. The key\ningredients are Meyers' type estimates for SPDEs with transport noise, which\nare combined with recent scaling limits for such SPDEs. The former enables us\nto establish, for the first time, uniform-in-time convergence in a space of\npositive smoothness for such scaling limits. Compared to previous work, one of\nthe main novelties is that anomalous dissipation might take place even in the\npresence of a transport noise of arbitrarily small intensity. Physical\ninterpretations of our results are also discussed.",
            "pdf_url": "http://arxiv.org/pdf/2405.03525v3",
            "published": "2024-05-06 14:41:46+00:00",
            "updated": "2025-10-09 17:53:21+00:00"
        },
        {
            "title": "How hard is it to verify a classical shadow?",
            "authors": "Georgios Karaiskos, Dorian Rudolph, Johannes Jakob Meyer, Jens Eisert, Sevag Gharibian",
            "summary": "Classical shadows are succinct classical representations of quantum states\nwhich allow one to encode a set of properties P of a quantum state rho, while\nonly requiring measurements on logarithmically many copies of rho in the size\nof P. In this work, we initiate the study of verification of classical shadows,\ndenoted classical shadow validity (CSV), from the perspective of computational\ncomplexity, which asks: Given a classical shadow S, how hard is it to verify\nthat S predicts the measurement statistics of a quantum state? We show that\neven for the elegantly simple classical shadow protocol of [Huang, Kueng,\nPreskill, Nature Physics 2020] utilizing local Clifford measurements, CSV is\nQMA-complete. This hardness continues to hold for the high-dimensional\nextension of said protocol due to [Mao, Yi, and Zhu, PRL 2025]. Among other\nresults, we also show that CSV for exponentially many observables is complete\nfor a quantum generalization of the second level of the polynomial hierarchy,\nyielding the first natural complete problem for such a class.",
            "pdf_url": "http://arxiv.org/pdf/2510.08515v1",
            "published": "2025-10-09 17:46:18+00:00",
            "updated": "2025-10-09 17:46:18+00:00"
        },
        {
            "title": "The quantum communication power of indefinite causal order",
            "authors": "Xuanqiang Zhao, Benchi Zhao, Giulio Chiribella",
            "summary": "Quantum theory is in principle compatible with scenarios where physical\nprocesses take place in an indefinite causal order, a possibility that was\nshown to yield advantages in several information processing tasks. However,\nadvantages in communication, the most basic form of information processing,\nhave so far remained controversial and hard to prove. Here we develop a\nframework that can be used to rigorously assess the role of causal order in a\nscenario where communication links are built by assembling multiple quantum\ndevices. In this setting, we establish a clear-cut advantage of indefinite\norder in the one-shot transmission of classical messages. On the other hand, we\nalso show that the advantage is not generic to all communication tasks.\nNotably, we find that indefinite order does not offer any advantage over shared\nentanglement in the asymptotic scenario where a large number of uses of the\nsame communication device is employed. Overall, our results unveil non-trivial\nrelations between communication, causal order, entanglement, and no-signaling\nresources in quantum mechanics.",
            "pdf_url": "http://arxiv.org/pdf/2510.08507v1",
            "published": "2025-10-09 17:42:04+00:00",
            "updated": "2025-10-09 17:42:04+00:00"
        },
        {
            "title": "Constraining the new contributions to electron $g-2$ in a radiative neutrino mass model",
            "authors": "Bayu Dirgantara, J. Julio",
            "summary": "We examine electron and muon anomalous magnetic dipole moments within a\nradiative neutrino mass model featuring TeV-scale scalar leptoquarks\n$S(3,1,-1/3)$ and $R(3,2,1/6)$. We utilize textures with decoupling electron\nand muon sectors, so that both electron and muon anomalous magnetic dipole\nmoments could receive internal chiral enhancements from different heavy up-type\nquarks while in the same time evading the stringent $\\mu\\to e\\gamma$\nconstraint. A successful fit to neutrino oscillation data requires the\nsimultaneous presence of one- and two-loop neutrino mass contributions. This\nseverely constrains the parameter space of the model, which results in a\nnegligible new physics correction to the muon $g-2$. The electron $g-2$\ndiscrepancy implied by the rubidium experiment, on the other hand, can be\nresolved within $2\\sigma$ uncertainty provided that neutrino mass ordering is\ninverted. Lepton-flavor-violating tau decay rates, such as $\\tau\\to e\\gamma$\nand $\\tau\\to 3e$, are predicted to be within the sensitivities of\nnext-generation experiments.",
            "pdf_url": "http://arxiv.org/pdf/2510.08504v1",
            "published": "2025-10-09 17:40:45+00:00",
            "updated": "2025-10-09 17:40:45+00:00"
        },
        {
            "title": "Quantum Probe Tomography",
            "authors": "Sitan Chen, Jordan Cotler, Hsin-Yuan Huang",
            "summary": "Characterizing quantum many-body systems is a fundamental problem across\nphysics, chemistry, and materials science. While significant progress has been\nmade, many existing Hamiltonian learning protocols demand digital quantum\ncontrol over the entire system, creating a disconnect from many real-world\nsettings that provide access only through small, local probes. Motivated by\nthis, we introduce and formalize the problem of quantum probe tomography, where\none seeks to learn the parameters of a many-body Hamiltonian using a single\nlocal probe access to a small subsystem of a many-body thermal state undergoing\ntime evolution. We address the identifiability problem of determining which\nHamiltonians can be distinguished from probe data through a new combination of\ntools from algebraic geometry and smoothed analysis. Using this approach, we\nprove that generic Hamiltonians in various physically natural families are\nidentifiable up to simple, unavoidable structural symmetries. Building on these\ninsights, we design the first efficient end-to-end algorithm for probe\ntomography that learns Hamiltonian parameters to accuracy $\\varepsilon$, with\nquery complexity scaling polynomially in $1/\\varepsilon$ and classical\npost-processing time scaling polylogarithmically in $1/\\varepsilon$. In\nparticular, we demonstrate that translation- and rotation-invariant\nnearest-neighbor Hamiltonians on square lattices in one, two, and three\ndimensions can be efficiently reconstructed from single-site probes of the\nGibbs state, up to inversion symmetry about the probed site. Our results\ndemonstrate that robust Hamiltonian learning remains achievable even under\nseverely constrained experimental access.",
            "pdf_url": "http://arxiv.org/pdf/2510.08499v1",
            "published": "2025-10-09 17:39:37+00:00",
            "updated": "2025-10-09 17:39:37+00:00"
        },
        {
            "title": "Average-case quantum complexity from glassiness",
            "authors": "Alexander Zlokapa, Bobak T. Kiani, Eric R. Anschuetz",
            "summary": "Glassiness -- a phenomenon in physics characterized by a rough free-energy\nlandscape -- implies hardness for stable classical algorithms. For example, it\ncan obstruct constant-time Langevin dynamics and message-passing in random\n$k$-SAT and max-cut instances. We provide an analogous framework for\naverage-case quantum complexity showing that a natural family of quantum\nalgorithms (e.g., Lindbladian evolution) fails for natural Hamiltonian\nensembles (e.g., random 3-local Hamiltonians). Specifically, we prove that the\nstandard notion of quantum glassiness based on replica symmetry breaking\nobstructs stable quantum algorithms for Gibbs sampling, which we define by a\nLipschitz temperature dependence in quantum Wasserstein complexity. Our proof\nrelies on showing that such algorithms fail to capture a structural phase\ntransition in the Gibbs state, where glassiness causes the Gibbs state to\ndecompose into clusters extensively separated in quantum Wasserstein distance.\nThis yields average-case lower bounds for constant-time local Lindbladian\nevolution and shallow variational circuits. Unlike mixing time lower bounds,\nour results hold even when dynamics are initialized from the maximally mixed\nstate. We apply these lower bounds to non-commuting, non-stoquastic\nHamiltonians by showing a glass transition via the replica trick. We find that\nthe ensemble of all 3-local Pauli strings with independent Gaussian\ncoefficients is average-case hard, while providing analytical evidence that the\ngeneral $p$-local Pauli ensemble is non-glassy for sufficiently large constant\n$p$, in contrast to its classical (Ising $p$-spin, always glassy) and fermionic\n(SYK, never glassy) counterparts.",
            "pdf_url": "http://arxiv.org/pdf/2510.08497v1",
            "published": "2025-10-09 17:37:33+00:00",
            "updated": "2025-10-09 17:37:33+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Who Said Neural Networks Aren't Linear?",
            "authors": "Nimrod Berman, Assaf Hallak, Assaf Shocher",
            "summary": "Neural networks are famously nonlinear. However, linearity is defined\nrelative to a pair of vector spaces, $f$$:$$X$$\\to$$Y$. Is it possible to\nidentify a pair of non-standard vector spaces for which a conventionally\nnonlinear function is, in fact, linear? This paper introduces a method that\nmakes such vector spaces explicit by construction. We find that if we sandwich\na linear operator $A$ between two invertible neural networks, $f(x)=g_y^{-1}(A\ng_x(x))$, then the corresponding vector spaces $X$ and $Y$ are induced by newly\ndefined addition and scaling actions derived from $g_x$ and $g_y$. We term this\nkind of architecture a Linearizer. This framework makes the entire arsenal of\nlinear algebra, including SVD, pseudo-inverse, orthogonal projection and more,\napplicable to nonlinear mappings. Furthermore, we show that the composition of\ntwo Linearizers that share a neural network is also a Linearizer. We leverage\nthis property and demonstrate that training diffusion models using our\narchitecture makes the hundreds of sampling steps collapse into a single step.\nWe further utilize our framework to enforce idempotency (i.e. $f(f(x))=f(x)$)\non networks leading to a globally projective generative model and to\ndemonstrate modular style transfer.",
            "pdf_url": "http://arxiv.org/pdf/2510.08570v1",
            "published": "2025-10-09 17:59:57+00:00",
            "updated": "2025-10-09 17:59:57+00:00"
        },
        {
            "title": "Improving Reasoning for Diffusion Language Models via Group Diffusion Policy Optimization",
            "authors": "Kevin Rojas, Jiahe Lin, Kashif Rasul, Anderson Schneider, Yuriy Nevmyvaka, Molei Tao, Wei Deng",
            "summary": "Diffusion language models (DLMs) enable parallel, order-agnostic generation\nwith iterative refinement, offering a flexible alternative to autoregressive\nlarge language models (LLMs). However, adapting reinforcement learning (RL)\nfine-tuning to DLMs remains an open challenge because of the intractable\nlikelihood. Pioneering work such as diffu-GRPO estimated token-level\nlikelihoods via one-step unmasking. While computationally efficient, this\napproach is severely biased. A more principled foundation lies in\nsequence-level likelihoods, where the evidence lower bound (ELBO) serves as a\nsurrogate. Yet, despite this clean mathematical connection, ELBO-based methods\nhave seen limited adoption due to the prohibitive cost of likelihood\nevaluation. In this work, we revisit ELBO estimation and disentangle its\nsources of variance. This decomposition motivates reducing variance through\nfast, deterministic integral approximations along a few pivotal dimensions.\nBuilding on this insight, we introduce \\textbf{Group Diffusion Policy\nOptimization (GDPO)}, a new RL algorithm tailored for DLMs. GDPO leverages\nsimple yet effective Semi-deterministic Monte Carlo schemes to mitigate the\nvariance explosion of ELBO estimators under vanilla double Monte Carlo\nsampling, yielding a provably lower-variance estimator under tight evaluation\nbudgets. Empirically, GDPO achieves consistent gains over pretrained\ncheckpoints and outperforms diffu-GRPO, one of the state-of-the-art baselines,\non the majority of math, reasoning, and coding benchmarks.",
            "pdf_url": "http://arxiv.org/pdf/2510.08554v1",
            "published": "2025-10-09 17:58:07+00:00",
            "updated": "2025-10-09 17:58:07+00:00"
        },
        {
            "title": "Permutation-Invariant Spectral Learning via Dyson Diffusion",
            "authors": "Tassilo Schwarz, Cai Dieball, Constantin Kogler, Kevin Lam, Renaud Lambiotte, Arnaud Doucet, Alja\u017e Godec, George Deligiannidis",
            "summary": "Diffusion models are central to generative modeling and have been adapted to\ngraphs by diffusing adjacency matrix representations. The challenge of having\nup to $n!$ such representations for graphs with $n$ nodes is only partially\nmitigated by using permutation-equivariant learning architectures. Despite\ntheir computational efficiency, existing graph diffusion models struggle to\ndistinguish certain graph families, unless graph data are augmented with ad hoc\nfeatures. This shortcoming stems from enforcing the inductive bias within the\nlearning architecture. In this work, we leverage random matrix theory to\nanalytically extract the spectral properties of the diffusion process, allowing\nus to push the inductive bias from the architecture into the dynamics. Building\non this, we introduce the Dyson Diffusion Model, which employs Dyson's Brownian\nMotion to capture the spectral dynamics of an Ornstein-Uhlenbeck process on the\nadjacency matrix while retaining all non-spectral information. We demonstrate\nthat the Dyson Diffusion Model learns graph spectra accurately and outperforms\nexisting graph diffusion models.",
            "pdf_url": "http://arxiv.org/pdf/2510.08535v1",
            "published": "2025-10-09 17:52:19+00:00",
            "updated": "2025-10-09 17:52:19+00:00"
        },
        {
            "title": "Wavefunction Flows: Efficient Quantum Simulation of Continuous Flow Models",
            "authors": "David Layden, Ryan Sweke, Vojt\u011bch Havl\u00ed\u010dek, Anirban Chowdhury, Kirill Neklyudov",
            "summary": "Flow models are a cornerstone of modern machine learning. They are generative\nmodels that progressively transform probability distributions according to\nlearned dynamics. Specifically, they learn a continuous-time Markov process\nthat efficiently maps samples from a simple source distribution into samples\nfrom a complex target distribution. We show that these models are naturally\nrelated to the Schr\\\"odinger equation, for an unusual Hamiltonian on continuous\nvariables. Moreover, we prove that the dynamics generated by this Hamiltonian\ncan be efficiently simulated on a quantum computer. Together, these results\ngive a quantum algorithm for preparing coherent encodings (a.k.a., qsamples)\nfor a vast family of probability distributions--namely, those expressible by\nflow models--by reducing the task to an existing classical learning problem,\nplus Hamiltonian simulation. For statistical problems defined by flow models,\nsuch as mean estimation and property testing, this enables the use of quantum\nalgorithms tailored to qsamples, which may offer advantages over classical\nalgorithms based only on samples from a flow model. More broadly, these results\nreveal a close connection between state-of-the-art machine learning models,\nsuch as flow matching and diffusion models, and one of the main expected\ncapabilities of quantum computers: simulating quantum dynamics.",
            "pdf_url": "http://arxiv.org/pdf/2510.08462v1",
            "published": "2025-10-09 17:05:54+00:00",
            "updated": "2025-10-09 17:05:54+00:00"
        },
        {
            "title": "SummDiff: Generative Modeling of Video Summarization with Diffusion",
            "authors": "Kwanseok Kim, Jaehoon Hahm, Sumin Kim, Jinhwan Sul, Byunghak Kim, Joonseok Lee",
            "summary": "Video summarization is a task of shortening a video by choosing a subset of\nframes while preserving its essential moments. Despite the innate subjectivity\nof the task, previous works have deterministically regressed to an averaged\nframe score over multiple raters, ignoring the inherent subjectivity of what\nconstitutes a good summary. We propose a novel problem formulation by framing\nvideo summarization as a conditional generation task, allowing a model to learn\nthe distribution of good summaries and to generate multiple plausible summaries\nthat better reflect varying human perspectives. Adopting diffusion models for\nthe first time in video summarization, our proposed method, SummDiff,\ndynamically adapts to visual contexts and generates multiple candidate\nsummaries conditioned on the input video. Extensive experiments demonstrate\nthat SummDiff not only achieves the state-of-the-art performance on various\nbenchmarks but also produces summaries that closely align with individual\nannotator preferences. Moreover, we provide a deeper insight with novel metrics\nfrom an analysis of the knapsack, which is an important last step of generating\nsummaries but has been overlooked in evaluation.",
            "pdf_url": "http://arxiv.org/pdf/2510.08458v1",
            "published": "2025-10-09 17:03:51+00:00",
            "updated": "2025-10-09 17:03:51+00:00"
        }
    ]
}