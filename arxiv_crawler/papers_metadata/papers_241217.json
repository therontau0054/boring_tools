{
    "Physics": [
        {
            "title": "QGP Physics from Attractor Perturbations",
            "authors": "Xin An, Micha\u0142 Spali\u0144ski",
            "summary": "The strong longitudinal expansion characteristic of heavy-ion collisions\nleads to universal attractor behavior of the resulting drop of quark-gluon\nplasma (QGP) already at very early times. Assuming approximate boost invariance\nand neglecting transverse expansion at the initial time, we incorporate\nsubsequent transverse dynamics of this system by linearizing the\nMueller-Israel-Stewart theory around the transversely homogeneous attractor.\nThe result is a system of coupled ordinary differential equations which\ndescribes the proper-time evolution of Fourier modes encoding the transverse\nstructure of the initial energy deposition. The late-time asymptotic behavior\nof these solutions is described by transseries which make manifest the\nstability of the attractor against transverse perturbations. In this framework,\ninformation about the structure of the plasma in the transverse plane resides\nmostly in exponentially suppressed corrections to evolution along the\nattractor, which are not yet negligible at freeze-out. These findings also\nsuggest a simple numerical approach to QGP dynamics using a finite number of\nFourier modes. Physical observables can be expressed in terms of the asymptotic\ndata evaluated at freeze-out. We demonstrate the efficacy of this approach by\ncalculating the final multiplicity distributions and collective flow\ncoefficients.",
            "pdf_url": "http://arxiv.org/pdf/2312.17237v2",
            "published": "2023-12-28 18:58:09+00:00",
            "updated": "2024-12-16 18:58:44+00:00"
        },
        {
            "title": "Extrapolating Jet Radiation with Autoregressive Transformers",
            "authors": "Anja Butter, Fran\u00e7ois Charton, Javier Mari\u00f1o Villadamigo, Ayodele Ore, Tilman Plehn, Jonas Spinner",
            "summary": "Generative networks are an exciting tool for fast LHC event generation.\nUsually, they are used to generate configurations with a fixed number of\nparticles. Autoregressive transformers allow us to generate events with\nvariable numbers of particles, very much in line with the physics of QCD jet\nradiation. We show how they can learn a factorized likelihood for jet radiation\nand extrapolate in terms of the number of generated jets. For this\nextrapolation, bootstrapping training data and training with modifications of\nthe likelihood loss can be used.",
            "pdf_url": "http://arxiv.org/pdf/2412.12074v1",
            "published": "2024-12-16 18:46:43+00:00",
            "updated": "2024-12-16 18:46:43+00:00"
        },
        {
            "title": "Accurate Surrogate Amplitudes with Calibrated Uncertainties",
            "authors": "Henning Bahl, Nina Elmer, Luigi Favaro, Manuel Hau\u00dfmann, Tilman Plehn, Ramon Winterhalder",
            "summary": "Neural networks for LHC physics have to be accurate, reliable, and\ncontrolled. Using surrogate loop amplitudes as a use case, we first show how\nactivation functions can be systematically tested with KANs. For reliability\nand control, we learn uncertainties together with the target amplitude over\nphase space. Systematic uncertainties can be learned by a heteroscedastic loss,\nbut a comprehensive learned uncertainty requires Bayesian networks or repulsive\nensembles. We compute pull distributions to show to what level learned\nuncertainties are calibrated correctly for cutting-edge precision surrogates.",
            "pdf_url": "http://arxiv.org/pdf/2412.12069v1",
            "published": "2024-12-16 18:42:52+00:00",
            "updated": "2024-12-16 18:42:52+00:00"
        },
        {
            "title": "Quasinormal coupled-mode analysis of dynamic gain in exceptional-point lasers",
            "authors": "Hao He, Xingwei Gao, Alexander Cerjan, Chia Wei Hsu",
            "summary": "One of the key features of lasers operating near exceptional points (EPs) is\nthat the gain medium can support an oscillating population inversion above a\npump threshold, leading to self-modulated laser dynamics. This unusual behavior\nopens up new possibilities for frequency comb generation and temporal\nmodulation. However, the dynamic population inversion couples signals with\ndifferent frequencies and thus cannot be captured by conventional temporal\ncoupled-mode theory (TCMT) based on static saturable gain. In this paper, we\ndevelop a perturbative coupled-mode analysis framework to capture the\nspatial-temporal dynamics of near-EP lasers. By decomposing discrete frequency\ngeneration into multiple excitations of resonant modes, our analysis\nestablishes a minimal physical model that translates the local distribution of\ndynamic population-inversion into a resonant modal interpretation of laser\ngain. This work enables the exploration of unique properties in this\nself-time-modulated systems, such as time-varying scattering and non-reciprocal\ntransmission.",
            "pdf_url": "http://arxiv.org/pdf/2412.12066v1",
            "published": "2024-12-16 18:41:03+00:00",
            "updated": "2024-12-16 18:41:03+00:00"
        },
        {
            "title": "Quantum Frequency Mixing using an N-$V$ Diamond Microscope",
            "authors": "Samuel J. Karlson, Pauli Kehayias, Jennifer M. Schloss, Andrew C. Maccabe, Adam Libson, David F. Phillips, Guoqing Wang, Paola Cappellaro, Danielle A. Braje",
            "summary": "Wide-field magnetic microscopy using nitrogen-vacancy (NV) centers in diamond\ncan yield high-quality magnetic images of DC and AC magnetic fields. The unique\ncombination of micron-scale spatial resolution of scalar or vector fields at\nroom temperature and parallel camera readout make this an appealing technique\nfor applications in biology, geology, condensed-matter physics, and\nelectronics. However, while NV magnetic microscopy has achieved great success\nin these areas, historically the accessible frequency range has been limited.\nIn this paper, we overcome this limitation by implementing the recently\ndeveloped technique of quantum frequency mixing. With this approach, we\ngenerate wide-field magnetic images of test structures driven by alternating\ncurrents up to 70 MHz, well outside the reach of DC and Rabi magnetometry\nmethods. With further improvements, this approach could find utility in\nhyperspectral imaging for electronics power spectrum analysis, electronics\ndiagnostics and troubleshooting, and quantum computing hardware validation.",
            "pdf_url": "http://arxiv.org/pdf/2407.07025v2",
            "published": "2024-07-09 16:46:00+00:00",
            "updated": "2024-12-16 18:40:17+00:00"
        },
        {
            "title": "Geometrically constrained localized configurations engendering non-topological profile",
            "authors": "D. Bazeia, I. Bezerra, R. Menezes",
            "summary": "This work deals with two real scalar fields in two-dimensional spacetime,\nwith the fields coupled to allow the study of localized configurations. We\nconsider models constructed to engender geometric constrictions, and use them\nto investigate solutions of the lump type, which attain no topological\nproperties. We show how to modify the internal structure of the field\nconfigurations and the corresponding energy densities in several distinct ways,\nmaking them thinner, thicker and also, in the form of a multi-lump solution\ncomposed of two or more lumps or asymmetrically distributed around their\nassociated centers. The results appear to be of current interest in high energy\nphysics and may, in particular, be used to study bright solitons in optical\nfibers and in Bose-Einstein condensates.",
            "pdf_url": "http://arxiv.org/pdf/2412.12044v1",
            "published": "2024-12-16 18:13:49+00:00",
            "updated": "2024-12-16 18:13:49+00:00"
        },
        {
            "title": "Thermodynamics-informed graph neural networks for real-time simulation of digital human twins",
            "authors": "Lucas Tes\u00e1n, David Gonz\u00e1lez, Pedro Martins, El\u00edas Cueto",
            "summary": "The growing importance of real-time simulation in the medical field has\nexposed the limitations and bottlenecks inherent in the digital representation\nof complex biological systems. This paper presents a novel methodology aimed at\nadvancing current lines of research in soft tissue simulation. The proposed\napproach introduces a hybrid model that integrates the geometric bias of graph\nneural networks with the physical bias derived from the imposition of a\nmetriplectic structure as soft and hard constrains in the architecture, being\nable to simulate hepatic tissue with dissipative properties. This approach\nprovides an efficient solution capable of generating predictions at high\nfeedback rate while maintaining a remarkable generalization ability for\npreviously unseen anatomies. This makes these features particularly relevant in\nthe context of precision medicine and haptic rendering.\n  Based on the adopted methodologies, we propose a model that predicts human\nliver responses to traction and compression loads in as little as 7.3\nmilliseconds for optimized configurations and as fast as 1.65 milliseconds in\nthe most efficient cases, all in the forward pass. The model achieves relative\nposition errors below 0.15\\%, with stress tensor and velocity estimations\nmaintaining relative errors under 7\\%. This demonstrates the robustness of the\napproach developed, which is capable of handling diverse load states and\nanatomies effectively. This work highlights the feasibility of integrating\nreal-time simulation with patient-specific geometries through deep learning,\npaving the way for more robust digital human twins in medical applications.",
            "pdf_url": "http://arxiv.org/pdf/2412.12034v1",
            "published": "2024-12-16 18:01:40+00:00",
            "updated": "2024-12-16 18:01:40+00:00"
        },
        {
            "title": "The causal structure of the quark propagator",
            "authors": "Jan M. Pawlowski, Jonas Wessely",
            "summary": "We study the causal structure of the quark propagator with the spectral DSE.\nThe spectral gap equation is solved with the input of the spectral\nrepresentation of the gluon and a causal STI-construction for the quark-gluon\nvertex. The latter includes a potential infrared enhancement of the vertex\nstrength of the classical tensor structure that accommodates for the physical\nstrength of chiral symmetry breaking. We find a critical vertex strength, below\nwhich the quark has a K\\\"all\\'en-Lehmann representation. While the nature of\nthe first singularity does not change above the critical strength, we find that\nthe quark propagator features at least two additional pairs of complex\nconjugate poles that are located approximately at the sum of quark pole mass\nand peak position of the quark-gluon coupling. These additional poles lead to\nviolations of causality, if they persist in $S$-matrix elements. While the\nvertex strength of the classical tensor structure in full QCD is below the\ncritical one, that of commonly used vertex models, which rely solely on the\nclassical vertex structure, is typically above it. Finally, we discuss how\nthese additional poles could be avoided in full QCD, where part of chiral\nsymmetry breaking is generated by the other tensor structures in the\nquark-gluon vertex.",
            "pdf_url": "http://arxiv.org/pdf/2412.12033v1",
            "published": "2024-12-16 17:59:56+00:00",
            "updated": "2024-12-16 17:59:56+00:00"
        },
        {
            "title": "Heterogeneous Freeform Metasurfaces: A Platform for Advanced Broadband Dispersion Engineering",
            "authors": "Zhaoyi Li, Sawyer D. Campell, Joon-Suh Park, Ronald P. Jenkins, Soon Wei Daniel Lim, Douglas H. Werner, Federico Capasso",
            "summary": "Metasurfaces, with their ability to control electromagnetic waves, hold\nimmense potential in optical device design, especially for applications\nrequiring precise control over dispersion. This work introduces an approach to\ndispersion engineering using heterogeneous freeform metasurfaces, which\novercomes the limitations of conventional metasurfaces that often suffer from\npoor transmission, narrow bandwidth, and restricted polarization responses. By\ntransitioning from single-layer, canonical meta-atoms to bilayer architectures\nwith non-intuitive geometries, our design decouples intrinsic material\nproperties (refractive index and group index), enabling independent engineering\nof phase and group delays as well as higher-order dispersion properties, while\nachieving high-efficiency under arbitrary polarization states. We implement a\ntwo-stage multi-objective optimization process to generate libraries of\nmeta-atoms, which are then utilized for the rapid design of\ndispersion-engineered metasurfaces. Additionally, we present a bilayer\nmetasurface stacking technique, paving the way for the realization of\nhigh-performance, dispersion-engineered optical devices. Our approach is\nvalidated through the demonstration of metasurfaces exhibiting superior\nchromatic aberration correction and broadband performance, with over 81%\naveraged efficiency across the 420-nm visible-to-near-infrared bandwidth. Our\nsynergistic combination of advanced design physics, powerful freeform\noptimization methods, and bi-layer nanofabrication techniques represents a\nsignificant breakthrough compared to the state-of-the-art while opening new\npossibilities for broadband metasurface applications.",
            "pdf_url": "http://arxiv.org/pdf/2412.12028v1",
            "published": "2024-12-16 17:55:36+00:00",
            "updated": "2024-12-16 17:55:36+00:00"
        },
        {
            "title": "Modelling the underlying event in photon-initiated processes",
            "authors": "J. M. Butterworth, I. M. Helenius, J. J. Juan Castella, B. Pattengale, S. Sanjrani, M. Wing",
            "summary": "Modelling the underlying event in high-energy hadronic collisions is\nimportant for physics at colliders. This includes lepton colliders, where\nlow-virtuality photons accompanying the lepton beam(s) may develop hadronic\nstructure. Similarly, photon-induced collisions also occur in proton or\nheavy-ion beam experiments. While the underlying event in proton-proton\ncollisions has been the subject of much study at the LHC, studies of\nhadronic-photon-induced underlying event are now of increasing interest in\nlight of planned future lepton and lepton-hadron colliders, as well as the\nphoton-induced processes in ultra-peripheral collisions at the LHC. Here we\npresent an investigation of the underlying event in photon-initiated processes,\nstarting from the PYTHIA models used to describe LHC and Tevatron data, and\nrevisiting HERA and LEP2 data. While no single tune describes all the data with\ndifferent beam configurations, we find that a good agreement can still be found\nwithin the same model by adjusting the relevant parameters separately for\n$\\gamma\\gamma$, $\\gamma p$ and $pp$. This suggests that the basic model of\nmultiparton interaction implemented in PYTHIA can be applied for different beam\nconfigurations. Furthermore, we find that a reasonable agreement for\n$\\gamma\\gamma$ and $\\gamma p$ data, and for $pp$ data at an LHC reference\nenergy, can be found within a single parametrization, but $pp$ collisions would\nprefer a stronger energy dependence, leading to too many multiparton\ninteractions in lower energy photon-induced collisions. On this basis, we make\nsome recommendations for simulations of photon-induced processes, such as\n$\\gamma \\gamma$ events at the LHC or FCC and $ep$ or $eA$ collisions at the\nEIC, and suggest possibilities for improvements in the modelling.",
            "pdf_url": "http://arxiv.org/pdf/2408.15842v2",
            "published": "2024-08-28 15:03:18+00:00",
            "updated": "2024-12-16 17:54:15+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning",
            "authors": "Gaojian Wang, Feng Lin, Tong Wu, Zhenguang Liu, Zhongjie Ba, Kui Ren",
            "summary": "This work asks: with abundant, unlabeled real faces, how to learn a robust\nand transferable facial representation that boosts various face security tasks\nwith respect to generalization performance? We make the first attempt and\npropose a self-supervised pretraining framework to learn fundamental\nrepresentations of real face images, FSFM, that leverages the synergy between\nmasked image modeling (MIM) and instance discrimination (ID). We explore\nvarious facial masking strategies for MIM and present a simple yet powerful\nCRFR-P masking, which explicitly forces the model to capture meaningful\nintra-region consistency and challenging inter-region coherency. Furthermore,\nwe devise the ID network that naturally couples with MIM to establish\nunderlying local-to-global correspondence via tailored self-distillation. These\nthree learning objectives, namely 3C, empower encoding both local features and\nglobal semantics of real faces. After pretraining, a vanilla ViT serves as a\nuniversal vision foundation model for downstream face security tasks:\ncross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen\ndiffusion facial forgery detection. Extensive experiments on 10 public datasets\ndemonstrate that our model transfers better than supervised pretraining, visual\nand facial self-supervised learning arts, and even outperforms task-specialized\nSOTA methods.",
            "pdf_url": "http://arxiv.org/pdf/2412.12032v1",
            "published": "2024-12-16 17:58:45+00:00",
            "updated": "2024-12-16 17:58:45+00:00"
        },
        {
            "title": "BrushEdit: All-In-One Image Inpainting and Editing",
            "authors": "Yaowei Li, Yuxuan Bian, Xuan Ju, Zhaoyang Zhang, Ying Shan, Yuexian Zou, Qiang Xu",
            "summary": "Image editing has advanced significantly with the development of diffusion\nmodels using both inversion-based and instruction-based methods. However,\ncurrent inversion-based approaches struggle with big modifications (e.g.,\nadding or removing objects) due to the structured nature of inversion noise,\nwhich hinders substantial changes. Meanwhile, instruction-based methods often\nconstrain users to black-box operations, limiting direct interaction for\nspecifying editing regions and intensity. To address these limitations, we\npropose BrushEdit, a novel inpainting-based instruction-guided image editing\nparadigm, which leverages multimodal large language models (MLLMs) and image\ninpainting models to enable autonomous, user-friendly, and interactive\nfree-form instruction editing. Specifically, we devise a system enabling\nfree-form instruction editing by integrating MLLMs and a dual-branch image\ninpainting model in an agent-cooperative framework to perform editing category\nclassification, main object identification, mask acquisition, and editing area\ninpainting. Extensive experiments show that our framework effectively combines\nMLLMs and inpainting models, achieving superior performance across seven\nmetrics including mask region preservation and editing effect coherence.",
            "pdf_url": "http://arxiv.org/pdf/2412.10316v2",
            "published": "2024-12-13 17:58:06+00:00",
            "updated": "2024-12-16 17:54:44+00:00"
        },
        {
            "title": "EmotiveTalk: Expressive Talking Head Generation through Audio Information Decoupling and Emotional Video Diffusion",
            "authors": "Haotian Wang, Yuzhe Weng, Yueyan Li, Zilu Guo, Jun Du, Shutong Niu, Jiefeng Ma, Shan He, Xiaoyan Wu, Qiming Hu, Bing Yin, Cong Liu, Qingfeng Liu",
            "summary": "Diffusion models have revolutionized the field of talking head generation,\nyet still face challenges in expressiveness, controllability, and stability in\nlong-time generation. In this research, we propose an EmotiveTalk framework to\naddress these issues. Firstly, to realize better control over the generation of\nlip movement and facial expression, a Vision-guided Audio Information\nDecoupling (V-AID) approach is designed to generate audio-based decoupled\nrepresentations aligned with lip movements and expression. Specifically, to\nachieve alignment between audio and facial expression representation spaces, we\npresent a Diffusion-based Co-speech Temporal Expansion (Di-CTE) module within\nV-AID to generate expression-related representations under multi-source emotion\ncondition constraints. Then we propose a well-designed Emotional Talking Head\nDiffusion (ETHD) backbone to efficiently generate highly expressive talking\nhead videos, which contains an Expression Decoupling Injection (EDI) module to\nautomatically decouple the expressions from reference portraits while\nintegrating the target expression information, achieving more expressive\ngeneration performance. Experimental results show that EmotiveTalk can generate\nexpressive talking head videos, ensuring the promised controllability of\nemotions and stability during long-time generation, yielding state-of-the-art\nperformance compared to existing methods.",
            "pdf_url": "http://arxiv.org/pdf/2411.16726v2",
            "published": "2024-11-23 04:38:51+00:00",
            "updated": "2024-12-16 17:11:49+00:00"
        },
        {
            "title": "Diffusion-based Reinforcement Learning via Q-weighted Variational Policy Optimization",
            "authors": "Shutong Ding, Ke Hu, Zhenhao Zhang, Kan Ren, Weinan Zhang, Jingyi Yu, Jingya Wang, Ye Shi",
            "summary": "Diffusion models have garnered widespread attention in Reinforcement Learning\n(RL) for their powerful expressiveness and multimodality. It has been verified\nthat utilizing diffusion policies can significantly improve the performance of\nRL algorithms in continuous control tasks by overcoming the limitations of\nunimodal policies, such as Gaussian policies, and providing the agent with\nenhanced exploration capabilities. However, existing works mainly focus on the\napplication of diffusion policies in offline RL, while their incorporation into\nonline RL is less investigated. The training objective of the diffusion model,\nknown as the variational lower bound, cannot be optimized directly in online RL\ndue to the unavailability of 'good' actions. This leads to difficulties in\nconducting diffusion policy improvement. To overcome this, we propose a novel\nmodel-free diffusion-based online RL algorithm, Q-weighted Variational Policy\nOptimization (QVPO). Specifically, we introduce the Q-weighted variational\nloss, which can be proved to be a tight lower bound of the policy objective in\nonline RL under certain conditions. To fulfill these conditions, the Q-weight\ntransformation functions are introduced for general scenarios. Additionally, to\nfurther enhance the exploration capability of the diffusion policy, we design a\nspecial entropy regularization term. We also develop an efficient behavior\npolicy to enhance sample efficiency by reducing the variance of the diffusion\npolicy during online interactions. Consequently, the QVPO algorithm leverages\nthe exploration capabilities and multimodality of diffusion policies,\npreventing the RL agent from converging to a sub-optimal policy. To verify the\neffectiveness of QVPO, we conduct comprehensive experiments on MuJoCo\nbenchmarks. The final results demonstrate that QVPO achieves state-of-the-art\nperformance on both cumulative reward and sample efficiency.",
            "pdf_url": "http://arxiv.org/pdf/2405.16173v3",
            "published": "2024-05-25 10:45:46+00:00",
            "updated": "2024-12-16 15:42:46+00:00"
        },
        {
            "title": "No More Adam: Learning Rate Scaling at Initialization is All You Need",
            "authors": "Minghao Xu, Lichuan Xiang, Xu Cai, Hongkai Wen",
            "summary": "In this work, we question the necessity of adaptive gradient methods for\ntraining deep neural networks. SGD-SaI is a simple yet effective enhancement to\nstochastic gradient descent with momentum (SGDM). SGD-SaI performs learning\nrate Scaling at Initialization (SaI) to distinct parameter groups, guided by\ntheir respective gradient signal-to-noise ratios (g-SNR). By adjusting learning\nrates without relying on adaptive second-order momentum, SGD-SaI helps prevent\ntraining imbalances from the very first iteration and cuts the optimizer's\nmemory usage by half compared to AdamW. Despite its simplicity and efficiency,\nSGD-SaI consistently matches or outperforms AdamW in training a variety of\nTransformer-based tasks, effectively overcoming a long-standing challenge of\nusing SGD for training Transformers. SGD-SaI excels in ImageNet-1K\nclassification with Vision Transformers(ViT) and GPT-2 pretraining for large\nlanguage models (LLMs, transformer decoder-only), demonstrating robustness to\nhyperparameter variations and practicality for diverse applications. We further\ntested its robustness on tasks like LoRA fine-tuning for LLMs and diffusion\nmodels, where it consistently outperforms state-of-the-art optimizers. From a\nmemory efficiency perspective, SGD-SaI achieves substantial memory savings for\noptimizer states, reducing memory usage by 5.93 GB for GPT-2 (1.5B parameters)\nand 25.15 GB for Llama2-7B compared to AdamW in full-precision training\nsettings.",
            "pdf_url": "http://arxiv.org/pdf/2412.11768v1",
            "published": "2024-12-16 13:41:37+00:00",
            "updated": "2024-12-16 13:41:37+00:00"
        }
    ]
}