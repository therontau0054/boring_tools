{
    "Physics": [
        {
            "title": "Radial Attention: $O(n\\log n)$ Sparse Attention with Energy Decay for Long Video Generation",
            "authors": "Xingyang Li, Muyang Li, Tianle Cai, Haocheng Xi, Shuo Yang, Yujun Lin, Lvmin Zhang, Songlin Yang, Jinbo Hu, Kelly Peng, Maneesh Agrawala, Ion Stoica, Kurt Keutzer, Song Han",
            "summary": "Recent advances in diffusion models have enabled high-quality video\ngeneration, but the additional temporal dimension significantly increases\ncomputational costs, making training and inference on long videos prohibitively\nexpensive. In this paper, we identify a phenomenon we term Spatiotemporal\nEnergy Decay in video diffusion models: post-softmax attention scores diminish\nas spatial and temporal distance between tokens increase, akin to the physical\ndecay of signal or waves over space and time in nature. Motivated by this, we\npropose Radial Attention, a scalable sparse attention mechanism with $O(n \\log\nn)$ complexity that translates energy decay into exponentially decaying compute\ndensity, which is significantly more efficient than standard $O(n^2)$ dense\nattention and more expressive than linear attention. Specifically, Radial\nAttention employs a simple, static attention mask where each token attends to\nspatially nearby tokens, with the attention window size shrinking with temporal\ndistance. Moreover, it allows pre-trained video diffusion models to extend\ntheir generation length with efficient LoRA-based fine-tuning. Extensive\nexperiments show that Radial Attention maintains video quality across\nWan2.1-14B, HunyuanVideo, and Mochi 1, achieving up to a 1.9$\\times$ speedup\nover the original dense attention. With minimal tuning, it enables video\ngeneration up to 4$\\times$ longer while reducing training costs by up to\n4.4$\\times$ compared to direct fine-tuning and accelerating inference by up to\n3.7$\\times$ compared to dense attention inference.",
            "pdf_url": "http://arxiv.org/pdf/2506.19852v1",
            "published": "2025-06-24 17:59:59+00:00",
            "updated": "2025-06-24 17:59:59+00:00"
        },
        {
            "title": "Marginally stable Schwarzschild-black-hole-non-minimally-coupled-Proca-field bound-state configurations",
            "authors": "Shahar Hod",
            "summary": "It has recently been revealed that, in curved black-hole spacetimes,\nnon-minimally coupled massive Proca fields may be characterized by the\nexistence of poles in their linearized perturbation equations and may therefore\ndevelop exponentially growing instabilities. Interestingly, recent numerical\ncomputations [H. W. Chiang, S. Garcia-Saenz, and A. Sang, arXiv:2504.04779]\nhave provided compelling evidence that the onset of monopole instabilities in\nthe composed black-hole-field system is controlled by the dimensionless\nphysical parameter $\\mu r_-$, where $\\mu$ is the proper mass of the\nnon-minimally coupled Proca field and $r_-\\equiv (-2\\alpha)^{1/3}r_{\\text{H}}$\nis the radial location of the pole [here $\\alpha$ is the non-minimal coupling\nparameter of the Einstein-Proca theory and $r_{\\text{H}}$ is the radius of the\nblack-hole horizon]. In the present paper we use {\\it analytical} techniques in\norder to explore the physical properties of critical (marginally-stable)\ncomposed Schwarzschild-black-hole-nonminimally-coupled-monopole-Proca-field\nconfigurations. In particular, we derive a remarkably compact analytical\nformula for the discrete spectrum $\\{\\mu(r_{\\text{H}},r_-;n)\n\\}^{n=\\infty}_{n=1}$ of Proca field masses which characterize the critical\nblack-hole-monopole-Proca-field configurations in the dimensionless regime\n${{r_- -r_{\\text{H}}}\\over{r_{\\text{H}}}}\\ll1$ of near-horizon poles. The\nphysical significance of the analytically derived resonance spectrum stems from\nthe fact that the critical field mass\n$\\mu_{\\text{c}}\\equiv\\mu(r_{\\text{H}},r_-;n=1)$ marks the onset of\ninstabilities in the\nSchwarzschild-black-hole-nonminimally-coupled-monopole-Proca-field system. In\nparticular, composed black-hole-linearized-Proca-field configurations in the\nsmall-mass regime $\\mu\\leq\\mu_{\\text{c}}$ of the Proca field are stable.",
            "pdf_url": "http://arxiv.org/pdf/2506.19849v1",
            "published": "2025-06-24 17:59:57+00:00",
            "updated": "2025-06-24 17:59:57+00:00"
        },
        {
            "title": "ManiGaussian++: General Robotic Bimanual Manipulation with Hierarchical Gaussian World Model",
            "authors": "Tengbo Yu, Guanxing Lu, Zaijia Yang, Haoyuan Deng, Season Si Chen, Jiwen Lu, Wenbo Ding, Guoqiang Hu, Yansong Tang, Ziwei Wang",
            "summary": "Multi-task robotic bimanual manipulation is becoming increasingly popular as\nit enables sophisticated tasks that require diverse dual-arm collaboration\npatterns. Compared to unimanual manipulation, bimanual tasks pose challenges to\nunderstanding the multi-body spatiotemporal dynamics. An existing method\nManiGaussian pioneers encoding the spatiotemporal dynamics into the visual\nrepresentation via Gaussian world model for single-arm settings, which ignores\nthe interaction of multiple embodiments for dual-arm systems with significant\nperformance drop. In this paper, we propose ManiGaussian++, an extension of\nManiGaussian framework that improves multi-task bimanual manipulation by\ndigesting multi-body scene dynamics through a hierarchical Gaussian world\nmodel. To be specific, we first generate task-oriented Gaussian Splatting from\nintermediate visual features, which aims to differentiate acting and\nstabilizing arms for multi-body spatiotemporal dynamics modeling. We then build\na hierarchical Gaussian world model with the leader-follower architecture,\nwhere the multi-body spatiotemporal dynamics is mined for intermediate visual\nrepresentation via future scene prediction. The leader predicts Gaussian\nSplatting deformation caused by motions of the stabilizing arm, through which\nthe follower generates the physical consequences resulted from the movement of\nthe acting arm. As a result, our method significantly outperforms the current\nstate-of-the-art bimanual manipulation techniques by an improvement of 20.2% in\n10 simulated tasks, and achieves 60% success rate on average in 9 challenging\nreal-world tasks. Our code is available at\nhttps://github.com/April-Yz/ManiGaussian_Bimanual.",
            "pdf_url": "http://arxiv.org/pdf/2506.19842v1",
            "published": "2025-06-24 17:59:06+00:00",
            "updated": "2025-06-24 17:59:06+00:00"
        },
        {
            "title": "Inferring Higher-Order Couplings with Neural Networks",
            "authors": "Aur\u00e9lien Decelle, Alfonso de Jes\u00fas Navas G\u00f3mez, Beatriz Seoane",
            "summary": "Maximum entropy methods, rooted in the inverse Ising/Potts problem from\nstatistical physics, are widely used to model pairwise interactions in complex\nsystems across disciplines such as bioinformatics and neuroscience. While\nsuccessful, these approaches often fail to capture higher-order interactions\nthat are critical for understanding collective behavior. In contrast, modern\nmachine learning methods can model such interactions, but their\ninterpretability often comes at a prohibitive computational cost. Restricted\nBoltzmann Machines (RBMs) provide a computationally efficient alternative by\nencoding statistical correlations through hidden units in a bipartite\narchitecture. In this work, we introduce a method that maps RBMs onto\ngeneralized Potts models, enabling the systematic extraction of interactions up\nto arbitrary order. Leveraging large-$N$ approximations -- made tractable by\nthe RBM's structure -- we extract effective many-body couplings with minimal\ncomputational effort. We further propose a robust framework for recovering\nhigher-order interactions in more complex generative models, and introduce a\nsimple gauge-fixing scheme for the effective Potts representation. Validation\non synthetic data demonstrates accurate recovery of two- and three-body\ninteractions. Applied to protein sequence data, our method reconstructs contact\nmaps with high fidelity and outperforms state-of-the-art inverse Potts models.\nThese results establish RBMs as a powerful and efficient tool for modeling\nhigher-order structure in high-dimensional categorical data.",
            "pdf_url": "http://arxiv.org/pdf/2501.06108v3",
            "published": "2025-01-10 17:01:09+00:00",
            "updated": "2025-06-24 17:51:24+00:00"
        },
        {
            "title": "Resonances of recurrence time of monitored quantum walks",
            "authors": "Ruoyu Yin, Qingyuan Wang, Sabine Tornow, Eli Barkai",
            "summary": "The recurrence time is the time a process first returns to its initial state.\nUsing quantum walks on a graph, the recurrence time is defined through\nstroboscopic monitoring of the arrival of the particle to a node of the system.\nWhen the time interval between repeated measurements is tuned in such a way\nthat eigenvalues of the unitary become degenerate, the mean recurrence time\nexhibits resonances. These resonances imply faster mean recurrence times, which\nwere recorded on quantum computers. The resonance broadening is captured by a\nrestart uncertainty relation [R. Yin, Q. Wang, S. Tornow, E. Barkai, Proc.\nNatl. Acad. Sci. U.S.A. 122, e2402912121 (2025)]. To ensure a comprehensive\nanalysis, we extend our investigation to include the impact of system size on\nthe widened resonances, showing how the connectivity and energy spectrum\nstructure of a system influence the restart uncertainty relation. Breaking the\nsymmetry of the system, for example time-reversal symmetry breaking with a\nmagnetic flux applied to a ring, removes the degeneracy of {the eigenvalues of\nthe unitary}, hence modifying {the mean recurrence time and the widening of the\ntransitions}, and this effect is studied in detail. The width of resonances\nstudied here is related to the finite time resolution of relevant experiments\non quantum computers, and to the restart paradigm.19",
            "pdf_url": "http://arxiv.org/pdf/2506.19832v1",
            "published": "2025-06-24 17:50:14+00:00",
            "updated": "2025-06-24 17:50:14+00:00"
        },
        {
            "title": "Curating art exhibitions using machine learning",
            "authors": "Eurico Covas",
            "summary": "Art curatorship has always been mostly the subjective work of human experts,\nwho, with extensive knowledge of many and diverse artworks, select a few of\nthose to present in communal spaces, spaces that evolved into what we now call\nart galleries. There are no hard and fast set of rules on how to select these\nartworks, given a theme which either is presented to the art curator or\nconstructed by her/him. Here we present a series of artificial models -- a\ntotal of four related models -- based on machine learning techniques (a subset\nof artificial intelligence) that attempt to learn from existing exhibitions\nwhich have been curated by human experts, in order to be able to do similar\ncuratorship work. We focus exclusively on the last 25 years of past exhibitions\nat the Metropolitan Museum of Art in New York, due to the quality of the data\navailable and the physical and time limitations of our research. Our four\nartificial intelligence models achieve a reasonable ability at imitating these\nvarious curators responsible for all those exhibitions, with various degrees of\nprecision and curatorial coherence. In particular, we can conclude two key\ninsights: first, that there is sufficient information in these exhibitions to\nconstruct an artificial intelligence model that replicates past exhibitions\nwith an accuracy well above random choices; second, that using feature\nengineering and carefully designing the architecture of modest size models can\nmake them as good as those using the so-called large language models such as\nGPT in a brute force approach. We also believe, based on small attempts to use\nthe models in out-of-sample experiments, that given more much more data, it\nshould be possible for these kinds of artificial intelligence agents to be\ncloser and closer to the aesthetic and curatorial judgment of human art\ncurators.",
            "pdf_url": "http://arxiv.org/pdf/2506.19813v1",
            "published": "2025-06-24 17:25:03+00:00",
            "updated": "2025-06-24 17:25:03+00:00"
        },
        {
            "title": "First-Passage Approach to Optimizing Perturbations for Improved Training of Machine Learning Models",
            "authors": "Sagi Meir, Tommer D. Keidar, Shlomi Reuveni, Barak Hirshberg",
            "summary": "Machine learning models have become indispensable tools in applications\nacross the physical sciences. Their training is often time-consuming, vastly\nexceeding the inference timescales. Several protocols have been developed to\nperturb the learning process and improve the training, such as shrink and\nperturb, warm restarts, and stochastic resetting. For classifiers, these\nperturbations have been shown to result in enhanced speedups or improved\ngeneralization. However, the design of such perturbations is usually done ad\nhoc by intuition and trial and error. To rationally optimize training\nprotocols, we frame them as first-passage processes and consider their response\nto perturbations. We show that if the unperturbed learning process reaches a\nquasi-steady state, the response at a single perturbation frequency can predict\nthe behavior at a wide range of frequencies. We employ this approach to a\nCIFAR-10 classifier using the ResNet-18 model and identify a useful\nperturbation and frequency among several possibilities. We demonstrate the\ntransferability of the approach to other datasets, architectures, optimizers\nand even tasks (regression instead of classification). Our work allows\noptimization of perturbations for improving the training of machine learning\nmodels using a first-passage approach.",
            "pdf_url": "http://arxiv.org/pdf/2502.04121v3",
            "published": "2025-02-06 14:53:21+00:00",
            "updated": "2025-06-24 17:16:47+00:00"
        },
        {
            "title": "Convolution-weighting method for the physics-informed neural network: A Primal-Dual Optimization Perspective",
            "authors": "Chenhao Si, Ming Yan",
            "summary": "Physics-informed neural networks (PINNs) are extensively employed to solve\npartial differential equations (PDEs) by ensuring that the outputs and\ngradients of deep learning models adhere to the governing equations. However,\nconstrained by computational limitations, PINNs are typically optimized using a\nfinite set of points, which poses significant challenges in guaranteeing their\nconvergence and accuracy. In this study, we proposed a new weighting scheme\nthat will adaptively change the weights to the loss functions from isolated\npoints to their continuous neighborhood regions. The empirical results show\nthat our weighting scheme can reduce the relative $L^2$ errors to a lower\nvalue.",
            "pdf_url": "http://arxiv.org/pdf/2506.19805v1",
            "published": "2025-06-24 17:13:51+00:00",
            "updated": "2025-06-24 17:13:51+00:00"
        },
        {
            "title": "Chimera baryons and mesons on the lattice: a spectral density analysis",
            "authors": "Ed Bennett, Luigi Del Debbio, Niccol\u00f2 Forzano, Ryan Hill, Deog Ki Hong, Ho Hsiao, Jong-Wan Lee, C. -J. David Lin, Biagio Lucini, Alessandro Lupo, Maurizio Piai, Davide Vadacchino, Fabian Zierler",
            "summary": "We develop and test a spectral-density analysis method, based on the\nintroduction of smeared energy kernels, to extract physical information from\ntwo-point correlation functions computed numerically in lattice field theory.\nWe apply it to a $Sp(4)$ gauge theory and fermion matter fields transforming in\ndistinct representations, with $N_{\\rm f}=2$ Dirac fermions in the fundamental\nand $N_{\\rm as}=3$ in the 2-index antisymmetric representation. The\ncorresponding continuum theory provides the minimal candidate model for a\ncomposite Higgs boson with partial top compositeness. We consider a broad class\nof composite operators, that source flavored mesons and (chimera) baryons, for\nseveral finite choices of lattice bare parameters. For the chimera baryons,\nwhich include candidate top-quark partners, we provide the first measurements,\nobtained with dynamical fermions, of the ground state and the lowest excited\nstate masses, in all channels of spin, isospin, and parity. We also measure\nmatrix elements and overlap factors, that are important to realize viable\nmodels of partial top compositeness, by implementing an innovative way of\nextracting this information from the spectral densities. For the mesons, among\nwhich the pseudoscalars can be reinterpreted to provide an extension of the\nHiggs sector of the Standard Model of particle physics, our measurements of the\nrenormalized matrix elements and decay constants are new results. We complement\nthem with an update of existing measurements of the meson masses, obtained with\nhigher statistics and improved analysis. The analysis software is made publicly\navailable, and can be used in other lattice studies, including application to\nquantum chromodynamics (QCD).",
            "pdf_url": "http://arxiv.org/pdf/2506.19804v1",
            "published": "2025-06-24 17:09:46+00:00",
            "updated": "2025-06-24 17:09:46+00:00"
        },
        {
            "title": "Noncontextual Pauli Hamiltonians",
            "authors": "Alexis Ralli, Tim Weaving, Peter J. Love",
            "summary": "Contextuality is a key feature of quantum mechanics, and identification of\nnoncontextual subtheories of quantum mechanics is of both fundamental and\npractical importance. Recently, noncontextual Pauli Hamiltonians have been\ndefined in the setting of variational quantum algorithms. In this work we\nrigorously establish a number of properties of noncontextual Pauli\nHamiltonians. We prove that these Hamiltonians can be composed of more Pauli\noperators than diagonal Hamiltonians. This establishes that noncontextual\nHamiltonians are able to describe a greater number of physical interactions. We\nthen show that the eigenspaces admit an efficient classical description. We\nanalyse the eigenspace of these Hamiltonians and prove that for every\neigenvalue there exists an associated eigenvector whose stabilizer rank scales\nlinearly with the number of qubits. We prove that further structure in these\nHamiltonians allow us to derive where degeneracies in the eigenspectrum can\narise. We thus open the field to a new class of efficiently simulatable states.",
            "pdf_url": "http://arxiv.org/pdf/2506.19778v1",
            "published": "2025-06-24 16:45:09+00:00",
            "updated": "2025-06-24 16:45:09+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Improving Progressive Generation with Decomposable Flow Matching",
            "authors": "Moayed Haji-Ali, Willi Menapace, Ivan Skorokhodov, Arpit Sahni, Sergey Tulyakov, Vicente Ordonez, Aliaksandr Siarohin",
            "summary": "Generating high-dimensional visual modalities is a computationally intensive\ntask. A common solution is progressive generation, where the outputs are\nsynthesized in a coarse-to-fine spectral autoregressive manner. While diffusion\nmodels benefit from the coarse-to-fine nature of denoising, explicit\nmulti-stage architectures are rarely adopted. These architectures have\nincreased the complexity of the overall approach, introducing the need for a\ncustom diffusion formulation, decomposition-dependent stage transitions,\nadd-hoc samplers, or a model cascade. Our contribution, Decomposable Flow\nMatching (DFM), is a simple and effective framework for the progressive\ngeneration of visual media. DFM applies Flow Matching independently at each\nlevel of a user-defined multi-scale representation (such as Laplacian pyramid).\nAs shown by our experiments, our approach improves visual quality for both\nimages and videos, featuring superior results compared to prior multistage\nframeworks. On Imagenet-1k 512px, DFM achieves 35.2% improvements in FDD scores\nover the base architecture and 26.4% over the best-performing baseline, under\nthe same training compute. When applied to finetuning of large models, such as\nFLUX, DFM shows faster convergence speed to the training distribution.\nCrucially, all these advantages are achieved with a single model, architectural\nsimplicity, and minimal modifications to existing training pipelines.",
            "pdf_url": "http://arxiv.org/pdf/2506.19839v1",
            "published": "2025-06-24 17:58:02+00:00",
            "updated": "2025-06-24 17:58:02+00:00"
        },
        {
            "title": "Machine Learning with Privacy for Protected Attributes",
            "authors": "Saeed Mahloujifar, Chuan Guo, G. Edward Suh, Kamalika Chaudhuri",
            "summary": "Differential privacy (DP) has become the standard for private data analysis.\nCertain machine learning applications only require privacy protection for\nspecific protected attributes. Using naive variants of differential privacy in\nsuch use cases can result in unnecessary degradation of utility. In this work,\nwe refine the definition of DP to create a more general and flexible framework\nthat we call feature differential privacy (FDP). Our definition is\nsimulation-based and allows for both addition/removal and replacement variants\nof privacy, and can handle arbitrary and adaptive separation of protected and\nnon-protected features. We prove the properties of FDP, such as adaptive\ncomposition, and demonstrate its implications for limiting attribute inference\nattacks. We also propose a modification of the standard DP-SGD algorithm that\nsatisfies FDP while leveraging desirable properties such as amplification via\nsub-sampling. We apply our framework to various machine learning tasks and show\nthat it can significantly improve the utility of DP-trained models when public\nfeatures are available. For example, we train diffusion models on the AFHQ\ndataset of animal faces and observe a drastic improvement in FID compared to\nDP, from 286.7 to 101.9 at $\\epsilon=8$, assuming that the blurred version of a\ntraining image is available as a public feature. Overall, our work provides a\nnew approach to private data analysis that can help reduce the utility cost of\nDP while still providing strong privacy guarantees.",
            "pdf_url": "http://arxiv.org/pdf/2506.19836v1",
            "published": "2025-06-24 17:53:28+00:00",
            "updated": "2025-06-24 17:53:28+00:00"
        },
        {
            "title": "ProxelGen: Generating Proteins as 3D Densities",
            "authors": "Felix Faltings, Hannes Stark, Regina Barzilay, Tommi Jaakkola",
            "summary": "We develop ProxelGen, a protein structure generative model that operates on\n3D densities as opposed to the prevailing 3D point cloud representations.\nRepresenting proteins as voxelized densities, or proxels, enables new tasks and\nconditioning capabilities. We generate proteins encoded as proxels via a 3D\nCNN-based VAE in conjunction with a diffusion model operating on its latent\nspace. Compared to state-of-the-art models, ProxelGen's samples achieve higher\nnovelty, better FID scores, and the same level of designability as the training\nset. ProxelGen's advantages are demonstrated in a standard motif scaffolding\nbenchmark, and we show how 3D density-based generation allows for more flexible\nshape conditioning.",
            "pdf_url": "http://arxiv.org/pdf/2506.19820v1",
            "published": "2025-06-24 17:35:55+00:00",
            "updated": "2025-06-24 17:35:55+00:00"
        },
        {
            "title": "Alleviating User-Sensitive bias with Fair Generative Sequential Recommendation Model",
            "authors": "Yang Liu, Feng Wu, Xuefang Zhu",
            "summary": "Recommendation fairness has recently attracted much attention. In the real\nworld, recommendation systems are driven by user behavior, and since users with\nthe same sensitive feature (e.g., gender and age) tend to have the same\npatterns, recommendation models can easily capture the strong correlation\npreference of sensitive features and thus cause recommendation unfairness.\nDiffusion model (DM) as a new generative model paradigm has achieved great\nsuccess in recommendation systems. DM's ability to model uncertainty and\nrepresent diversity, and its modeling mechanism has a high degree of\nadaptability with the real-world recommendation process with bias. Therefore,\nwe use DM to effectively model the fairness of recommendation and enhance the\ndiversity. This paper proposes a FairGENerative sequential Recommendation model\nbased on DM, FairGENRec. In the training phase, we inject random noise into the\noriginal distribution under the guidance of the sensitive feature recognition\nmodel, and a sequential denoise model is designed for the reverse\nreconstruction of items. Simultaneously, recommendation fairness modeling is\ncompleted by injecting multi-interests representational information that\neliminates the bias of sensitive user features into the generated results. In\nthe inference phase, the model obtains the noise in the form of noise addition\nby using the history interactions which is followed by reverse iteration to\nreconstruct the target item representation. Finally, our extensive experiments\non three datasets demonstrate the dual enhancement effect of FairGENRec on\naccuracy and fairness, while the statistical analysis of the cases visualizes\nthe degree of improvement on the fairness of the recommendation.",
            "pdf_url": "http://arxiv.org/pdf/2506.19777v1",
            "published": "2025-06-24 16:42:46+00:00",
            "updated": "2025-06-24 16:42:46+00:00"
        },
        {
            "title": "Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation",
            "authors": "Jun Wang, Xijuan Zeng, Chunyu Qiang, Ruilong Chen, Shiyao Wang, Le Wang, Wangjing Zhou, Pengfei Cai, Jiahui Zhao, Nan Li, Zihan Li, Yuzhe Liang, Xiaopeng Wang, Haorui Zheng, Ming Wen, Kang Yin, Yiran Wang, Nan Li, Feng Deng, Liang Dong, Chen Zhang, Di Zhang, Kun Gai",
            "summary": "We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation\nmodel that synthesizes high-quality audio synchronized with video content. In\nKling-Foley, we introduce multimodal diffusion transformers to model the\ninteractions between video, audio, and text modalities, and combine it with a\nvisual semantic representation module and an audio-visual synchronization\nmodule to enhance alignment capabilities. Specifically, these modules align\nvideo conditions with latent audio elements at the frame level, thereby\nimproving semantic alignment and audio-visual synchronization. Together with\ntext conditions, this integrated approach enables precise generation of\nvideo-matching sound effects. In addition, we propose a universal latent audio\ncodec that can achieve high-quality modeling in various scenarios such as sound\neffects, speech, singing, and music. We employ a stereo rendering method that\nimbues synthesized audio with a spatial presence. At the same time, in order to\nmake up for the incomplete types and annotations of the open-source benchmark,\nwe also open-source an industrial-level benchmark Kling-Audio-Eval. Our\nexperiments show that Kling-Foley trained with the flow matching objective\nachieves new audio-visual SOTA performance among public models in terms of\ndistribution matching, semantic alignment, temporal alignment and audio\nquality.",
            "pdf_url": "http://arxiv.org/pdf/2506.19774v1",
            "published": "2025-06-24 16:39:39+00:00",
            "updated": "2025-06-24 16:39:39+00:00"
        }
    ]
}