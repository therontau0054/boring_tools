{
    "Physics": [
        {
            "title": "Universal tradeoff relations between resource cost and irreversibility of channels: General-resource Wigner-Araki-Yanase theorems and beyond",
            "authors": "Hiroyasu Tajima, Koji Yamaguchi, Ryuji Takagi, Yui Kuramochi",
            "summary": "Quantum technologies offer exceptional -- sometimes almost magical -- speed\nand performance, yet every quantum process costs physical resources. Designing\nnext-generation quantum devices, therefore, depends on solving the following\nquestion: which resources, and in what amount, are required to implement a\ndesired quantum process? Casting the problem in the language of quantum\nresource theories, we prove a universal cost-irreversibility tradeoff: the\nlower the irreversibility of a quantum process, the greater the required\nresource cost for its realization. The trade-off law holds for a broad range of\nresources -- energy, magic, asymmetry, coherence, athermality, and others --\nyielding lower bounds on resource cost of any quantum channel. Its broad scope\npositions this result as a foundation for deriving the following key results:\n(1) we show a universal relation between the energetic cost and the\nirreversibility for arbitrary channels, encompassing the energy-error tradeoff\nfor any measurement or unitary gate; (2) we extend the energy-error tradeoff to\nfree energy and work costs; (3) we extend the Wigner-Araki-Yanase theorem,\nwhich is the universal limitation on measurements under conservation laws, to a\nwide class of resource theories: the probability of failure in distinguishing\nresourceful states via a measurement is inversely proportional to its resource\ncost; (4) we prove that infinitely many resource-non-increasing operations in\nfact require an infinite implementation cost. These findings reveal a universal\nrelationship between quantumness and irreversibility, providing a first step\ntoward a general theory that explains when -- and how -- quantumness can\nsuppress irreversibility.",
            "pdf_url": "http://arxiv.org/pdf/2507.23760v1",
            "published": "2025-07-31 17:48:14+00:00",
            "updated": "2025-07-31 17:48:14+00:00"
        },
        {
            "title": "Floquet Non-Bloch Formalism for a Non-Hermitian Ladder: From Theoretical Framework to Topolectrical Circuits",
            "authors": "Koustav Roy, Dipendu Halder, Koustabh Gogoi, B. Tanatar, Saurabh Basu",
            "summary": "Periodically driven systems intertwined with non-Hermiticity opens a rich\narena for topological phases that transcend conventional Hermitian limits. The\nphysical significance of these phases hinges on obtaining the topological\ninvariants that restore the bulk-boundary correspondence, a task well explored\nfor static non-Hermitian (NH) systems, while it remains elusive for the driven\nscenario. Here, we address this problem by constructing a generalized Floquet\nnon-Bloch framework that analytically captures the spectral and topological\nproperties of time-periodic NH systems. Em- ploying a high-frequency Magnus\nexpansion, we analytically derive an effective Floquet Hamiltonian and\nformulate the generalized Brillouin zone for a periodically driven\nquasi-one-dimensional system, namely, the Creutz ladder with a staggered\ncomplex potential. Our study demonstrates that the skin effect remains robust\n(despite the absence of non-reciprocal hopping) across a broad range of driving\nparameters, and is notably amplified in the low-frequency regime due to\nemergent longer- range couplings. We further employ a symmetric time frame\napproach that generates chiral-partner Hamiltonians, whose invariants, when\nappropriately combined, account for the full edge-state struc- ture. To\nsubstantiate the theoretical framework, we propose a topolectrical circuit\n(TEC) that serves as a viable experimental setting. Apart from capturing the\nskin modes, the proposed TEC design faithfully reproduces the presence of\ndistinct Floquet edge states, as revealed through the voltage and impedance\nprofiles, respectively. Thus, our work not only offers a theoretical framework\nfor exploring NH-driven systems, but also provides an experimentally feasible\nTEC architecture for realizing these phenomena stated above in a laboratory.",
            "pdf_url": "http://arxiv.org/pdf/2507.23744v1",
            "published": "2025-07-31 17:31:02+00:00",
            "updated": "2025-07-31 17:31:02+00:00"
        },
        {
            "title": "Search for $t\\bar tt\\bar tW$ Production at $\\sqrt{s} = 13$ TeV Using a Modified Graph Neural Network at the LHC",
            "authors": "Syed Haider Ali, Ashfaq Ahmad, Muhammad Saiel, Nadeem Shaukat",
            "summary": "The simultaneous production of four top quarks in association with a ($W$)\nboson at $(\\sqrt{s} = 13)$ TeV is an rare SM process with a\nnext-to-leading-order (NLO) cross-section of $(6.6^{+2.4}_{-2.6}\n{ab})$\\cite{saiel}. Identifying this process in the fully hadronic decay\nchannel is particularly challenging due to overwhelming backgrounds from\n$t\\bar{t}, t\\bar{t}W, t\\bar{t}Z$, and triple-top production processes. This\nstudy introduces a modified physics informed Neural Network, a hybrid graph\nneural network (GNN) enhancing event classification. The proposed model\nintegrates Graph layers for particle-level features, a custom Multi Layer\nPerceptron(MLP) based global stream with a quantum circuit and cross-attention\nfusion to combine local and global representations. Physics-informed Loss\nfunction enforce jet multiplicity constraints, derived from event decay\ndynamics. Benchmarked against conventional methods, the GNN achieves a signal\nsignificance $(S/\\sqrt{S+B})$ of $0.174$ and ROC-AUC of 0.974, surpassing BDT's\nsignificance of $0.148$ and ROC of $0.913$, while Xgboost achieves a\nsignificance of $0.149$ and ROC of $0.920$. The classification models are\ntrained on Monte Carlo (MC) simulations, with events normalized using\ncross-section-based reweighting to reflect their expected contributions in a\ndataset corresponding to $350\\;$fb$^{-1}$ of integrated luminosity. This\nenhanced approach offers a framework for precision event selection at the LHC,\nleveraging high dimensional statistical learning and physics informed inference\nto tackle fundamental HEP challenges, aligning with ML developments.",
            "pdf_url": "http://arxiv.org/pdf/2507.23723v1",
            "published": "2025-07-31 16:57:08+00:00",
            "updated": "2025-07-31 16:57:08+00:00"
        },
        {
            "title": "Chirality structure of vector like new physics operators in charged current transitions",
            "authors": "Sajawal Zafar, Qazi Maaz Us Salam, Rana Khan, Ishtiaq Ahmed, Rizwan Khalid",
            "summary": "We investigate the cascade decay $B^{*0}_{s} \\rightarrow D_s^-(\\rightarrow\n\\tau^-\\,\\bar\\nu_{\\tau})\\,\\ell^{+}\\,{\\nu}_\\ell$ induced by flavor changing\ncharged currents in the context of the Standard Model and in vector-like\ncouplings beyond the Standard Model. We employ the helicity amplitude formalism\nfor analysis and highlight the role of new vector-like couplings in charged\ncurrent interactions. We find, in particular, that while new left handed\nchiral-vector like interactions contribute to the branching ratio, they do not\naffect the forward-backward asymmetry, or the angular observables. On the other\nhand, the right handed chiral vector-like coupling in the case of this decay\ncontributes to the branching ratio, forward-backward asymmetry and the angular\nobservables. We confirm that this difference in behavior between the left and\nright handed NP couplings is a general feature of charged current processes\nwith a vector meson going to a pseudoscalar at the tree level in effective weak\ntheory by cross checking with the cascade decays $B^{*+}_c \\rightarrow\nP(\\rightarrow P'\\,\\mu^+\\,\\nu_{\\mu})\\,\\ell^{+}\\,{\\nu}_\\ell$ where $P$ is $B_s^0$\n($D^0$) and $P'$ is $D_s^{*-}$ ($K^-$).",
            "pdf_url": "http://arxiv.org/pdf/2507.23721v1",
            "published": "2025-07-31 16:56:32+00:00",
            "updated": "2025-07-31 16:56:32+00:00"
        },
        {
            "title": "Multi-Gap superconductivity in HgS under pressure",
            "authors": "Pietro Maria Forcella, Cesare Tresca, Antonio Sanna, Gianni Profeta",
            "summary": "Mercury chalcogenides is a class of materials that exhibit diverse structural\nphases under pressure, hosting exotic physical properties, including\ntopological phases and chiral phonons. In particular, recent experimental\nresults on HgS reports a new superconducting phase at 21 GPa, whose origin is\nunknown. In this letter we theoretically investigate the pressure-induced\nstructural phase transition in HgS and the emergence of superconductivity in\nthe rock salt phase. Remarkably, we discover that the rock salt phase hosts a\ntwo-gap superconducting phase originating from distinct Fermi surfaces. The\nunusually high critical temperature of 11 K emerges naturally within this\nmultiband scenario, highlighting the role of interband coupling beyond\nisotropic approximation. These results place HgS among the few systems where\nmultiband superconductivity is observed.",
            "pdf_url": "http://arxiv.org/pdf/2507.21869v3",
            "published": "2025-07-29 14:41:19+00:00",
            "updated": "2025-07-31 16:38:01+00:00"
        },
        {
            "title": "High-resolution eikonal imaging and uncertainty quantification of the Kilauea caldera",
            "authors": "Angela F. Gao, John D. Wilding, Ettore Biondi, Katherine L. Bouman, Zachary E. Ross",
            "summary": "Images of the Earth's interior can provide us with insight into the\nunderlying properties of the Earth, such as how seismic activity might emerge\nand the interplay between seismic and volcanic activity. Understanding these\nsystems requires reliable high-resolution images to understand mechanisms and\nestimate physical quantities. However, reliable images are often difficult to\nobtain due to the non-linear nature of seismic wave propagation and the\nill-posedness of the related inverse problem. Reconstructions rely on good\ninitial estimates as well as hand-crafted priors, which can ultimately bias\nsolutions. In our work, we present a 3D reconstruction of Kilauea's magmatic\nsystem at a previously unattained resolution. Our eikonal tomography procedure\nimproves upon prior imaging results of Kilauea through increased resolution and\nper-pixel uncertainties estimated through variational inference. In particular,\nsolving eikonal imaging using variational inference with stochastic gradient\ndescent enables stable inversion and uncertainty quantification in the absence\nof strong prior knowledge of the velocity structure. Our work makes two key\ncontributions: developing a stochastic eikonal tomography scheme with\nuncertainty quantification and illuminating the structure and melt quantity of\nthe magmatic system that underlies Kilauea.",
            "pdf_url": "http://arxiv.org/pdf/2507.23692v1",
            "published": "2025-07-31 16:09:33+00:00",
            "updated": "2025-07-31 16:09:33+00:00"
        },
        {
            "title": "Families of $d=2$ 2D subsystem stabilizer codes for universal Hamiltonian quantum computation with two-body interactions",
            "authors": "Phattharaporn Singkanipa, Zihan Xia, Daniel A. Lidar",
            "summary": "In the absence of fault tolerant quantum error correction for analog,\nHamiltonian quantum computation, error suppression via energy penalties is an\neffective alternative. We construct families of distance-$2$ stabilizer\nsubsystem codes we call ``trapezoid codes'', that are tailored for\nenergy-penalty schemes. We identify a family of codes achieving the maximum\ncode rate, and by slightly relaxing this constraint, uncover a broader range of\ncodes with enhanced physical locality, thus increasing their practical\napplicability. Additionally, we provide an algorithm to map the required qubit\nconnectivity graph into graphs compatible with the locality constraints of\nquantum hardware. Finally, we provide a systematic framework to evaluate the\nperformance of these codes in terms of code rate, physical locality, graph\nproperties, and penalty gap, enabling an informed selection of\nerror-suppression codes for specific quantum computing applications. We\nidentify the $[[4k+2,2k,g,2]]$ family of subsystem codes as optimal in terms of\ncode rate and penalty gap scaling.",
            "pdf_url": "http://arxiv.org/pdf/2412.06744v3",
            "published": "2024-12-09 18:36:38+00:00",
            "updated": "2025-07-31 15:56:58+00:00"
        },
        {
            "title": "Recovering Hidden Degrees of Freedom Using Gaussian Processes",
            "authors": "Georg Diez, Nele Dethloff, Gerhard Stock",
            "summary": "Dimensionality reduction represents a crucial step in extracting meaningful\ninsights from Molecular Dynamics (MD) simulations. Conventional approaches,\nincluding linear methods such as principal component analysis as well as\nvarious autoencoder architectures, typically operate under the assumption of\nindependent and identically distributed data, disregarding the sequential\nnature of MD simulations. Here, we introduce a physics-informed representation\nlearning framework that leverages Gaussian Processes combined with variational\nautoencoders to exploit the temporal dependencies inherent in MD data.\nTime-dependent kernel functions--such as the Mat\\'ern kernel--directly impose\nthe temporal correlation structure of the input coordinates onto a\nlow-dimensional space, preserving Markovianity in the reduced representation\nwhile faithfully capturing the essential dynamics. Using a three-dimensional\ntoy model, we demonstrate that this approach can successfully identify and\nseparate dynamically distinct states that are geometrically indistinguishable\ndue to hidden degrees of freedom. Applying the framework to a $50\\,\\mu$s-long\nMD trajectory of T4 lysozyme, we uncover dynamically distinct conformational\nsubstates that previous analyses failed to resolve, revealing functional\nrelationships that become apparent only when temporal correlations are taken\ninto account. This time-aware perspective provides a promising framework for\nunderstanding complex biomolecular systems, in which conventional collective\nvariables fail to capture the full dynamical picture.",
            "pdf_url": "http://arxiv.org/pdf/2505.18072v2",
            "published": "2025-05-23 16:17:52+00:00",
            "updated": "2025-07-31 15:52:43+00:00"
        },
        {
            "title": "Cheng's eigenvalue comparison on metric measure spaces and applications",
            "authors": "G. Bruno De Luca, Nicol\u00f2 De Ponti, Andrea Mondino, Alessandro Tomasiello",
            "summary": "Using the localization technique, we prove a sharp upper bound on the first\nDirichlet eigenvalue of metric balls in essentially non-branching\n$\\mathsf{CD}^{\\star}(K,N)$ spaces. This extends a celebrated result of Cheng to\nthe non-smooth setting of metric measure spaces satisfying Ricci curvature\nlower bounds in a synthetic sense, via optimal transport. A rigidity statement\nis also provided for $\\mathsf{RCD}^{\\star}(K,N)$ spaces. We then present some\nmathematical and physical applications: in the former, we obtain an upper bound\non the $j^{th}$ Neumann eigenvalue in essentially non-branching\n$\\mathsf{CD}^{\\star}(K,N)$ spaces and a bound on the essential spectrum in\nnon-compact $\\mathsf{RCD}^{\\star}(K,N)$ spaces; in the latter, the eigenvalue\nbounds correspond to general upper bounds on the masses of the spin-2\nKaluza-Klein excitations around general warped compactifications of\nhigher-dimensional theories of gravity.",
            "pdf_url": "http://arxiv.org/pdf/2507.23671v1",
            "published": "2025-07-31 15:49:18+00:00",
            "updated": "2025-07-31 15:49:18+00:00"
        },
        {
            "title": "Testing New Physics in Oscillations at a Neutrino Factory",
            "authors": "Peter B. Denton, Julia Gehrlein, Chui-Fan Kong",
            "summary": "A neutrino factory is a potential successor to the upcoming generation of\nneutrino oscillation experiments and a possible precursor to next-generation\nmuon colliders. Such a machine would provide a well-characterized beam of\n$\\nu_\\mu$, $\\bar\\nu_\\mu$, $\\nu_e$, and $\\bar\\nu_e$ neutrinos with comparable\nstatistics. Here we show the sensitivity of a neutrino factory to new\noscillation physics scenarios such as vector neutrino non-standard interactions\nand CPT violation. We study two different potential setups for a neutrino\nfactory with different assumptions on charge identification in the far\ndetector. We find that 10 years of a neutrino factory combined with 10 years of\nDUNE can improve over most of the current constraints on these scenarios and\neven over forecasted constraints by 20 years of DUNE. Additionally, we find\nthat a neutrino factory can break degeneracies between the standard oscillation\nparameters and neutrino non-standard interaction parameters present at DUNE.",
            "pdf_url": "http://arxiv.org/pdf/2502.14027v2",
            "published": "2025-02-19 19:00:00+00:00",
            "updated": "2025-07-31 15:43:37+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions",
            "authors": "Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata",
            "summary": "Concept Bottleneck Models (CBMs) and other concept-based interpretable models\nshow great promise for making AI applications more transparent, which is\nessential in fields like medicine. Despite their success, we demonstrate that\nCBMs struggle to reliably identify the correct concepts under distribution\nshifts. To assess the robustness of CBMs to concept variations, we introduce\nSUB: a fine-grained image and concept benchmark containing 38,400 synthetic\nimages based on the CUB dataset. To create SUB, we select a CUB subset of 33\nbird classes and 45 concepts to generate images which substitute a specific\nconcept, such as wing color or belly pattern. We introduce a novel Tied\nDiffusion Guidance (TDG) method to precisely control generated images, where\nnoise sharing for two parallel denoising processes ensures that both the\ncorrect bird class and the correct attribute are generated. This novel\nbenchmark enables rigorous evaluation of CBMs and similar interpretable models,\ncontributing to the development of more robust methods. Our code is available\nat https://github.com/ExplainableML/sub and the dataset at\nhttp://huggingface.co/datasets/Jessica-bader/SUB.",
            "pdf_url": "http://arxiv.org/pdf/2507.23784v1",
            "published": "2025-07-31 17:59:40+00:00",
            "updated": "2025-07-31 17:59:40+00:00"
        },
        {
            "title": "Learning to Align and Refine: A Foundation-to-Diffusion Framework for Occlusion-Robust Two-Hand Reconstruction",
            "authors": "Gaoge Han, Yongkang Cheng, Zhe Chen, Shaoli Huang, Tongliang Liu",
            "summary": "Two-hand reconstruction from monocular images faces persistent challenges due\nto complex and dynamic hand postures and occlusions, causing significant\ndifficulty in achieving plausible interaction alignment. Existing approaches\nstruggle with such alignment issues, often resulting in misalignment and\npenetration artifacts. To tackle this, we propose a dual-stage\nFoundation-to-Diffusion framework that precisely align 2D prior guidance from\nvision foundation models and diffusion-based generative 3D interaction\nrefinement to achieve occlusion-robust two-hand reconstruction. First, we\nintroduce a lightweight fusion alignment encoder that aligns fused multimodal\n2D priors like key points, segmentation maps, and depth cues from vision\nfoundation models during training. This provides robust structured guidance,\nfurther enabling efficient inference without heavy foundation model encoders at\ntest time while maintaining high reconstruction accuracy. Second, we implement\na two-hand diffusion model explicitly trained to convert interpenetrated 3D\nposes into plausible, penetration-free counterparts. Through collision\ngradient-guided denoising, the model rectifies artifacts while preserving\nnatural spatial relationships between hands. Extensive evaluations demonstrate\nthat our method achieves state-of-the-art performance on InterHand2.6M, HIC,\nand FreiHAND datasets, significantly advancing occlusion handling and\ninteraction robustness. Our code will be publicly released.",
            "pdf_url": "http://arxiv.org/pdf/2503.17788v2",
            "published": "2025-03-22 14:42:27+00:00",
            "updated": "2025-07-31 17:55:56+00:00"
        },
        {
            "title": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data",
            "authors": "Rabeya Tus Sadia, Qiang Cheng",
            "summary": "Microbiome data analysis is essential for understanding host health and\ndisease, yet its inherent sparsity and noise pose major challenges for accurate\nimputation, hindering downstream tasks such as biomarker discovery. Existing\nimputation methods, including recent diffusion-based models, often fail to\ncapture the complex interdependencies between microbial taxa and overlook\ncontextual metadata that can inform imputation. We introduce DepMicroDiff, a\nnovel framework that combines diffusion-based generative modeling with a\nDependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise\ndependencies and autoregressive relationships. DepMicroDiff is further enhanced\nby VAE-based pretraining across diverse cancer datasets and conditioning on\npatient metadata encoded via a large language model (LLM). Experiments on TCGA\nmicrobiome datasets show that DepMicroDiff substantially outperforms\nstate-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),\ncosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer\ntypes, demonstrating its robustness and generalizability for microbiome\nimputation.",
            "pdf_url": "http://arxiv.org/pdf/2507.23676v1",
            "published": "2025-07-31 15:51:41+00:00",
            "updated": "2025-07-31 15:51:41+00:00"
        },
        {
            "title": "One-Step Flow Policy Mirror Descent",
            "authors": "Tianyi Chen, Haitong Ma, Na Li, Kai Wang, Bo Dai",
            "summary": "Diffusion policies have achieved great success in online reinforcement\nlearning (RL) due to their strong expressive capacity. However, the inference\nof diffusion policy models relies on a slow iterative sampling process, which\nlimits their responsiveness. To overcome this limitation, we propose Flow\nPolicy Mirror Descent (FPMD), an online RL algorithm that enables 1-step\nsampling during policy inference. Our approach exploits a theoretical\nconnection between the distribution variance and the discretization error of\nsingle-step sampling in straight interpolation flow matching models, and\nrequires no extra distillation or consistency training. We present two\nalgorithm variants based on flow policy and MeanFlow policy parametrizations,\nrespectively. Extensive empirical evaluations on MuJoCo benchmarks demonstrate\nthat our algorithms show strong performance comparable to diffusion policy\nbaselines while requiring hundreds of times fewer function evaluations during\ninference.",
            "pdf_url": "http://arxiv.org/pdf/2507.23675v1",
            "published": "2025-07-31 15:51:10+00:00",
            "updated": "2025-07-31 15:51:10+00:00"
        },
        {
            "title": "DivControl: Knowledge Diversion for Controllable Image Generation",
            "authors": "Yucheng Xie, Fu Feng, Ruixiao Shi, Jing Wang, Yong Rui, Xin Geng",
            "summary": "Diffusion models have advanced from text-to-image (T2I) to image-to-image\n(I2I) generation by incorporating structured inputs such as depth maps,\nenabling fine-grained spatial control. However, existing methods either train\nseparate models for each condition or rely on unified architectures with\nentangled representations, resulting in poor generalization and high adaptation\ncosts for novel conditions. To this end, we propose DivControl, a decomposable\npretraining framework for unified controllable generation and efficient\nadaptation. DivControl factorizes ControlNet via SVD into basic\ncomponents-pairs of singular vectors-which are disentangled into\ncondition-agnostic learngenes and condition-specific tailors through knowledge\ndiversion during multi-condition training. Knowledge diversion is implemented\nvia a dynamic gate that performs soft routing over tailors based on the\nsemantics of condition instructions, enabling zero-shot generalization and\nparameter-efficient adaptation to novel conditions. To further improve\ncondition fidelity and training efficiency, we introduce a representation\nalignment loss that aligns condition embeddings with early diffusion features.\nExtensive experiments demonstrate that DivControl achieves state-of-the-art\ncontrollability with 36.4$\\times$ less training cost, while simultaneously\nimproving average performance on basic conditions. It also delivers strong\nzero-shot and few-shot performance on unseen conditions, demonstrating superior\nscalability, modularity, and transferability.",
            "pdf_url": "http://arxiv.org/pdf/2507.23620v1",
            "published": "2025-07-31 15:00:15+00:00",
            "updated": "2025-07-31 15:00:15+00:00"
        }
    ]
}