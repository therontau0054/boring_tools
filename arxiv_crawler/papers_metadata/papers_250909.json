{
    "Physics": [
        {
            "title": "Neutron Reflectometry by Gradient Descent",
            "authors": "Max D. ~Champneys, Andrew J. ~Parnell, Philipp Gutfreund, Maximilian W. A. Skoda, . Patrick A. Fairclough, Timothy J. ~Rogers, Stephanie L. ~Burg",
            "summary": "Neutron reflectometry (NR) is a powerful technique to probe surfaces and\ninterfaces. NR is inherently an indirect measurement technique, access to the\nphysical quantities of interest (layer thickness, scattering length density,\nroughness), necessitate the solution of an inverse modelling problem, that is\ninefficient for large amounts of data or complex multiplayer structures (e.g.\nlithium batteries / electrodes). Recently, surrogate machine learning models\nhave been proposed as an alternative to existing optimisation routines.\nAlthough such approaches have been successful, physical intuition is lost when\nreplacing governing equations with fast neural networks. Instead, we propose a\nnovel and efficient approach; to optimise reflectivity data analysis by\nperforming gradient descent on the forward reflection model itself. Herein,\nautomatic differentiation techniques are used to evaluate exact gradients of\nthe error function with respect to the parameters of interest. Access to these\nquantities enables users of neutron reflectometry to harness a host of powerful\nmodern optimisation and inference techniques that remain thus far unexploited\nin the context of neutron reflectometry. This paper presents two benchmark case\nstudies; demonstrating state-of-the-art performance on a thick oxide quartz\nfilm, and robust co-fitting performance in the high complexity regime of\norganic LED multilayer devices. Additionally, we provide an open-source library\nof differentiable reflectometry kernels in the python programming language so\nthat gradient based approaches can readily be applied to other NR datasets.",
            "pdf_url": "http://arxiv.org/pdf/2509.06924v1",
            "published": "2025-09-08 17:38:01+00:00",
            "updated": "2025-09-08 17:38:01+00:00"
        },
        {
            "title": "On CP-violation and quark masses: reducing the number of free parameters",
            "authors": "A. Kleppe",
            "summary": "A physically viable ansatz for quark mass matrices must satisfy certain\nconstraints, like the constraint imposed by CP-violation. In this article we\nstudy a concrete example, by looking at some generic matrices with a nearly\ndemocratic texture, and the implications of the constraints imposed by\nCP-violation, specifically the Jarlskog invariant. This constraint reduces the\nnumber of parameters from six to five, implying that the six mass eigenvalues\nof the up-quarks and the down-quarks are interdependent, which in our approach\nis explicitly demonstrated.",
            "pdf_url": "http://arxiv.org/pdf/2508.11081v2",
            "published": "2025-08-14 21:31:53+00:00",
            "updated": "2025-09-08 17:37:36+00:00"
        },
        {
            "title": "Targets for Flavor-Violating Top Decay",
            "authors": "Wolfgang Altmannshofer, Zev Balme, Christopher M. Donohue, Stefania Gori, Siddharth Vignesh Mukundhan",
            "summary": "Analyticity and unitarity constrain certain classe of new physics models by\nlinking flavor-conserving and flavor-violating four-fermion interactions. In\nthis work, we explore how these theoretical relations impact flavor-violating\nrare top quark decays. Building on our previous results, we present an updated\nanalysis of the decays $t \\to q \\ell^+ \\ell^-$ and identify interesting target\nbranching ratios in the range of $10^{-7}$ to $10^{-6}$ once current\nexperimental constraints from flavor-conserving processes are taken into\naccount. We extend the analysis to top decays with lepton flavor violation,\nderiving correlations among the relevant Wilson coefficients and confronting\nthem with existing limits from LEP and the LHC. Notably, we find that current\nsearches for $t \\to q e \\mu$ are already probing theoretically motivated\nregions of parameter space. These results strongly support continued efforts to\nexplore flavor-violating top decays as a powerful probe of new physics.",
            "pdf_url": "http://arxiv.org/pdf/2504.18664v2",
            "published": "2025-04-25 19:37:39+00:00",
            "updated": "2025-09-08 17:13:25+00:00"
        },
        {
            "title": "Tensor Network based Gene Regulatory Network Inference for Single-Cell Transcriptomic Data",
            "authors": "Olatz Sanz Larrarte, Borja Aizpurua, Reza Dastbasteh, Ruben M. Otxoa, Josu Etxezarreta Martinez",
            "summary": "Deciphering complex gene-gene interactions remains challenging in\ntranscriptomics as traditional methods often miss higher-order and nonlinear\ndependencies. This study introduces a quantum-inspired framework leveraging\ntensor networks (TNs) to optimally map expression data into a lower dimensional\nrepresentation preserving biological locality. Using Quantum Mutual Information\n(QMI), a nonparametric measure natural for tensor networks, we quantify gene\ndependencies and establish statistical significance via permutation testing.\nThis constructs robust interaction networks where the edges reflect\nbiologically meaningful relationships that are resilient to random chance. The\napproach effectively distinguishes true regulatory patterns from experimental\nnoise and biological stochasticity. To test the proposed method, we recover a\ngene regulatory network consisted of six pathway genes from single-cell RNA\nsequencing data comprising over $28.000$ lymphoblastoid cells. Furthermore, we\nunveil several triadic regulatory mechanisms. By merging quantum physics\ninspired techniques with computational biology, our method provides novel\ninsights into gene regulation, with applications in disease mechanisms and\nprecision medicine.",
            "pdf_url": "http://arxiv.org/pdf/2509.06891v1",
            "published": "2025-09-08 17:11:12+00:00",
            "updated": "2025-09-08 17:11:12+00:00"
        },
        {
            "title": "LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation",
            "authors": "Yinglin Duan, Zhengxia Zou, Tongwei Gu, Wei Jia, Zhan Zhao, Luyi Xu, Xinzhu Liu, Yenan Lin, Hao Jiang, Kang Chen, Shuang Qiu",
            "summary": "Recent research has been increasingly focusing on developing 3D world models\nthat simulate complex real-world scenarios. World models have found broad\napplications across various domains, including embodied AI, autonomous driving,\nentertainment, etc. A more realistic simulation with accurate physics will\neffectively narrow the sim-to-real gap and allow us to gather rich information\nabout the real world conveniently. While traditional manual modeling has\nenabled the creation of virtual 3D scenes, modern approaches have leveraged\nadvanced machine learning algorithms for 3D world generation, with most recent\nadvances focusing on generative methods that can create virtual worlds based on\nuser instructions. This work explores such a research direction by proposing\nLatticeWorld, a simple yet effective 3D world generation framework that\nstreamlines the industrial production pipeline of 3D environments. LatticeWorld\nleverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering\nengine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed\nframework accepts textual descriptions and visual instructions as multimodal\ninputs and creates large-scale 3D interactive worlds with dynamic agents,\nfeaturing competitive multi-agent interaction, high-fidelity physics\nsimulation, and real-time rendering. We conduct comprehensive experiments to\nevaluate LatticeWorld, showing that it achieves superior accuracy in scene\nlayout generation and visual fidelity. Moreover, LatticeWorld achieves over a\n$90\\times$ increase in industrial production efficiency while maintaining high\ncreative quality compared with traditional manual production methods. Our demo\nvideo is available at https://youtu.be/8VWZXpERR18",
            "pdf_url": "http://arxiv.org/pdf/2509.05263v2",
            "published": "2025-09-05 17:22:33+00:00",
            "updated": "2025-09-08 17:05:47+00:00"
        },
        {
            "title": "Characterization of low-nitrogen quantum diamond for pulsed magnetometry applications",
            "authors": "Jiashen Tang, Connor A. Roncaioli, Andrew M. Edmonds, Atli Davidsson, Connor A. Hart, Matthew L. Markham, Ronald L. Walsworth",
            "summary": "Ensembles of nitrogen-vacancy (NV) centers in diamond are versatile quantum\nsensors with broad applications in the physical and life sciences. The\nconcentration of neutral substitutional nitrogen ([N$_\\text{s}^0$]) strongly\ninfluences coherence times, sensitivity, and optimal sensing strategies.\nDiamonds with [N$_\\text{s}^0$] $\\sim\\,1-10\\,\\text{ppm}$ are a focus of recent\nmaterial engineering efforts, with higher concentrations being favorable for\ncontinuous-wave optically detected magnetic resonance (CW-ODMR) and lower\nconcentrations expected to benefit pulsed magnetometry techniques through\nextended NV electronic spin coherence times and improved sensing duty cycles.\nIn this work, we synthesize and characterize low-[N$_\\text{s}^0$]\n($\\sim\\,0.8\\,\\text{ppm}$), NV-enriched diamond material, engineered through\nlow-strain chemical vapor deposition (CVD) growth on high-quality substrates,\n$^{12}$C isotopic purification, and controlled electron irradiation and\nannealing. Our results demonstrate good strain homogeneity in diamonds grown on\nCVD substrates and spin-bath-limited NV dephasing times. By measuring NV spin\nand charge properties across a wide range of optical NV excitation intensity,\nwe provide direct comparisons of photon-shot-noise-limited magnetic sensitivity\nbetween the current low-[$\\text{N}_\\text{s}^0$] and previously studied\nhigher-[$\\text{N}_\\text{s}^0$] ($\\sim\\,14\\,\\text{ppm}$) NV-diamond sensors. We\nshow that low-[N$_\\text{s}^0$] diamond can outperform higher-[N$_\\text{s}^0$]\ndiamond at moderate and low optical NV excitation intensity. Our results\nprovide practical benchmarks and guidance for selecting NV-diamond sensors\ntailored to specific experimental constraints and sensing requirements.",
            "pdf_url": "http://arxiv.org/pdf/2509.06884v1",
            "published": "2025-09-08 17:02:46+00:00",
            "updated": "2025-09-08 17:02:46+00:00"
        },
        {
            "title": "Benchmarking Single-Qubit Gates on a Neutral Atom Quantum Processor",
            "authors": "Artem Rozanov, Boris Bantysh, Ivan Bobrov, Gleb Struchalin, Stanislav Straupe",
            "summary": "We present benchmarking results for single-qubit gates implemented on a\nneutral atom quantum processor using Direct Randomized Benchmarking (DRB) and\nGate Set Tomography (GST). The DRB protocol involves preparing stabilizer\nstates, applying $m$ layers of native single-qubit gates, and measuring in the\ncomputational basis, providing an efficient error characterization under a\nstochastic Pauli noise model. GST enables the full, self-consistent\nreconstruction of quantum processes, including gates, input states, and\nmeasurements. Both protocols provide robust to state preparation and\nmeasurement (SPAM) errors estimations of gate performance, offering\ncomplementary perspectives on quantum gate fidelity. For single-qubit gates,\nDRB yields an average fidelity of $99.963 \\pm 0.016\\%$. The protocol was\nfurther applied to a 25-qubit array under global single-qubit control. GST\nresults are consistent with those obtained via DRB. We also introduce a gauge\noptimization procedure for GST that brings the reconstructed gates, input\nstates, and measurements into a canonical frame, enabling meaningful fidelity\ncomparisons while preserving physical constraints. These constraints of the\noperators -- such as complete positivity and trace preservation -- are enforced\nby performing the optimization over the Stiefel manifold. The combined analysis\nsupports the use of complementary benchmarking techniques for characterizing\nscalable quantum architectures.",
            "pdf_url": "http://arxiv.org/pdf/2509.06881v1",
            "published": "2025-09-08 16:58:44+00:00",
            "updated": "2025-09-08 16:58:44+00:00"
        },
        {
            "title": "Quantum convolutional neural networks for jet images classification",
            "authors": "Hala Elhag, Tobias Hartung, Karl Jansen, Lento Nagano, Giorgio Menicagli Pirina, Alice Di Tucci",
            "summary": "Recently, interest in quantum computing has significantly increased, driven\nby its potential advantages over classical techniques. Quantum machine learning\n(QML) exemplifies one of the important quantum computing applications that are\nexpected to surpass classical machine learning in a wide range of instances.\nThis paper addresses the performance of QML in the context of high-energy\nphysics (HEP). As an example, we focus on the top-quark tagging, for which\nclassical convolutional neural networks (CNNs) have been effective but fall\nshort in accuracy when dealing with highly energetic jet images. In this paper,\nwe use a quantum convolutional neural network (QCNN) for this task and compare\nits performance with CNN using a classical noiseless simulator. We compare\nvarious setups for the QCNN, varying the convolutional circuit, type of\nencoding, loss function, and batch sizes. For every quantum setup, we design a\nsimilar setup to the corresponding classical model for a fair comparison. Our\nresults indicate that QCNN with proper setups tend to perform better than their\nCNN counterparts, particularly when the convolution block has a lower number of\nparameters. For the higher parameter regime, the QCNN circuit was adjusted\naccording to the dimensional expressivity analysis (DEA) to lower the parameter\ncount while preserving its optimal structure. The DEA circuit demonstrated\nimproved results over the comparable classical CNN model.",
            "pdf_url": "http://arxiv.org/pdf/2408.08701v3",
            "published": "2024-08-16 12:28:10+00:00",
            "updated": "2025-09-08 16:49:50+00:00"
        },
        {
            "title": "Learning spatially structured open quantum dynamics with regional-attention transformers",
            "authors": "Dounan Du, Eden Figueroa",
            "summary": "Simulating the dynamics of open quantum systems with spatial structure and\nexternal control is an important challenge in quantum information science.\nClassical numerical solvers for such systems require integrating coupled master\nand field equations, which is computationally demanding for simulation and\noptimization tasks and often precluding real-time use in network-scale\nsimulations or feedback control. We introduce a regional attention-based neural\narchitecture that learns the spatiotemporal dynamics of structured open quantum\nsystems. The model incorporates translational invariance of physical laws as an\ninductive bias to achieve scalable complexity, and supports conditioning on\ntime-dependent global control parameters. We demonstrate learning on two\nrepresentative systems: a driven dissipative single qubit and an\nelectromagnetically induced transparency (EIT) quantum memory. The model\nachieves high predictive fidelity under both in-distribution and\nout-of-distribution control protocols, and provides substantial acceleration up\nto three orders of magnitude over numerical solvers. These results demonstrate\nthat the architecture establishes a general surrogate modeling framework for\nspatially structured open quantum dynamics, with immediate relevance to\nlarge-scale quantum network simulation, quantum repeater and protocol design,\nreal-time experimental optimization, and scalable device modeling across\ndiverse light-matter platforms.",
            "pdf_url": "http://arxiv.org/pdf/2509.06871v1",
            "published": "2025-09-08 16:40:32+00:00",
            "updated": "2025-09-08 16:40:32+00:00"
        },
        {
            "title": "Seeing the Forest Through the Trees: Knowledge Retrieval for Streamlining Particle Physics Analysis",
            "authors": "James McGreivy, Blaise Delaney, Anja Beck, Mike Williams",
            "summary": "Generative Large Language Models (LLMs) are a promising approach to\nstructuring knowledge contained within the corpora of research literature\nproduced by large-scale and long-running scientific collaborations. Within\nexperimental particle physics, such structured knowledge bases could expedite\nmethodological and editorial review. Complementarily, within the broader\nscientific community, generative LLM systems grounded in published work could\nmake for reliable companions allowing non-experts to analyze open-access data.\nTechniques such as Retrieval Augmented Generation (RAG) rely on semantically\nmatching localized text chunks, but struggle to maintain coherent context when\nrelevant information spans multiple segments, leading to a fragmented\nrepresentation devoid of global cross-document information. Here, we utilize\nthe hierarchical organization of experimental physics articles to build a tree\nrepresentation of the corpus, and present the SciTreeRAG system that uses this\nstructure to create contexts that are more focused and contextually rich than\nstandard RAG. Additionally, we develop methods for using LLMs to transform the\nunstructured corpus into a structured knowledge graph representation. We then\nimplement SciGraphRAG, a retrieval system that leverages this knowledge graph\nto access global cross-document relationships eluding standard RAG, thereby\nencapsulating domain-specific connections and expertise. We demonstrate\nproof-of-concept implementations using the corpus of the LHCb experiment at\nCERN.",
            "pdf_url": "http://arxiv.org/pdf/2509.06855v1",
            "published": "2025-09-08 16:23:44+00:00",
            "updated": "2025-09-08 16:23:44+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Directly Aligning the Full Diffusion Trajectory with Fine-Grained Human Preference",
            "authors": "Xiangwei Shen, Zhimin Li, Zhantao Yang, Shiyi Zhang, Yingfang Zhang, Donghao Li, Chunyu Wang, Qinglin Lu, Yansong Tang",
            "summary": "Recent studies have demonstrated the effectiveness of directly aligning\ndiffusion models with human preferences using differentiable reward. However,\nthey exhibit two primary challenges: (1) they rely on multistep denoising with\ngradient computation for reward scoring, which is computationally expensive,\nthus restricting optimization to only a few diffusion steps; (2) they often\nneed continuous offline adaptation of reward models in order to achieve desired\naesthetic quality, such as photorealism or precise lighting effects. To address\nthe limitation of multistep denoising, we propose Direct-Align, a method that\npredefines a noise prior to effectively recover original images from any time\nsteps via interpolation, leveraging the equation that diffusion states are\ninterpolations between noise and target images, which effectively avoids\nover-optimization in late timesteps. Furthermore, we introduce Semantic\nRelative Preference Optimization (SRPO), in which rewards are formulated as\ntext-conditioned signals. This approach enables online adjustment of rewards in\nresponse to positive and negative prompt augmentation, thereby reducing the\nreliance on offline reward fine-tuning. By fine-tuning the FLUX.1.dev model\nwith optimized denoising and online reward adjustment, we improve its\nhuman-evaluated realism and aesthetic quality by over 3x.",
            "pdf_url": "http://arxiv.org/pdf/2509.06942v1",
            "published": "2025-09-08 17:54:08+00:00",
            "updated": "2025-09-08 17:54:08+00:00"
        },
        {
            "title": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL",
            "authors": "Bhavya Agrawalla, Michal Nauman, Khush Agarwal, Aviral Kumar",
            "summary": "A hallmark of modern large-scale machine learning techniques is the use of\ntraining objectives that provide dense supervision to intermediate\ncomputations, such as teacher forcing the next token in language models or\ndenoising step-by-step in diffusion models. This enables models to learn\ncomplex functions in a generalizable manner. Motivated by this observation, we\ninvestigate the benefits of iterative computation for temporal difference (TD)\nmethods in reinforcement learning (RL). Typically they represent value\nfunctions in a monolithic fashion, without iterative compute. We introduce floq\n(flow-matching Q-functions), an approach that parameterizes the Q-function\nusing a velocity field and trains it using techniques from flow-matching,\ntypically used in generative modeling. This velocity field underneath the flow\nis trained using a TD-learning objective, which bootstraps from values produced\nby a target velocity field, computed by running multiple steps of numerical\nintegration. Crucially, floq allows for more fine-grained control and scaling\nof the Q-function capacity than monolithic architectures, by appropriately\nsetting the number of integration steps. Across a suite of challenging offline\nRL benchmarks and online fine-tuning tasks, floq improves performance by nearly\n1.8x. floq scales capacity far better than standard TD-learning architectures,\nhighlighting the potential of iterative computation for value learning.",
            "pdf_url": "http://arxiv.org/pdf/2509.06863v1",
            "published": "2025-09-08 16:31:09+00:00",
            "updated": "2025-09-08 16:31:09+00:00"
        },
        {
            "title": "UMO: Scaling Multi-Identity Consistency for Image Customization via Matching Reward",
            "authors": "Yufeng Cheng, Wenxu Wu, Shaojin Wu, Mengqi Huang, Fei Ding, Qian He",
            "summary": "Recent advancements in image customization exhibit a wide range of\napplication prospects due to stronger customization capabilities. However,\nsince we humans are more sensitive to faces, a significant challenge remains in\npreserving consistent identity while avoiding identity confusion with\nmulti-reference images, limiting the identity scalability of customization\nmodels. To address this, we present UMO, a Unified Multi-identity Optimization\nframework, designed to maintain high-fidelity identity preservation and\nalleviate identity confusion with scalability. With \"multi-to-multi matching\"\nparadigm, UMO reformulates multi-identity generation as a global assignment\noptimization problem and unleashes multi-identity consistency for existing\nimage customization methods generally through reinforcement learning on\ndiffusion models. To facilitate the training of UMO, we develop a scalable\ncustomization dataset with multi-reference images, consisting of both\nsynthesised and real parts. Additionally, we propose a new metric to measure\nidentity confusion. Extensive experiments demonstrate that UMO not only\nimproves identity consistency significantly, but also reduces identity\nconfusion on several image customization methods, setting a new\nstate-of-the-art among open-source methods along the dimension of identity\npreserving. Code and model: https://github.com/bytedance/UMO",
            "pdf_url": "http://arxiv.org/pdf/2509.06818v1",
            "published": "2025-09-08 15:54:55+00:00",
            "updated": "2025-09-08 15:54:55+00:00"
        },
        {
            "title": "Sequential Controlled Langevin Diffusions",
            "authors": "Junhua Chen, Lorenz Richter, Julius Berner, Denis Blessing, Gerhard Neumann, Anima Anandkumar",
            "summary": "An effective approach for sampling from unnormalized densities is based on\nthe idea of gradually transporting samples from an easy prior to the\ncomplicated target distribution. Two popular methods are (1) Sequential Monte\nCarlo (SMC), where the transport is performed through successive annealed\ndensities via prescribed Markov chains and resampling steps, and (2) recently\ndeveloped diffusion-based sampling methods, where a learned dynamical transport\nis used. Despite the common goal, both approaches have different, often\ncomplementary, advantages and drawbacks. The resampling steps in SMC allow\nfocusing on promising regions of the space, often leading to robust\nperformance. While the algorithm enjoys asymptotic guarantees, the lack of\nflexible, learnable transitions can lead to slow convergence. On the other\nhand, diffusion-based samplers are learned and can potentially better adapt\nthemselves to the target at hand, yet often suffer from training instabilities.\nIn this work, we present a principled framework for combining SMC with\ndiffusion-based samplers by viewing both methods in continuous time and\nconsidering measures on path space. This culminates in the new Sequential\nControlled Langevin Diffusion (SCLD) sampling method, which is able to utilize\nthe benefits of both methods and reaches improved performance on multiple\nbenchmark problems, in many cases using only 10% of the training budget of\nprevious diffusion-based samplers.",
            "pdf_url": "http://arxiv.org/pdf/2412.07081v2",
            "published": "2024-12-10 00:47:10+00:00",
            "updated": "2025-09-08 12:53:38+00:00"
        },
        {
            "title": "Fairness-Aware Data Augmentation for Cardiac MRI using Text-Conditioned Diffusion Models",
            "authors": "Grzegorz Skorupko, Richard Osuala, Zuzanna Szafranowska, Kaisar Kushibar, Vien Ngoc Dang, Nay Aung, Steffen E Petersen, Karim Lekadir, Polyxeni Gkontra",
            "summary": "While deep learning holds great promise for disease diagnosis and prognosis\nin cardiac magnetic resonance imaging, its progress is often constrained by\nhighly imbalanced and biased training datasets. To address this issue, we\npropose a method to alleviate imbalances inherent in datasets through the\ngeneration of synthetic data based on sensitive attributes such as sex, age,\nbody mass index (BMI), and health condition. We adopt ControlNet based on a\ndenoising diffusion probabilistic model to condition on text assembled from\npatient metadata and cardiac geometry derived from segmentation masks. We\nassess our method using a large-cohort study from the UK Biobank by evaluating\nthe realism of the generated images using established quantitative metrics.\nFurthermore, we conduct a downstream classification task aimed at debiasing a\nclassifier by rectifying imbalances within underrepresented groups through\nsynthetically generated samples. Our experiments demonstrate the effectiveness\nof the proposed approach in mitigating dataset imbalances, such as the scarcity\nof diagnosed female patients or individuals with normal BMI level suffering\nfrom heart failure. This work represents a major step towards the adoption of\nsynthetic data for the development of fair and generalizable models for medical\nclassification tasks. Notably, we conduct all our experiments using a single,\nconsumer-level GPU to highlight the feasibility of our approach within\nresource-constrained environments. Our code is available at\nhttps://github.com/faildeny/debiasing-cardiac-mri.",
            "pdf_url": "http://arxiv.org/pdf/2403.19508v2",
            "published": "2024-03-28 15:41:43+00:00",
            "updated": "2025-09-08 09:37:31+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Finance-Grounded Optimization For Algorithmic Trading",
            "authors": "Kasymkhan Khubiev, Mikhail Semenov, Irina Podlipnova",
            "summary": "Deep Learning is evolving fast and integrates into various domains. Finance\nis a challenging field for deep learning, especially in the case of\ninterpretable artificial intelligence (AI). Although classical approaches\nperform very well with natural language processing, computer vision, and\nforecasting, they are not perfect for the financial world, in which specialists\nuse different metrics to evaluate model performance.\n  We first introduce financially grounded loss functions derived from key\nquantitative finance metrics, including the Sharpe ratio, Profit-and-Loss\n(PnL), and Maximum Draw down. Additionally, we propose turnover regularization,\na method that inherently constrains the turnover of generated positions within\npredefined limits.\n  Our findings demonstrate that the proposed loss functions, in conjunction\nwith turnover regularization, outperform the traditional mean squared error\nloss for return prediction tasks when evaluated using algorithmic trading\nmetrics. The study shows that financially grounded metrics enhance predictive\nperformance in trading strategies and portfolio optimization.",
            "pdf_url": "http://arxiv.org/pdf/2509.04541v1",
            "published": "2025-09-04 09:18:54+00:00",
            "updated": "2025-09-04 09:18:54+00:00"
        }
    ]
}