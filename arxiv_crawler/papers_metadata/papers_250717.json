{
    "Physics": [
        {
            "title": "Fault-tolerant fermionic quantum computing",
            "authors": "Alexander Schuckert, Eleanor Crane, Alexey V. Gorshkov, Mohammad Hafezi, Michael J. Gullans",
            "summary": "Simulating the dynamics of electrons and other fermionic particles in quantum\nchemistry, materials science, and high-energy physics is one of the most\npromising applications of fault-tolerant quantum computers. However, the\noverhead in mapping time evolution under fermionic Hamiltonians to qubit gates\nrenders this endeavor challenging. We introduce fermionic fault-tolerant\nquantum computing, a framework which removes this overhead altogether. Using\nnative fermionic operations we first construct a repetition code which corrects\nphase errors only. Within a fermionic color code, which corrects for both phase\nand loss errors, we then realize a universal fermionic gate set, including\ntransversal fermionic Clifford gates. Interfacing with qubit color codes we\nintroduce qubit-fermion fault-tolerant computation, which allows for\nqubit-controlled fermionic time evolution, a crucial subroutine in\nstate-of-the-art quantum algorithms. As an application, we consider simulating\ncrystalline materials, finding an exponential improvement in circuit depth for\na single time step from $\\mathcal{O}(N)$ to $\\mathcal{O}(\\log(N))$ with respect\nto lattice site number $N$ while retaining a site count of\n$\\tilde{\\mathcal{O}}(N)$, implying a linear-in-$N$ end-to-end gate depth for\nsimulating materials, as opposed to quadratic in previous approaches. We also\nintroduce a fermion-inspired qubit algorithm with $O(\\mathrm{log}(N)$ depth,\nbut a prohibitive number of additional ancilla qubits. We show how our\nframework can be implemented in neutral atoms, overcoming the apparent\ninability of neutral atoms to implement non-number-conserving gates. Our work\nopens the door to fermion-qubit fault-tolerant quantum computation in platforms\nwith native fermions such as neutral atoms, quantum dots and donors in silicon,\nwith applications in quantum chemistry, material science, and high-energy\nphysics.",
            "pdf_url": "http://arxiv.org/pdf/2411.08955v2",
            "published": "2024-11-13 19:00:02+00:00",
            "updated": "2025-07-16 17:58:47+00:00"
        },
        {
            "title": "The Utility of the Virtual Imaging Trials Methodology for Objective Characterization of AI Systems and Training Data",
            "authors": "Fakrul Islam Tushar, Lavsen Dahal, Saman Sotoudeh-Paima, Ehsan Abadi, W. Paul Segars, Ehsan Samei, Joseph Y. Lo",
            "summary": "Purpose: The credibility of Artificial Intelligence (AI) models for medical\nimaging continues to be a challenge, affected by the diversity of models, the\ndata used to train the models, and applicability of their combination to\nproduce reproducible results for new data. Approach: In this work we aimed to\nexplore if the emerging Virtual Imaging Trials (VIT) methodologies can provide\nan objective resource to approach this challenge. The study was conducted for\nthe case example of COVID-19 diagnosis using clinical and virtual computed\ntomography (CT) and chest radiography (CXR) processed with convolutional neural\nnetworks. Multiple AI models were developed and tested using 3D ResNet-like and\n2D EfficientNetv2 architectures across diverse datasets. Results: The\nperformance differences were evaluated in terms of the area under the curve\n(AUC) and the DeLong method for AUC confidence intervals. The models trained on\nthe most diverse datasets showed the highest external testing performance, with\nAUC values ranging from 0.73-0.76 for CT and 0.70-0.73 for CXR. Internal\ntesting yielded higher AUC values (0.77 -0.85 for CT and 0.77-1.0 for CXR),\nhighlighting a substantial drop in performance during external validation,\nwhich underscores the importance of diverse and comprehensive training and\ntesting data. Most notably, VIT approach provided objective assessment of the\nutility of diverse models and datasets while further providing insight into the\ninfluence of dataset characteristics, patient factors, and imaging physics on\nAI efficacy. Conclusions: The VIT approach can be used to enhance model\ntransparency and reliability, offering nuanced insights into the factors\ndriving AI performance and bridging the gap between experimental and clinical\nsettings.",
            "pdf_url": "http://arxiv.org/pdf/2308.09730v5",
            "published": "2023-08-17 19:12:32+00:00",
            "updated": "2025-07-16 17:29:38+00:00"
        },
        {
            "title": "Radiation-Reaction on the Straight-Line Motion of a Point Charge accelerated by a constant applied Electric Field in an Electromagnetic Bopp-Land\u00e9-Thomas-Podolsky vacuum",
            "authors": "Ryan J. McGuigan, Michael K. -H. Kiessling",
            "summary": "The radiation-reaction problem of standard Lorentz electrodynamics with point\ncharges is pathological, standing in contrast to\nBopp--Land\\'e--Thomas--Podolsky (BLTP) electrodynamics where it is in fact\nwell-defined and calculable, as reported in a previous publication. To\ndemonstrate the viability of BLTP electrodynamics, we consider the BLTP\nanalogue of the radiation reaction of a classical point charge accelerated from\nrest by a static homogeneous capacitor plate field, and calculate it up to\n$O(\\varkappa^4)$ in a formal expansion about $\\varkappa=0$ in powers of\n$\\varkappa$, Bopp's reciprocal length, a new electrodynamics parameter\nintroduced by BLTP theory. In a paper by Carley and Kiessling (arXiv:2303.01720\n[physics.class-ph]) the radiation-reaction corrections to test-particle motion\nwere explicitly computed to $O(\\varkappa^3)$, the first non-vanishing order. In\nthis article a crucial question regarding this ``small-$\\varkappa$'' expansion,\nraised by Carley and Kiessling, is answered as follows: The motions computed\nwith terms $O(\\varkappa^3)$ included are mathematically accurate approximations\nto {physically reasonable} solutions of the actual BLTP initial value problem\nfor short times $t$, viz. when $\\varkappa c t \\ll 1$, where $c$ is the speed of\nlight in vacuo, but their unphysical behavior over {much} longer times does not\naccurately approximate the actual BLTP solutions even when the dimensionless\nparameter $\\varkappa e^2 / |m_b| c^2 \\ll 1$, where $e$ is the elementary charge\nand $m_b$ the bare rest mass of the electron. This has the important\nimplication that BLTP electrodynamics remains a viable contender for an\naccurate classical electrodynamics with point charges that does not suffer from\nthe infinite self-interaction problems of textbook Lorentz electrodynamics with\npoint charges.",
            "pdf_url": "http://arxiv.org/pdf/2506.08799v2",
            "published": "2025-06-10 13:46:53+00:00",
            "updated": "2025-07-16 17:14:36+00:00"
        },
        {
            "title": "\"Is it always watching? Is it always listening?\" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots",
            "authors": "Henry Bell, Jabari Kwesi, Hiba Laabadli, Pardis Emami-Naeini",
            "summary": "Equipped with artificial intelligence (AI) and advanced sensing capabilities,\nsocial robots are gaining interest among consumers in the United States. These\nrobots seem like a natural evolution of traditional smart home devices.\nHowever, their extensive data collection capabilities, anthropomorphic\nfeatures, and capacity to interact with their environment make social robots a\nmore significant security and privacy threat. Increased risks include data\nlinkage, unauthorized data sharing, and the physical safety of users and their\nhomes. It is critical to investigate U.S. users' security and privacy needs and\nconcerns to guide the design of social robots while these devices are still in\nthe early stages of commercialization in the U.S. market. Through 19\nsemi-structured interviews, we identified significant security and privacy\nconcerns, highlighting the need for transparency, usability, and robust privacy\ncontrols to support adoption. For educational applications, participants\nworried most about misinformation, and in medical use cases, they worried about\nthe reliability of these devices. Participants were also concerned with the\ndata inference that social robots could enable. We found that participants\nexpect tangible privacy controls, indicators of data collection, and\ncontext-appropriate functionality.",
            "pdf_url": "http://arxiv.org/pdf/2507.10786v2",
            "published": "2025-07-14 20:27:40+00:00",
            "updated": "2025-07-16 16:58:46+00:00"
        },
        {
            "title": "Bounding the asymptotic quantum value of all multipartite compiled non-local games",
            "authors": "Matilde Baroni, Dominik Leichtle, Sini\u0161a Jankovi\u0107, Ivan \u0160upi\u0107",
            "summary": "Non-local games are a powerful tool to distinguish between correlations\npossible in classical and quantum worlds. Kalai et al. (STOC'23) proposed a\ncompiler that converts multipartite non-local games into interactive protocols\nwith a single prover, relying on cryptographic tools to remove the assumption\nof physical separation of the players. While quantum completeness and classical\nsoundness of the construction have been established for all multipartite games,\nquantum soundness is known only in the special case of bipartite games.\n  In this paper, we prove that the Kalai et al.'s compiler indeed achieves\nquantum soundness for all multipartite compiled non-local games, by showing\nthat any correlations that can be generated in the asymptotic case correspond\nto quantum commuting strategies.\n  Our proof uses techniques from the theory of operator algebras, and relies on\na characterisation of sequential operationally no-signalling strategies as\nquantum commuting operator strategies in the multipartite case, thereby\ngeneralising several previous results. On the way, we construct universal\nC*-algebras of sequential PVMs and prove a new chain rule for Radon-Nikodym\nderivatives of completely positive maps on C*-algebras which may be of\nindependent interest.",
            "pdf_url": "http://arxiv.org/pdf/2507.12408v1",
            "published": "2025-07-16 16:58:39+00:00",
            "updated": "2025-07-16 16:58:39+00:00"
        },
        {
            "title": "Light Scalars in the Extended Georgi-Machacek Model",
            "authors": "Poulami Mondal, Subrata Samanta",
            "summary": "We perform global fits of the CP-conserving Georgi-Machacek (GM) and extended\nGeorgi-Machacek (eGM) models, incorporating a light CP-even beyond the Standard\nModel (BSM) scalar within the mass range of $90$ GeV to $100$ GeV. These fits\ncombine the Higgs signal strengths and direct search limits from ATLAS and CMS\nat $\\sqrt{s} = 8$ and $13$ TeV, $B$-physics observables, and theoretical\nconstraints arising from next-to-leading order (NLO) unitarity and BFB\nconstraints. From the global fit, we show that the LHC diphoton and LEP\n$b\\bar{b}$ excesses around $95$ GeV are well compatible with the $125$ GeV\nHiggs data. Whereas the CMS ditau excess is incompatible with the $125$ GeV\nHiggs signal strength data in both the CP-conserving GM and eGM models. We\npresent the results from the combined fit, including the $95$ GeV Higgs signal\nstrength data. In the eGM model, the triplet VEV cannot exceed $12$ GeV for\nadditional BSM scalar masses below $160$ GeV and approximately $20$ GeV for\nadditional BSM scalar masses above $160$ GeV. The masses of additional BSM\nscalars cannot exceed $600$ GeV. The maximum mass splitting is of around $120$\nGeV within the members of each custodial multiplet, and up to $250$ GeV between\nthe members of different multiplets. In the GM model, these constraints become\nmore stringent: the triplet VEV is limited to below $15$ GeV, which tightens to\n$4$ GeV once the BSM scalar masses are below $160$ GeV. Masses of the quintet\n$m_5$ and the triplet $m_3$ are restricted to be below $530$ GeV and $320$ GeV,\nrespectively. A mass hierarchy, $m_5 > m_3$, is favoured in the high-mass\nregion, with the mass splitting constrained to be less than $210$ GeV.",
            "pdf_url": "http://arxiv.org/pdf/2506.06427v2",
            "published": "2025-06-06 18:00:02+00:00",
            "updated": "2025-07-16 16:57:43+00:00"
        },
        {
            "title": "Deep Learning-Assisted Fourier Analysis for High-Efficiency Structural Design: A Case Study on Three-Dimensional Photonic Crystals Enumeration",
            "authors": "Congcong Cui, Guangfeng Wei, Matthias Saba, Yuanyuan Cao, Lu Han",
            "summary": "The geometric design of structures with optimized physical and chemical\nproperties is one of the core topics in materials science. However, designing\nnew functional materials is challenging due to the vast number of existing and\nthe possible unknown structures to be enumerated and difficulties in mining the\nunderlying correlations between structures and their properties. Here, we\npropose a universal method for periodic structural design and property\noptimization. The key in our approach is a deep-learning assisted inverse\nFourier transform, which enables the creation of arbitrary geometries within\ncrystallographic space groups. It effectively explores extensive parameter\nspaces to identify ideal structures with desired properties. Taking the\nresearch of three-dimensional (3D) photonic structures as a case study, this\nmethod is capable of modelling numerous structures and identifying their\nphotonic bandgaps in just a few hours. We confirmed the established knowledge\nthat the widest photonic bandgaps exist in network morphologies, among which\nthe single diamond (dia net) reigns supreme. Additionally, this method\nidentified a rarely-known lcs topology with excellent photonic properties,\nhighlighting the infinitely extensible application boundaries of our approach.\nThis work demonstrates the high efficiency and effectiveness of the\nFourier-based method, advancing material design and providing insights for\nnext-generation functional materials.",
            "pdf_url": "http://arxiv.org/pdf/2501.18495v2",
            "published": "2025-01-30 17:07:56+00:00",
            "updated": "2025-07-16 16:49:28+00:00"
        },
        {
            "title": "Neural Network-Guided Symbolic Regression for Interpretable Descriptor Discovery in Perovskite Catalysts",
            "authors": "Yeming Xian, Xiaoming Wang, Yanfa Yan",
            "summary": "Understanding and predicting the activity of oxide perovskite catalysts for\nthe oxygen evolution reaction (OER) requires descriptors that are both accurate\nand physically interpretable. While symbolic regression (SR) offers a path to\ndiscover such formulas, its performance degrades with high-dimensional inputs\nand small datasets. We present a two-phase framework that combines neural\nnetworks (NN), feature importance analysis, and symbolic regression (SR) to\ndiscover interpretable descriptors for OER activity in oxide perovskites. In\nPhase I, using a small dataset and seven structural features, we reproduce and\nimprove the known {\\mu}/t descriptor by engineering composite features and\napplying symbolic regression, achieving training and validation MAEs of 22.8\nand 20.8 meV, respectively. In Phase II, we expand to 164 features, reduce\ndimensionality, and identify LUMO energy as a key electronic descriptor. A\nfinal formula using {\\mu}/t, {\\mu}/RA, and LUMO energy achieves improved\naccuracy (training and validation MAEs of 22.1 and 20.6 meV) with strong\nphysical interpretability. Our results demonstrate that NN-guided symbolic\nregression enables accurate, interpretable, and physically meaningful\ndescriptor discovery in data-scarce regimes, indicating interpretability need\nnot sacrifice accuracy for materials informatics.",
            "pdf_url": "http://arxiv.org/pdf/2507.12404v1",
            "published": "2025-07-16 16:47:38+00:00",
            "updated": "2025-07-16 16:47:38+00:00"
        },
        {
            "title": "Beyond Ground States: Physics-Inspired Optimization of Excited States of Classical Hamiltonians",
            "authors": "Erik Altelarrea-Ferr\u00e9, J\u00falia Barber\u00e0-Rodr\u00edguez, David Jansen, Antonio Ac\u00edn",
            "summary": "We introduce excited local quantum annealing (ExcLQA), a classical,\nphysics-inspired algorithm that extends local quantum annealing (LQA) to\nidentify excited states of classical Ising Hamiltonians. LQA simulates quantum\nannealing while constraining the quantum state to remain in a product state and\nuses a gradient-based approach to find approximate solutions to large-scale\nquadratic unconstrained binary optimization problems. ExcLQA extends this\nframework by adding a penalty term in the cost function to target excited\nstates, with a single hyperparameter that can be tuned via binary search to set\nthe desired penalization level. We benchmark ExcLQA on the shortest vector\nproblem (SVP), a fundamental lattice problem underlying the security of many\npostquantum cryptographic schemes. Solving an SVP instance can be mapped to\nidentifying the first excited state of a Hamiltonian, with approximate\nsolutions located among nearby excited states. Our results show that ExcLQA\nmanages to solve SVP instances up to rank 46, and outperforms the\nMetropolis-Hastings algorithm in solved ratio, number of shots, and\napproximation factor in the tested instances.",
            "pdf_url": "http://arxiv.org/pdf/2507.12394v1",
            "published": "2025-07-16 16:40:49+00:00",
            "updated": "2025-07-16 16:40:49+00:00"
        },
        {
            "title": "Derivation of the time-dependent Hartree equations for strongly interacting dense fermionic systems",
            "authors": "Duc Viet Hoang, David Mitrouskas, Peter Pickl",
            "summary": "The time-dependent Hartree and Hartree-Fock equations provide effective\nmean-field descriptions for the dynamics of large fermionic systems and play a\nfundamental role in many areas of physics. In this work, we rigorously derive\nthe time-dependent Hartree equations as the large-$N$ limit of the microscopic\nSchr\\\"odinger dynamics of $N$ fermions confined to a volume of order one and\ninteracting via strong pair potentials. A central step in our analysis is the\nimplementation of time-dependent gauge transformations, which eliminate the\ndominant contribution from the interaction potential in both the Schr\\\"odinger\nand Hartree evolutions.",
            "pdf_url": "http://arxiv.org/pdf/2507.12390v1",
            "published": "2025-07-16 16:36:56+00:00",
            "updated": "2025-07-16 16:36:56+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models",
            "authors": "Samuel Lavoie, Michael Noukhovitch, Aaron Courville",
            "summary": "We argue that diffusion models' success in modeling complex distributions is,\nfor the most part, coming from their input conditioning. This paper\ninvestigates the representation used to condition diffusion models from the\nperspective that ideal representations should improve sample fidelity, be easy\nto generate, and be compositional to allow out-of-training samples generation.\nWe introduce Discrete Latent Code (DLC), an image representation derived from\nSimplicial Embeddings trained with a self-supervised learning objective. DLCs\nare sequences of discrete tokens, as opposed to the standard continuous image\nembeddings. They are easy to generate and their compositionality enables\nsampling of novel images beyond the training distribution. Diffusion models\ntrained with DLCs have improved generation fidelity, establishing a new\nstate-of-the-art for unconditional image generation on ImageNet. Additionally,\nwe show that composing DLCs allows the image generator to produce\nout-of-distribution samples that coherently combine the semantics of images in\ndiverse ways. Finally, we showcase how DLCs can enable text-to-image generation\nby leveraging large-scale pretrained language models. We efficiently finetune a\ntext diffusion language model to generate DLCs that produce novel samples\noutside of the image generator training distribution.",
            "pdf_url": "http://arxiv.org/pdf/2507.12318v1",
            "published": "2025-07-16 15:12:17+00:00",
            "updated": "2025-07-16 15:12:17+00:00"
        },
        {
            "title": "RadioDiff-3D: A 3D$\\times$3D Radio Map Dataset and Generative Diffusion Based Benchmark for 6G Environment-Aware Communication",
            "authors": "Xiucheng Wang, Qiming Zhang, Nan Cheng, Junting Chen, Zezhong Zhang, Zan Li, Shuguang Cui, Xuemin Shen",
            "summary": "Radio maps (RMs) serve as a critical foundation for enabling\nenvironment-aware wireless communication, as they provide the spatial\ndistribution of wireless channel characteristics. Despite recent progress in RM\nconstruction using data-driven approaches, most existing methods focus solely\non pathloss prediction in a fixed 2D plane, neglecting key parameters such as\ndirection of arrival (DoA), time of arrival (ToA), and vertical spatial\nvariations. Such a limitation is primarily due to the reliance on static\nlearning paradigms, which hinder generalization beyond the training data\ndistribution. To address these challenges, we propose UrbanRadio3D, a\nlarge-scale, high-resolution 3D RM dataset constructed via ray tracing in\nrealistic urban environments. UrbanRadio3D is over 37$\\times$3 larger than\nprevious datasets across a 3D space with 3 metrics as pathloss, DoA, and ToA,\nforming a novel 3D$\\times$33D dataset with 7$\\times$3 more height layers than\nprior state-of-the-art (SOTA) dataset. To benchmark 3D RM construction, a UNet\nwith 3D convolutional operators is proposed. Moreover, we further introduce\nRadioDiff-3D, a diffusion-model-based generative framework utilizing the 3D\nconvolutional architecture. RadioDiff-3D supports both radiation-aware\nscenarios with known transmitter locations and radiation-unaware settings based\non sparse spatial observations. Extensive evaluations on UrbanRadio3D validate\nthat RadioDiff-3D achieves superior performance in constructing rich,\nhigh-dimensional radio maps under diverse environmental dynamics. This work\nprovides a foundational dataset and benchmark for future research in 3D\nenvironment-aware communication. The dataset is available at\nhttps://github.com/UNIC-Lab/UrbanRadio3D.",
            "pdf_url": "http://arxiv.org/pdf/2507.12166v1",
            "published": "2025-07-16 11:54:08+00:00",
            "updated": "2025-07-16 11:54:08+00:00"
        },
        {
            "title": "FourCastNet 3: A geometric approach to probabilistic machine-learning weather forecasting at scale",
            "authors": "Boris Bonev, Thorsten Kurth, Ankur Mahesh, Mauro Bisson, Jean Kossaifi, Karthik Kashinath, Anima Anandkumar, William D. Collins, Michael S. Pritchard, Alexander Keller",
            "summary": "FourCastNet 3 advances global weather modeling by implementing a scalable,\ngeometric machine learning (ML) approach to probabilistic ensemble forecasting.\nThe approach is designed to respect spherical geometry and to accurately model\nthe spatially correlated probabilistic nature of the problem, resulting in\nstable spectra and realistic dynamics across multiple scales. FourCastNet 3\ndelivers forecasting accuracy that surpasses leading conventional ensemble\nmodels and rivals the best diffusion-based methods, while producing forecasts 8\nto 60 times faster than these approaches. In contrast to other ML approaches,\nFourCastNet 3 demonstrates excellent probabilistic calibration and retains\nrealistic spectra, even at extended lead times of up to 60 days. All of these\nadvances are realized using a purely convolutional neural network architecture\ntailored for spherical geometry. Scalable and efficient large-scale training on\n1024 GPUs and more is enabled by a novel training paradigm for combined model-\nand data-parallelism, inspired by domain decomposition methods in classical\nnumerical models. Additionally, FourCastNet 3 enables rapid inference on a\nsingle GPU, producing a 90-day global forecast at 0.25{\\deg}, 6-hourly\nresolution in under 20 seconds. Its computational efficiency, medium-range\nprobabilistic skill, spectral fidelity, and rollout stability at subseasonal\ntimescales make it a strong candidate for improving meteorological forecasting\nand early warning systems through large ensemble predictions.",
            "pdf_url": "http://arxiv.org/pdf/2507.12144v1",
            "published": "2025-07-16 11:22:18+00:00",
            "updated": "2025-07-16 11:22:18+00:00"
        },
        {
            "title": "RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization",
            "authors": "Vladimir Bogachev, Vladimir Aletov, Alexander Molozhavenko, Denis Bobkov, Vera Soboleva, Aibek Alanov, Maxim Rakhuba",
            "summary": "Low-Rank Adaptation (LoRA) has become a widely adopted standard for\nparameter-efficient fine-tuning of large language models (LLMs), significantly\nreducing memory and computational demands. However, challenges remain,\nincluding finding optimal initialization strategies or mitigating\noverparametrization in low-rank matrix factorization. In this work, we propose\na novel approach that addresses both of the challenges simultaneously within a\nunified framework. Our method treats a set of fixed-rank LoRA matrices as a\nsmooth manifold. Considering adapters as elements on this manifold removes\noverparametrization, while determining the direction of the fastest loss\ndecrease along the manifold provides initialization. Special care is taken to\nobtain numerically stable and computationally efficient implementation of our\nmethod, using best practices from numerical linear algebra and Riemannian\noptimization. Experimental results on LLM and diffusion model architectures\ndemonstrate that RiemannLoRA consistently improves both convergence speed and\nfinal performance over standard LoRA and its state-of-the-art modifications.",
            "pdf_url": "http://arxiv.org/pdf/2507.12142v1",
            "published": "2025-07-16 11:17:12+00:00",
            "updated": "2025-07-16 11:17:12+00:00"
        },
        {
            "title": "Neurons: Emulating the Human Visual Cortex Improves Fidelity and Interpretability in fMRI-to-Video Reconstruction",
            "authors": "Haonan Wang, Qixiang Zhang, Lehan Wang, Xuanqi Huang, Xiaomeng Li",
            "summary": "Decoding visual stimuli from neural activity is essential for understanding\nthe human brain. While fMRI methods have successfully reconstructed static\nimages, fMRI-to-video reconstruction faces challenges due to the need for\ncapturing spatiotemporal dynamics like motion and scene transitions. Recent\napproaches have improved semantic and perceptual alignment but struggle to\nintegrate coarse fMRI data with detailed visual features. Inspired by the\nhierarchical organization of the visual system, we propose NEURONS, a novel\nframework that decouples learning into four correlated sub-tasks: key object\nsegmentation, concept recognition, scene description, and blurry video\nreconstruction. This approach simulates the visual cortex's functional\nspecialization, allowing the model to capture diverse video content. In the\ninference stage, NEURONS generates robust conditioning signals for a\npre-trained text-to-video diffusion model to reconstruct the videos. Extensive\nexperiments demonstrate that NEURONS outperforms state-of-the-art baselines,\nachieving solid improvements in video consistency (26.6%) and semantic-level\naccuracy (19.1%). Notably, NEURONS shows a strong functional correlation with\nthe visual cortex, highlighting its potential for brain-computer interfaces and\nclinical applications. Code and model weights are available at:\nhttps://github.com/xmed-lab/NEURONS.",
            "pdf_url": "http://arxiv.org/pdf/2503.11167v3",
            "published": "2025-03-14 08:12:28+00:00",
            "updated": "2025-07-16 08:58:13+00:00"
        }
    ]
}