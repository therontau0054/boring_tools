{
    "Physics": [
        {
            "title": "On the relation between perspective-neutral, algebraic, and effective quantum reference frames",
            "authors": "Philipp A. Hoehn, Julian De Vuyst, Artur Tsobanjan",
            "summary": "The framework of internal quantum reference frames (QRFs) constitutes a\nuniversal toolset for dealing with symmetries in quantum theory and has led to\nnew revelations in quantum gravity, gauge theories and foundational physics.\nMultiple approaches have emerged, sometimes differing in scope and the way\nsymmetries are implemented, raising the question as to their relation. Here, we\ninvestigate the relation between three approaches to QRFs for gauge symmetries,\nnamely the effective semiclassical, algebraic, and perspective-neutral (PN)\napproaches. Rather than constructing Hilbert spaces, as the PN approach, the\neffective approach is based on a quantum phase space parametrized by\nexpectation values and fluctuations, while the emphasis of the algebraic\napproach is on the state space of complex linear functionals on a kinematical\nalgebra. Nevertheless, external frame information is treated as gauge in all\nthree formalisms, manifested in constraints on states and algebra. We show that\nthese three approaches are, in fact, equivalent for ideal QRFs, distinguished\nby sharp orientations, which is the previous setting of the first two\napproaches. Our demonstration pertains to single constraints, including\nrelativistic ones, and encompasses QRF changes. In particular, the QRF\ntransformations of the PN framework agree semiclassically with those of the\nolder effective approach, by which it was inspired. As a physical application,\nwe explore the QRF covariance of uncertainties and fluctuations, which turn out\nto be frame-dependent. This is particularly well-suited for the effective and\nalgebraic approaches, for which these quantities form a natural basis. Finally,\nwe pave the way towards extending these two approaches to non-ideal QRFs by\nstudying the projection and gauge-fixing operations of the Page-Wootters\nformalism, built into the PN framework, on algebraic states.",
            "pdf_url": "http://arxiv.org/pdf/2507.14131v1",
            "published": "2025-07-18 17:58:04+00:00",
            "updated": "2025-07-18 17:58:04+00:00"
        },
        {
            "title": "NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining",
            "authors": "Maksim Kuprashevich, Grigorii Alekseenko, Irina Tolstykh, Georgii Fedorov, Bulat Suleimanov, Vladimir Dokholyan, Aleksandr Gordeev",
            "summary": "Recent advances in generative modeling enable image editing assistants that\nfollow natural language instructions without additional user input. Their\nsupervised training requires millions of triplets: original image, instruction,\nedited image. Yet mining pixel-accurate examples is hard. Each edit must affect\nonly prompt-specified regions, preserve stylistic coherence, respect physical\nplausibility, and retain visual appeal. The lack of robust automated\nedit-quality metrics hinders reliable automation at scale. We present an\nautomated, modular pipeline that mines high-fidelity triplets across domains,\nresolutions, instruction complexities, and styles. Built on public generative\nmodels and running without human intervention, our system uses a task-tuned\nGemini validator to score instruction adherence and aesthetics directly,\nremoving any need for segmentation or grounding models. Inversion and\ncompositional bootstrapping enlarge the mined set by approximately 2.2x,\nenabling large-scale high-fidelity training data. By automating the most\nrepetitive annotation steps, the approach allows a new scale of training\nwithout human labeling effort. To democratize research in this\nresource-intensive area, we release NHR-Edit: an open dataset of 358k\nhigh-quality triplets. In the largest cross-dataset evaluation, it surpasses\nall public alternatives. We also release Bagel-NHR-Edit, an open-source\nfine-tuned Bagel model, which achieves state-of-the-art metrics in our\nexperiments.",
            "pdf_url": "http://arxiv.org/pdf/2507.14119v1",
            "published": "2025-07-18 17:50:00+00:00",
            "updated": "2025-07-18 17:50:00+00:00"
        },
        {
            "title": "Spatiotemporal Order and Parametric Instabilities from First-Principles",
            "authors": "Daniel Kaplan, Pavel A. Volkov, Jennifer Coulter, Shiwei Zhang, Premala Chandra",
            "summary": "Shaping crystal structure with light is an enduring goal of physics and\nmaterials engineering. Here we present calculations in candidate materials\nselected by symmetry that allow light-induced spatiotemporal parametric\ninstabilities. We demonstrate a theoretical framework that includes a complete\nsymmetry analysis of phonon modes that contribute to parametric instabilities\nacross all non-centrosymmetric point groups, a detailed survey of the materials\nlandscape and finally the computation of nonlinear couplings from first\nprinciples. We then showcase detailed results for chiral crystals,\nferroelectrics, and layered van der Waals materials. Our results pave the way\ntowards realizing designer time-crystalline order in quantum materials,\ndetectable with time-resolved diffractive probes.",
            "pdf_url": "http://arxiv.org/pdf/2507.14110v1",
            "published": "2025-07-18 17:43:08+00:00",
            "updated": "2025-07-18 17:43:08+00:00"
        },
        {
            "title": "An Adversarial-Driven Experimental Study on Deep Learning for RF Fingerprinting",
            "authors": "Xinyu Cao, Bimal Adhikari, Shangqing Zhao, Jingxian Wu, Yanjun Pan",
            "summary": "Radio frequency (RF) fingerprinting, which extracts unique hardware\nimperfections of radio devices, has emerged as a promising physical-layer\ndevice identification mechanism in zero trust architectures and beyond 5G\nnetworks. In particular, deep learning (DL) methods have demonstrated\nstate-of-the-art performance in this domain. However, existing approaches have\nprimarily focused on enhancing system robustness against temporal and spatial\nvariations in wireless environments, while the security vulnerabilities of\nthese DL-based approaches have often been overlooked. In this work, we\nsystematically investigate the security risks of DL-based RF fingerprinting\nsystems through an adversarial-driven experimental analysis. We observe a\nconsistent misclassification behavior for DL models under domain shifts, where\na device is frequently misclassified as another specific one. Our analysis\nbased on extensive real-world experiments demonstrates that this behavior can\nbe exploited as an effective backdoor to enable external attackers to intrude\ninto the system. Furthermore, we show that training DL models on raw received\nsignals causes the models to entangle RF fingerprints with environmental and\nsignal-pattern features, creating additional attack vectors that cannot be\nmitigated solely through post-processing security methods such as confidence\nthresholds.",
            "pdf_url": "http://arxiv.org/pdf/2507.14109v1",
            "published": "2025-07-18 17:42:20+00:00",
            "updated": "2025-07-18 17:42:20+00:00"
        },
        {
            "title": "Ultrafast thermal boundary conductance under large temperature discontinuities of ultrathin epitaxial Pb films on Si(111)",
            "authors": "Christian Brand, Tobias Witte, Mohammad Tajik, Jonas D. Fortmann, Birk Finke, Michael Horn-von Hoegen",
            "summary": "Heat transfer is a critical aspect of modern electronics, and a deeper\nunderstanding of the underlying physics is essential for building faster,\nsmaller, and more powerful devices with an improved performance and efficiency.\nIn such nanoscale structures the heat transfer between two materials is limited\nby the finite thermal boundary conductance across their interface. Using\nultrafast electron diffraction under grazing incidence we investigated the heat\ntransfer from ultrathin epitaxial Pb films to an Si(111) substrate under strong\nnon-equilibrium conditions. Applying an intense femtosecond laser pulse, the\n5-7 ML thin Pb film experiences a strong heat up by 10-120 K while the Si\nsubstrate remains cold at $\\approx$ 10 K. At such large temperature\ndiscontinuities we observe a significantly faster cooling for stronger excited\nPb films. The decrease of the corresponding cooling time constant is explained\nthrough the thermal boundary conductance in the framework of the diffuse\nmismatch model. The thermal boundary conductance is reduced by more than a\nfactor of three in comparison with Pb films grown on H-terminated substrates,\npointing out the importance of the morphology of substrate, film and their\ninterface.",
            "pdf_url": "http://arxiv.org/pdf/2507.13109v2",
            "published": "2025-07-17 13:23:56+00:00",
            "updated": "2025-07-18 17:30:59+00:00"
        },
        {
            "title": "Generative AI-Driven High-Fidelity Human Motion Simulation",
            "authors": "Hari Iyer, Neel Macwan, Atharva Jitendra Hude, Heejin Jeong, Shenghan Guo",
            "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.",
            "pdf_url": "http://arxiv.org/pdf/2507.14097v1",
            "published": "2025-07-18 17:24:50+00:00",
            "updated": "2025-07-18 17:24:50+00:00"
        },
        {
            "title": "Machine Learning-aided Optimal Control of a noisy qubit",
            "authors": "Riccardo Cantone, Shreyasi Mukherjee, Luigi Giannelli, Elisabetta Paladino, Giuseppe Falci",
            "summary": "We apply a graybox machine-learning framework to model and control a qubit\nundergoing Markovian and non-Markovian dynamics from environmental noise. The\napproach combines physics-informed equations with a lightweight transformer\nneural network based on the self-attention mechanism. The model is trained on\nsimulated data and learns an effective operator that predicts observables\naccurately, even in the presence of memory effects. We benchmark both\nnon-Gaussian random-telegraph noise and Gaussian Ornstein-Uhlenbeck noise and\nachieve low prediction errors even in challenging noise coupling regimes. Using\nthe model as a dynamics emulator, we perform gradient-based optimal control to\nidentify pulse sequences implementing a universal set of single-qubit gates,\nachieving fidelities above 99% for the lowest considered value of the coupling\nand remaining above 90% for the highest.",
            "pdf_url": "http://arxiv.org/pdf/2507.14085v1",
            "published": "2025-07-18 17:06:58+00:00",
            "updated": "2025-07-18 17:06:58+00:00"
        },
        {
            "title": "Constraining scalars of $16_H$ through proton decays in non-renormalisable $SO(10)$ models",
            "authors": "Saurabh K. Shukla",
            "summary": "Non-renormalisable versions of $SO(10)$\\, based on irreducible\nrepresentations with lesser degrees of freedom, are free of running into the\ncatastrophe of non-perturbativity of standard model gauge couplings in contrast\nto the renormalisable versions having tensors with many degrees of freedom.\n$16_H$ is the smallest representation, participates in Yukawa Lagrangian at the\nnon-renormalisable level, contributing to the charged and neutral fermion\nmasses, and has six distinct scalars with different $B-L$ charges. We computed\nthe leptoquark and diquark couplings of different pairs of scalars stemming\nfrom all possible decomposition of the term resulting from the coupling of\n$16_{H}$ with the ${\\mathbf{16}}$ dimensional fermion multiplet of $SO(10)$,\\,\ni.e. $\\frac{{\\mathbf{16}}\\,{\\mathbf{16}}\\,16_{H}\\,16_{H}}{\\Lambda}$. Computing\nthe tree and loop level contribution of different pairs to the effective\ndimension six, $B-L$ conserving operators, it turns out only three pairs, viz\n$\\sigma\\big(1,1,0\\big)- T\\big(3,1,\\frac{1}{3}\\big)$, and\n$H\\big(1,2,-\\frac{1}{2}\\big)-\\Delta\\big(3,2,\\frac{1}{6}\\big)$, and $H-T$ can\ninduce proton decay at tree level. Assuming that the Yukawa couplings of the\n$16_{H}$ are comparable to those of the $\\overline{126}_{H}$ of a realistic\n$SO(10)$ model and setting the cutoff scale to the Planck scale typically\nconstrains the $B-L$ breaking scale to be $4\\sim 5$ orders of magnitude less\nthan the cutoff scale $(\\Lambda)$. Moreover, analysing the branching pattern of\nthe leading two-body decay modes of the proton, we observed a preference for\nthe proton to decay into second-generation mesons due to the hierarchical\nnature of Yukawa couplings. In a realistic $SO(10)$\\, scenario, we find that\n$M_T >10^{8}$ TeV, while $M_\\Delta$ could be as light as a few TeV$s$.",
            "pdf_url": "http://arxiv.org/pdf/2403.14331v2",
            "published": "2024-03-21 11:56:39+00:00",
            "updated": "2025-07-18 16:52:41+00:00"
        },
        {
            "title": "Critiques of World Models",
            "authors": "Eric Xing, Mingkai Deng, Jinyu Hou, Zhiting Hu",
            "summary": "World Model, the supposed algorithmic surrogate of the real-world environment\nwhich biological agents experience with and act upon, has been an emerging\ntopic in recent years because of the rising needs to develop virtual agents\nwith artificial (general) intelligence. There has been much debate on what a\nworld model really is, how to build it, how to use it, and how to evaluate it.\nIn this essay, starting from the imagination in the famed Sci-Fi classic Dune,\nand drawing inspiration from the concept of \"hypothetical thinking\" in\npsychology literature, we offer critiques of several schools of thoughts on\nworld modeling, and argue the primary goal of a world model to be simulating\nall actionable possibilities of the real world for purposeful reasoning and\nacting. Building on the critiques, we propose a new architecture for a\ngeneral-purpose world model, based on hierarchical, multi-level, and mixed\ncontinuous/discrete representations, and a generative and self-supervision\nlearning framework, with an outlook of a Physical, Agentic, and Nested (PAN)\nAGI system enabled by such a model.",
            "pdf_url": "http://arxiv.org/pdf/2507.05169v2",
            "published": "2025-07-07 16:23:46+00:00",
            "updated": "2025-07-18 16:48:16+00:00"
        },
        {
            "title": "High stakes exams inflate a gender gap and contribute to systematic grading errors in introductory physics",
            "authors": "David J. Webb, Cassandra A. Paul",
            "summary": "Previous research has suggested that changing the percentage of the course\ngrade associated with exam grades in STEM courses can change the gender gap in\nthe course. It has also been shown that assessments with the highest stakes\nhave the lowest (relative) scores for female students. Previous research by the\nauthors has shown that the implementation of retake exams can eliminate the\ngender gap in introductory physics courses. This paper explores several\ndifferent hypotheses for why retake exams are associated with a zeroed gender\ngap. Two independent measurements comparing exams with different stakes are\nused in support of the argument that the entire gender gap on introductory\nphysics exams may be due to the stakes associated with those exams. In other\nwords, these data support the idea that a gender grade gap on exams is not\nmeasuring a gender difference in the physics knowledge or physics ability of\nthese students. Implications suggest that instructors should choose lower\nstakes assessment options if they are interested in exam measurements that are\nnot influenced by differences in students' performance related to exam stakes.",
            "pdf_url": "http://arxiv.org/pdf/2504.09418v2",
            "published": "2025-04-13 03:28:17+00:00",
            "updated": "2025-07-18 16:34:16+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "A General Framework for Inference-time Scaling and Steering of Diffusion Models",
            "authors": "Raghav Singhal, Zachary Horvitz, Ryan Teehan, Mengye Ren, Zhou Yu, Kathleen McKeown, Rajesh Ranganath",
            "summary": "Diffusion models produce impressive results in modalities ranging from images\nand video to protein design and text. However, generating samples with\nuser-specified properties remains a challenge. Recent research proposes\nfine-tuning models to maximize rewards that capture desired properties, but\nthese methods require expensive training and are prone to mode collapse. In\nthis work, we present Feynman-Kac (FK) steering, an inference-time framework\nfor steering diffusion models with reward functions. FK steering works by\nsampling a system of multiple interacting diffusion processes, called\nparticles, and resampling particles at intermediate steps based on scores\ncomputed using functions called potentials. Potentials are defined using\nrewards for intermediate states and are selected such that a high value\nindicates that the particle will yield a high-reward sample. We explore various\nchoices of potentials, intermediate rewards, and samplers. We evaluate FK\nsteering on text-to-image and text diffusion models. For steering text-to-image\nmodels with a human preference reward, we find that FK steering a 0.8B\nparameter model outperforms a 2.6B parameter fine-tuned model on prompt\nfidelity, with faster sampling and no training. For steering text diffusion\nmodels with rewards for text quality and specific text attributes, we find that\nFK steering generates lower perplexity, more linguistically acceptable outputs\nand enables gradient-free control of attributes like toxicity. Our results\ndemonstrate that inference-time scaling and steering of diffusion models - even\nwith off-the-shelf rewards - can provide significant sample quality gains and\ncontrollability benefits. Code is available at\nhttps://github.com/zacharyhorvitz/Fk-Diffusion-Steering .",
            "pdf_url": "http://arxiv.org/pdf/2501.06848v5",
            "published": "2025-01-12 15:34:24+00:00",
            "updated": "2025-07-18 17:52:45+00:00"
        },
        {
            "title": "CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models",
            "authors": "Quang-Binh Nguyen, Minh Luu, Quang Nguyen, Anh Tran, Khoi Nguyen",
            "summary": "Disentangling content and style from a single image, known as content-style\ndecomposition (CSD), enables recontextualization of extracted content and\nstylization of extracted styles, offering greater creative flexibility in\nvisual synthesis. While recent personalization methods have explored the\ndecomposition of explicit content style, they remain tailored for diffusion\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\npromising alternative with a next-scale prediction paradigm, achieving\nperformance comparable to that of diffusion models. In this paper, we explore\nVAR as a generative framework for CSD, leveraging its scale-wise generation\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\nmethod that introduces three key innovations: (1) a scale-aware alternating\noptimization strategy that aligns content and style representation with their\nrespective scales to enhance separation, (2) an SVD-based rectification method\nto mitigate content leakage into style representations, and (3) an Augmented\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\nthis task, we introduce CSD-100, a dataset specifically designed for\ncontent-style decomposition, featuring diverse subjects rendered in various\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\napproaches, achieving superior content preservation and stylization fidelity.",
            "pdf_url": "http://arxiv.org/pdf/2507.13984v1",
            "published": "2025-07-18 14:45:48+00:00",
            "updated": "2025-07-18 14:45:48+00:00"
        },
        {
            "title": "Generalist Forecasting with Frozen Video Models via Latent Diffusion",
            "authors": "Jacob C Walker, Pedro V\u00e9lez, Luisa Polania Cabrera, Guangyao Zhou, Rishabh Kabra, Carl Doersch, Maks Ovsjanikov, Jo\u00e3o Carreira, Shiry Ginosar",
            "summary": "Forecasting what will happen next is a critical skill for general-purpose\nsystems that plan or act in the world at different levels of abstraction. In\nthis paper, we identify a strong correlation between a vision model's\nperceptual ability and its generalist forecasting performance over short time\nhorizons. This trend holds across a diverse set of pretrained models-including\nthose trained generatively-and across multiple levels of abstraction, from raw\npixels to depth, point tracks, and object motion. The result is made possible\nby a novel generalist forecasting framework that operates on any frozen vision\nbackbone: we train latent diffusion models to forecast future features in the\nfrozen representation space, which are then decoded via lightweight,\ntask-specific readouts. To enable consistent evaluation across tasks, we\nintroduce distributional metrics that compare distributional properties\ndirectly in the space of downstream tasks and apply this framework to nine\nmodels and four tasks. Our results highlight the value of bridging\nrepresentation learning and generative modeling for temporally grounded video\nunderstanding.",
            "pdf_url": "http://arxiv.org/pdf/2507.13942v1",
            "published": "2025-07-18 14:14:19+00:00",
            "updated": "2025-07-18 14:14:19+00:00"
        },
        {
            "title": "Improved DDIM Sampling with Moment Matching Gaussian Mixtures",
            "authors": "Prasad Gabbur",
            "summary": "We propose using a Gaussian Mixture Model (GMM) as reverse transition\noperator (kernel) within the Denoising Diffusion Implicit Models (DDIM)\nframework, which is one of the most widely used approaches for accelerated\nsampling from pre-trained Denoising Diffusion Probabilistic Models (DDPM).\nSpecifically we match the first and second order central moments of the DDPM\nforward marginals by constraining the parameters of the GMM. We see that moment\nmatching is sufficient to obtain samples with equal or better quality than the\noriginal DDIM with Gaussian kernels. We provide experimental results with\nunconditional models trained on CelebAHQ and FFHQ and class-conditional models\ntrained on ImageNet datasets respectively. Our results suggest that using the\nGMM kernel leads to significant improvements in the quality of the generated\nsamples when the number of sampling steps is small, as measured by FID and IS\nmetrics. For example on ImageNet 256x256, using 10 sampling steps, we achieve a\nFID of 6.94 and IS of 207.85 with a GMM kernel compared to 10.15 and 196.73\nrespectively with a Gaussian kernel.",
            "pdf_url": "http://arxiv.org/pdf/2311.04938v3",
            "published": "2023-11-08 00:24:50+00:00",
            "updated": "2025-07-18 13:31:06+00:00"
        },
        {
            "title": "Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction",
            "authors": "Mingyang Yu, Zhijian Wu, Dingjiang Huang",
            "summary": "Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its\ndegraded 2D measurements. Recently great progress has been made in deep\nlearning-based methods, however, these methods often struggle to accurately\ncapture high-frequency details of the HSI. To address this issue, this paper\nproposes a Spectral Diffusion Prior (SDP) that is implicitly learned from\nhyperspectral images using a diffusion model. Leveraging the powerful ability\nof the diffusion model to reconstruct details, this learned prior can\nsignificantly improve the performance when injected into the HSI model. To\nfurther improve the effectiveness of the learned prior, we also propose the\nSpectral Prior Injector Module (SPIM) to dynamically guide the model to recover\nthe HSI details. We evaluate our method on two representative HSI methods: MST\nand BISRNet. Experimental results show that our method outperforms existing\nnetworks by about 0.5 dB, effectively improving the performance of HSI\nreconstruction.",
            "pdf_url": "http://arxiv.org/pdf/2507.13769v1",
            "published": "2025-07-18 09:27:11+00:00",
            "updated": "2025-07-18 09:27:11+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Machine-learning regression methods for American-style path-dependent contracts",
            "authors": "Matteo Gambara, Giulia Livieri, Andrea Pallavicini",
            "summary": "Evaluating financial products with early-termination clauses, in particular\nthose with path-dependent structures, is challenging. This paper focuses on\nAsian options, look-back options, and callable certificates. We will compare\nregression methods for pricing and computing sensitivities, highlighting modern\nmachine learning techniques against traditional polynomial basis functions.\nSpecifically, we will analyze randomized recurrent and feed-forward neural\nnetworks, along with a novel approach using signatures of the underlying price\nprocess. For option sensitivities like Delta and Gamma, we will incorporate\nChebyshev interpolation. Our findings show that machine learning algorithms\noften match the accuracy and efficiency of traditional methods for Asian and\nlook-back options, while randomized neural networks are best for callable\ncertificates. Furthermore, we apply Chebyshev interpolation for Delta and Gamma\ncalculations for the first time in Asian options and callable certificates.",
            "pdf_url": "http://arxiv.org/pdf/2311.16762v2",
            "published": "2023-11-28 13:05:06+00:00",
            "updated": "2025-07-18 08:51:58+00:00"
        }
    ]
}