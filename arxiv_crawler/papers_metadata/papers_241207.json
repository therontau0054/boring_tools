{
    "Physics": [
        {
            "title": "Block Lanczos for lattice QCD spectroscopy and matrix elements",
            "authors": "Daniel C. Hackett, Michael L. Wagman",
            "summary": "Recent work introduced a new framework for analyzing correlation functions\nwith improved convergence and signal-to-noise properties, as well as rigorous\nquantification of excited-state effects, based on the Lanczos algorithm and\nspurious eigenvalue filtering with the Cullum-Willoughby test. Here, we extend\nthis framework to the analysis of correlation-function matrices built from\nmultiple interpolating operators in lattice quantum chromodynamics (QCD) by\nconstructing an oblique generalization of the block Lanczos algorithm, as well\nas a new physically motivated reformulation of the Cullum-Willoughby test that\ngeneralizes to block Lanczos straightforwardly. The resulting block Lanczos\nmethod directly extends generalized eigenvalue problem (GEVP) methods, which\ncan be viewed as applying a single iteration of block Lanczos. Block Lanczos\nprovides qualitative and quantitative advantages over GEVP methods analogous to\nthe benefits of Lanczos over the standard effective mass, including faster\nconvergence to ground- and excited-state energies, explicitly computable\ntwo-sided error bounds, straightforward extraction of matrix elements of\nexternal currents, and asymptotically constant signal-to-noise. No fits or\nstatistical inference are required. Proof-of-principle calculations are\nperformed for noiseless mock-data examples as well as two-by-two proton\ncorrelation-function matrices in lattice QCD.",
            "pdf_url": "http://arxiv.org/pdf/2412.04444v1",
            "published": "2024-12-05 18:57:02+00:00",
            "updated": "2024-12-05 18:57:02+00:00"
        },
        {
            "title": "PDMD: Potential-free Data-driven Molecular Dynamics for Variable-sized Water Clusters",
            "authors": "Hongyu Yan, Qi Dai, Yong Wei, Minghan Chen, Hanning Chen",
            "summary": "Conventional molecular dynamics (MD) simulation approaches, such as ab initio\nMD and empirical force field MD, face significant trade-offs between physical\naccuracy and computational efficiency. This work presents a novel\nPotential-free Data-driven Molecular Dynamics (PDMD) framework for predicting\nsystem energy and atomic forces of variable-sized water clusters. Specifically,\nPDMD employs the smooth overlap of atomic positions descriptor to generate\nhigh-dimensional, equivariant features before leveraging ChemGNN, a graph\nneural network model that adaptively learns the atomic chemical environments\nwithout requiring a priori knowledge. Through an iterative self-consistent\ntraining approach, the converged PDMD achieves a mean absolute error of 7.1\nmeV/atom for energy and 59.8 meV/angstrom for forces, outperforming the\nstate-of-the-art DeepMD by ~80% in energy accuracy and ~200% in force\nprediction. As a result, PDMD can reproduce the ab initio MD properties of\nwater clusters at a tiny fraction of its computational cost. These results\ndemonstrate that the proposed PDMD offers multiple-phase predictive power,\nenabling ultra-fast, general-purpose MD simulations while retaining ab initio\naccuracy.",
            "pdf_url": "http://arxiv.org/pdf/2412.04442v1",
            "published": "2024-12-05 18:56:26+00:00",
            "updated": "2024-12-05 18:56:26+00:00"
        },
        {
            "title": "Masked Autoencoders are PDE Learners",
            "authors": "Anthony Zhou, Amir Barati Farimani",
            "summary": "Neural solvers for partial differential equations (PDEs) have great potential\nto generate fast and accurate physics solutions, yet their practicality is\ncurrently limited by their generalizability. PDEs evolve over broad scales and\nexhibit diverse behaviors; predicting these phenomena will require learning\nrepresentations across a wide variety of inputs which may encompass different\ncoefficients, boundary conditions, resolutions, or even equations. As a step\ntowards generalizable PDE modeling, we adapt masked pretraining for physics\nproblems. Through self-supervised learning across PDEs, masked autoencoders can\nconsolidate heterogeneous physics to learn rich latent representations. We show\nthat learned representations can generalize to a limited set of unseen\nequations or parameters and are meaningful enough to regress PDE coefficients\nor the classify PDE features. Furthermore, conditioning neural solvers on\nlearned latent representations can improve time-stepping and super-resolution\nperformance across a variety of coefficients, discretizations, or boundary\nconditions, as well as on certain unseen PDEs. We hope that masked pretraining\ncan emerge as a unifying method across large, unlabeled, and heterogeneous\ndatasets to learn latent physics at scale.",
            "pdf_url": "http://arxiv.org/pdf/2403.17728v3",
            "published": "2024-03-26 14:17:01+00:00",
            "updated": "2024-12-05 18:55:44+00:00"
        },
        {
            "title": "Black Hole Solutions in Non-Minimally Coupled Weyl Connection Gravity",
            "authors": "M. Margarida Lima, Cl\u00e1udio Gomes",
            "summary": "Schwarzschild and Reissner-Nordstr{\\o}m black hole solutions are found in the\ncontext of a non-minimal matter-curvature coupling with the Weyl connection,\nboth in vacuum and in the presence of a cosmological constant-like matter\ncontent. This special case of non-metricity leads to black hole solutions with\nnon-vanishing scalar curvature. Moreover, vacuum Schwarzschild solutions differ\nfrom the ones from a constant curvature scenario in $f(R)$ theories with the\nappearance of a coefficient in the term linear in r and a corrected\n\"cosmological constant\". Non-vacuum Shwarzschild solutions have formally the\nsame solutions as in the previous case with the exception being the physical\ninterpretation of a cosmological constant as the source of the matter\nLagrangian as not a simple reparametrization of the $f(R)$ description.\nReissner-Nordstr{\\o}m solutions cannot be found in vacuum, but only in the\npresence of matter fields, such that the solutions also differ from the\nconstant curvature scenario in $f(R)$ theories by the term linear in r and\ncorrected/dressed charge and cosmological constant.",
            "pdf_url": "http://arxiv.org/pdf/2410.01856v2",
            "published": "2024-10-02 00:14:39+00:00",
            "updated": "2024-12-05 18:47:29+00:00"
        },
        {
            "title": "ACE2-SOM: Coupling to a slab ocean and learning the sensitivity of climate to changes in CO$_2$",
            "authors": "Spencer K. Clark, Oliver Watt-Meyer, Anna Kwa, Jeremy McGibbon, Brian Henn, W. Andre Perkins, Elynn Wu, Christopher S. Bretherton, Lucas M. Harris",
            "summary": "While autoregressive machine-learning-based emulators have been trained to\nproduce stable and accurate rollouts in the climate of the present-day and\nrecent past, none so far have been trained to emulate the sensitivity of\nclimate to substantial changes in CO$_2$ or other greenhouse gases. As an\ninitial step we couple the Ai2 Climate Emulator version 2 to a slab ocean model\n(hereafter ACE2-SOM) and train it on output from a collection of\nequilibrium-climate physics-based reference simulations with varying levels of\nCO$_2$. We test it in equilibrium and non-equilibrium climate scenarios with\nCO$_2$ concentrations seen and unseen in training.\n  ACE2-SOM performs well in equilibrium-climate inference with both in-sample\nand out-of-sample CO$_2$ concentrations, accurately reproducing the emergent\ntime-mean spatial patterns of surface temperature and precipitation change with\nCO$_2$ doubling, tripling, or quadrupling. In addition, the vertical profile of\natmospheric warming and change in extreme precipitation rates with increased\nCO$_2$ closely agree with the reference model. Non-equilibrium-climate\ninference is more challenging. With CO$_2$ increasing gradually at a rate of 2%\nyear$^{-1}$, ACE2-SOM can accurately emulate the global annual mean trends of\nsurface and lower-to-middle atmosphere fields but produces unphysical jumps in\nstratospheric fields. With an abrupt quadrupling of CO$_2$, ML-controlled\nfields transition unrealistically quickly to the 4xCO$_2$ regime. In doing so\nthey violate global energy conservation and exhibit unphysical sensitivities of\nand surface and top of atmosphere radiative fluxes to instantaneous changes in\nCO$_2$. Future emulator development needed to address these issues should\nimprove its generalizability to diverse climate change scenarios.",
            "pdf_url": "http://arxiv.org/pdf/2412.04418v1",
            "published": "2024-12-05 18:44:33+00:00",
            "updated": "2024-12-05 18:44:33+00:00"
        },
        {
            "title": "Emergent unitary designs for encoded qubits from coherent errors and syndrome measurements",
            "authors": "Zihan Cheng, Eric Huang, Vedika Khemani, Michael J. Gullans, Matteo Ippoliti",
            "summary": "Unitary $k$-designs are distributions of unitary gates that match the Haar\ndistribution up to its $k$-th statistical moment. They are a crucial resource\nfor randomized quantum protocols. However, their implementation on encoded\nlogical qubits is nontrivial due to the need for magic gates, which can require\na large resource overhead. In this work, we propose an efficient approach to\ngenerate unitary designs for encoded qubits in surface codes by applying local\nunitary rotations (\"coherent errors\") on the physical qubits followed by\nsyndrome measurement and error correction. We prove that under some conditions\non the coherent errors (notably including all single-qubit unitaries) and on\nthe error correcting code, this process induces a unitary transformation of the\nlogical subspace. We numerically show that the ensemble of logical unitaries\n(indexed by the random syndrome outcomes) converges to a unitary design in the\nthermodynamic limit, provided the density or strength of coherent errors is\nabove a finite threshold. This \"unitary design\" phase transition coincides with\nthe code's coherent error threshold under optimal decoding. Furthermore, we\npropose a classical algorithm to simulate the protocol based on a \"staircase\"\nimplementation of the surface code encoder and decoder circuits. This enables a\nmapping to a 1+1D monitored circuit, where we observe an entanglement phase\ntransition (and thus a classical complexity phase transition of the decoding\nalgorithm) coinciding with the aforementioned unitary design phase transition.\nOur results provide a practical way to realize unitary designs on encoded\nqubits, with applications including quantum state tomography and benchmarking\nin error correcting codes.",
            "pdf_url": "http://arxiv.org/pdf/2412.04414v1",
            "published": "2024-12-05 18:36:14+00:00",
            "updated": "2024-12-05 18:36:14+00:00"
        },
        {
            "title": "Providing Differential Privacy for Federated Learning Over Wireless: A Cross-layer Framework",
            "authors": "Jiayu Mao, Tongxin Yin, Aylin Yener, Mingyan Liu",
            "summary": "Federated Learning (FL) is a distributed machine learning framework that\ninherently allows edge devices to maintain their local training data, thus\nproviding some level of privacy. However, FL's model updates still pose a risk\nof privacy leakage, which must be mitigated. Over-the-air FL (OTA-FL) is an\nadapted FL design for wireless edge networks that leverages the natural\nsuperposition property of the wireless medium. We propose a wireless physical\nlayer (PHY) design for OTA-FL which improves differential privacy (DP) through\na decentralized, dynamic power control that utilizes both inherent Gaussian\nnoise in the wireless channel and a cooperative jammer (CJ) for additional\nartificial noise generation when higher privacy levels are required. Although\nprimarily implemented within the Upcycled-FL framework, where a\nresource-efficient method with first-order approximations is used at every even\niteration to decrease the required information from clients, our power control\nstrategy is applicable to any FL framework, including FedAvg and FedProx as\nshown in the paper. This adaptation showcases the flexibility and effectiveness\nof our design across different learning algorithms while maintaining a strong\nemphasis on privacy. Our design removes the need for client-side artificial\nnoise injection for DP, utilizing a cooperative jammer to enhance privacy\nwithout affecting transmission efficiency for higher privacy demands. Privacy\nanalysis is provided using the Moments Accountant method. We perform a\nconvergence analysis for non-convex objectives to tackle heterogeneous data\ndistributions, highlighting the inherent trade-offs between privacy and\naccuracy. Numerical results show that our approach with various FL algorithms\noutperforms the state-of-the-art under the same DP conditions on the non-i.i.d.\nFEMNIST dataset, and highlight the cooperative jammer's effectiveness in\nensuring strict privacy.",
            "pdf_url": "http://arxiv.org/pdf/2412.04408v1",
            "published": "2024-12-05 18:27:09+00:00",
            "updated": "2024-12-05 18:27:09+00:00"
        },
        {
            "title": "Demonstration of quantum computation and error correction with a tesseract code",
            "authors": "Ben W. Reichardt, David Aasen, Rui Chao, Alex Chernoguzov, Wim van Dam, John P. Gaebler, Dan Gresh, Dominic Lucchetti, Michael Mills, Steven A. Moses, Brian Neyenhuis, Adam Paetznick, Andres Paz, Peter E. Siegfried, Marcus P. da Silva, Krysta M. Svore, Zhenghan Wang, Matt Zanner",
            "summary": "A critical milestone for quantum computers is to demonstrate fault-tolerant\ncomputation that outperforms computation on physical qubits. The tesseract\nsubsystem color code protects four logical qubits in 16 physical qubits, to\ndistance four. Using the tesseract code on Quantinuum's trapped-ion quantum\ncomputers, we prepare high-fidelity encoded graph states on up to 12 logical\nqubits, beneficially combining for the first time fault-tolerant error\ncorrection and computation. We also protect encoded states through up to five\nrounds of error correction. Using performant quantum software and hardware\ntogether allows moderate-depth logical quantum circuits to have an order of\nmagnitude less error than the equivalent unencoded circuits.",
            "pdf_url": "http://arxiv.org/pdf/2409.04628v2",
            "published": "2024-09-06 21:36:49+00:00",
            "updated": "2024-12-05 18:22:15+00:00"
        },
        {
            "title": "Enhanced Sampling of Protein Conformational Changes via True Reaction Coordinates from Energy Relaxation",
            "authors": "Huiyu Li, Ao Ma",
            "summary": "The bottleneck in enhanced sampling lies in finding collective variables\n(CVs) that can effectively accelerate protein conformational changes. True\nreaction coordinates (tRCs) that can predict the committor are considered the\noptimal CVs, but identifying them requires unbiased natural reactive\ntrajectories, which, paradoxically, depend on effective enhanced sampling.\nUsing the generalized work functional method, we found that tRCs control both\nconformational changes and energy relaxation, enabling us to compute tRCs from\nenergy relaxation simulations. Applying bias to tRCs accelerated conformational\nchanges and ligand dissociation in HIV-1 protease and the PDZ2 domain by 10^5\nto 10^15-fold. The resulting trajectories follow natural transition pathways,\nenabling efficient generation of natural reactive trajectories. In contrast,\nbiased trajectories from empirical CVs often display non-physical features.\nFurthermore, by computing tRCs from a single protein structure, our method\nenables predictive sampling of conformational changes. These findings\nsignificantly broaden the range of protein functional processes accessible to\nmolecular dynamics simulations.",
            "pdf_url": "http://arxiv.org/pdf/2412.04400v1",
            "published": "2024-12-05 18:14:49+00:00",
            "updated": "2024-12-05 18:14:49+00:00"
        },
        {
            "title": "Studies of Cherenkov Photon Production in PbF$_2$ Crystals using Proton Beams at Fermilab",
            "authors": "Thomas Anderson, Alberto Belloni, Grace Cummings, Sarah Eno, Nora Fischer, Liang Guan, Yuxiang Guo, Robert Hirosky, James Hirschauer, Yihui Lai, Daniel Levin, Hui-Chi Lin, Mekhala Paranjpe, Jianming Qian, Bing Zhou, Junjie Zhu, Ren-Yuan Zhu",
            "summary": "Future lepton colliders such as the FCC-ee, CEPC, ILC, or a muon collider\nwill collect large data samples that allow precision physics studies with\nunprecedented accuracy, especially when the data is collected by innovative\nstate-of-the-art detectors. An electromagnetic calorimeter based on\nscintillating crystals, designed to separately record Cherenkov and\nscintillation light, can achieve precision measurements of electrons and\nphotons without sacrificing jet energy resolution, given adequate light\ncollection efficiency and separation. This paper presents initial measurements\nfrom a program aimed at developing such a calorimeter system for future\ncolliders. We focus on using PbF2 crystals to enhance the understanding of\nCherenkov light collection, marking the first step in this endeavor.",
            "pdf_url": "http://arxiv.org/pdf/2407.08033v2",
            "published": "2024-07-10 20:16:18+00:00",
            "updated": "2024-12-05 18:12:21+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "PaintScene4D: Consistent 4D Scene Generation from Text Prompts",
            "authors": "Vinayak Gupta, Yunze Man, Yu-Xiong Wang",
            "summary": "Recent advances in diffusion models have revolutionized 2D and 3D content\ncreation, yet generating photorealistic dynamic 4D scenes remains a significant\nchallenge. Existing dynamic 4D generation methods typically rely on distilling\nknowledge from pre-trained 3D generative models, often fine-tuned on synthetic\nobject datasets. Consequently, the resulting scenes tend to be object-centric\nand lack photorealism. While text-to-video models can generate more realistic\nscenes with motion, they often struggle with spatial understanding and provide\nlimited control over camera viewpoints during rendering. To address these\nlimitations, we present PaintScene4D, a novel text-to-4D scene generation\nframework that departs from conventional multi-view generative models in favor\nof a streamlined architecture that harnesses video generative models trained on\ndiverse real-world datasets. Our method first generates a reference video using\na video generation model, and then employs a strategic camera array selection\nfor rendering. We apply a progressive warping and inpainting technique to\nensure both spatial and temporal consistency across multiple viewpoints.\nFinally, we optimize multi-view images using a dynamic renderer, enabling\nflexible camera control based on user preferences. Adopting a training-free\narchitecture, our PaintScene4D efficiently produces realistic 4D scenes that\ncan be viewed from arbitrary trajectories. The code will be made publicly\navailable. Our project page is at https://paintscene4d.github.io/",
            "pdf_url": "http://arxiv.org/pdf/2412.04471v1",
            "published": "2024-12-05 18:59:57+00:00",
            "updated": "2024-12-05 18:59:57+00:00"
        },
        {
            "title": "Negative Token Merging: Image-based Adversarial Feature Guidance",
            "authors": "Jaskirat Singh, Lindsey Li, Weijia Shi, Ranjay Krishna, Yejin Choi, Pang Wei Koh, Michael F. Cohen, Stephen Gould, Liang Zheng, Luke Zettlemoyer",
            "summary": "Text-based adversarial guidance using a negative prompt has emerged as a\nwidely adopted approach to steer diffusion models away from producing undesired\nconcepts. While useful, performing adversarial guidance using text alone can be\ninsufficient to capture complex visual concepts or avoid specific visual\nelements like copyrighted characters. In this paper, for the first time we\nexplore an alternate modality in this direction by performing adversarial\nguidance directly using visual features from a reference image or other images\nin a batch. We introduce negative token merging (NegToMe), a simple but\neffective training-free approach which performs adversarial guidance through\nimages by selectively pushing apart matching visual features between reference\nand generated images during the reverse diffusion process. By simply adjusting\nthe used reference, NegToMe enables a diverse range of applications. Notably,\nwhen using other images in same batch as reference, we find that NegToMe\nsignificantly enhances output diversity (e.g., racial, gender, visual) by\nguiding features of each image away from others. Similarly, when used w.r.t.\ncopyrighted reference images, NegToMe reduces visual similarity to copyrighted\ncontent by 34.57%. NegToMe is simple to implement using just few-lines of code,\nuses only marginally higher (<4%) inference time and is compatible with\ndifferent diffusion architectures, including those like Flux, which don't\nnatively support the use of a negative prompt. Code is available at\nhttps://negtome.github.io",
            "pdf_url": "http://arxiv.org/pdf/2412.01339v2",
            "published": "2024-12-02 10:06:57+00:00",
            "updated": "2024-12-05 18:43:25+00:00"
        },
        {
            "title": "Learning to Reconstruct Accelerated MRI Through K-space Cold Diffusion without Noise",
            "authors": "Guoyao Shen, Mengyu Li, Chad W. Farris, Stephan Anderson, Xin Zhang",
            "summary": "Deep learning-based MRI reconstruction models have achieved superior\nperformance these days. Most recently, diffusion models have shown remarkable\nperformance in image generation, in-painting, super-resolution, image editing\nand more. As a generalized diffusion model, cold diffusion further broadens the\nscope and considers models built around arbitrary image transformations such as\nblurring, down-sampling, etc. In this paper, we propose a k-space cold\ndiffusion model that performs image degradation and restoration in k-space\nwithout the need for Gaussian noise. We provide comparisons with multiple deep\nlearning-based MRI reconstruction models and perform tests on a well-known\nlarge open-source MRI dataset. Our results show that this novel way of\nperforming degradation can generate high-quality reconstruction images for\naccelerated MRI.",
            "pdf_url": "http://arxiv.org/pdf/2311.10162v3",
            "published": "2023-11-16 19:34:18+00:00",
            "updated": "2024-12-05 18:16:10+00:00"
        },
        {
            "title": "GeoPos: A Minimal Positional Encoding for Enhanced Fine-Grained Details in Image Synthesis Using Convolutional Neural Networks",
            "authors": "Mehran Hosseini, Peyman Hosseini",
            "summary": "The enduring inability of image generative models to recreate intricate\ngeometric features, such as those present in human hands and fingers has been\nan ongoing problem in image generation for nearly a decade. While strides have\nbeen made by increasing model sizes and diversifying training datasets, this\nissue remains prevalent across all models, from denoising diffusion models to\nGenerative Adversarial Networks (GAN), pointing to a fundamental shortcoming in\nthe underlying architectures. In this paper, we demonstrate how this problem\ncan be mitigated by augmenting convolution layers geometric capabilities\nthrough providing them with a single input channel incorporating the relative\nn-dimensional Cartesian coordinate system. We show this drastically improves\nquality of images generated by Diffusion Models, GANs, and Variational\nAutoEncoders (VAE).",
            "pdf_url": "http://arxiv.org/pdf/2401.01951v2",
            "published": "2024-01-03 19:27:20+00:00",
            "updated": "2024-12-05 17:31:43+00:00"
        },
        {
            "title": "ActFusion: a Unified Diffusion Model for Action Segmentation and Anticipation",
            "authors": "Dayoung Gong, Suha Kwak, Minsu Cho",
            "summary": "Temporal action segmentation and long-term action anticipation are two\npopular vision tasks for the temporal analysis of actions in videos. Despite\napparent relevance and potential complementarity, these two problems have been\ninvestigated as separate and distinct tasks. In this work, we tackle these two\nproblems, action segmentation and action anticipation, jointly using a unified\ndiffusion model dubbed ActFusion. The key idea to unification is to train the\nmodel to effectively handle both visible and invisible parts of the sequence in\nan integrated manner; the visible part is for temporal segmentation, and the\ninvisible part is for future anticipation. To this end, we introduce a new\nanticipative masking strategy during training in which a late part of the video\nframes is masked as invisible, and learnable tokens replace these frames to\nlearn to predict the invisible future. Experimental results demonstrate the\nbi-directional benefits between action segmentation and anticipation. ActFusion\nachieves the state-of-the-art performance across the standard benchmarks of 50\nSalads, Breakfast, and GTEA, outperforming task-specific models in both of the\ntwo tasks with a single unified model through joint learning.",
            "pdf_url": "http://arxiv.org/pdf/2412.04353v1",
            "published": "2024-12-05 17:12:35+00:00",
            "updated": "2024-12-05 17:12:35+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "A Unified Framework for Evaluating the Effectiveness and Enhancing the Transparency of Explainable AI Methods in Real-World Applications",
            "authors": "Md. Ariful Islam, M. F. Mridha, Md Abrar Jahin, Nilanjan Dey",
            "summary": "The rapid advancement of deep learning has resulted in substantial\nadvancements in AI-driven applications; however, the \"black box\" characteristic\nof these models frequently constrains their interpretability, transparency, and\nreliability. Explainable artificial intelligence (XAI) seeks to elucidate AI\ndecision-making processes, guaranteeing that explanations faithfully represent\nthe model's rationale and correspond with human comprehension. Despite\ncomprehensive research in XAI, a significant gap persists in standardized\nprocedures for assessing the efficacy and transparency of XAI techniques across\nmany real-world applications. This study presents a unified XAI evaluation\nframework incorporating extensive quantitative and qualitative criteria to\nsystematically evaluate the correctness, interpretability, robustness,\nfairness, and completeness of explanations generated by AI models. The\nframework prioritizes user-centric and domain-specific adaptations, hence\nimproving the usability and reliability of AI models in essential domains. To\naddress deficiencies in existing evaluation processes, we suggest defined\nbenchmarks and a systematic evaluation pipeline that includes data loading,\nexplanation development, and thorough method assessment. The suggested\nframework's relevance and variety are evidenced by case studies in healthcare,\nfinance, agriculture, and autonomous systems. These provide a solid basis for\nthe equitable and dependable assessment of XAI methodologies. This paradigm\nenhances XAI research by offering a systematic, flexible, and pragmatic method\nto guarantee transparency and accountability in AI systems across many\nreal-world contexts.",
            "pdf_url": "http://arxiv.org/pdf/2412.03884v1",
            "published": "2024-12-05 05:30:10+00:00",
            "updated": "2024-12-05 05:30:10+00:00"
        }
    ]
}