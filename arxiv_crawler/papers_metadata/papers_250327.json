{
    "Physics": [
        {
            "title": "A Pretraining-Finetuning Computational Framework for Material Homogenization",
            "authors": "Yizheng Wang, Xiang Li, Ziming Yan, Shuaifeng Ma, Jinshuai Bai, Bokai Liu, Timon Rabczuk, Yinghua Liu",
            "summary": "Homogenization is a fundamental tool for studying multiscale physical\nphenomena. Traditional numerical homogenization methods, heavily reliant on\nfinite element analysis, demand significant computational resources, especially\nfor complex geometries, materials, and high-resolution problems. To address\nthese challenges, we propose PreFine-Homo, a novel numerical homogenization\nframework comprising two phases: pretraining and fine-tuning. In the\npretraining phase, a Fourier Neural Operator (FNO) is trained on large datasets\nto learn the mapping from input geometries and material properties to\ndisplacement fields. In the fine-tuning phase, the pretrained predictions serve\nas initial solutions for iterative algorithms, drastically reducing the number\nof iterations needed for convergence. The pretraining phase of PreFine-Homo\ndelivers homogenization results up to 1000 times faster than conventional\nmethods, while the fine-tuning phase further enhances accuracy. Moreover, the\nfine-tuning phase grants PreFine-Homo unlimited generalization capabilities,\nenabling continuous learning and improvement as data availability increases. We\nvalidate PreFine-Homo by predicting the effective elastic tensor for 3D\nperiodic materials, specifically Triply Periodic Minimal Surfaces (TPMS). The\nresults demonstrate that PreFine-Homo achieves high precision, exceptional\nefficiency, robust learning capabilities, and strong extrapolation ability,\nestablishing it as a powerful tool for multiscale homogenization tasks.",
            "pdf_url": "http://arxiv.org/pdf/2404.07943v2",
            "published": "2024-03-18 06:47:35+00:00",
            "updated": "2025-03-26 17:52:45+00:00"
        },
        {
            "title": "On the magnetic perturbation theory for Chern insulators",
            "authors": "Horia D. Cornean, Massimo Moscolari",
            "summary": "The gauge covariant magnetic perturbation theory is tailored for one-body\nSchr\\\"odinger operators perturbed by long-range magnetic fields. In this work\nwe present a self-contained exposition of the method, by outlining its\ntechnical foundations and discussing the physical heuristics behind the proofs.\nWe apply it in order to prove the stability of spectral gaps and to study the\nlocation of the discrete spectrum. We also analyze the (lack of) continuity\nwith respect to the magnetic field of spectral projections corresponding to\nfinite spectral islands, which is a particularly important situation for\nsystems modelling Chern insulators. Finally, we show how to construct\napproximate projections that have an explicit dependence with respect to the\nmagnetic field parameter.",
            "pdf_url": "http://arxiv.org/pdf/2503.20763v1",
            "published": "2025-03-26 17:50:27+00:00",
            "updated": "2025-03-26 17:50:27+00:00"
        },
        {
            "title": "Stabilizing Neural Likelihood Ratio Estimation",
            "authors": "Fernando Torales Acosta, Tanvi Wamorkar, Vinicius Mikuni, Benjamin Nachman",
            "summary": "Likelihood ratios are used for a variety of applications in particle physics\ndata analysis, including parameter estimation, unfolding, and anomaly\ndetection. When the data are high-dimensional, neural networks provide an\neffective tools for approximating these ratios. However, neural network\ntraining has an inherent stochasticity that limits their precision. A\nwidely-used approach to reduce these fluctuations is to train many times and\naverage the output (ensembling). We explore different approaches to ensembling\nand pretraining neural networks for stabilizing likelihood ratio estimation.\nFor numerical studies focus on unbinned unfolding with OmniFold, as it requires\nmany likelihood ratio estimations. We find that ensembling approaches that\naggregate the models at step 1, before pushing the weights to step 2 improve\nboth bias and variance of final results. Variance can be further improved by\npre-training, however at the cost increasing bias.",
            "pdf_url": "http://arxiv.org/pdf/2503.20753v1",
            "published": "2025-03-26 17:38:44+00:00",
            "updated": "2025-03-26 17:38:44+00:00"
        },
        {
            "title": "Accelerated State Expansion of a Nanoparticle in a Dark Inverted Potential",
            "authors": "Gregoire F. M. Tomassi, Daniel Veldhuizen, Bruno Melo, Davide Candoli, Andreu Riera-Campeny, Oriol Romero-Isart, Nadine Meyer, Romain Quidant",
            "summary": "While the wave packet of a massive particle grows linearly under free\ndynamics, it grows exponentially in an inverted harmonic potential, offering a\npathway to rapidly increase quantum fluctuations to macroscopic dimensions. In\nthis work, we experimentally demonstrate this principle by expanding the\ncenter-of-mass thermal state of a 125nm silica nanoparticle to a position\nuncertainty of 43.4nm within 260 $\\mu$s. This expansion, achieved using an\ninverted dark potential to minimize decoherence from photon recoil, represents\na 952-fold increase, reaching a scale comparable to the nanoparticle's physical\nsize. This work represents a key advancement toward preparing macroscopic\nquantum superpositions at unprecedented mass and length scales.",
            "pdf_url": "http://arxiv.org/pdf/2503.20707v1",
            "published": "2025-03-26 16:40:33+00:00",
            "updated": "2025-03-26 16:40:33+00:00"
        },
        {
            "title": "CyberDiver: an untethered robotic impactor for water-entry experiments",
            "authors": "John T. Antolik, Eli A. Silver, Jesse L. Belden, Daniel M. Harris",
            "summary": "We present the CyberDiver, an untethered robotic impactor capable of actively\nmodulating the fluid physics during high-speed water entry. First, we utilize\nthe CyberDiver to extend our understanding of the water entry of passively\nflexible systems, designing a high-bandwidth controller that enables the\nCyberDiver to operate as a cyber-physical system that permits an arbitrary\nprogrammable structural coupling to be experimentally tested. Onboard sensors\nrecord the body acceleration during impact and reveal that the introduction of\ndamping or a nonlinear force-versus-displacement structural law can\nsignificantly reduce impact loading as compared to a linear elastic case, with\nimplications for damage mitigation in aerospace and naval applications. Next,\nby operating the CyberDiver in a displacement control mode, we demonstrate that\nthe splash size can be dramatically altered depending on the parameters of an\nactive maneuver, laying a groundwork for better understanding the techniques of\nhuman competitive divers.",
            "pdf_url": "http://arxiv.org/pdf/2503.20702v1",
            "published": "2025-03-26 16:34:51+00:00",
            "updated": "2025-03-26 16:34:51+00:00"
        },
        {
            "title": "Low-Energy Constants of Chiral Perturbation Theory from Pion Scalar Form Factors in $N_f=2+1$-Flavor Lattice QCD with Controlled Errors",
            "authors": "Georg von Hippel, Konstantin Ottnad",
            "summary": "We determine the low-energy constants (LECs) $f_0$, $L_4^r$ and $L_5^r$ of\nSU(3) Chiral Perturbation Theory ($\\chi$PT) from a lattice QCD calculation of\nthe scalar form factors of the pion with fully controlled systematics. Lattice\nresults are computed on a large set of $N_f=2+1$ gauge ensembles covering four\nlattice spacings $a\\in[0.049,0.086]\\mathrm{fm}$, pion masses\n$M_\\pi\\in[130,350]\\mathrm{MeV}$, and various large physical volumes. By\ndetermining the notorious quark-disconnected contributions with unprecedented\nprecision and using a large range of source-sink separations\n$t_\\mathrm{sep}\\in[1.0,3.25]\\mathrm{fm}$, we are able for the first time to\nobtain the scalar radii from a $z$-expansion parameterization of the form\nfactors rather than a simple linear approximation at small momentum transfer.\nThe LECs are obtained from the physical extrapolation of the radii using NLO\nSU(3) NLO $\\chi$PT to parameterize the quark mass dependence. Systematic\nuncertainties are estimated via model averages based on the Akaike Information\nCriterion. Our determination of $L_4^r$ is the first lattice determination to\nobtain a result not compatible with zero.",
            "pdf_url": "http://arxiv.org/pdf/2503.20689v1",
            "published": "2025-03-26 16:20:50+00:00",
            "updated": "2025-03-26 16:20:50+00:00"
        },
        {
            "title": "The Scalar Size of the Pion from Lattice QCD",
            "authors": "Konstantin Ottnad, Georg von Hippel",
            "summary": "We present a lattice QCD calculation of the pion scalar form factor and\nassociated radii with fully controlled systematics. Lattice results are\ncomputed on a large set of 17 gauge ensembles with $N_f=2+1$ Wilson\nClover-improved sea quarks. These ensembles cover four values of the lattice\nspacing between $a=0.049\\mathrm{fm}$ and $a=0.086\\mathrm{fm}$, a pion mass\nrange of $130 - 350\\mathrm{MeV}$ and various physical volumes. A precise\ndetermination of the notorious quark-disconnected contributions facilitates an\nunprecedented momentum resolution for the form factor, particularly on large\nand fine ensembles in the vicinity of physical quark mass. A large range of\nsource-sink separations $1.0\\mathrm{fm} \\lesssim t_\\mathrm{sep} \\lesssim\n3.25\\mathrm{fm}$ is used to reliably extract the relevant ground state matrix\nelements at vanishing and non-vanishing momentum transfer. This allows us for\nthe first time to obtain the scalar radii from a $z$-expansion parametrization\nof the $Q^2$-dependence of the resulting form factors rather than a simple,\nlinear approximation at small momentum transfer. The physical extrapolation for\nthe radii is carried out using three-flavor NLO chiral perturbation theory to\nparametrize the quark mass dependence in terms of three low-energy constants,\nincluding the first lattice determination of $L_4^r$. Systematic uncertainties\non the final results related to the ground state extraction, form factor\nparametrization as well as the physical extrapolation are accounted for via\nmodel averages based on the Akaike Information Criterion.",
            "pdf_url": "http://arxiv.org/pdf/2503.20687v1",
            "published": "2025-03-26 16:20:11+00:00",
            "updated": "2025-03-26 16:20:11+00:00"
        },
        {
            "title": "Towards Scalable Foundation Model for Multi-modal and Hyperspectral Geospatial Data",
            "authors": "Haozhe Si, Yuxuan Wan, Minh Do, Deepak Vasisht, Han Zhao, Hendrik F. Hamann",
            "summary": "Geospatial raster data, such as that collected by satellite-based imaging\nsystems at different times and spectral bands, hold immense potential for\nenabling a wide range of high-impact applications. This potential stems from\nthe rich information that is spatially and temporally contextualized across\nmultiple channels and sensing modalities. Recent work has adapted existing\nself-supervised learning approaches for such geospatial data. However, they\nfall short of scalable model architectures, leading to inflexibility and\ncomputational inefficiencies when faced with an increasing number of channels\nand modalities. To address these limitations, we introduce Low-rank Efficient\nSpatial-Spectral Vision Transformer with three key innovations: i) the LESS\nAttention Block that approximates high-dimensional spatial-spectral attention\nthrough Kronecker's product of the low-dimensional spatial and spectral\nattention components; ii) the Continuous Positional-Channel Embedding Layer\nthat preserves both the continuity and physical characteristics of each\nspatial-spectral patch; and iii) the Perception Field Mask that exploits local\nspatial dependencies by constraining attention to neighboring patches. To\nevaluate the proposed innovations, we construct GFM-Bench, which serves as a\ncomprehensive benchmark for such geospatial raster data. We pretrain LESS ViT\nusing a Hyperspectral Masked Autoencoder framework with integrated positional\nand channel masking strategies. Experimental results demonstrate that our\nproposed method achieves competitive performance against state-of-the-art\nmulti-modal geospatial foundation models while outperforming them on\ncross-satellite generalization tasks with higher computational efficiency. The\nflexibility and extensibility of our framework make it a promising direction\nfor future geospatial data analysis tasks that involve a wide range of\nmodalities and channels.",
            "pdf_url": "http://arxiv.org/pdf/2503.12843v3",
            "published": "2025-03-17 05:42:19+00:00",
            "updated": "2025-03-26 16:15:55+00:00"
        },
        {
            "title": "Jet Substructure Analysis for Distinguishing Left- and Right-Handed Couplings of Heavy Neutrino in $W'$ Decay at the HL-LHC",
            "authors": "Songshaptak De, Atri Dey, Tousik Samui",
            "summary": "The search for heavy $W'$ bosons in their decay modes to a lepton and a heavy\nneutrino offers a promising avenue for probing new physics beyond the Standard\nModel. This work focuses on such a signature with an energetic lepton plus a\nfat jet, originating from the heavy neutrino and containing a lepton. We have\nemployed the jet substructure techniques to isolate the embedded lepton as a\nsubjet of the fat jet. The Lepton Subjet Fraction ($LSF$) and Lepton Mass Drop\n($LMD$) variables constructed from the lepton subjet help in separating the\nsignal region from the background. We further study the polarization properties\nof the $W'$ coupling to the lepton and heavy neutrino through the decay\nproducts of the neutrino. Instead of relying on a specific model, we employ\ngeneric couplings and explore the discrimination power. Jet substructure-based\nangular variables $z_\\ell$, $z_\\theta$, and $z_k$ are combined to form BDT\nscores to obtain better separation power between left-chiral ($V-A$) and\nright-chiral ($V+A$) coupling configurations. By using $CL_s$ type profile\nlikelihood estimator, we could achieve $\\sim$ 2$\\sigma$ $-$ 3$\\sigma$\nsignificance of excluding one coupling configuration in favour of the other.",
            "pdf_url": "http://arxiv.org/pdf/2411.14910v2",
            "published": "2024-11-22 13:10:05+00:00",
            "updated": "2025-03-26 15:55:06+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "High Quality Diffusion Distillation on a Single GPU with Relative and Absolute Position Matching",
            "authors": "Guoqiang Zhang, Kenta Niwa, J. P. Lewis, Cedric Mesnage, W. Bastiaan Kleijn",
            "summary": "We introduce relative and absolute position matching (RAPM), a diffusion\ndistillation method resulting in high quality generation that can be trained\nefficiently on a single GPU. Recent diffusion distillation research has\nachieved excellent results for high-resolution text-to-image generation with\nmethods such as phased consistency models (PCM) and improved distribution\nmatching distillation (DMD2). However, these methods generally require many\nGPUs (e.g.~8-64) and significant batchsizes (e.g.~128-2048) during training,\nresulting in memory and compute requirements that are beyond the resources of\nsome researchers. RAPM provides effective single-GPU diffusion distillation\ntraining with a batchsize of 1. The new method attempts to mimic the sampling\ntrajectories of the teacher model by matching the relative and absolute\npositions. The design of relative positions is inspired by PCM. Two\ndiscriminators are introduced accordingly in RAPM, one for matching relative\npositions and the other for absolute positions. Experimental results on\nStableDiffusion (SD) V1.5 and SDXL indicate that RAPM with 4 timesteps produces\ncomparable FID scores as the best method with 1 timestep under very limited\ncomputational resources.",
            "pdf_url": "http://arxiv.org/pdf/2503.20744v1",
            "published": "2025-03-26 17:29:08+00:00",
            "updated": "2025-03-26 17:29:08+00:00"
        },
        {
            "title": "RecTable: Fast Modeling Tabular Data with Rectified Flow",
            "authors": "Masane Fuchi, Tomohiro Takagi",
            "summary": "Score-based or diffusion models generate high-quality tabular data,\nsurpassing GAN-based and VAE-based models. However, these methods require\nsubstantial training time. In this paper, we introduce RecTable, which uses the\nrectified flow modeling, applied in such as text-to-image generation and\ntext-to-video generation. RecTable features a simple architecture consisting of\na few stacked gated linear unit blocks. Additionally, our training strategies\nare also simple, incorporating a mixed-type noise distribution and a\nlogit-normal timestep distribution. Our experiments demonstrate that RecTable\nachieves competitive performance compared to the several state-of-the-art\ndiffusion and score-based models while reducing the required training time. Our\ncode is available at https://github.com/fmp453/rectable.",
            "pdf_url": "http://arxiv.org/pdf/2503.20731v1",
            "published": "2025-03-26 17:12:20+00:00",
            "updated": "2025-03-26 17:12:20+00:00"
        },
        {
            "title": "A weakly-supervised deep learning model for fast localisation and delineation of the skeleton, internal organs, and spinal canal on Whole-Body Diffusion-Weighted MRI (WB-DWI)",
            "authors": "A. Candito, A. Dragan, R. Holbrey, A. Ribeiro, R. Donners, C. Messiou, N. Tunariu, D. -M. Koh, M. D. Blackledge, The Institute of Cancer Research, London, United Kingdom, The Royal Marsden NHS Foundation Trust, London, United Kingdom, University Hospital Basel, Basel, Switzerland",
            "summary": "Background: Apparent Diffusion Coefficient (ADC) values and Total Diffusion\nVolume (TDV) from Whole-body diffusion-weighted MRI (WB-DWI) are recognized\ncancer imaging biomarkers. However, manual disease delineation for ADC and TDV\nmeasurements is unfeasible in clinical practice, demanding automation. As a\nfirst step, we propose an algorithm to generate fast and reproducible\nprobability maps of the skeleton, adjacent internal organs (liver, spleen,\nurinary bladder, and kidneys), and spinal canal. Methods: We developed an\nautomated deep-learning pipeline based on a 3D patch-based Residual U-Net\narchitecture that localizes and delineates these anatomical structures on\nWB-DWI. The algorithm was trained using \"soft-labels\" (non-binary\nsegmentations) derived from a computationally intensive atlas-based approach.\nFor training and validation, we employed a multi-center WB-DWI dataset\ncomprising 532 scans from patients with Advanced Prostate Cancer (APC) or\nMultiple Myeloma (MM), with testing on 45 patients. Results: Our\nweakly-supervised deep learning model achieved an average dice\nscore/precision/recall of 0.66/0.6/0.73 for skeletal delineations,\n0.8/0.79/0.81 for internal organs, and 0.85/0.79/0.94 for spinal canal, with\nsurface distances consistently below 3 mm. Relative median ADC and\nlog-transformed volume differences between automated and manual expert-defined\nfull-body delineations were below 10% and 4%, respectively. The computational\ntime for generating probability maps was 12x faster than the atlas-based\nregistration algorithm (25 s vs. 5 min). An experienced radiologist rated the\nmodel's accuracy \"good\" or \"excellent\" on test datasets. Conclusion: Our model\noffers fast and reproducible probability maps for localizing and delineating\nbody regions on WB-DWI, enabling ADC and TDV quantification, potentially\nsupporting clinicians in disease staging and treatment response assessment.",
            "pdf_url": "http://arxiv.org/pdf/2503.20722v1",
            "published": "2025-03-26 17:03:46+00:00",
            "updated": "2025-03-26 17:03:46+00:00"
        },
        {
            "title": "Text-to-Model: Text-Conditioned Neural Network Diffusion for Train-Once-for-All Personalization",
            "authors": "Zexi Li, Lingzhi Gao, Chao Wu",
            "summary": "Generative artificial intelligence (GenAI) has made significant progress in\nunderstanding world knowledge and generating content from human languages\nacross various modalities, like text-to-text large language models,\ntext-to-image stable diffusion, and text-to-video Sora. While in this paper, we\ninvestigate the capability of GenAI for text-to-model generation, to see\nwhether GenAI can comprehend hyper-level knowledge embedded within AI itself\nparameters. Specifically, we study a practical scenario termed\ntrain-once-for-all personalization, aiming to generate personalized models for\ndiverse end-users and tasks using text prompts. Inspired by the recent\nemergence of neural network diffusion, we present Tina, a text-conditioned\nneural network diffusion for train-once-for-all personalization. Tina leverages\na diffusion transformer model conditioned on task descriptions embedded using a\nCLIP model. Despite the astronomical number of potential personalized tasks\n(e.g., $1.73\\times10^{13}$), by our design, Tina demonstrates remarkable\nin-distribution and out-of-distribution generalization even trained on small\ndatasets ($\\sim 1000$). We further verify whether and how \\Tina understands\nworld knowledge by analyzing its capabilities under zero-shot/few-shot image\nprompts, different numbers of personalized classes, prompts of natural language\ndescriptions, and predicting unseen entities.",
            "pdf_url": "http://arxiv.org/pdf/2405.14132v2",
            "published": "2024-05-23 03:11:18+00:00",
            "updated": "2025-03-26 16:33:17+00:00"
        },
        {
            "title": "Data Augmentation in Earth Observation: A Diffusion Model Approach",
            "authors": "Tiago Sousa, Beno\u00eet Ries, Nicolas Guelfi",
            "summary": "High-quality Earth Observation (EO) imagery is essential for accurate\nanalysis and informed decision making across sectors. However, data scarcity\ncaused by atmospheric conditions, seasonal variations, and limited geographical\ncoverage hinders the effective application of Artificial Intelligence (AI) in\nEO. Traditional data augmentation techniques, which rely on basic parameterized\nimage transformations, often fail to introduce sufficient diversity across key\nsemantic axes. These axes include natural changes such as snow and floods,\nhuman impacts like urbanization and roads, and disasters such as wildfires and\nstorms, which limits the accuracy of AI models in EO applications. To address\nthis, we propose a four-stage data augmentation approach that integrates\ndiffusion models to enhance semantic diversity. Our method employs meta-prompts\nfor instruction generation, vision-language models for rich captioning,\nEO-specific diffusion model fine-tuning, and iterative data augmentation.\nExtensive experiments using four augmentation techniques demonstrate that our\napproach consistently outperforms established methods, generating semantically\ndiverse EO images and improving AI model performance.",
            "pdf_url": "http://arxiv.org/pdf/2406.06218v2",
            "published": "2024-06-10 12:33:47+00:00",
            "updated": "2025-03-26 16:23:33+00:00"
        }
    ]
}