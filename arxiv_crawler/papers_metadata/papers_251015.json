{
    "Physics": [
        {
            "title": "Ax-Prover: A Deep Reasoning Agentic Framework for Theorem Proving in Mathematics and Quantum Physics",
            "authors": "Marco Del Tredici, Jacob McCarran, Benjamin Breen, Javier Aspuru Mijares, Weichen Winston Yin, Jacob M. Taylor, Frank Koppens, Dirk Englund",
            "summary": "We present Ax-Prover, a multi-agent system for automated theorem proving in\nLean that can solve problems across diverse scientific domains and operate\neither autonomously or collaboratively with human experts. To achieve this,\nAx-Prover approaches scientific problem solving through formal proof\ngeneration, a process that demands both creative reasoning and strict syntactic\nrigor. Ax-Prover meets this challenge by equipping Large Language Models\n(LLMs), which provide knowledge and reasoning, with Lean tools via the Model\nContext Protocol (MCP), which ensure formal correctness. To evaluate its\nperformance as an autonomous prover, we benchmark our approach against frontier\nLLMs and specialized prover models on two public math benchmarks and on two\nLean benchmarks we introduce in the fields of abstract algebra and quantum\ntheory. On public datasets, Ax-Prover is competitive with state-of-the-art\nprovers, while it largely outperform them on the new benchmarks. This shows\nthat, unlike specialized systems that struggle to generalize, our tool-based\nagentic theorem prover approach offers a generalizable methodology for formal\nverification across diverse scientific domains. Furthermore, we demonstrate\nAx-Prover's assistant capabilities in a practical use case, showing how it\nenabled an expert mathematician to formalize the proof of a complex\ncryptography theorem.",
            "pdf_url": "http://arxiv.org/pdf/2510.12787v1",
            "published": "2025-10-14 17:57:04+00:00",
            "updated": "2025-10-14 17:57:04+00:00"
        },
        {
            "title": "Leading soft theorems on plane wave backgrounds",
            "authors": "Sonja Klisch",
            "summary": "The infrared singularities of scattering amplitudes have historically\ncontributed to much development in understanding fundamental structures in\nphysics. However, the fate of the leading soft singularities of amplitudes in\nnon-trivial background fields has remained largely unknown. In this paper, we\nderive the leading soft theorems for photons, gluons and gravitons on generic\nplane wave backgrounds in gauge theory and gravity. The results differ from the\nflat space results through dependence on the initial conditions of the soft\nmediator. We also consider the special case of self-dual plane wave\nbackgrounds, and match onto the flat space results when the background is\ntreated perturbatively.",
            "pdf_url": "http://arxiv.org/pdf/2504.09314v2",
            "published": "2025-04-12 19:23:53+00:00",
            "updated": "2025-10-14 17:44:56+00:00"
        },
        {
            "title": "Entanglement detection in quantum materials with competing orders",
            "authors": "Giacomo Mazza, Costantino Budroni",
            "summary": "We investigate entanglement detection in quantum materials through criteria\nbased on the simultaneous suppression of collective matter excitations. Unlike\nother detection schemes, these criteria can be applied to continuous and\nunbounded variables. By considering a system of interacting dipoles on a\nlattice, we show the detection of collective entanglement arising from two\ndifferent physical mechanisms, namely, the ferroelectric ordering and the\ndressing of matter degrees of freedom by light. In the latter case, the\ndetection shows the formation of a collective entangled phase not directly\nrelated to spontaneous symmetry breaking. These results open a new perspective\nfor the entanglement characterization of competing orders in quantum materials,\nand have direct application to quantum paraelectrics with large polariton\nsplittings.",
            "pdf_url": "http://arxiv.org/pdf/2404.12931v2",
            "published": "2024-04-19 14:58:58+00:00",
            "updated": "2025-10-14 17:31:56+00:00"
        },
        {
            "title": "Digital Twin Simulations Toolbox of the Nitrogen-Vacancy Center in Diamond",
            "authors": "Lucas Tsunaki, Anmol Singh, Sergei Trofimov, Boris Naydenov",
            "summary": "The nitrogen-vacancy (NV) center in diamond is a crucial platform for quantum\ntechnologies, where its precise numerical modeling is indispensable for the\ncontinued advancement of the field. We present here a Python library for\nsimulating the NV spin dynamics under general experimental conditions, i.e. a\ndigital twin. Our library accounts for electromagnetic pulses and other\nenvironmental inputs, which are used to solve the system's time evolution,\nresulting in a physical output in the form of a quantum observable given by\nfluorescence. The simulation framework is based on a non-perturbative\ntime-dependent Hamiltonian model, where the states initialization and readout\nare postulated from the interaction with optical fields. By eliminating\noversimplifications such as the adoption of rotating frames for the microwave\nand radio frequency fields, our simulations reveal subtle dynamics emerging\nfrom realistic pulse constraints. The software is illustrated with three\nexamples and validated by comparing the simulations with experimental reports,\nrelevant to the fields of quantum computing (conditional logic gates), sensing\n(dynamical decoupling sequences with coupled spins) and networks (state\nteleportation). Overall, this digital twin delivers a robust numerical modeling\nof the NV spin dynamics, with simple and accessible usability, which can be\nused for a wide range of applications.",
            "pdf_url": "http://arxiv.org/pdf/2507.18759v2",
            "published": "2025-07-24 19:22:23+00:00",
            "updated": "2025-10-14 16:37:59+00:00"
        },
        {
            "title": "Superdiffusion resilience in Heisenberg Chains with 2D interactions on a quantum processor",
            "authors": "Keerthi Kumaran, Manas Sajjan, Bibek Pokharel, Kevin Wang, Joe Gibbs, Jeffrey Cohn, Barbara Jones, Sarah Mostame, Sabre Kais, Arnab Banerjee",
            "summary": "Observing superdiffusive scaling in the spin transport of the integrable 1D\nHeisenberg model is one of the key discoveries in non-equilibrium quantum\nmany-body physics. Despite this remarkable theoretical development and the\nsubsequent experimental observation of the phenomena in KCuF$_3$, real\nmaterials are often imperfect and contain integrability breaking interactions.\nUnderstanding the effect of such terms on the superdiffusion is crucial in\nidentifying connections to such materials. Current quantum hardware has already\nascertained its utility in studying such non-equilibrium phenomena by\nsimulating the superdiffusion of the 1D Heisenberg model. In this work, we\nperform a quantum simulation of the superdiffusion breakdown by generalizing\nthe superdiffusive Floquet-type 1D Heisenberg model to a general 2D model. We\ncomprehensively study the effect of different 2D interactions on the\nsuperdiffusion breakdown by tuning up their strength from zero, corresponding\nto the 1D Heisenberg chain, to finite nonzero values. We observe that certain\n2D interactions are more resilient against superdiffusion breakdown than others\nand that the $SU(2)$ preserving 2D interaction has the highest resilience among\nall the 2D interactions we study. Importantly, this observed resilience has\ndirect implications for sustaining superdiffusive spin transport in\ntwo-dimensional lattices. We reason out the relative resilience against the\nsuperdiffusion breakdown through an analysis of the scattering coefficients off\nthe 2D interaction in otherwise 1D chains. The relative resilience of different\ninteraction types against superdiffusion breakdown was also captured in quantum\nhardware with remarkable accuracy, further establishing the current quantum\nhardware's applicability in simulating interesting non-equilibrium quantum\nmany-body phenomena.",
            "pdf_url": "http://arxiv.org/pdf/2503.14371v2",
            "published": "2025-03-18 16:02:33+00:00",
            "updated": "2025-10-14 16:26:49+00:00"
        },
        {
            "title": "Stable bi-frequency spinor modes as Dark Matter candidates",
            "authors": "Andrew Comech, Niranjana Kulkarni, Nabile Boussa\u00efd, Jes\u00fas Cuevas-Maraver",
            "summary": "We show that spinor systems with scalar self-interaction, such as the\nDirac--Klein--Gordon system with Yukawa coupling or the Soler model,\ngenerically have bi-frequency solitary wave solutions. We develop the approach\nto stability properties of such waves and use the radial reduction to show that\nindeed the (linear) stability is available for a wide range of parameters. We\nshow that only bi-frequency modes can be dynamically stable and suggest that\nstable bi-frequency modes can serve as storages of the Dark Matter. The\napproach is based on linear stability results of one-frequency solitary waves\nin (3+1)D Soler model, which we obtain as a by-product.",
            "pdf_url": "http://arxiv.org/pdf/2501.04027v3",
            "published": "2024-12-30 18:52:12+00:00",
            "updated": "2025-10-14 16:21:37+00:00"
        },
        {
            "title": "Physics-Informed Autonomous LLM Agents for Explainable Power Electronics Modulation Design",
            "authors": "Junhua Liu, Fanfan Lin, Xinze Li, Kwan Hui Lim, Shuai Zhao",
            "summary": "LLM-based autonomous agents have recently shown strong capabilities in\nsolving complex industrial design tasks. However, in domains aiming for carbon\nneutrality and high-performance renewable energy systems, current AI-assisted\ndesign automation methods face critical challenges in explainability,\nscalability, and practical usability. To address these limitations, we\nintroduce PHIA (Physics-Informed Autonomous Agent), an LLM-driven system that\nautomates modulation design for power converters in Power Electronics Systems\nwith minimal human intervention. In contrast to traditional pipeline-based\nmethods, PHIA incorporates an LLM-based planning module that interactively\nacquires and verifies design requirements via a user-friendly chat interface.\nThis planner collaborates with physics-informed simulation and optimization\ncomponents to autonomously generate and iteratively refine modulation designs.\nThe interactive interface also supports interpretability by providing textual\nexplanations and visual outputs throughout the design process. Experimental\nresults show that PHIA reduces standard mean absolute error by 63.2% compared\nto the second-best benchmark and accelerates the overall design process by over\n33 times. A user study involving 20 domain experts further confirms PHIA's\nsuperior design efficiency and usability, highlighting its potential to\ntransform industrial design workflows in power electronics.",
            "pdf_url": "http://arxiv.org/pdf/2411.14214v2",
            "published": "2024-11-21 15:24:41+00:00",
            "updated": "2025-10-14 16:10:53+00:00"
        },
        {
            "title": "In-pixel integration of signal processing and AI/ML based data filtering for particle tracking detectors",
            "authors": "Benjamin Parpillon, Anthony Badea, Danush Shekar, Christian Gingu, Giuseppe Di Guglielmo, Tom Deline, Adam Quinn, Michele Ronchi, Benjamin Weiss, Jennet Dickinson, Jieun Yoo, Corrinne Mills, Daniel Abadjiev, Aidan Nicholas, Eliza Howard, Carissa Kumar, Eric You, Mira Littmann, Karri DiPetrillo, Arghya Ranjan Das, Mia Liu, David Jiang, Mark S. Neubauer, Morris Swartz, Petar Maksimovic, Alice Bean, Ricardo Silvestre, Jannicke Pearkes, Keith Ulmer, Nick Manganelli, Chinar Syal, Doug Berry, Nhan Tran, Lindsey Gray, Farah Fahim",
            "summary": "We present the first physical realization of in-pixel signal processing with\nintegrated AI-based data filtering for particle tracking detectors. Building on\nprior work that demonstrated a physics-motivated edge-AI algorithm suitable for\nASIC implementation, this work marks a significant milestone toward intelligent\nsilicon trackers. Our prototype readout chip performs real-time data reduction\nat the sensor level while meeting stringent requirements on power, area, and\nlatency. The chip is taped-out in 28nm TSMC CMOS bulk process, which has been\nshown to have sufficient radiation hardness for particle experiments. This\ndevelopment represents a key step toward enabling fully on-detector edge AI,\nwith broad implications for data throughput and discovery potential in\nhigh-rate, high-radiation environments such as the High-Luminosity LHC.",
            "pdf_url": "http://arxiv.org/pdf/2510.07485v2",
            "published": "2025-10-08 19:35:15+00:00",
            "updated": "2025-10-14 16:08:40+00:00"
        },
        {
            "title": "Measurement of the tau anomalous magnetic moment using Ultra-peripheral collisions with the ALICE detector in Run 3 Pb-Pb data",
            "authors": "Roman Lavi\u010dka, Paul Alois B\u00fchler",
            "summary": "The anomalous magnetic moment of the tau lepton ($a_{\\tau}$) is a sensitive\nprobe for the search for deviations from the Standard Model predictions and\nthus for new physics. This study investigates the feasibility of measuring\n$a_{\\tau}$ using ultra-peripheral collisions (UPCs) at the LHC, where\nphoton-photon interactions ($\\gamma\\gamma \\to \\tau^+ \\tau^-$) produce tau\nlepton pairs. We focus on events recorded by the ALICE detector during Run 3\nPb-Pb data-taking. Events are selected in the decay channel where one tau\ndecays into an electron and neutrinos, and the other decays into a charged\npion, or three charged pions, and neutrinos. These samples are enhanced with\ndecays into muons, which are inseparable in the ALICE detector. The clean\nenvironment of UPCs minimizes hadronic background, while the advanced particle\nidentification capabilities of the ALICE Time Projection Chamber (TPC) and\nTime-of-Flight (TOF) systems allow for efficient separation of electrons,\npions, and background particles. In this talk, prospects for measuring this\nprocess by ALICE in Run 3, which benefits from high statistics and improved\nsystematics uncertainties, will be discussed. Results will provide tighter\nconstraints on $a_{\\tau}$, contributing to the broader effort to test the\nStandard Model's robustness and explore physics beyond it.",
            "pdf_url": "http://arxiv.org/pdf/2510.12661v1",
            "published": "2025-10-14 15:58:01+00:00",
            "updated": "2025-10-14 15:58:01+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "DriveVLA-W0: World Models Amplify Data Scaling Law in Autonomous Driving",
            "authors": "Yingyan Li, Shuyao Shang, Weisong Liu, Bing Zhan, Haochen Wang, Yuqi Wang, Yuntao Chen, Xiaoman Wang, Yasong An, Chufeng Tang, Lu Hou, Lue Fan, Zhaoxiang Zhang",
            "summary": "Scaling Vision-Language-Action (VLA) models on large-scale data offers a\npromising path to achieving a more generalized driving intelligence. However,\nVLA models are limited by a ``supervision deficit'': the vast model capacity is\nsupervised by sparse, low-dimensional actions, leaving much of their\nrepresentational power underutilized. To remedy this, we propose\n\\textbf{DriveVLA-W0}, a training paradigm that employs world modeling to\npredict future images. This task generates a dense, self-supervised signal that\ncompels the model to learn the underlying dynamics of the driving environment.\nWe showcase the paradigm's versatility by instantiating it for two dominant VLA\narchetypes: an autoregressive world model for VLAs that use discrete visual\ntokens, and a diffusion world model for those operating on continuous visual\nfeatures. Building on the rich representations learned from world modeling, we\nintroduce a lightweight action expert to address the inference latency for\nreal-time deployment. Extensive experiments on the NAVSIM v1/v2 benchmark and a\n680x larger in-house dataset demonstrate that DriveVLA-W0 significantly\noutperforms BEV and VLA baselines. Crucially, it amplifies the data scaling\nlaw, showing that performance gains accelerate as the training dataset size\nincreases.",
            "pdf_url": "http://arxiv.org/pdf/2510.12796v1",
            "published": "2025-10-14 17:59:47+00:00",
            "updated": "2025-10-14 17:59:47+00:00"
        },
        {
            "title": "UniFusion: Vision-Language Model as Unified Encoder in Image Generation",
            "authors": "Kevin Li, Manuel Brack, Sudeep Katakol, Hareesh Ravi, Ajinkya Kale",
            "summary": "Although recent advances in visual generation have been remarkable, most\nexisting architectures still depend on distinct encoders for images and text.\nThis separation constrains diffusion models' ability to perform cross-modal\nreasoning and knowledge transfer. Prior attempts to bridge this gap often use\nthe last layer information from VLM, employ multiple visual encoders, or train\nlarge unified models jointly for text and image generation, which demands\nsubstantial computational resources and large-scale data, limiting its\naccessibility.We present UniFusion, a diffusion-based generative model\nconditioned on a frozen large vision-language model (VLM) that serves as a\nunified multimodal encoder. At the core of UniFusion is the Layerwise Attention\nPooling (LAP) mechanism that extracts both high level semantics and low level\ndetails from text and visual tokens of a frozen VLM to condition a diffusion\ngenerative model. We demonstrate that LAP outperforms other shallow fusion\narchitectures on text-image alignment for generation and faithful transfer of\nvisual information from VLM to the diffusion model which is key for editing. We\npropose VLM-Enabled Rewriting Injection with Flexibile Inference (VERIFI),\nwhich conditions a diffusion transformer (DiT) only on the text tokens\ngenerated by the VLM during in-model prompt rewriting. VERIFI combines the\nalignment of the conditioning distribution with the VLM's reasoning\ncapabilities for increased capabilities and flexibility at inference. In\naddition, finetuning on editing task not only improves text-image alignment for\ngeneration, indicative of cross-modality knowledge transfer, but also exhibits\ntremendous generalization capabilities. Our model when trained on single image\nediting, zero-shot generalizes to multiple image references further motivating\nthe unified encoder design of UniFusion.",
            "pdf_url": "http://arxiv.org/pdf/2510.12789v1",
            "published": "2025-10-14 17:57:56+00:00",
            "updated": "2025-10-14 17:57:56+00:00"
        },
        {
            "title": "MVP4D: Multi-View Portrait Video Diffusion for Animatable 4D Avatars",
            "authors": "Felix Taubner, Ruihang Zhang, Mathieu Tuli, Sherwin Bahmani, David B. Lindell",
            "summary": "Digital human avatars aim to simulate the dynamic appearance of humans in\nvirtual environments, enabling immersive experiences across gaming, film,\nvirtual reality, and more. However, the conventional process for creating and\nanimating photorealistic human avatars is expensive and time-consuming,\nrequiring large camera capture rigs and significant manual effort from\nprofessional 3D artists. With the advent of capable image and video generation\nmodels, recent methods enable automatic rendering of realistic animated avatars\nfrom a single casually captured reference image of a target subject. While\nthese techniques significantly lower barriers to avatar creation and offer\ncompelling realism, they lack constraints provided by multi-view information or\nan explicit 3D representation. So, image quality and realism degrade when\nrendered from viewpoints that deviate strongly from the reference image. Here,\nwe build a video model that generates animatable multi-view videos of digital\nhumans based on a single reference image and target expressions. Our model,\nMVP4D, is based on a state-of-the-art pre-trained video diffusion model and\ngenerates hundreds of frames simultaneously from viewpoints varying by up to\n360 degrees around a target subject. We show how to distill the outputs of this\nmodel into a 4D avatar that can be rendered in real-time. Our approach\nsignificantly improves the realism, temporal consistency, and 3D consistency of\ngenerated avatars compared to previous methods.",
            "pdf_url": "http://arxiv.org/pdf/2510.12785v1",
            "published": "2025-10-14 17:56:14+00:00",
            "updated": "2025-10-14 17:56:14+00:00"
        },
        {
            "title": "DiffEM: Learning from Corrupted Data with Diffusion Models via Expectation Maximization",
            "authors": "Danial Hosseintabar, Fan Chen, Giannis Daras, Antonio Torralba, Constantinos Daskalakis",
            "summary": "Diffusion models have emerged as powerful generative priors for\nhigh-dimensional inverse problems, yet learning them when only corrupted or\nnoisy observations are available remains challenging. In this work, we propose\na new method for training diffusion models with Expectation-Maximization (EM)\nfrom corrupted data. Our proposed method, DiffEM, utilizes conditional\ndiffusion models to reconstruct clean data from observations in the E-step, and\nthen uses the reconstructed data to refine the conditional diffusion model in\nthe M-step. Theoretically, we provide monotonic convergence guarantees for the\nDiffEM iteration, assuming appropriate statistical conditions. We demonstrate\nthe effectiveness of our approach through experiments on various image\nreconstruction tasks.",
            "pdf_url": "http://arxiv.org/pdf/2510.12691v1",
            "published": "2025-10-14 16:25:02+00:00",
            "updated": "2025-10-14 16:25:02+00:00"
        },
        {
            "title": "Denoised Diffusion for Object-Focused Image Augmentation",
            "authors": "Nisha Pillai, Aditi Virupakshaiah, Harrison W. Smith, Amanda J. Ashworth, Prasanna Gowda, Phillip R. Owens, Adam R. Rivers, Bindu Nanduri, Mahalingam Ramkumar",
            "summary": "Modern agricultural operations increasingly rely on integrated monitoring\nsystems that combine multiple data sources for farm optimization. Aerial\ndrone-based animal health monitoring serves as a key component but faces\nlimited data availability, compounded by scene-specific issues such as small,\noccluded, or partially visible animals. Transfer learning approaches often fail\nto address this limitation due to the unavailability of large datasets that\nreflect specific farm conditions, including variations in animal breeds,\nenvironments, and behaviors. Therefore, there is a need for developing a\nproblem-specific, animal-focused data augmentation strategy tailored to these\nunique challenges. To address this gap, we propose an object-focused data\naugmentation framework designed explicitly for animal health monitoring in\nconstrained data settings. Our approach segments animals from backgrounds and\naugments them through transformations and diffusion-based synthesis to create\nrealistic, diverse scenes that enhance animal detection and monitoring\nperformance. Our initial experiments demonstrate that our augmented dataset\nyields superior performance compared to our baseline models on the animal\ndetection task. By generating domain-specific data, our method empowers\nreal-time animal health monitoring solutions even in data-scarce scenarios,\nbridging the gap between limited data and practical applicability.",
            "pdf_url": "http://arxiv.org/pdf/2510.08955v2",
            "published": "2025-10-10 03:03:40+00:00",
            "updated": "2025-10-14 15:47:16+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "TabAttackBench: A Benchmark for Adversarial Attacks on Tabular Data",
            "authors": "Zhipeng He, Chun Ouyang, Lijie Wen, Cong Liu, Catarina Moreira",
            "summary": "Adversarial attacks pose a significant threat to machine learning models by\ninducing incorrect predictions through imperceptible perturbations to input\ndata. While these attacks are well studied in unstructured domains such as\nimages, their behaviour on tabular data remains underexplored due to mixed\nfeature types and complex inter-feature dependencies. This study introduces a\ncomprehensive benchmark that evaluates adversarial attacks on tabular datasets\nwith respect to both effectiveness and imperceptibility. We assess five\nwhite-box attack algorithms (FGSM, BIM, PGD, DeepFool, and C\\&W) across four\nrepresentative models (LR, MLP, TabTransformer and FT-Transformer) using eleven\ndatasets spanning finance, energy, and healthcare domains. The benchmark\nemploys four quantitative imperceptibility metrics (proximity, sparsity,\ndeviation, and sensitivity) to characterise perturbation realism. The analysis\nquantifies the trade-off between these two aspects and reveals consistent\ndifferences between attack types, with $\\ell_\\infty$-based attacks achieving\nhigher success but lower subtlety, and $\\ell_2$-based attacks offering more\nrealistic perturbations. The benchmark findings offer actionable insights for\ndesigning more imperceptible adversarial attacks, advancing the understanding\nof adversarial vulnerability in tabular machine learning.",
            "pdf_url": "http://arxiv.org/pdf/2505.21027v2",
            "published": "2025-05-27 11:01:32+00:00",
            "updated": "2025-10-13 03:56:19+00:00"
        },
        {
            "title": "GrifFinNet: A Graph-Relation Integrated Transformer for Financial Predictions",
            "authors": "Chenlanhui Dai, Wenyan Wang, Yusi Fan, Yueying Wang, Lan Huang, Kewei Li, Fengfeng Zhou",
            "summary": "Predicting stock returns remains a central challenge in quantitative finance,\ntransitioning from traditional statistical methods to contemporary deep\nlearning techniques. However, many current models struggle with effectively\ncapturing spatio-temporal dynamics and integrating multiple relational data\nsources. This study proposes GrifFinNet, a Graph-Relation Integrated\nTransformer for Financial Predictions, which combines multi-relational graph\nmodeling with Transformer-based temporal encoding. GrifFinNet constructs\ninter-stock relation graphs based on industry sectors and institutional\nownership, and incorporates an adaptive gating mechanism to dynamically\nintegrate relational data in response to changing market conditions. This\napproach enables the model to jointly capture spatial dependencies and temporal\npatterns, offering a comprehensive representation of market dynamics. Extensive\nexperiments on two Chinese A-share indices show that GrifFinNet consistently\noutperforms several baseline models and provides valuable, interpretable\ninsights into financial market behavior. The code and data are available at:\nhttps://www.healthinformaticslab.org/supp/.",
            "pdf_url": "http://arxiv.org/pdf/2510.10387v1",
            "published": "2025-10-12 00:50:15+00:00",
            "updated": "2025-10-12 00:50:15+00:00"
        }
    ]
}