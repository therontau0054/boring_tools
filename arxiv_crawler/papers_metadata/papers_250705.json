{
    "Physics": [
        {
            "title": "LiteReality: Graphics-Ready 3D Scene Reconstruction from RGB-D Scans",
            "authors": "Zhening Huang, Xiaoyang Wu, Fangcheng Zhong, Hengshuang Zhao, Matthias Nie\u00dfner, Joan Lasenby",
            "summary": "We propose LiteReality, a novel pipeline that converts RGB-D scans of indoor\nenvironments into compact, realistic, and interactive 3D virtual replicas.\nLiteReality not only reconstructs scenes that visually resemble reality but\nalso supports key features essential for graphics pipelines -- such as object\nindividuality, articulation, high-quality physically based rendering materials,\nand physically based interaction. At its core, LiteReality first performs scene\nunderstanding and parses the results into a coherent 3D layout and objects with\nthe help of a structured scene graph. It then reconstructs the scene by\nretrieving the most visually similar 3D artist-crafted models from a curated\nasset database. Next, the Material Painting module enhances realism by\nrecovering high-quality, spatially varying materials. Finally, the\nreconstructed scene is integrated into a simulation engine with basic physical\nproperties to enable interactive behavior. The resulting scenes are compact,\neditable, and fully compatible with standard graphics pipelines, making them\nsuitable for applications in AR/VR, gaming, robotics, and digital twins. In\naddition, LiteReality introduces a training-free object retrieval module that\nachieves state-of-the-art similarity performance on the Scan2CAD benchmark,\nalong with a robust material painting module capable of transferring\nappearances from images of any style to 3D assets -- even under severe\nmisalignment, occlusion, and poor lighting. We demonstrate the effectiveness of\nLiteReality on both real-life scans and public datasets. Project page:\nhttps://litereality.github.io; Video:\nhttps://www.youtube.com/watch?v=ecK9m3LXg2c",
            "pdf_url": "http://arxiv.org/pdf/2507.02861v1",
            "published": "2025-07-03 17:59:55+00:00",
            "updated": "2025-07-03 17:59:55+00:00"
        },
        {
            "title": "Nine circles of elastic brittle fracture: A series of challenge problems to assess fracture models",
            "authors": "Farhad Kamarei, Bo Zheng, John E. Dolbow, Oscar Lopez-Pamies",
            "summary": "Since the turn of the millennium, capitalizing on modern advances in\nmathematics and computation, a slew of computational models have been proposed\nin the literature with the objective of describing the nucleation and\npropagation of fracture in materials subjected to mechanical, thermal, and/or\nother types of loads. By and large, each new proposal focuses on a particular\naspect of the problem, while ignoring others that have been well-established.\nThis approach has resulted in a plethora of models that are, at best,\ndescriptors of fracture only under a restricted set of conditions, while they\nmay predict grossly incorrect and even non-physical behaviors in general. In an\nattempt to address this predicament, this paper introduces a vetting process in\nthe form of nine challenge problems that any computational model of fracture\nmust convincingly handle if it is to potentially describe fracture nucleation\nand propagation in general. The focus is on the most basic of settings, that of\nisotropic elastic brittle materials subjected to quasi-static mechanical loads.\nThe challenge problems have been carefully selected so that: $i$) they can be\ncarried out experimentally with standard testing equipment; $ii$) they can be\nunambiguously analyzed with a sharp description of fracture; and, most\ncritically, $iii$) in aggregate they span the entire range of well settled\nexperimental knowledge on fracture nucleation and propagation that has been\namassed for over a century. For demonstration purposes, after their\nintroduction, each challenge problem is solved with two phase-field models of\nfracture.",
            "pdf_url": "http://arxiv.org/pdf/2507.00266v2",
            "published": "2025-06-30 21:19:53+00:00",
            "updated": "2025-07-03 17:26:23+00:00"
        },
        {
            "title": "Bayesian frequency estimation at the fundamental quantum limit",
            "authors": "James W. Gardner, Tuvia Gefen, Ethan Payne, Su Direkci, Sander M. Vermeulen, Simon A. Haine, Joseph J. Hope, Lee McCuller, Yanbei Chen",
            "summary": "Searching for a weak signal at an unknown frequency is a canonical task in\nexperiments probing fundamental physics such as gravitational-wave\nobservatories and ultra-light dark matter haloscopes. These state-of-the-art\nsensors are limited by quantum noise arising from the fundamental uncertainty\nabout the state of the device. Classically, frequency estimation suffers from a\nthreshold effect in the signal-to-noise ratio such that weak signals are\nextremely hard to localise in frequency. We show that this phenomenon persists\nat the fundamental quantum limit but that the classical approach, a quadrature\nmeasurement, can nevertheless be beaten by a coherent protocol of projecting\nonto the \"quantum whitened\" possible quantum states. Quantum whitening is a\ncovariant measurement, and we examine it analytically in the wide-prior limit\nand numerically for finite-width priors. Beyond accelerating searches for\nunknown frequencies, quantum whitening may be used generally to sense the\nparameter of a unitary encoding given no prior information about the parameter.",
            "pdf_url": "http://arxiv.org/pdf/2507.02811v1",
            "published": "2025-07-03 17:20:31+00:00",
            "updated": "2025-07-03 17:20:31+00:00"
        },
        {
            "title": "PAD: Phase-Amplitude Decoupling Fusion for Multi-Modal Land Cover Classification",
            "authors": "Huiling Zheng, Xian Zhong, Bin Liu, Yi Xiao, Bihan Wen, Xiaofeng Li",
            "summary": "The fusion of Synthetic Aperture Radar (SAR) and RGB imagery for land cover\nclassification remains challenging due to modality heterogeneity and\nunderutilized spectral complementarity. Existing methods often fail to decouple\nshared structural features from modality-complementary radiometric attributes,\ncausing feature conflicts and information loss. To address this, we propose\nPhase-Amplitude Decoupling (PAD), a frequency-aware framework that separates\nphase (modality-shared) and amplitude (modality-complementary) components in\nthe Fourier domain, thus reinforcing shared structures while preserving\ncomplementary characteristics to improve fusion quality. Unlike prior\napproaches that overlook the distinct physical properties encoded in frequency\nspectra, PAD is the first to introduce explicit amplitude-phase decoupling for\nmulti-modal fusion. Specifically, PAD comprises two key components: 1) Phase\nSpectrum Correction (PSC), which aligns cross-modal phase features via\nconvolution-guided scaling to enhance geometric consistency; and 2) Amplitude\nSpectrum Fusion (ASF), which dynamically integrates high-frequency and\nlow-frequency patterns using frequency-adaptive multilayer perceptrons,\nleveraging SAR's morphological sensitivity and RGB's spectral richness.\nExtensive experiments on WHU-OPT-SAR and DDHR-SK datasets demonstrate\nstate-of-the-art performance. Our work establishes a new paradigm for\nphysics-aware multi-modal fusion in remote sensing. The code will be available\nat https://github.com/RanFeng2/PAD.",
            "pdf_url": "http://arxiv.org/pdf/2504.19136v2",
            "published": "2025-04-27 07:21:42+00:00",
            "updated": "2025-07-03 16:45:10+00:00"
        },
        {
            "title": "LLM-Powered Prediction of Hyperglycemia and Discovery of Behavioral Treatment Pathways from Wearables and Diet",
            "authors": "Abdullah Mamun, Asiful Arefeen, Susan B. Racette, Dorothy D. Sears, Corrie M. Whisner, Matthew P. Buman, Hassan Ghasemzadeh",
            "summary": "Postprandial hyperglycemia, marked by the blood glucose level exceeding the\nnormal range after consuming a meal, is a critical indicator of progression\ntoward type 2 diabetes in people with prediabetes and in healthy individuals. A\nkey metric for understanding blood glucose dynamics after eating is the\npostprandial area under the curve (AUC). Predicting postprandial AUC in advance\nbased on a person's lifestyle factors, such as diet and physical activity\nlevel, and explaining the factors that affect postprandial blood glucose could\nallow an individual to adjust their lifestyle accordingly to maintain normal\nglucose levels. In this study, we developed an explainable machine learning\nsolution, GlucoLens, that takes sensor-driven inputs and uses advanced data\nprocessing, large language models, and trainable machine learning models to\npredict postprandial AUC and hyperglycemia from diet, physical activity, and\nrecent glucose patterns. We used data obtained from wearables in a five-week\nclinical trial of 10 adults who worked full-time to develop and evaluate the\nproposed computational model that integrates wearable sensing, multimodal data,\nand machine learning. Our machine learning model takes multimodal data from\nwearable activity and glucose monitoring sensors, along with food and work\nlogs, and provides an interpretable prediction of the postprandial glucose\npattern. Our GlucoLens system achieves a normalized root mean squared error\n(NRMSE) of 0.123 in its best configuration. On average, the proposed technology\nprovides a 16% better performance level compared to the comparison models.\nAdditionally, our technique predicts hyperglycemia with an accuracy of 73.3%\nand an F1 score of 0.716 and recommends different treatment options to help\navoid hyperglycemia through diverse counterfactual explanations. Code\navailable: https://github.com/ab9mamun/GlucoLens.",
            "pdf_url": "http://arxiv.org/pdf/2503.03935v2",
            "published": "2025-03-05 22:10:14+00:00",
            "updated": "2025-07-03 16:39:21+00:00"
        },
        {
            "title": "Grounding Intelligence in Movement",
            "authors": "Melanie Segado, Felipe Parodi, Jordan K. Matelsky, Michael L. Platt, Eva B. Dyer, Konrad P. Kording",
            "summary": "Recent advances in machine learning have dramatically improved our ability to\nmodel language, vision, and other high-dimensional data, yet they continue to\nstruggle with one of the most fundamental aspects of biological systems:\nmovement. Across neuroscience, medicine, robotics, and ethology, movement is\nessential for interpreting behavior, predicting intent, and enabling\ninteraction. Despite its core significance in our intelligence, movement is\noften treated as an afterthought rather than as a rich and structured modality\nin its own right. This reflects a deeper fragmentation in how movement data is\ncollected and modeled, often constrained by task-specific goals and\ndomain-specific assumptions. But movement is not domain-bound. It reflects\nshared physical constraints, conserved morphological structures, and purposeful\ndynamics that cut across species and settings. We argue that movement should be\ntreated as a primary modeling target for AI. It is inherently structured and\ngrounded in embodiment and physics. This structure, often allowing for compact,\nlower-dimensional representations (e.g., pose), makes it more interpretable and\ncomputationally tractable to model than raw, high-dimensional sensory inputs.\nDeveloping models that can learn from and generalize across diverse movement\ndata will not only advance core capabilities in generative modeling and\ncontrol, but also create a shared foundation for understanding behavior across\nbiological and artificial systems. Movement is not just an outcome, it is a\nwindow into how intelligent systems engage with the world.",
            "pdf_url": "http://arxiv.org/pdf/2507.02771v1",
            "published": "2025-07-03 16:34:34+00:00",
            "updated": "2025-07-03 16:34:34+00:00"
        },
        {
            "title": "Defining and classifying models of groups: The social ontology of higher-order networks",
            "authors": "Jonathan St-Onge, Randall Harp, Giulio Burgio, Timothy M. Waring, Juniper Lovato, Laurent H\u00e9bert-Dufresne",
            "summary": "In complex systems research, the study of higher-order interactions has\nexploded in recent years. Researchers have formalized various types of group\ninteractions, such as public goods games, biological contagion, and information\nbroadcasting, showing how higher-order networks can capture group effects more\ndirectly than pairwise models. However, equating hyperedges-edges involving\nmore than two agents-with groups can be misleading, as it obscures the\npolysemous nature of ``group interactions''. For instance, many models of\nhigher-order interactions focus on the internal state of the hyperedge,\nspecifying dynamical rules at the group level. These models often neglect how\ninteractions with external groups can influence behaviors and dynamics within\nthe group. Yet, anthropologists and philosophers remind us that external norms,\nfactors, and forces governing intergroup behavior are essential to defining\nwithin-group dynamics. In this paper, we synthesize concepts from social\nontology relevant to the emerging physics of higher-order networks. We propose\na typology for classifying models of group interactions based on two\nperspectives. The first focuses on individuals within groups engaging in\ncollective action, where shared agency serves as the binding force. The second\nadopts a group-first approach, emphasizing institutional facts that extend\nbeyond the specific individuals involved. Building on these perspectives, we\nintroduce four dimensions to classify models of group interactions:\npersistence, coupling, reducibility, and alignment. For the physics of\nhigher-order networks, we provide a hierarchy of nested mathematical models to\nexplore the complex properties of social groups. We highlight social\ninteractions not yet explored in the literature on higher-order networks and\npropose future research avenues to foster collaboration between social ontology\nand the physics of complex systems.",
            "pdf_url": "http://arxiv.org/pdf/2507.02758v1",
            "published": "2025-07-03 16:20:52+00:00",
            "updated": "2025-07-03 16:20:52+00:00"
        },
        {
            "title": "Bounded information as a foundation for quantum theory",
            "authors": "Paolo Ferro",
            "summary": "The purpose of this paper is to formalize the concept that best synthesizes\nour intuitive understanding of quantum mechanics -- that the information\ncarried by a system is limited -- and, from this principle, to construct the\nfoundations of quantum theory. In our discussion, we also introduce a second\nimportant hypothesis: if a measurement closely approximates an ideal one in\nterms of experimental precision, the information it provides about a physical\nsystem is independent of the measurement method and, specifically, of the\nsystem's physical quantities being measured. This principle can be expressed in\nterms of metric properties of a manifold whose points represent the state of\nthe system. These and other reasonable hypotheses provide the foundation for a\nframework of quantum reconstruction.\n  The theory presented in this paper is based on a description of physical\nsystems in terms of their statistical properties, specifically statistical\nparameters, and focuses on the study of estimators for these parameters. To\nachieve the goal of quantum reconstruction, a divide-and-conquer approach is\nemployed, wherein the space of two discrete conjugate Hamiltonian variables is\npartitioned into a binary tree of nested sets. This approach naturally leads to\nthe reconstruction of the linear and probabilistic structure of quantum\nmechanics.",
            "pdf_url": "http://arxiv.org/pdf/2506.18549v2",
            "published": "2025-06-23 11:57:26+00:00",
            "updated": "2025-07-03 16:19:27+00:00"
        },
        {
            "title": "Generation of Intense Deep-Ultraviolet Pulses at 200 nm",
            "authors": "X. Xie, S. Soultanis, G. Knopp, A. L. Cavalieri, S. L. Johnson",
            "summary": "We report the generation of intense deep ultraviolet pulses at 200 nm with a\nduration of 48 fs and pulse energy of 130 uJ, achieved via cascaded sum\nfrequency generation using 800 nm femtosecond pulses in barium borate crystals.\nEfficient frequency up-conversion is realized by optimizing phase-matching\nconditions and implementing dispersion control, while maintaining the\nultrashort pulse characteristics. The generated deep ultraviolet pulses are\ncharacterized using two-photon absorption frequency-resolved optical gating,\nproviding detailed insight into their temporal profile and phase. This approach\naddresses key challenges in ultrashort deep ultraviolet pulse generation,\ndelivering a high-energy, ultrashort source suitable for ultrafast\nspectroscopy, nonlinear optics, and strong-field physics. These results\nrepresent a significant advancement in the generation of high-energy,\nultrashort deep ultraviolet pulses, opening new possibilities for time-resolved\ninvestigations in ultrafast molecular dynamics, as well as emerging\napplications in semiconductor science, quantum materials, and photochemistry.",
            "pdf_url": "http://arxiv.org/pdf/2507.02756v1",
            "published": "2025-07-03 16:17:43+00:00",
            "updated": "2025-07-03 16:17:43+00:00"
        },
        {
            "title": "Linear Attention with Global Context: A Multipole Attention Mechanism for Vision and Physics",
            "authors": "Alex Colagrande, Paul Caillon, Eva Feillet, Alexandre Allauzen",
            "summary": "Transformers have become the de facto standard for a wide range of tasks,\nfrom image classification to physics simulations. Despite their impressive\nperformance, the quadratic complexity of standard Transformers in both memory\nand time with respect to the input length makes them impractical for processing\nhigh-resolution inputs. Therefore, several variants have been proposed, the\nmost successful relying on patchification, downsampling, or coarsening\ntechniques, often at the cost of losing the finest-scale details. In this work,\nwe take a different approach. Inspired by state-of-the-art techniques in\n$n$-body numerical simulations, we cast attention as an interaction problem\nbetween grid points. We introduce the Multipole Attention Neural Operator\n(MANO), which computes attention in a distance-based multiscale fashion. MANO\nmaintains, in each attention head, a global receptive field and achieves linear\ntime and memory complexity with respect to the number of grid points. Empirical\nresults on image classification and Darcy flows demonstrate that MANO rivals\nstate-of-the-art models such as ViT and Swin Transformer, while reducing\nruntime and peak memory usage by orders of magnitude. We open source our code\nfor reproducibility at https://github.com/AlexColagrande/MANO.",
            "pdf_url": "http://arxiv.org/pdf/2507.02748v1",
            "published": "2025-07-03 16:05:26+00:00",
            "updated": "2025-07-03 16:05:26+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "USAD: An Unsupervised Data Augmentation Spatio-Temporal Attention Diffusion Network",
            "authors": "Ying Yu, Hang Xiao, Siyao Li, Jiarui Li, Haotian Tang, Hanyu Liu, Chao Li",
            "summary": "The primary objective of human activity recognition (HAR) is to infer ongoing\nhuman actions from sensor data, a task that finds broad applications in health\nmonitoring, safety protection, and sports analysis. Despite proliferating\nresearch, HAR still faces key challenges, including the scarcity of labeled\nsamples for rare activities, insufficient extraction of high-level features,\nand suboptimal model performance on lightweight devices. To address these\nissues, this paper proposes a comprehensive optimization approach centered on\nmulti-attention interaction mechanisms. First, an unsupervised,\nstatistics-guided diffusion model is employed to perform data augmentation,\nthereby alleviating the problems of labeled data scarcity and severe class\nimbalance. Second, a multi-branch spatio-temporal interaction network is\ndesigned, which captures multi-scale features of sequential data through\nparallel residual branches with 3*3, 5*5, and 7*7 convolutional kernels.\nSimultaneously, temporal attention mechanisms are incorporated to identify\ncritical time points, while spatial attention enhances inter-sensor\ninteractions. A cross-branch feature fusion unit is further introduced to\nimprove the overall feature representation capability. Finally, an adaptive\nmulti-loss function fusion strategy is integrated, allowing for dynamic\nadjustment of loss weights and overall model optimization. Experimental results\non three public datasets, WISDM, PAMAP2, and OPPORTUNITY, demonstrate that the\nproposed unsupervised data augmentation spatio-temporal attention diffusion\nnetwork (USAD) achieves accuracies of 98.84%, 93.81%, and 80.92% respectively,\nsignificantly outperforming existing approaches. Furthermore, practical\ndeployment on embedded devices verifies the efficiency and feasibility of the\nproposed method.",
            "pdf_url": "http://arxiv.org/pdf/2507.02827v1",
            "published": "2025-07-03 17:38:44+00:00",
            "updated": "2025-07-03 17:38:44+00:00"
        },
        {
            "title": "FairHuman: Boosting Hand and Face Quality in Human Image Generation with Minimum Potential Delay Fairness in Diffusion Models",
            "authors": "Yuxuan Wang, Tianwei Cao, Huayu Zhang, Zhongjiang He, Kongming Liang, Zhanyu Ma",
            "summary": "Image generation has achieved remarkable progress with the development of\nlarge-scale text-to-image models, especially diffusion-based models. However,\ngenerating human images with plausible details, such as faces or hands, remains\nchallenging due to insufficient supervision of local regions during training.\nTo address this issue, we propose FairHuman, a multi-objective fine-tuning\napproach designed to enhance both global and local generation quality fairly.\nSpecifically, we first construct three learning objectives: a global objective\nderived from the default diffusion objective function and two local objectives\nfor hands and faces based on pre-annotated positional priors. Subsequently, we\nderive the optimal parameter updating strategy under the guidance of the\nMinimum Potential Delay (MPD) criterion, thereby attaining fairness-ware\noptimization for this multi-objective problem. Based on this, our proposed\nmethod can achieve significant improvements in generating challenging local\ndetails while maintaining overall quality. Extensive experiments showcase the\neffectiveness of our method in improving the performance of human image\ngeneration under different scenarios.",
            "pdf_url": "http://arxiv.org/pdf/2507.02714v1",
            "published": "2025-07-03 15:27:45+00:00",
            "updated": "2025-07-03 15:27:45+00:00"
        },
        {
            "title": "APT: Adaptive Personalized Training for Diffusion Models with Limited Data",
            "authors": "JungWoo Chae, Jiyoon Kim, JaeWoong Choi, Kyungyul Kim, Sangheum Hwang",
            "summary": "Personalizing diffusion models using limited data presents significant\nchallenges, including overfitting, loss of prior knowledge, and degradation of\ntext alignment. Overfitting leads to shifts in the noise prediction\ndistribution, disrupting the denoising trajectory and causing the model to lose\nsemantic coherence. In this paper, we propose Adaptive Personalized Training\n(APT), a novel framework that mitigates overfitting by employing adaptive\ntraining strategies and regularizing the model's internal representations\nduring fine-tuning. APT consists of three key components: (1) Adaptive Training\nAdjustment, which introduces an overfitting indicator to detect the degree of\noverfitting at each time step bin and applies adaptive data augmentation and\nadaptive loss weighting based on this indicator; (2)Representation\nStabilization, which regularizes the mean and variance of intermediate feature\nmaps to prevent excessive shifts in noise prediction; and (3) Attention\nAlignment for Prior Knowledge Preservation, which aligns the cross-attention\nmaps of the fine-tuned model with those of the pretrained model to maintain\nprior knowledge and semantic coherence. Through extensive experiments, we\ndemonstrate that APT effectively mitigates overfitting, preserves prior\nknowledge, and outperforms existing methods in generating high-quality, diverse\nimages with limited reference data.",
            "pdf_url": "http://arxiv.org/pdf/2507.02687v1",
            "published": "2025-07-03 14:58:08+00:00",
            "updated": "2025-07-03 14:58:08+00:00"
        },
        {
            "title": "Learning few-step posterior samplers by unfolding and distillation of diffusion models",
            "authors": "Charlesquin Kemajou Mbakam, Jonathan Spence, Marcelo Pereyra",
            "summary": "Diffusion models (DMs) have emerged as powerful image priors in Bayesian\ncomputational imaging. Two primary strategies have been proposed for leveraging\nDMs in this context: Plug-and-Play methods, which are zero-shot and highly\nflexible but rely on approximations; and specialized conditional DMs, which\nachieve higher accuracy and faster inference for specific tasks through\nsupervised training. In this work, we introduce a novel framework that\nintegrates deep unfolding and model distillation to transform a DM image prior\ninto a few-step conditional model for posterior sampling. A central innovation\nof our approach is the unfolding of a Markov chain Monte Carlo (MCMC) algorithm\n- specifically, the recently proposed LATINO Langevin sampler (Spagnoletti et\nal., 2025) - representing the first known instance of deep unfolding applied to\na Monte Carlo sampling scheme. We demonstrate our proposed unfolded and\ndistilled samplers through extensive experiments and comparisons with the state\nof the art, where they achieve excellent accuracy and computational efficiency,\nwhile retaining the flexibility to adapt to variations in the forward model at\ninference time.",
            "pdf_url": "http://arxiv.org/pdf/2507.02686v1",
            "published": "2025-07-03 14:55:53+00:00",
            "updated": "2025-07-03 14:55:53+00:00"
        },
        {
            "title": "Guided Generation for Developable Antibodies",
            "authors": "Siqi Zhao, Joshua Moller, Porfi Quintero-Cadena, Lood van Niekerk",
            "summary": "Therapeutic antibodies require not only high-affinity target engagement, but\nalso favorable manufacturability, stability, and safety profiles for clinical\neffectiveness. These properties are collectively called `developability'. To\nenable a computational framework for optimizing antibody sequences for\nfavorable developability, we introduce a guided discrete diffusion model\ntrained on natural paired heavy- and light-chain sequences from the Observed\nAntibody Space (OAS) and quantitative developability measurements for 246\nclinical-stage antibodies. To steer generation toward biophysically viable\ncandidates, we integrate a Soft Value-based Decoding in Diffusion (SVDD) Module\nthat biases sampling without compromising naturalness. In unconstrained\nsampling, our model reproduces global features of both the natural repertoire\nand approved therapeutics, and under SVDD guidance we achieve significant\nenrichment in predicted developability scores over unguided baselines. When\ncombined with high-throughput developability assays, this framework enables an\niterative, ML-driven pipeline for designing antibodies that satisfy binding and\nbiophysical criteria in tandem.",
            "pdf_url": "http://arxiv.org/pdf/2507.02670v1",
            "published": "2025-07-03 14:35:14+00:00",
            "updated": "2025-07-03 14:35:14+00:00"
        }
    ]
}