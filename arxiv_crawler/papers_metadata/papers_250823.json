{
    "Physics": [
        {
            "title": "Energy conditions for regular black holes in EFT of gravity",
            "authors": "Ziyue Zhu, Alexey S. Koshelev, Yang Liu, Anna Tokareva",
            "summary": "As Einstein's gravity is a non-renormalizable theory, it can be a good\ndescription of physics only at the scales of energy or spacetime curvature\nbelow the Planck mass. Moreover, it requires the presence of an infinite tower\nof higher-derivative corrections, as required in the framework of effective\nfield theory (EFT). Black holes, known to be vacuum solutions in Einstein's\ngravity, necessarily have singularities in the center, where both Einstein's\ngravity and low-energy EFT expansions break down. In this work, we address the\nquestion of whether, in the presence of matter, regular solutions looking like\nblack holes from outside do exist. We show that the matter distribution\nsupporting the regular black hole solution in the presence of Riemann tensor\ncube and Riemann tensor to the fourth power EFT corrections satisfies\npositivity of energy (also called weak energy condition, WEC) and null energy\ncondition (NEC) everywhere outside the horizon. Unlike the case of singular\nsolutions, the EFT description is also valid in the interior of such an object,\ngiven that the maximal curvature is bounded and does not exceed the cut-off\nscale. We found that in a wide range of parameters, WEC is satisfied inside the\nhorizon, but NEC is violated inside the horizon in all cases.",
            "pdf_url": "http://arxiv.org/pdf/2508.15745v1",
            "published": "2025-08-21 17:42:09+00:00",
            "updated": "2025-08-21 17:42:09+00:00"
        },
        {
            "title": "On quantum creation of a toroidal universe",
            "authors": "Alan H. Guth, Alexander Vilenkin",
            "summary": "We consider the quantum creation of a universe with flat spatial sections and\nthe topology of a 3-torus, taking into account the effect of Casimir energy. We\nshow that the corresponding instantons are singular. Since these instantons\ndescribe universes originating in a state of infinite energy, we argue that\nthey cannot be interpreted as quantum creation from `nothing'. If quantum\ncorrections to the energy-momentum tensor are neglected, the spacetime of the\ntoroidal universe reduces to de Sitter space with appropriate periodic\nidentifications. Contrary to previous claims in the literature, this spacetime\nis geodesically incomplete. We argue that this spacetime describes a classical\nuniverse originating at a singularity, and not a quantum origin. We conclude\nthat the quantum creation of a toroidal universe from nothing cannot be\ndescribed in the context of semiclassical quantum gravity -- it is either\nimpossible, or it depends essentially on Planck-scale physics. We therefore see\nno reasonable way to compare the probability of creation of a toroidal\nuniverse, if it is possible at all, with that of a spherical universe.",
            "pdf_url": "http://arxiv.org/pdf/2508.08747v2",
            "published": "2025-08-12 08:43:04+00:00",
            "updated": "2025-08-21 17:32:18+00:00"
        },
        {
            "title": "Power Stabilization for AI Training Datacenters",
            "authors": "Esha Choukse, Brijesh Warrier, Scot Heath, Luz Belmont, April Zhao, Hassan Ali Khan, Brian Harry, Matthew Kappel, Russell J. Hewett, Kushal Datta, Yu Pei, Caroline Lichtenberger, John Siegler, David Lukofsky, Zaid Kahn, Gurpreet Sahota, Andy Sullivan, Charles Frederick, Hien Thai, Rebecca Naughton, Daniel Jurnove, Justin Harp, Reid Carper, Nithish Mahalingam, Srini Varkala, Alok Gautam Kumbhare, Satyajit Desai, Venkatesh Ramamurthy, Praneeth Gottumukkala, Girish Bhatia, Kelsey Wildstone, Laurentiu Olariu, Ileana Incorvaia, Alex Wetmore, Prabhat Ram, Melur Raghuraman, Mohammed Ayna, Mike Kendrick, Ricardo Bianchini, Aaron Hurst, Reza Zamani, Xin Li, Michael Petrov, Gene Oden, Rory Carmichael, Tom Li, Apoorv Gupta, Pratikkumar Patel, Nilesh Dattani, Lawrence Marwong, Rob Nertney, Hirofumi Kobayashi, Jeff Liott, Miro Enev, Divya Ramakrishnan, Ian Buck, Jonah Alben",
            "summary": "Large Artificial Intelligence (AI) training workloads spanning several tens\nof thousands of GPUs present unique power management challenges. These arise\ndue to the high variability in power consumption during the training. Given the\nsynchronous nature of these jobs, during every iteration there is a\ncomputation-heavy phase, where each GPU works on the local data, and a\ncommunication-heavy phase where all the GPUs synchronize on the data. Because\ncompute-heavy phases require much more power than communication phases, large\npower swings occur. The amplitude of these power swings is ever increasing with\nthe increase in the size of training jobs. An even bigger challenge arises from\nthe frequency spectrum of these power swings which, if harmonized with critical\nfrequencies of utilities, can cause physical damage to the power grid\ninfrastructure. Therefore, to continue scaling AI training workloads safely, we\nneed to stabilize the power of such workloads. This paper introduces the\nchallenge with production data and explores innovative solutions across the\nstack: software, GPU hardware, and datacenter infrastructure. We present the\npros and cons of each of these approaches and finally present a multi-pronged\napproach to solving the challenge. The proposed solutions are rigorously tested\nusing a combination of real hardware and Microsoft's in-house cloud power\nsimulator, providing critical insights into the efficacy of these interventions\nunder real-world conditions.",
            "pdf_url": "http://arxiv.org/pdf/2508.14318v2",
            "published": "2025-08-20 00:04:06+00:00",
            "updated": "2025-08-21 17:25:27+00:00"
        },
        {
            "title": "Exploring the Landscape of Non-Equilibrium Memories with Neural Cellular Automata",
            "authors": "Ethan Lake, Ehsan Pajouheshgar",
            "summary": "We investigate the landscape of many-body memories: families of local\nnon-equilibrium dynamics that retain information about their initial conditions\nfor thermodynamically long time scales, even in the presence of arbitrary\nperturbations. In two dimensions, the only well-studied memory is Toom's rule.\nUsing a combination of rigorous proofs and machine learning methods, we show\nthat the landscape of 2D memories is in fact quite vast. We discover memories\nthat correct errors in ways qualitatively distinct from Toom's rule, have\nordered phases stabilized by fluctuations, and preserve information only in the\npresence of noise. Taken together, our results show that physical systems can\nperform robust information storage in many distinct ways, and demonstrate that\nthe physics of many-body memories is richer than previously realized.\nInteractive visualizations of the dynamics studied in this work are available\nat https://memorynca.github.io/2D.",
            "pdf_url": "http://arxiv.org/pdf/2508.15726v1",
            "published": "2025-08-21 17:09:07+00:00",
            "updated": "2025-08-21 17:09:07+00:00"
        },
        {
            "title": "Surya: Foundation Model for Heliophysics",
            "authors": "Sujit Roy, Johannes Schmude, Rohit Lal, Vishal Gaur, Marcus Freitag, Julian Kuehnert, Theodore van Kessel, Dinesha V. Hegde, Andr\u00e9s Mu\u00f1oz-Jaramillo, Johannes Jakubik, Etienne Vos, Kshitiz Mandal, Ata Akbari Asanjan, Joao Lucas de Sousa Almeida, Amy Lin, Talwinder Singh, Kang Yang, Chetraj Pandey, Jinsu Hong, Berkay Aydin, Thorsten Kurth, Ryan McGranaghan, Spiridon Kasapis, Vishal Upendran, Shah Bahauddin, Daniel da Silva, Nikolai V. Pogorelov, Anne Spalding, Campbell Watson, Manil Maskey, Madhulika Guhathakurta, Juan Bernabe-Moreno, Rahul Ramachandran",
            "summary": "Heliophysics is central to understanding and forecasting space weather events\nand solar activity. Despite decades of high-resolution observations from the\nSolar Dynamics Observatory (SDO), most models remain task-specific and\nconstrained by scarce labeled data, limiting their capacity to generalize\nacross solar phenomena. We introduce Surya, a 366M parameter foundation model\nfor heliophysics designed to learn general-purpose solar representations from\nmulti-instrument SDO observations, including eight Atmospheric Imaging Assembly\n(AIA) channels and five Helioseismic and Magnetic Imager (HMI) products. Surya\nemploys a spatiotemporal transformer architecture with spectral gating and\nlong--short range attention, pretrained on high-resolution solar image\nforecasting tasks and further optimized through autoregressive rollout tuning.\nZero-shot evaluations demonstrate its ability to forecast solar dynamics and\nflare events, while downstream fine-tuning with parameter-efficient Low-Rank\nAdaptation (LoRA) shows strong performance on solar wind forecasting, active\nregion segmentation, solar flare forecasting, and EUV spectra. Surya is the\nfirst foundation model in heliophysics that uses time advancement as a pretext\ntask on full-resolution SDO data. Its novel architecture and performance\nsuggest that the model is able to learn the underlying physics behind solar\nevolution.",
            "pdf_url": "http://arxiv.org/pdf/2508.14112v2",
            "published": "2025-08-18 05:44:25+00:00",
            "updated": "2025-08-21 16:53:36+00:00"
        },
        {
            "title": "Conditionally adaptive augmented Lagrangian method for physics-informed learning of forward and inverse problems using artificial neural networks",
            "authors": "Qifeng Hu, Shamsulhaq Basir, Inanc Senocak",
            "summary": "We present several advances to the physics and equality constrained\nartificial neural networks (PECANN) framework that substantially improve its\ncapability to learn solutions of canonical partial differential equations\n(PDEs). First, we generalize the augmented Lagrangian method (ALM) to support\nmultiple independent penalty parameters, enabling simultaneous enforcement of\nheterogeneous constraints. Second, we reformulate pointwise constraint\nenforcement and Lagrange multipliers as expectations over constraint terms,\nreducing memory overhead and permitting efficient mini-batch training. Third,\nto address PDEs with oscillatory, multi-scale features, we incorporate Fourier\nfeature mappings and show that a single mapping suffices where multiple\nmappings or more costly architectures were required in related methods. Fourth,\nwe introduce a time-windowing strategy for long-time evolution in which the\nterminal state of each window is enforced as an initial-condition constraint\nfor the next, ensuring continuity without discrete time models. Crucially, we\npropose a conditionally adaptive penalty update (CAPU) strategy for ALM, which\npreserves the principle that larger constraint violations incur stronger\npenalties. CAPU accelerates the growth of Lagrange multipliers for selectively\nchallenging constraints, enhancing constraint enforcement during training. We\ndemonstrate the effectiveness of PECANN-CAPU on problems including the\ntransonic rarefaction problem, reversible advection of a passive by a vortex,\nhigh-wavenumber Helmholtz and Poisson equations, and inverse identification of\nspatially varying heat sources. Comparisons with established methods and recent\nKolmogorov-Arnold network approaches show that PECANN-CAPU achieves competitive\naccuracy across all cases. Collectively, these advances improve PECANN's\nrobustness, efficiency, and applicability to demanding problems in scientific\ncomputing.",
            "pdf_url": "http://arxiv.org/pdf/2508.15695v1",
            "published": "2025-08-21 16:22:40+00:00",
            "updated": "2025-08-21 16:22:40+00:00"
        },
        {
            "title": "The Prospect from the Upcoming CMB Experiment LiteBIRD to Discover Axion-like Particles Using Milky Way",
            "authors": "Harsh Mehta, Suvodip Mukherjee",
            "summary": "The existence of axion-like particles (ALPs) can be probed from their\nsignatures in the Cosmic Microwave Background (CMB) due to the photon-ALP\nresonant conversion over the mass range of ALPs that matches with the effective\nmass of photons in the plasma in the astrophysical systems. Such a conversion\ncan also occur in the Milky Way halo and disk and can cause a unique spatial\nand spectral distortion. The signal is highly non-Gaussian and cannot be\nmeasured precisely by the usual power-spectrum approach. We devise a new\ntechnique to search for this signal from the upcoming full-sky CMB experiment\nLiteBIRD using its multi-frequency band using a template-based spatial profile\nof the ALP distortion signal. This technique captures the large-scale\nnon-Gaussian aspects of the ALP distortion signal in terms of a spatial\ntemplate and makes it possible to search for any non-zero ALP signal. We show\nthat the inference of the ALP coupling using the template-based technique from\nLiteBIRD can provide constraints on the coupling constant approximately $\ng_{a\\gamma} < 6.5 \\times 10^{-12} \\, \\mathrm{GeV}^{-1}$ for ALP masses below\n$10^{-14}$ eV at 95\\% confidence interval which is an order of magnitude better\nthan the current bounds from CERN Axion Solar Telescope (CAST) at $g_{a\\gamma}\n< 6.6 \\times 10^{-11} \\, \\mathrm{GeV}^{-1}$, This shows the capability of\nfuture multi-band CMB experiment LiteBIRD in opening the discovery space\ntowards physics beyond the standard model.",
            "pdf_url": "http://arxiv.org/pdf/2505.11592v2",
            "published": "2025-05-16 18:00:30+00:00",
            "updated": "2025-08-21 16:22:32+00:00"
        },
        {
            "title": "Trotter-based quantum algorithm for solving transport equations with exponentially fewer time-steps",
            "authors": "Julien Zylberman, Thibault Fredon, Nuno F. Loureiro, Fabrice Debbasch",
            "summary": "The extent to which quantum computers can simulate physical phenomena and\nsolve the partial differential equations (PDEs) that govern them remains a\ncentral open question. In this work, one of the most fundamental PDEs is\naddressed: the multidimensional transport equation with space- and\ntime-dependent coefficients. We present a quantum numerical scheme based on\nthree steps: quantum state preparation, evolution, and measurement of relevant\nobservables. The evolution step combines a high-order centered finite\ndifference with a time-splitting scheme based on product formula\napproximations, also known as Trotterization. Novel numerical analysis is\nintroduced to bound the different sources of error and we prove that, for the\nproduct formula approximations, vector norm analysis guarantees similar\naccuracy with exponentially fewer time steps than operator-norm-based\napproaches, thereby significantly reducing the projected computational\nresources. We also present efficient quantum circuits and numerical simulations\nthat confirm the predicted vector-norm scaling. We report results on real\nquantum hardware for the one-dimensional convection equation, and solve a\nnon-linear ordinary differential equation via its associated Liouville\nequation, a particular case of transport equations. This work provides a\npractical framework for efficiently simulating transport phenomena on quantum\ncomputers, with potential applications in plasma physics, molecular gas\ndynamics and non-linear dynamical systems, including chaotic systems.",
            "pdf_url": "http://arxiv.org/pdf/2508.15691v1",
            "published": "2025-08-21 16:14:05+00:00",
            "updated": "2025-08-21 16:14:05+00:00"
        },
        {
            "title": "Quantum algorithm for linear matrix equations",
            "authors": "Rolando D. Somma, Guang Hao Low, Dominic W. Berry, Ryan Babbush",
            "summary": "We describe an efficient quantum algorithm for solving the linear matrix\nequation AX+XB=C, where A, B, and C are given complex matrices and X is\nunknown. This is known as the Sylvester equation, a fundamental equation with\napplications in control theory and physics. Our approach constructs the\nsolution matrix X/x in a block-encoding, where x is a rescaling factor needed\nfor normalization. This allows us to obtain certain properties of the entries\nof X exponentially faster than would be possible from preparing X as a quantum\nstate. The query and gate complexities of the quantum circuit that implements\nthis block-encoding are almost linear in a condition number that depends on A\nand B, and depend logarithmically in the dimension and inverse error. We show\nhow our quantum circuits can solve BQP-complete problems efficiently, discuss\npotential applications and extensions of our approach, its connection to\nRiccati equation, and comment on open problems.",
            "pdf_url": "http://arxiv.org/pdf/2508.02822v2",
            "published": "2025-08-04 18:45:05+00:00",
            "updated": "2025-08-21 15:58:20+00:00"
        },
        {
            "title": "Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation",
            "authors": "Nikita Kachaev, Andrei Spiridonov, Andrey Gorodetsky, Kirill Muravyev, Nikita Oskolkov, Aditya Narendra, Vlad Shakhuro, Dmitry Makarov, Aleksandr I. Panov, Polina Fedotova, Alexey K. Kovalev",
            "summary": "Benchmarks are crucial for evaluating progress in robotics and embodied AI.\nHowever, a significant gap exists between benchmarks designed for high-level\nlanguage instruction following, which often assume perfect low-level execution,\nand those for low-level robot control, which rely on simple, one-step commands.\nThis disconnect prevents a comprehensive evaluation of integrated systems where\nboth task planning and physical execution are critical. To address this, we\npropose Kitchen-R, a novel benchmark that unifies the evaluation of task\nplanning and low-level control within a simulated kitchen environment. Built as\na digital twin using the Isaac Sim simulator and featuring more than 500\ncomplex language instructions, Kitchen-R supports a mobile manipulator robot.\nWe provide baseline methods for our benchmark, including a task-planning\nstrategy based on a vision-language model and a low-level control policy based\non diffusion policy. We also provide a trajectory collection system. Our\nbenchmark offers a flexible framework for three evaluation modes: independent\nassessment of the planning module, independent assessment of the control\npolicy, and, crucially, an integrated evaluation of the whole system. Kitchen-R\nbridges a key gap in embodied AI research, enabling more holistic and realistic\nbenchmarking of language-guided robotic agents.",
            "pdf_url": "http://arxiv.org/pdf/2508.15663v1",
            "published": "2025-08-21 15:48:51+00:00",
            "updated": "2025-08-21 15:48:51+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Probability Density from Latent Diffusion Models for Out-of-Distribution Detection",
            "authors": "Joonas J\u00e4rve, Karl Kaspar Haavel, Meelis Kull",
            "summary": "Despite rapid advances in AI, safety remains the main bottleneck to deploying\nmachine-learning systems. A critical safety component is out-of-distribution\ndetection: given an input, decide whether it comes from the same distribution\nas the training data. In generative models, the most natural OOD score is the\ndata likelihood. Actually, under the assumption of uniformly distributed OOD\ndata, the likelihood is even the optimal OOD detector, as we show in this work.\nHowever, earlier work reported that likelihood often fails in practice, raising\ndoubts about its usefulness. We explore whether, in practice, the\nrepresentation space also suffers from the inability to learn good density\nestimation for OOD detection, or if it is merely a problem of the pixel space\ntypically used in generative models. To test this, we trained a Variational\nDiffusion Model not on images, but on the representation space of a pre-trained\nResNet-18 to assess the performance of our likelihood-based detector in\ncomparison to state-of-the-art methods from the OpenOOD suite.",
            "pdf_url": "http://arxiv.org/pdf/2508.15737v1",
            "published": "2025-08-21 17:27:35+00:00",
            "updated": "2025-08-21 17:27:35+00:00"
        },
        {
            "title": "Inverse Problem Sampling in Latent Space Using Sequential Monte Carlo",
            "authors": "Idan Achituve, Hai Victor Habi, Amir Rosenfeld, Arnon Netzer, Idit Diamant, Ethan Fetaya",
            "summary": "In image processing, solving inverse problems is the task of finding\nplausible reconstructions of an image that was corrupted by some (usually\nknown) degradation operator. Commonly, this process is done using a generative\nimage model that can guide the reconstruction towards solutions that appear\nnatural. The success of diffusion models over the last few years has made them\na leading candidate for this task. However, the sequential nature of diffusion\nmodels makes this conditional sampling process challenging. Furthermore, since\ndiffusion models are often defined in the latent space of an autoencoder, the\nencoder-decoder transformations introduce additional difficulties. To address\nthese challenges, we suggest a novel sampling method based on sequential Monte\nCarlo (SMC) in the latent space of diffusion models. We name our method LD-SMC.\nWe define a generative model for the data using additional auxiliary\nobservations and perform posterior inference with SMC sampling based on a\nreverse diffusion process. Empirical evaluations on ImageNet and FFHQ show the\nbenefits of LD-SMC over competing methods in various inverse problem tasks and\nespecially in challenging inpainting tasks.",
            "pdf_url": "http://arxiv.org/pdf/2502.05908v3",
            "published": "2025-02-09 14:03:47+00:00",
            "updated": "2025-08-21 08:23:36+00:00"
        },
        {
            "title": "TextSplat: Text-Guided Semantic Fusion for Generalizable Gaussian Splatting",
            "authors": "Zhicong Wu, Hongbin Xu, Gang Xu, Ping Nie, Zhixin Yan, Jinkai Zheng, Liangqiong Qu, Ming Li, Liqiang Nie",
            "summary": "Recent advancements in Generalizable Gaussian Splatting have enabled robust\n3D reconstruction from sparse input views by utilizing feed-forward Gaussian\nSplatting models, achieving superior cross-scene generalization. However, while\nmany methods focus on geometric consistency, they often neglect the potential\nof text-driven guidance to enhance semantic understanding, which is crucial for\naccurately reconstructing fine-grained details in complex scenes. To address\nthis limitation, we propose TextSplat--the first text-driven Generalizable\nGaussian Splatting framework. By employing a text-guided fusion of diverse\nsemantic cues, our framework learns robust cross-modal feature representations\nthat improve the alignment of geometric and semantic information, producing\nhigh-fidelity 3D reconstructions. Specifically, our framework employs three\nparallel modules to obtain complementary representations: the Diffusion Prior\nDepth Estimator for accurate depth information, the Semantic Aware Segmentation\nNetwork for detailed semantic information, and the Multi-View Interaction\nNetwork for refined cross-view features. Then, in the Text-Guided Semantic\nFusion Module, these representations are integrated via the text-guided and\nattention-based feature aggregation mechanism, resulting in enhanced 3D\nGaussian parameters enriched with detailed semantic cues. Experimental results\non various benchmark datasets demonstrate improved performance compared to\nexisting methods across multiple evaluation metrics, validating the\neffectiveness of our framework. The code will be publicly available.",
            "pdf_url": "http://arxiv.org/pdf/2504.09588v2",
            "published": "2025-04-13 14:14:10+00:00",
            "updated": "2025-08-21 07:53:36+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Eigen Portfolios: From Single Component Models to Ensemble Approaches",
            "authors": "ZhengXiang Zhou, Yuqi Luan",
            "summary": "The increasing integration of data science techniques into quantitative\nfinance has enabled more systematic and data-driven approaches to portfolio\nconstruction. This paper investigates the use of Principal Component Analysis\n(PCA) in constructing eigen-portfolios - portfolios derived from the principal\ncomponents of the asset return correlation matrix. We begin by formalizing the\nmathematical underpinnings of eigen-portfolios and demonstrate how PCA can\nreveal latent orthogonal factors driving market behavior. Using the 30\nconstituent stocks of the Dow Jones Industrial Average (DJIA) from 2020 onward,\nwe conduct an empirical analysis to evaluate the in-sample and out-of-sample\nperformance of eigen-portfolios. Our results highlight that selecting a single\neigen-portfolio based on in-sample Sharpe ratio often leads to significant\noverfitting and poor generalization. In response, we propose an ensemble\nstrategy that combines multiple top-performing eigen-portfolios. This ensemble\nmethod substantially improves out-of-sample performance and exceeds benchmark\nreturns in terms of Sharpe ratio, offering a practical and interpretable\nalternative to conventional portfolio construction methods.",
            "pdf_url": "http://arxiv.org/pdf/2508.15586v1",
            "published": "2025-08-21 13:58:35+00:00",
            "updated": "2025-08-21 13:58:35+00:00"
        },
        {
            "title": "FinAgentBench: A Benchmark Dataset for Agentic Retrieval in Financial Question Answering",
            "authors": "Chanyeol Choi, Jihoon Kwon, Alejandro Lopez-Lira, Chaewoon Kim, Minjae Kim, Juneha Hwang, Jaeseon Ha, Hojun Choi, Suyeol Yun, Yongjin Kim, Yongjae Lee",
            "summary": "Accurate information retrieval (IR) is critical in the financial domain,\nwhere investors must identify relevant information from large collections of\ndocuments. Traditional IR methods-whether sparse or dense-often fall short in\nretrieval accuracy, as it requires not only capturing semantic similarity but\nalso performing fine-grained reasoning over document structure and\ndomain-specific knowledge. Recent advances in large language models (LLMs) have\nopened up new opportunities for retrieval with multi-step reasoning, where the\nmodel ranks passages through iterative reasoning about which information is\nmost relevant to a given query. However, there exists no benchmark to evaluate\nsuch capabilities in the financial domain. To address this gap, we introduce\nFinAgentBench, the first large-scale benchmark for evaluating retrieval with\nmulti-step reasoning in finance -- a setting we term agentic retrieval. The\nbenchmark consists of 3,429 expert-annotated examples on S&P-100 listed firms\nand assesses whether LLM agents can (1) identify the most relevant document\ntype among candidates, and (2) pinpoint the key passage within the selected\ndocument. Our evaluation framework explicitly separates these two reasoning\nsteps to address context limitations. This design enables to provide a\nquantitative basis for understanding retrieval-centric LLM behavior in finance.\nWe evaluate a suite of state-of-the-art models and further demonstrated how\ntargeted fine-tuning can significantly improve agentic retrieval performance.\nOur benchmark provides a foundation for studying retrieval-centric LLM behavior\nin complex, domain-specific tasks for finance. We will release the dataset\npublicly upon acceptance of the paper and plan to expand and share dataset for\nthe full S&P 500 and beyond.",
            "pdf_url": "http://arxiv.org/pdf/2508.14052v2",
            "published": "2025-08-07 22:15:22+00:00",
            "updated": "2025-08-21 09:53:46+00:00"
        }
    ]
}