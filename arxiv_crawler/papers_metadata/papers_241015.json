{
    "Physics": [
        {
            "title": "General Signals for Charged Lepton Flavor Violating Decays",
            "authors": "Spencer Chang, Thomas Driscoll",
            "summary": "We explore the most general phenomenology of charged lepton flavor violating\n(CLFV) decays of muon and tau leptons to the three body final states\n$(\\bar{e}ee, \\bar{\\mu}\\mu\\mu, \\bar{e}\\mu\\mu, \\bar{\\mu}\\mu e,\\bar{\\mu}ee,\n\\bar{e}e\\mu)$. By constructing a complete basis of operators at each dimension,\nwe derive the most general amplitudes for these decay processes. By considering\nconstraints from unitarity and LEP, we show that operators of mass dimension 6\nand 7 are the most likely to be observed in next generation experiments.\nFocusing on these dimensions, we compute the results of unpolarized\n(spin-averaged) decays parameterized in terms of the invariant masses of the\ndaughter particles. For the $\\mu \\rightarrow \\bar{e}ee$ decay, we also compute\nthe differential decay rate for polarized decays, in anticipation of the\nexperimental search Mu3e, which expects to have a muon beam with $\\sim 90\\%$\npolarization. To determine the extent to which the operators may be\ndistinguished experimentally, we plot the differential distributions for each\noperator, showing that the differential distributions leave only a few possible\ndegenerate explanations. These results are adapted to treat $\\ell\\to \\ell' \\nu\n\\bar{\\nu}$, where the angular distribution of the outgoing charged lepton has\nenhanced distinguishing power. With many Standard Model extensions predicting\nthese CLFV decays, these results will better enable upcoming searches to\nidentify and/or constrain physics beyond the Standard Model.",
            "pdf_url": "http://arxiv.org/pdf/2410.10778v1",
            "published": "2024-10-14 17:49:30+00:00",
            "updated": "2024-10-14 17:49:30+00:00"
        },
        {
            "title": "Adaptive Diffusion Terrain Generator for Autonomous Uneven Terrain Navigation",
            "authors": "Youwei Yu, Junhong Xu, Lantao Liu",
            "summary": "Model-free reinforcement learning has emerged as a powerful method for\ndeveloping robust robot control policies capable of navigating through complex\nand unstructured terrains. The effectiveness of these methods hinges on two\nessential elements: (1) the use of massively parallel physics simulations to\nexpedite policy training, and (2) an environment generator tasked with crafting\nsufficiently challenging yet attainable terrains to facilitate continuous\npolicy improvement. Existing methods of environment generation often rely on\nheuristics constrained by a set of parameters, limiting the diversity and\nrealism. In this work, we introduce the Adaptive Diffusion Terrain Generator\n(ADTG), a novel method that leverages Denoising Diffusion Probabilistic Models\nto dynamically expand existing training environments by adding more diverse and\ncomplex terrains adaptive to the current policy. ADTG guides the diffusion\nmodel's generation process through initial noise optimization, blending\nnoise-corrupted terrains from existing training environments weighted by the\npolicy's performance in each corresponding environment. By manipulating the\nnoise corruption level, ADTG seamlessly transitions between generating similar\nterrains for policy fine-tuning and novel ones to expand training diversity.\nOur experiments show that the policy trained by ADTG outperforms both\nprocedural generated and natural environments, along with popular navigation\nmethods.",
            "pdf_url": "http://arxiv.org/pdf/2410.10766v1",
            "published": "2024-10-14 17:42:37+00:00",
            "updated": "2024-10-14 17:42:37+00:00"
        },
        {
            "title": "Probing topological phases in a perturbed Kane-Mele model via RKKY interaction: Application to monolayer jacutingaite Pt$_2$HgSe$_3$",
            "authors": "Mohsen Yarmohammadi, Saeed Rahmanian Koshkaki, Jamal Berakdar, Marin Bukov, Michael H. Kolodrubetz",
            "summary": "Quantum spin Hall insulators (QSHIs) are promising for spintronics,\nleveraging strong spin-orbit coupling for efficient spin manipulation via\nelectrical and optical methods, with potential applications in memory storage,\nquantum computing, and spin-based logic. While the Kane-Mele model effectively\ncaptures the low-energy physics of these materials, the impact of perturbations\ndriving phase transitions is less well understood. Developing approaches to\ndescribe these phases is crucial. Here, we study the noncollinear\nRuderman-Kittel-Kasuya-Yosida (RKKY) interaction between two magnetic\nimpurities in a \\textit{perturbed} Kane-Mele model with strong spin-orbit\ncoupling, relevant to monolayer jacutingaite Pt$_2$HgSe$_3$ as a prominent\nQSHI. By analyzing RKKY interactions, we reveal distinct, relative (rather than\nabsolute) signatures of the different phase transitions induced by static and\ndynamic perturbations based on their impact on magnetic impurities. We then\nemploy these perturbations to switch between ferromagnetic and\nantiferromagnetic or clockwise and counterclockwise magnetic interactions for\ncontrol processes. Our results offer a practical way to track topological\nphases via magnetic properties.",
            "pdf_url": "http://arxiv.org/pdf/2410.10764v1",
            "published": "2024-10-14 17:42:19+00:00",
            "updated": "2024-10-14 17:42:19+00:00"
        },
        {
            "title": "Towards Generalist Robot Learning from Internet Video: A Survey",
            "authors": "Robert McCarthy, Daniel C. H. Tan, Dominik Schmidt, Fernando Acero, Nathan Herr, Yilun Du, Thomas G. Thuruthel, Zhibin Li",
            "summary": "Scaling deep learning to huge internet-scraped datasets has yielded\nremarkably general capabilities in natural language processing and visual\nunderstanding and generation. In contrast, data is scarce and expensive to\ncollect in robotics. This has seen robot learning struggle to match the\ngenerality of capabilities observed in other domains. Learning from Videos\n(LfV) methods seek to address this data bottleneck by augmenting traditional\nrobot data with large internet-scraped video datasets. Such video data may\nprovide the model with foundational information regarding physical behaviours\nand the physics of the world. This holds great promise for improving the\ngenerality of our robots.\n  In this survey, we present an overview of the emerging field of LfV. We\noutline fundamental concepts, including the benefits and challenges of LfV. We\nprovide a comprehensive review of current methods for: extracting knowledge\nfrom large-scale internet video; tackling key LfV challenges; and boosting\ndownstream reinforcement and robot learning via the use of video data. LfV\ndatasets and benchmarks are also reviewed. The survey closes with a critical\ndiscussion of challenges and opportunities. Here, we advocate for scalable\nfoundation model approaches that can leverage the full range of available\ninternet video to aid the learning of robot policies and dynamics models. We\nhope this survey can inform and catalyse further LfV research, facilitating\nprogress towards the development of general-purpose robots.",
            "pdf_url": "http://arxiv.org/pdf/2404.19664v3",
            "published": "2024-04-30 15:57:41+00:00",
            "updated": "2024-10-14 17:41:06+00:00"
        },
        {
            "title": "SensorBench: Benchmarking LLMs in Coding-Based Sensor Processing",
            "authors": "Pengrui Quan, Xiaomin Ouyang, Jeya Vikranth Jeyakumar, Ziqi Wang, Yang Xing, Mani Srivastava",
            "summary": "Effective processing, interpretation, and management of sensor data have\nemerged as a critical component of cyber-physical systems. Traditionally,\nprocessing sensor data requires profound theoretical knowledge and proficiency\nin signal-processing tools. However, recent works show that Large Language\nModels (LLMs) have promising capabilities in processing sensory data,\nsuggesting their potential as copilots for developing sensing systems.\n  To explore this potential, we construct a comprehensive benchmark,\nSensorBench, to establish a quantifiable objective. The benchmark incorporates\ndiverse real-world sensor datasets for various tasks. The results show that\nwhile LLMs exhibit considerable proficiency in simpler tasks, they face\ninherent challenges in processing compositional tasks with parameter selections\ncompared to engineering experts. Additionally, we investigate four prompting\nstrategies for sensor processing and show that self-verification can outperform\nall other baselines in 48% of tasks. Our study provides a comprehensive\nbenchmark and prompting analysis for future developments, paving the way toward\nan LLM-based sensor processing copilot.",
            "pdf_url": "http://arxiv.org/pdf/2410.10741v1",
            "published": "2024-10-14 17:21:39+00:00",
            "updated": "2024-10-14 17:21:39+00:00"
        },
        {
            "title": "DrivingDojo Dataset: Advancing Interactive and Knowledge-Enriched Driving World Model",
            "authors": "Yuqi Wang, Ke Cheng, Jiawei He, Qitai Wang, Hengchen Dai, Yuntao Chen, Fei Xia, Zhaoxiang Zhang",
            "summary": "Driving world models have gained increasing attention due to their ability to\nmodel complex physical dynamics. However, their superb modeling capability is\nyet to be fully unleashed due to the limited video diversity in current driving\ndatasets. We introduce DrivingDojo, the first dataset tailor-made for training\ninteractive world models with complex driving dynamics. Our dataset features\nvideo clips with a complete set of driving maneuvers, diverse multi-agent\ninterplay, and rich open-world driving knowledge, laying a stepping stone for\nfuture world model development. We further define an action instruction\nfollowing (AIF) benchmark for world models and demonstrate the superiority of\nthe proposed dataset for generating action-controlled future predictions.",
            "pdf_url": "http://arxiv.org/pdf/2410.10738v1",
            "published": "2024-10-14 17:19:23+00:00",
            "updated": "2024-10-14 17:19:23+00:00"
        },
        {
            "title": "High sensitivity pressure and temperature quantum sensing in organic crystals",
            "authors": "Harpreet Singh, Noella DSouza, Joseph Garrett, Angad Singh, Brian Blankenship, Emanuel Druga, Riccardo Montis, Liang Tan, Ashok Ajoy",
            "summary": "The inherent sensitivity of quantum sensors to their physical environment can\nmake them good reporters of parameters such as temperature, pressure, strain,\nand electric fields. Here, we present a molecular platform for pressure (P) and\ntemperature (T) sensing using para-terphenyl crystals doped with pentacene. We\nleverage the optically detected magnetic resonance (ODMR) of the photoexcited\ntriplet electron in the pentacene molecule, that serves as a sensitive probe\nfor lattice changes in the host para-terphenyl due to pressure or temperature\nvariations. We observe maximal ODMR frequency variations of df/dP=1.8 MHz/bar\nand df/dT=247 kHz/K, which are over 1,200 times and three times greater,\nrespectively, than those seen in nitrogen-vacancy centers in diamond. This\nresults in a >85-fold improvement in pressure sensitivity over best previously\nreported. The larger variation reflects the weaker nature of the para-terphenyl\nlattice, with first-principles DFT calculations indicating that even\npicometer-level shifts in the molecular orbitals due to P, T changes are\nmeasurable. The platform offers additional advantages including high levels of\nsensor doping, narrow ODMR linewidths and high contrasts, and ease of\ndeployment, leveraging the ability for large single crystals at low cost.\nOverall, this work paves the way for low-cost, optically-interrogated pressure\nand temperature sensors and lays the foundation for even more versatile sensors\nenabled by synthetic tunability in designer molecular systems.",
            "pdf_url": "http://arxiv.org/pdf/2410.10705v1",
            "published": "2024-10-14 16:44:51+00:00",
            "updated": "2024-10-14 16:44:51+00:00"
        },
        {
            "title": "Spontaneous emergence of phonon angular momentum through hybridization with magnons",
            "authors": "Honglie Ning, Tianchuang Luo, Batyr Ilyas, Emil Vi\u00f1as Bostr\u00f6m, Jaena Park, Junghyun Kim, Je-Geun Park, Dominik M. Juraschek, Angel Rubio, Nuh Gedik",
            "summary": "Chirality, the breaking of improper rotational symmetry, is a fundamental\nconcept spanning diverse scientific domains. In condensed matter physics,\nchiral phonons, originating from circular atomic motions that carry angular\nmomentum, have sparked intense interest due to their coupling to magnetic\ndegrees of freedom, enabling potential phonon-controlled spintronics. However,\nmodes and their counter-rotating counterparts are typically degenerate at the\nBrillouin zone center. Selective excitation of a single-handed circulating\nphonon requires external stimuli that break the degeneracy. Whether\nenergetically nondegenerate circularly polarized phonons can appear\nspontaneously without structural or external symmetry breaking remains an open\nquestion. Here, we demonstrate that nondegenerate elliptically polarized phonon\npairs can be induced by coupling to magnons with same helicity in the van der\nWaals antiferromagnet $\\mathrm{FePSe_3}$. We confirm the presence of\nmagnon-phonon hybrids, also known as magnon polarons, which exhibit inherent\nelliptical polarization with opposite helicities and distinct energies. This\nnondegeneracy enables their coherent excitation with linearly polarized\nterahertz pulses, which also endows these rotating modes with chirality. By\ntuning the polarization of the terahertz drive and measuring phase-resolved\npolarimetry of the resulting coherent oscillations, we determine the\nellipticity and map the trajectory of these hybrid quasiparticles. Our findings\nestablish a general approach to search for intrinsically nondegenerate phonons\nwith angular momentum at the center of the Brillouin zone and introduce a new\nmethodology for characterizing their ellipticity, outlining a roadmap towards\nchiral-phonon-controlled spintronic functionalities.",
            "pdf_url": "http://arxiv.org/pdf/2410.10693v1",
            "published": "2024-10-14 16:32:07+00:00",
            "updated": "2024-10-14 16:32:07+00:00"
        },
        {
            "title": "Enhanced Quantum Energy Teleportation using a 3-Qubit System",
            "authors": "Md Shoyib Hassan, Syed Emad Uddin Shubha, M. R. C Mahdy",
            "summary": "Quantum Energy Teleportation (QET) is a novel method that leverages quantum\nentanglement to transfer energy between two distant locations without any\nphysical movement of the energy. The first realization of QET on\nsuperconducting hardware, utilizing a 2-qubit system, demonstrated an average\nenergy retrieval efficiency of 35.4% (observing only V ) by the receiver, Bob.\nIn this paper, we present a new approach using a 3-qubit system to enhance the\nenergy efficiency of QET. We have incorporated a novel 3-qubit ground state\nHamiltonian H to achieve this, which conforms to the constraints of Zero mean\nenergy and anti-commutative properties of the operations on the observable of\nthe senders and receiver. Our experimental results show a significant\nimprovement in terms of energy retrieval. Though the Multiple-Input\nSingle-Output (MISO) model demonstrates a similar result achieving an average\nefficiency of 32.5% (observing only V ), the Single-Input Multiple-Output\n(SIMO) model shows a significantly higher result than that of the 2-qubit\nsystem considering practical usage, which is 58.2%",
            "pdf_url": "http://arxiv.org/pdf/2408.07997v5",
            "published": "2024-08-15 07:47:08+00:00",
            "updated": "2024-10-14 16:14:37+00:00"
        },
        {
            "title": "Petz map recovery for long-range entangled quantum many-body states",
            "authors": "Yangrui Hu, Yijian Zou",
            "summary": "Given a tripartite quantum state on $A,B,C$ and the erasure channel on $C$,\nthe rotated Petz map is a recovery channel that acts on $B$ to recover the\nerased quantum information. The infidelity of the best recovery is\nupper-bounded by the conditional mutual information (CMI). In this work, we\nstudy the infidelity of the rotated Petz map on several physically-relevant\nlong-range entangled quantum states. Specifically, we study three classes of\nquantum phases: (i) steady states of measurement-induced phase transitions,\n(ii) critical ground state under local measurements, and (iii) chiral states\nunder local measurements. We find that the averaged infidelity of the Petz map\nrecovery sharply distinguishes the three classes: (i) and (ii) are\ndistinguished by the scaling of the infidelity with CMI and (iii) is\ncharacterized by an asymmetry of the infidelity with the rotation parameter. We\nalso study Petz map recovery for topological order and find an operational\ninterpretation of the topological entanglement entropy. Our result indicates\nthat recovery fidelity of the Petz map is a useful diagnostic of quantum phases\nof matter.",
            "pdf_url": "http://arxiv.org/pdf/2408.00857v3",
            "published": "2024-08-01 18:11:17+00:00",
            "updated": "2024-10-14 16:09:27+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Depth Any Video with Scalable Synthetic Data",
            "authors": "Honghui Yang, Di Huang, Wei Yin, Chunhua Shen, Haifeng Liu, Xiaofei He, Binbin Lin, Wanli Ouyang, Tong He",
            "summary": "Video depth estimation has long been hindered by the scarcity of consistent\nand scalable ground truth data, leading to inconsistent and unreliable results.\nIn this paper, we introduce Depth Any Video, a model that tackles the challenge\nthrough two key innovations. First, we develop a scalable synthetic data\npipeline, capturing real-time video depth data from diverse synthetic\nenvironments, yielding 40,000 video clips of 5-second duration, each with\nprecise depth annotations. Second, we leverage the powerful priors of\ngenerative video diffusion models to handle real-world videos effectively,\nintegrating advanced techniques such as rotary position encoding and flow\nmatching to further enhance flexibility and efficiency. Unlike previous models,\nwhich are limited to fixed-length video sequences, our approach introduces a\nnovel mixed-duration training strategy that handles videos of varying lengths\nand performs robustly across different frame rates-even on single frames. At\ninference, we propose a depth interpolation method that enables our model to\ninfer high-resolution video depth across sequences of up to 150 frames. Our\nmodel outperforms all previous generative depth models in terms of spatial\naccuracy and temporal consistency.",
            "pdf_url": "http://arxiv.org/pdf/2410.10815v1",
            "published": "2024-10-14 17:59:46+00:00",
            "updated": "2024-10-14 17:59:46+00:00"
        },
        {
            "title": "HART: Efficient Visual Generation with Hybrid Autoregressive Transformer",
            "authors": "Haotian Tang, Yecheng Wu, Shang Yang, Enze Xie, Junsong Chen, Junyu Chen, Zhuoyang Zhang, Han Cai, Yao Lu, Song Han",
            "summary": "We introduce Hybrid Autoregressive Transformer (HART), an autoregressive (AR)\nvisual generation model capable of directly generating 1024x1024 images,\nrivaling diffusion models in image generation quality. Existing AR models face\nlimitations due to the poor image reconstruction quality of their discrete\ntokenizers and the prohibitive training costs associated with generating 1024px\nimages. To address these challenges, we present the hybrid tokenizer, which\ndecomposes the continuous latents from the autoencoder into two components:\ndiscrete tokens representing the big picture and continuous tokens representing\nthe residual components that cannot be represented by the discrete tokens. The\ndiscrete component is modeled by a scalable-resolution discrete AR model, while\nthe continuous component is learned with a lightweight residual diffusion\nmodule with only 37M parameters. Compared with the discrete-only VAR tokenizer,\nour hybrid approach improves reconstruction FID from 2.11 to 0.30 on MJHQ-30K,\nleading to a 31% generation FID improvement from 7.85 to 5.38. HART also\noutperforms state-of-the-art diffusion models in both FID and CLIP score, with\n4.5-7.7x higher throughput and 6.9-13.4x lower MACs. Our code is open sourced\nat https://github.com/mit-han-lab/hart.",
            "pdf_url": "http://arxiv.org/pdf/2410.10812v1",
            "published": "2024-10-14 17:59:42+00:00",
            "updated": "2024-10-14 17:59:42+00:00"
        },
        {
            "title": "TrajDiffuse: A Conditional Diffusion Model for Environment-Aware Trajectory Prediction",
            "authors": "Qingze, Liu, Danrui Li, Samuel S. Sohn, Sejong Yoon, Mubbasir Kapadia, Vladimir Pavlovic",
            "summary": "Accurate prediction of human or vehicle trajectories with good diversity that\ncaptures their stochastic nature is an essential task for many applications.\nHowever, many trajectory prediction models produce unreasonable trajectory\nsamples that focus on improving diversity or accuracy while neglecting other\nkey requirements, such as collision avoidance with the surrounding environment.\nIn this work, we propose TrajDiffuse, a planning-based trajectory prediction\nmethod using a novel guided conditional diffusion model. We form the trajectory\nprediction problem as a denoising impaint task and design a map-based guidance\nterm for the diffusion process. TrajDiffuse is able to generate trajectory\npredictions that match or exceed the accuracy and diversity of the SOTA, while\nadhering almost perfectly to environmental constraints. We demonstrate the\nutility of our model through experiments on the nuScenes and PFSD datasets and\nprovide an extensive benchmark analysis against the SOTA methods.",
            "pdf_url": "http://arxiv.org/pdf/2410.10804v1",
            "published": "2024-10-14 17:59:03+00:00",
            "updated": "2024-10-14 17:59:03+00:00"
        },
        {
            "title": "Generalizable Humanoid Manipulation with Improved 3D Diffusion Policies",
            "authors": "Yanjie Ze, Zixuan Chen, Wenhao Wang, Tianyi Chen, Xialin He, Ying Yuan, Xue Bin Peng, Jiajun Wu",
            "summary": "Humanoid robots capable of autonomous operation in diverse environments have\nlong been a goal for roboticists. However, autonomous manipulation by humanoid\nrobots has largely been restricted to one specific scene, primarily due to the\ndifficulty of acquiring generalizable skills. Recent advances in 3D visuomotor\npolicies, such as the 3D Diffusion Policy (DP3), have shown promise in\nextending these capabilities to wilder environments. However, 3D visuomotor\npolicies often rely on camera calibration and point-cloud segmentation, which\npresent challenges for deployment on mobile robots like humanoids. In this\nwork, we introduce the Improved 3D Diffusion Policy (iDP3), a novel 3D\nvisuomotor policy that eliminates these constraints by leveraging egocentric 3D\nvisual representations. We demonstrate that iDP3 enables a full-sized humanoid\nrobot to autonomously perform skills in diverse real-world scenarios, using\nonly data collected in the lab. Videos are available at:\nhttps://humanoid-manipulation.github.io",
            "pdf_url": "http://arxiv.org/pdf/2410.10803v1",
            "published": "2024-10-14 17:59:00+00:00",
            "updated": "2024-10-14 17:59:00+00:00"
        },
        {
            "title": "Boosting Camera Motion Control for Video Diffusion Transformers",
            "authors": "Soon Yau Cheong, Duygu Ceylan, Armin Mustafa, Andrew Gilbert, Chun-Hao Paul Huang",
            "summary": "Recent advancements in diffusion models have significantly enhanced the\nquality of video generation. However, fine-grained control over camera pose\nremains a challenge. While U-Net-based models have shown promising results for\ncamera control, transformer-based diffusion models (DiT)-the preferred\narchitecture for large-scale video generation - suffer from severe degradation\nin camera motion accuracy. In this paper, we investigate the underlying causes\nof this issue and propose solutions tailored to DiT architectures. Our study\nreveals that camera control performance depends heavily on the choice of\nconditioning methods rather than camera pose representations that is commonly\nbelieved. To address the persistent motion degradation in DiT, we introduce\nCamera Motion Guidance (CMG), based on classifier-free guidance, which boosts\ncamera control by over 400%. Additionally, we present a sparse camera control\npipeline, significantly simplifying the process of specifying camera poses for\nlong videos. Our method universally applies to both U-Net and DiT models,\noffering improved camera control for video generation tasks.",
            "pdf_url": "http://arxiv.org/pdf/2410.10802v1",
            "published": "2024-10-14 17:58:07+00:00",
            "updated": "2024-10-14 17:58:07+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Backtesting Framework for Concentrated Liquidity Market Makers on Uniswap V3 Decentralized Exchange",
            "authors": "Andrey Urusov, Rostislav Berezovskiy, Yury Yanovich",
            "summary": "Decentralized finance (DeFi) has revolutionized the financial landscape, with\nprotocols like Uniswap offering innovative automated market-making mechanisms.\nThis article explores the development of a backtesting framework specifically\ntailored for concentrated liquidity market makers (CLMM). The focus is on\nleveraging the liquidity distribution approximated using a parametric model, to\nestimate the rewards within liquidity pools.\n  The article details the design, implementation, and insights derived from\nthis novel approach to backtesting within the context of Uniswap V3. The\ndeveloped backtester was successfully utilized to assess reward levels across\nseveral pools using historical data from 2023 (pools Uniswap v3 for pairs of\naltcoins, stablecoins and USDC/ETH with different fee levels). Moreover, the\nerror in modeling the level of rewards for the period under review for each\npool was less than 1\\%. This demonstrated the effectiveness of the backtester\nin quantifying liquidity pool rewards and its potential in estimating LP's\nrevenues as part of the pool rewards, as focus of our next research.\n  The backtester serves as a tool to simulate trading strategies and liquidity\nprovision scenarios, providing a quantitative assessment of potential returns\nfor liquidity providers (LP). By incorporating statistical tools to mirror CLMM\npool liquidity dynamics, this framework can be further leveraged for strategy\nenhancement and risk evaluation for LPs operating within decentralized\nexchanges.",
            "pdf_url": "http://arxiv.org/pdf/2410.09983v1",
            "published": "2024-10-13 19:56:11+00:00",
            "updated": "2024-10-13 19:56:11+00:00"
        },
        {
            "title": "Scalable Signature-Based Distribution Regression via Reference Sets",
            "authors": "Andrew Alden, Carmine Ventre, Blanka Horvath",
            "summary": "Distribution Regression (DR) on stochastic processes describes the learning\ntask of regression on collections of time series. Path signatures, a technique\nprevalent in stochastic analysis, have been used to solve the DR problem.\nRecent works have demonstrated the ability of such solutions to leverage the\ninformation encoded in paths via signature-based features. However, current\nstate of the art DR solutions are memory intensive and incur a high computation\ncost. This leads to a trade-off between path length and the number of paths\nconsidered. This computational bottleneck limits the application to small\nsample sizes which consequently introduces estimation uncertainty. In this\npaper, we present a methodology for addressing the above issues; resolving\nestimation uncertainties whilst also proposing a pipeline that enables us to\nuse DR for a wide variety of learning tasks. Integral to our approach is our\nnovel distance approximator. This allows us to seamlessly apply our methodology\nacross different application domains, sampling rates, and stochastic process\ndimensions. We show that our model performs well in applications related to\nestimation theory, quantitative finance, and physical sciences. We demonstrate\nthat our model generalises well, not only to unseen data within a given\ndistribution, but also under unseen regimes (unseen classes of stochastic\nmodels).",
            "pdf_url": "http://arxiv.org/pdf/2410.09196v1",
            "published": "2024-10-11 18:58:28+00:00",
            "updated": "2024-10-11 18:58:28+00:00"
        }
    ]
}