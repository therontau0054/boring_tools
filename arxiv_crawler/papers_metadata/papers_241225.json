{
    "Physics": [
        {
            "title": "Crosscap Quenches and Entanglement Evolution",
            "authors": "Zixia Wei, Yasushi Yoneta",
            "summary": "Understanding the mechanisms by which complex correlations emerge through the\ndynamics of quantum many-body systems remains a fundamental challenge in modern\nphysics. To address this, quench dynamics starting from nonequilibrium states\nhave been extensively studied, leading to significant progress. In this paper,\nwe propose a novel quench protocol, termed the ``crosscap quench'', to\ninvestigate how highly structured thermal pure states relax into typical ones.\nWe begin by analyzing conformal field theories (CFTs) and derive universal\nfeatures in the time evolution of entanglement entropy. Furthermore, leveraging\nthe AdS/CFT correspondence, we study holographic CFTs, providing an\nanalytically tractable example in chaotic CFTs. Finally, we validate these\nfindings through numerical simulations in both nonintegrable and integrable\nquantum spin systems.",
            "pdf_url": "http://arxiv.org/pdf/2412.18610v1",
            "published": "2024-12-24 18:59:58+00:00",
            "updated": "2024-12-24 18:59:58+00:00"
        },
        {
            "title": "A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs",
            "authors": "OpenMind, Shaohong Zhong, Adam Zhou, Boyuan Chen, Homin Luo, Jan Liphardt",
            "summary": "Large Language Models (LLMs) are compact representations of all public\nknowledge of our physical environment and animal and human behaviors. The\napplication of LLMs to robotics may offer a path to highly capable robots that\nperform well across most human tasks with limited or even zero tuning. Aside\nfrom increasingly sophisticated reasoning and task planning, networks of\n(suitably designed) LLMs offer ease of upgrading capabilities and allow humans\nto directly observe the robot's thinking. Here we explore the advantages,\nlimitations, and particularities of using LLMs to control physical robots. The\nbasic system consists of four LLMs communicating via a human language data bus\nimplemented via web sockets and ROS2 message passing. Surprisingly, rich robot\nbehaviors and good performance across different tasks could be achieved despite\nthe robot's data fusion cycle running at only 1Hz and the central data bus\nrunning at the extremely limited rates of the human brain, of around 40 bits/s.\nThe use of natural language for inter-LLM communication allowed the robot's\nreasoning and decision making to be directly observed by humans and made it\ntrivial to bias the system's behavior with sets of rules written in plain\nEnglish. These rules were immutably written into Ethereum, a global, public,\nand censorship resistant Turing-complete computer. We suggest that by using\nnatural language as the data bus among interacting AIs, and immutable public\nledgers to store behavior constraints, it is possible to build robots that\ncombine unexpectedly rich performance, upgradability, and durable alignment\nwith humans.",
            "pdf_url": "http://arxiv.org/pdf/2412.18588v1",
            "published": "2024-12-24 18:41:15+00:00",
            "updated": "2024-12-24 18:41:15+00:00"
        },
        {
            "title": "ReducedLUT: Table Decomposition with \"Don't Care\" Conditions",
            "authors": "Oliver Cassidy, Marta Andronic, Samuel Coward, George A. Constantinides",
            "summary": "Lookup tables (LUTs) are frequently used to efficiently store arrays of\nprecomputed values for complex mathematical computations. When used in the\ncontext of neural networks, these functions exhibit a lack of recognizable\npatterns which presents an unusual challenge for conventional logic synthesis\ntechniques. Several approaches are known to break down a single large lookup\ntable into multiple smaller ones that can be recombined. Traditional methods,\nsuch as plain tabulation, piecewise linear approximation, and multipartite\ntable methods, often yield inefficient hardware solutions when applied to\nLUT-based NNs.\n  This paper introduces ReducedLUT, a novel method to reduce the footprint of\nthe LUTs by injecting don't cares into the compression process. This additional\nfreedom introduces more self-similarities which can be exploited using known\ndecomposition techniques. We then demonstrate a particular application to\nmachine learning; by replacing unobserved patterns within the training data of\nneural network models with don't cares, we enable greater compression with\nminimal model accuracy degradation. In practice, we achieve up to $1.63\\times$\nreduction in Physical LUT utilization, with a test accuracy drop of no more\nthan $0.01$ accuracy points.",
            "pdf_url": "http://arxiv.org/pdf/2412.18579v1",
            "published": "2024-12-24 18:11:01+00:00",
            "updated": "2024-12-24 18:11:01+00:00"
        },
        {
            "title": "Randomized Benchmarking with Synthetic Quantum Circuits",
            "authors": "Yale Fan, Riley Murray, Thaddeus D. Ladd, Kevin Young, Robin Blume-Kohout",
            "summary": "Randomized benchmarking (RB) comprises a set of mature and widely used\ntechniques for assessing the quality of operations on a quantum\ninformation-processing system. Modern RB protocols for multiqubit systems\nextract physically relevant error rates by exploiting the structure of the\ngroup representation generated by the set of benchmarked operations. However,\nexisting techniques become prohibitively inefficient for representations that\nare highly reducible yet decompose into irreducible subspaces of high\ndimension. These situations prevail when benchmarking high-dimensional systems\nsuch as qudits or bosonic modes, where experimental control is limited to\nimplementing a small subset of all possible unitary operations. In this work,\nwe introduce a broad framework for enhancing the sample efficiency of RB that\nis sufficiently powerful to extend the practical reach of RB beyond the\nmultiqubit setting. Our strategy, which applies to any benchmarking group, uses\n\"synthetic\" quantum circuits with classical post-processing of both input and\noutput data to leverage the full structure of reducible superoperator\nrepresentations. To demonstrate the efficacy of our approach, we develop a\ndetailed theory of RB for systems with rotational symmetry. Such systems carry\na natural action of the group $\\text{SU}(2)$, and they form the basis for\nseveral novel quantum error-correcting codes. We show that, for experimentally\naccessible high-spin systems, synthetic RB protocols can reduce the complexity\nof measuring rotationally invariant error rates by more than two orders of\nmagnitude relative to standard approaches such as character RB.",
            "pdf_url": "http://arxiv.org/pdf/2412.18578v1",
            "published": "2024-12-24 18:10:00+00:00",
            "updated": "2024-12-24 18:10:00+00:00"
        },
        {
            "title": "Scalable Quantum-Inspired Optimization through Dynamic Qubit Compression",
            "authors": "Co Tran, Quoc-Bao Tran, Hy Truong Son, Thang N Dinh",
            "summary": "Hard combinatorial optimization problems, often mapped to Ising models,\npromise potential solutions with quantum advantage but are constrained by\nlimited qubit counts in near-term devices. We present an innovative\nquantum-inspired framework that dynamically compresses large Ising models to\nfit available quantum hardware of different sizes. Thus, we aim to bridge the\ngap between large-scale optimization and current hardware capabilities. Our\nmethod leverages a physics-inspired GNN architecture to capture complex\ninteractions in Ising models and accurately predict alignments among\nneighboring spins (aka qubits) at ground states. By progressively merging such\naligned spins, we can reduce the model size while preserving the underlying\noptimization structure. It also provides a natural trade-off between the\nsolution quality and size reduction, meeting different hardware constraints of\nquantum computing devices. Extensive numerical studies on Ising instances of\ndiverse topologies show that our method can reduce instance size at multiple\nlevels with virtually no losses in solution quality on the latest D-wave\nquantum annealers.",
            "pdf_url": "http://arxiv.org/pdf/2412.18571v1",
            "published": "2024-12-24 17:51:42+00:00",
            "updated": "2024-12-24 17:51:42+00:00"
        },
        {
            "title": "Efficient Aircraft Design Optimization Using Multi-Fidelity Models and Multi-fidelity Physics Informed Neural Networks",
            "authors": "Apurba Sarker",
            "summary": "Aircraft design optimization traditionally relies on computationally\nexpensive simulation techniques such as Finite Element Method (FEM) and Finite\nVolume Method (FVM), which, while accurate, can significantly slow down the\ndesign iteration process. The challenge lies in reducing the computational\ncomplexity while maintaining high accuracy for quick evaluations of multiple\ndesign alternatives. This research explores advanced methods, including\nsurrogate models, reduced-order models (ROM), and multi-fidelity machine\nlearning techniques, to achieve more efficient aircraft design evaluations.\nSpecifically, the study investigates the application of Multi-fidelity\nPhysics-Informed Neural Networks (MPINN) and autoencoders for manifold\nalignment, alongside the potential of Generative Adversarial Networks (GANs)\nfor refining design geometries. Through a proof-of-concept task, the research\ndemonstrates the ability to predict high-fidelity results from low-fidelity\nsimulations, offering a path toward faster and more cost effective aircraft\ndesign iterations.",
            "pdf_url": "http://arxiv.org/pdf/2412.18564v1",
            "published": "2024-12-24 17:36:27+00:00",
            "updated": "2024-12-24 17:36:27+00:00"
        },
        {
            "title": "Spread Complexity of High Energy Neutrino Propagation over Astrophysical Distances",
            "authors": "Khushboo Dixit, S. Shajidul Haque, Soebur Razzaque",
            "summary": "Spread complexity measures the minimized spread of quantum states over all\nchoices of basis. It generalizes Krylov operator complexity to quantum states\nunder continuous Hamiltonian evolution. In this paper, we study spread\ncomplexity in the context of high-energy astrophysical neutrinos and propose a\nnew flavor ratio based on complexity. Our findings indicate that our proposal\nmight favor an initial ratio of fluxes as $\\phi_{\\nu_e}^0: \\phi_{\\nu_\\mu}^0:\n\\phi_{\\nu_\\tau}^0 = 1:0:0$ over a more generally expected ratio of $1:2:0$,\nwhen the IceCube neutrino observatory achieves its projected sensitivity to\ndiscriminate between flavors. Additionally, complexity-based definitions of\nflavor ratios exhibit a slight but nonzero sensitivity to the neutrino mass\nordering, which traditional flavor ratios cannot capture.",
            "pdf_url": "http://arxiv.org/pdf/2406.07491v2",
            "published": "2024-06-11 17:29:55+00:00",
            "updated": "2024-12-24 17:33:04+00:00"
        },
        {
            "title": "Fano physics behind the N-resonance in graphene",
            "authors": "R. O. Kuzian, D. V. Efremov, E. E. Krasovskii",
            "summary": "Bound states and scattering resonances in the unoccupied continuum of a\ntwo-dimensional crystal predicted in [Phys.Rev. B 87, 041405(R) (2013)] are\nconsidered within an exactly solvable model. A close connection of the observed\nresonances with those arising in the Fano theory is revealed. The resonance\noccurs when the lateral scattering couples the layer-perpendicular incident\nelectron wave to a strictly bound state. The coupling strength determines the\nlocation of the pole in the scattering amplitude in the complex energy plane,\nwhich is analytically shown to lead to a characteristic Fano-lineshape of the\nenergy dependence of the electron transmissivity through the crystal. The\nimplications for the timing of the resonance scattering are discussed. The\nanalytical results are illustrated by ab initio calculations for a graphene\nmonolayer.",
            "pdf_url": "http://arxiv.org/pdf/2412.18561v1",
            "published": "2024-12-24 17:25:37+00:00",
            "updated": "2024-12-24 17:25:37+00:00"
        },
        {
            "title": "Born-Oppenheimer Renormalization group for High Energy Scattering: the Modified BFKL, or where did it all go?",
            "authors": "Haowu Duan, Alex Kovner, Michael Lublinsky",
            "summary": "We continue exploring the Born-Oppenheimer renormalization group generating\nevolution in frequency of physical observables. In this paper we study the\nevolution of the total cross section for dilute-dilute scattering retaining\nonly eikonal emissions. We derive and analyze the analog of the BFKL equation\nin this framework. The frequency evolution has a very strong effect on the\nsolutions of the BO-BFKL equation, slowing down the evolution of the scattering\namplitude in a spectacular fashion: the intercept of the Pomeron is decreased\nby about a factor of three relative to the canonical LO BFKL result. The\nanomalous dimension is also modified significantly - from the BFKL value of one\nit goes down to the negative value of $\\approx-0.2$. Introducing saturation\nboundary as a proxy for the full saturation dynamics, we find that the\ndependence of the saturation momentum on rapidity $\\eta$ becomes quite weak\nwith $Q^2_s\\sim e^{a\\bar\\alpha_s\\eta}$ with $a\\approx 0.784$ as opposed to the\nBFKL value $a=4.88$. Our results underscore the necessity to take into account\nthe DGLAP effects in the high energy evolution. This is left for future work.",
            "pdf_url": "http://arxiv.org/pdf/2412.10560v2",
            "published": "2024-12-13 21:05:51+00:00",
            "updated": "2024-12-24 17:02:36+00:00"
        },
        {
            "title": "Post-pandemic social contacts in Italy: implications for social distancing measures on in-person school and work attendance",
            "authors": "Lorenzo Lucchini, Valentina Marziano, Filippo Trentini, Chiara Chiavenna, Elena D'Agnese, Vittoria Offeddu, Mattia Manica, Piero Poletti, Duilio Balsamo, Giorgio Guzzetta, Marco Aielli, Alessia Melegaro, Stefano Merler",
            "summary": "The collection of updated data on social contact patterns following the\nCOVID-19 pandemic disruptions is crucial for future epidemiological assessments\nand evaluating non-pharmaceutical interventions (NPIs) based on physical\ndistancing. We conducted two waves of an online survey in March 2022 and March\n2023 in Italy, gathering data from a representative population sample on direct\n(verbal/physical interactions) and indirect (prolonged co-location in indoor\nspaces) contacts. Using a generalized linear mixed model, we examined\ndeterminants of individuals' total social contacts and evaluated the potential\nimpact of work-from-home and distance learning on the transmissibility of\nrespiratory pathogens. In-person attendance at work or school emerged as a\nprimary driver of social contacts. Adults attending in person reported a mean\nof 1.69 (95% CI: 1.56-1.84) times the contacts of those staying home; among\nchildren and adolescents, this ratio increased to 2.38 (95% CI: 1.98-2.87). We\nestimated that suspending all non-essential work alone would marginally reduce\ntransmissibility. However, combining distance learning for all education levels\nwith work-from-home policies could decrease transmissibility by up to 23.7%\n(95% CI: 18.2%-29.0%). Extending these measures to early childcare services\nwould yield only minimal additional benefits. These results provide useful data\nfor modelling the transmission of respiratory pathogens in Italy after the end\nof the COVID-19 emergency. They also provide insights into the potential\nepidemiological effectiveness of social distancing interventions targeting work\nand school attendance, supporting considerations on the balance between the\nexpected benefits and their heavy societal costs.",
            "pdf_url": "http://arxiv.org/pdf/2412.18549v1",
            "published": "2024-12-24 17:01:29+00:00",
            "updated": "2024-12-24 17:01:29+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "DiTCtrl: Exploring Attention Control in Multi-Modal Diffusion Transformer for Tuning-Free Multi-Prompt Longer Video Generation",
            "authors": "Minghong Cai, Xiaodong Cun, Xiaoyu Li, Wenze Liu, Zhaoyang Zhang, Yong Zhang, Ying Shan, Xiangyu Yue",
            "summary": "Sora-like video generation models have achieved remarkable progress with a\nMulti-Modal Diffusion Transformer MM-DiT architecture. However, the current\nvideo generation models predominantly focus on single-prompt, struggling to\ngenerate coherent scenes with multiple sequential prompts that better reflect\nreal-world dynamic scenarios. While some pioneering works have explored\nmulti-prompt video generation, they face significant challenges including\nstrict training data requirements, weak prompt following, and unnatural\ntransitions. To address these problems, we propose DiTCtrl, a training-free\nmulti-prompt video generation method under MM-DiT architectures for the first\ntime. Our key idea is to take the multi-prompt video generation task as\ntemporal video editing with smooth transitions. To achieve this goal, we first\nanalyze MM-DiT's attention mechanism, finding that the 3D full attention\nbehaves similarly to that of the cross/self-attention blocks in the UNet-like\ndiffusion models, enabling mask-guided precise semantic control across\ndifferent prompts with attention sharing for multi-prompt video generation.\nBased on our careful design, the video generated by DiTCtrl achieves smooth\ntransitions and consistent object motion given multiple sequential prompts\nwithout additional training. Besides, we also present MPVBench, a new benchmark\nspecially designed for multi-prompt video generation to evaluate the\nperformance of multi-prompt generation. Extensive experiments demonstrate that\nour method achieves state-of-the-art performance without additional training.",
            "pdf_url": "http://arxiv.org/pdf/2412.18597v1",
            "published": "2024-12-24 18:51:19+00:00",
            "updated": "2024-12-24 18:51:19+00:00"
        },
        {
            "title": "Resolution-Robust 3D MRI Reconstruction with 2D Diffusion Priors: Diverse-Resolution Training Outperforms Interpolation",
            "authors": "Anselm Krainovic, Stefan Ruschke, Reinhard Heckel",
            "summary": "Deep learning-based 3D imaging, in particular magnetic resonance imaging\n(MRI), is challenging because of limited availability of 3D training data.\nTherefore, 2D diffusion models trained on 2D slices are starting to be\nleveraged for 3D MRI reconstruction. However, as we show in this paper,\nexisting methods pertain to a fixed voxel size, and performance degrades when\nthe voxel size is varied, as it is often the case in clinical practice. In this\npaper, we propose and study several approaches for resolution-robust 3D MRI\nreconstruction with 2D diffusion priors. As a result of this investigation, we\nobtain a simple resolution-robust variational 3D reconstruction approach based\non diffusion-guided regularization of randomly sampled 2D slices. This method\nprovides competitive reconstruction quality compared to posterior sampling\nbaselines. Towards resolving the sensitivity to resolution-shifts, we\ninvestigate state-of-the-art model-based approaches including Gaussian\nsplatting, neural representations, and infinite-dimensional diffusion models,\nas well as a simple data-centric approach of training the diffusion model on\nseveral resolutions. Our experiments demonstrate that the model-based\napproaches fail to close the performance gap in 3D MRI. In contrast, the\ndata-centric approach of training the diffusion model on various resolutions\neffectively provides a resolution-robust method without compromising accuracy.",
            "pdf_url": "http://arxiv.org/pdf/2412.18584v1",
            "published": "2024-12-24 18:25:50+00:00",
            "updated": "2024-12-24 18:25:50+00:00"
        },
        {
            "title": "CognitionCapturer: Decoding Visual Stimuli From Human EEG Signal With Multimodal Information",
            "authors": "Kaifan Zhang, Lihuo He, Xin Jiang, Wen Lu, Di Wang, Xinbo Gao",
            "summary": "Electroencephalogram (EEG) signals have attracted significant attention from\nresearchers due to their non-invasive nature and high temporal sensitivity in\ndecoding visual stimuli. However, most recent studies have focused solely on\nthe relationship between EEG and image data pairs, neglecting the valuable\n``beyond-image-modality\" information embedded in EEG signals. This results in\nthe loss of critical multimodal information in EEG. To address this limitation,\nwe propose CognitionCapturer, a unified framework that fully leverages\nmultimodal data to represent EEG signals. Specifically, CognitionCapturer\ntrains Modality Expert Encoders for each modality to extract cross-modal\ninformation from the EEG modality. Then, it introduces a diffusion prior to map\nthe EEG embedding space to the CLIP embedding space, followed by using a\npretrained generative model, the proposed framework can reconstruct visual\nstimuli with high semantic and structural fidelity. Notably, the framework does\nnot require any fine-tuning of the generative models and can be extended to\nincorporate more modalities. Through extensive experiments, we demonstrate that\nCognitionCapturer outperforms state-of-the-art methods both qualitatively and\nquantitatively. Code: https://github.com/XiaoZhangYES/CognitionCapturer.",
            "pdf_url": "http://arxiv.org/pdf/2412.10489v2",
            "published": "2024-12-13 16:27:54+00:00",
            "updated": "2024-12-24 13:03:44+00:00"
        },
        {
            "title": "Discovery of 2D Materials via Symmetry-Constrained Diffusion Model",
            "authors": "Shihang Xu, Shibing Chu, Rami Mrad, Zhejun Zhang, Zhelin Li, Runxian Jiao, Yuanping Chen",
            "summary": "Generative model for 2D materials has shown significant promise in\naccelerating the material discovery process. The stability and performance of\nthese materials are strongly influenced by their underlying symmetry. However,\nexisting generative models for 2D materials often neglect symmetry constraints,\nwhich limits both the diversity and quality of the generated structures. Here,\nwe introduce a symmetry-constrained diffusion model (SCDM) that integrates\nspace group symmetry into the generative process. By incorporating Wyckoff\npositions, the model ensures adherence to symmetry principles, leading to the\ngeneration of 2,000 candidate structures. DFT calculations were conducted to\nevaluate the convex hull energies of these structures after structural\nrelaxation. From the generated samples, 843 materials that met the energy\nstability criteria (Ehull < 0.6 eV/atom) were identified. Among these, six\ncandidates were selected for further stability analysis, including phonon band\nstructure evaluations and electronic properties investigations, all of which\nexhibited phonon spectrum stability. To benchmark the performance of SCDM, a\nsymmetry-unconstrained diffusion model was also evaluated via crystal structure\nprediction model. The results highlight that incorporating symmetry constraints\nenhances the effectiveness of generated 2D materials, making a contribution to\nthe discovery of 2D materials through generative modeling.",
            "pdf_url": "http://arxiv.org/pdf/2412.18414v1",
            "published": "2024-12-24 13:03:33+00:00",
            "updated": "2024-12-24 13:03:33+00:00"
        },
        {
            "title": "RDPM: Solve Diffusion Probabilistic Models via Recurrent Token Prediction",
            "authors": "Wu Xiaoping, Hu Jie, Wei Xiaoming",
            "summary": "Diffusion Probabilistic Models (DPMs) have emerged as the de facto approach\nfor high-fidelity image synthesis, operating diffusion processes on continuous\nVAE latent, which significantly differ from the text generation methods\nemployed by Large Language Models (LLMs). In this paper, we introduce a novel\ngenerative framework, the Recurrent Diffusion Probabilistic Model (RDPM), which\nenhances the diffusion process through a recurrent token prediction mechanism,\nthereby pioneering the field of Discrete Diffusion. By progressively\nintroducing Gaussian noise into the latent representations of images and\nencoding them into vector-quantized tokens in a recurrent manner, RDPM\nfacilitates a unique diffusion process on discrete-value domains. This process\niteratively predicts the token codes for subsequent timesteps, transforming the\ninitial standard Gaussian noise into the source data distribution, aligning\nwith GPT-style models in terms of the loss function. RDPM demonstrates superior\nperformance while benefiting from the speed advantage of requiring only a few\ninference steps. This model not only leverages the diffusion process to ensure\nhigh-quality generation but also converts continuous signals into a series of\nhigh-fidelity discrete tokens, thereby maintaining a unified optimization\nstrategy with other discrete tokens, such as text. We anticipate that this work\nwill contribute to the development of a unified model for multimodal\ngeneration, specifically by integrating continuous signal domains such as\nimages, videos, and audio with text. We will release the code and model weights\nto the open-source community.",
            "pdf_url": "http://arxiv.org/pdf/2412.18390v1",
            "published": "2024-12-24 12:28:19+00:00",
            "updated": "2024-12-24 12:28:19+00:00"
        }
    ]
}