{
    "Physics": [
        {
            "title": "LLMPhy: Complex Physical Reasoning Using Large Language Models and World Models",
            "authors": "Anoop Cherian, Radu Corcodel, Siddarth Jain, Diego Romeres",
            "summary": "Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.",
            "pdf_url": "http://arxiv.org/pdf/2411.08027v1",
            "published": "2024-11-12 18:56:58+00:00",
            "updated": "2024-11-12 18:56:58+00:00"
        },
        {
            "title": "Commissioning of the 2.6 m tall two-phase xenon time projection chamber of Xenoscope",
            "authors": "M. Adrover, M. Babicz, L. Baudis, Y. Biondi, A. Bismark, C. Capelli, A. P. Cimental Ch\u00e1vez, J. J. Cuenca-Garc\u00eda, M. Galloway, F. Girard, F. J\u00f6rg, S. Ouahada, R. Peres, F. Piastra, M. Rajado Silva, D. Ram\u00edrez Garc\u00eda, C. Wittweg",
            "summary": "Xenoscope is a demonstrator for a next-generation xenon-based observatory for\nastroparticle physics, as proposed by the XLZD (XENON-LUX-ZEPLIN-DARWIN)\ncollaboration. It houses a 2.6 m tall, two-phase xenon time projection chamber\n(TPC), in a cryostat filled with $\\sim$ 360 kg of liquid xenon. The main goals\nof the facility are to demonstrate electron drift in liquid xenon over this\ndistance, to measure the electron cloud transversal and longitudinal diffusion,\nas well as the optical properties of the medium. In this work, we describe in\ndetail the construction and commissioning of the TPC and report on the\nobservation of light and charge signals with cosmic muons.",
            "pdf_url": "http://arxiv.org/pdf/2411.08022v1",
            "published": "2024-11-12 18:52:57+00:00",
            "updated": "2024-11-12 18:52:57+00:00"
        },
        {
            "title": "Last passage percolation in hierarchical environments",
            "authors": "Shirshendu Ganguly, Victor Ginsburg, Kyeongsik Nam",
            "summary": "Last passage percolation (LPP) is a model of a directed metric and a\nzero-temperature polymer where the main observable is a directed path evolving\nin a random environment accruing as energy the sum of the random weights along\nitself. When the environment has light tails and a fast decay of correlation,\nthe fluctuations of LPP are predicted to be explained by the\nKardar-Parisi-Zhang (KPZ) universality theory. However, the KPZ theory is not\nexpected to apply for many natural environments, particularly \"critical\" ones\nexhibiting a hierarchical structure often leading to logarithmic correlations.\n  In this article, we initiate a novel study of LPP in such hierarchical\nenvironments by investigating two particularly interesting examples. The first\nis an i.i.d. environment but with a power-law distribution with an inverse\nquadratic tail decay which is conjectured to be the critical point for the\nvalidity of the KPZ scaling relation. The second is the Branching Random Walk\nwhich is a hierarchical approximation of the two-dimensional Gaussian Free\nField. The second example may be viewed as a high-temperature directed version\nof Liouville Quantum Gravity, which is a model of random geometry driven by the\nexponential of a logarithmically-correlated field. Due to the underlying\nfractal structure, LPP in such environments is expected to exhibit logarithmic\ncorrection terms with novel critical exponents. While discussions about such\ncritical models appear in the physics literature, precise predictions about\nexponents seem to be missing. Developing a framework based on multi-scale\nanalysis, we obtain bounds on such exponents and prove almost optimal\nconcentration results in all dimensions for both models. As a byproduct of our\nanalysis we answer a long-standing question of Martin concerning necessary and\nsufficient conditions for the linear growth of the LPP energy in i.i.d.\nenvironments.",
            "pdf_url": "http://arxiv.org/pdf/2411.08018v1",
            "published": "2024-11-12 18:50:30+00:00",
            "updated": "2024-11-12 18:50:30+00:00"
        },
        {
            "title": "New Physics effects with right-handed neutrinos in semileptonic decay $B_c^+ \\to B_s \u03bc^+ \u03bd_\u03bc$",
            "authors": "Priyanka Boora, Dinesh Kumar, Kavita Lalwani",
            "summary": "We extend the Standard Model with the general effective Hamiltonian for the\nquark level transition $c \\to s \\ell \\nu$ with a complete set of four fermion\noperators including right-handed neutrinos. The current experimental\nmeasurements in charm decays are compatible with the Standard Model predictions\nand are used to constrain the new physics. With the available experimental\ndata, we fit a $\\chi^2$ function to get the best-fit values of the NP WCs. We\ninvestigate the impact of allowed new physics in the observables such as\ndifferential branching fraction, forward-backward asymmetry, lepton\npolarization asymmetry, and convexity parameter in the semileptonic decay\n$B_c^+ \\to B_s \\mu^+ \\nu_{\\mu}$. The different types of new physics scenarios\nhave significant effects on these considered observables. The future\nexperimental information of these observables can help to disentangle the\nstructure of new physics.",
            "pdf_url": "http://arxiv.org/pdf/2411.07987v1",
            "published": "2024-11-12 18:13:30+00:00",
            "updated": "2024-11-12 18:13:30+00:00"
        },
        {
            "title": "Transparent and Electrically Switchable Thin Film Tactile Actuators Based on Molecular Orientation",
            "authors": "Abigail Nolin, Chun-Yuan Lo, Laure V. Kayser, Charles B. Dhong",
            "summary": "Most tactile actuators create tactile sensations through vibrations or the\nmechanical and electrochemical formation of bumps. However, tactile sensations\nof real objects arise from friction which is derived not only from physical\ntopography, but also surface chemistry. Here, we show that molecular\nrearrangement can be leveraged to create new classes of tactile actuators based\non the phases of liquid crystals embedded in a solid and transparent polymer\nfilm. We found that humans can feel differences by touch, especially between\nplanar alignment and its disrupted phase, as actuated by a DC electrical field.\nIn subjective terms, the sensation was described as a tacky to polished-like\nfeeling. We attribute the mechanism of tactile contrast to microscale phase\nseparation and changes in molecular orientation, as the nanoscale differences\nin topography are too small to be detected on their own by humans. This\nmolecular rearrangement occurs quicker (<17 ms) than actuation through ionic or\nfluid movement. This enables a new class of tactile actuators based on\nmolecular orientation (TAMO) for haptic interfaces.",
            "pdf_url": "http://arxiv.org/pdf/2411.07968v1",
            "published": "2024-11-12 17:47:00+00:00",
            "updated": "2024-11-12 17:47:00+00:00"
        },
        {
            "title": "Composite fermions and parton wavefunctions in twisted graphene on hexagonal boron nitride",
            "authors": "J. Salvador-S\u00e1nchez, A. P\u00e9rez-Rodriguez, V. Cleric\u00f2, O. Zheliuk, U. Zeitler, K. Watanabe, T. Taniguchi, E. Diez, M. Amado, V. Bellani",
            "summary": "In a twisted graphene on hexagonal Boron Nitride, the presence of a gap and\nthe breaking of the symmetry between carbon sublattices leads to multicomponent\nfractional quantum Hall effect (FQHE) due to the electrons correlation. We\nreport on the FQHE at filling factors nu = k/2 and nu = k/3 with nu > 1, and on\nthe composite fermions at in the nu < 1 lowest landau Level nu = 4/5, 5/7 and\n2/3. These fractional states can be described with a partons model, in which\nthe electron is broken down into sub-particles each one residing in an integer\nquantum Hall effect state; partons are fictitious particles that, glued back\ntogether, recover the physical electrons. The parton states host exotic anyons\nthat could potentially form building blocks of a fault-tolerant topological\nquantum computer.",
            "pdf_url": "http://arxiv.org/pdf/2411.07958v1",
            "published": "2024-11-12 17:36:08+00:00",
            "updated": "2024-11-12 17:36:08+00:00"
        },
        {
            "title": "NLO QCD effects on angular observables in single Higgs production at electron-proton collider",
            "authors": "Pramod Sharma, Biswajit Das, Ambresh Shivaji",
            "summary": "Properties of the Higgs boson ($H$) at current and future particle colliders\nare crucial to explore new physics beyond the standard model. In particular,\nexperimental and theoretical outlooks at future colliders drive interest in\nHiggs to gauge boson couplings. Single Higgs production via vector-boson fusion\nallows probing Higgs couplings with massive vector bosons ($V = W, Z$). We\nconsider electron-proton (eP) collider to study these couplings due to the low\nbackground. In a recent study, we considered the most general anomalous\nHiggs-vector boson ($HVV$) couplings and explored the potential of eP collider\nin constraining the parameters of $HVV$ couplings. Our results were based on\nleading order predictions in perturbation theory. We include further Next to\nLeading Order (NLO) corrections of Quantum Chromodynamic (QCD) in Standard\nModel signal to make precise predictions. In this talk, I will present the\neffect of NLO QCD corrections on the standard model and anomalous $HVV$\ncouplings.",
            "pdf_url": "http://arxiv.org/pdf/2411.07950v1",
            "published": "2024-11-12 17:25:54+00:00",
            "updated": "2024-11-12 17:25:54+00:00"
        },
        {
            "title": "Larmor radius effect on the control of chaotic transport in tokamaks",
            "authors": "L. A. Osorio-Quiroga, M. Roberto, R. L. Viana, Y. Elskens, I. L. Caldas",
            "summary": "We investigate the influence of the finite Larmor radius on the dynamics of\nguiding-center test particles subjected to an $\\mathbf{E} \\times \\mathbf{B}$\ndrift in a large aspect-ratio tokamak. For that, we adopt the drift-wave test\nparticle transport model presented by W. Horton [Physics of Plasmas \\textbf{5},\n3910 (1998)] and introduce a second-order gyro-averaged extension, which\naccounts for the finite Larmor radius effect that arises from a spatially\nvarying electric field. Using this extended model, we numerically examine the\ninfluence of the finite Larmor radius on chaotic transport and the formation of\ntransport barriers. For non-monotonic plasma profiles, we show that the twist\ncondition of the dynamical system, i.e.,\\ KAM theorem's non-degeneracy\ncondition for the Hamiltonian, is violated along a special curve, which, under\nnon-equilibrium conditions, exhibits significant resilience to destruction,\nthereby inhibiting chaotic transport. This curve acts as a robust barrier to\ntransport and is usually called shearless transport barrier. While varying the\namplitude of the electrostatic perturbations, we analyze bifurcation diagrams\nof the shearless barriers and escape rates of orbits to explore the impact of\nthe finite Larmor radius on controlling chaotic transport. Our findings show\nthat increasing the Larmor radius enhances the robustness of transport\nbarriers, as larger electrostatic perturbation amplitudes are required to\ndisrupt them. Additionally, as the Larmor radius increases, even in the absence\nof transport barriers, we observe a reduction in the escape rates, indicating a\ndecrease in chaotic transport.",
            "pdf_url": "http://arxiv.org/pdf/2407.15963v2",
            "published": "2024-07-22 18:24:32+00:00",
            "updated": "2024-11-12 17:14:16+00:00"
        },
        {
            "title": "Improving quantum metrology protocols with programmable photonic circuits",
            "authors": "A. Mu\u00f1oz de las Heras, D. Porras, A. Gonz\u00e1lez-Tudela",
            "summary": "Photonic quantum metrology enables the measurement of physical parameters\nwith precision surpassing classical limits by using quantum states of light.\nHowever, generating states providing a large metrological advantage is hard\nbecause standard probabilistic methods suffer from low generation rates.\nDeterministic protocols using non-linear interactions offer a path to overcome\nthis problem, but they are currently limited by the errors introduced during\nthe interaction time. Thus, finding strategies to minimize the interaction time\nof these non-linearities is still a relevant question. In this work, we\nintroduce and compare different deterministic strategies based on continuous\nand programmable Jaynes-Cummings and Kerr-type interactions, aiming to maximize\nthe metrological advantage while minimizing the interaction time. We find that\nprogrammable interactions provide a larger metrological advantage than\ncontinuous operations at the expense of slightly larger interaction times. We\nshow that while for Jaynes-Cummings non-linearities the interaction time grows\nwith the photon number, for Kerr-type ones it decreases, favoring the\nscalability to big photon numbers. Finally, we also optimize different\nmeasurement strategies for the deterministically generated states based on\nphoton-counting and homodyne detection.",
            "pdf_url": "http://arxiv.org/pdf/2411.07929v1",
            "published": "2024-11-12 17:02:38+00:00",
            "updated": "2024-11-12 17:02:38+00:00"
        },
        {
            "title": "Isometric Transformations for Image Augmentation in Mueller Matrix Polarimetry",
            "authors": "Christopher Hahne, Omar Rodriguez-Nunez, \u00c9l\u00e9a Gros, Th\u00e9otim Lucas, Ekkehard Hewer, Tatiana Novikova, Theoni Maragkou, Philippe Schucht, Richard McKinley",
            "summary": "Mueller matrix polarimetry captures essential information about polarized\nlight interactions with a sample, presenting unique challenges for data\naugmentation in deep learning due to its distinct structure. While\naugmentations are an effective and affordable way to enhance dataset diversity\nand reduce overfitting, standard transformations like rotations and flips do\nnot preserve the polarization properties in Mueller matrix images. To this end,\nwe introduce a versatile simulation framework that applies physically\nconsistent rotations and flips to Mueller matrices, tailored to maintain\npolarization fidelity. Our experimental results across multiple datasets reveal\nthat conventional augmentations can lead to misleading results when applied to\npolarimetric data, underscoring the necessity of our physics-based approach. In\nour experiments, we first compare our polarization-specific augmentations\nagainst real-world captures to validate their physical consistency. We then\napply these augmentations in a semantic segmentation task, achieving\nsubstantial improvements in model generalization and performance. This study\nunderscores the necessity of physics-informed data augmentation for\npolarimetric imaging in deep learning (DL), paving the way for broader adoption\nand more robust applications across diverse research in the field. In\nparticular, our framework unlocks the potential of DL models for polarimetric\ndatasets with limited sample sizes. Our code implementation is available at\ngithub.com/hahnec/polar_augment.",
            "pdf_url": "http://arxiv.org/pdf/2411.07918v1",
            "published": "2024-11-12 16:50:13+00:00",
            "updated": "2024-11-12 16:50:13+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Scaling Properties of Diffusion Models for Perceptual Tasks",
            "authors": "Rahul Ravishankar, Zeeshan Patel, Jathushan Rajasegaran, Jitendra Malik",
            "summary": "In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and segmentation\nunder image-to-image translation, and show how diffusion models benefit from\nscaling training and test-time compute for these perception tasks. Through a\ncareful analysis of these scaling behaviors, we present various techniques to\nefficiently train diffusion models for visual perception tasks. Our models\nachieve improved or comparable performance to state-of-the-art methods using\nsignificantly less data and compute. To use our code and models, see\nhttps://scaling-diffusion-perception.github.io .",
            "pdf_url": "http://arxiv.org/pdf/2411.08034v1",
            "published": "2024-11-12 18:59:35+00:00",
            "updated": "2024-11-12 18:59:35+00:00"
        },
        {
            "title": "GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D Generation",
            "authors": "Yushi Lan, Shangchen Zhou, Zhaoyang Lyu, Fangzhou Hong, Shuai Yang, Bo Dai, Xingang Pan, Chen Change Loy",
            "summary": "While 3D content generation has advanced significantly, existing methods\nstill face challenges with input formats, latent space design, and output\nrepresentations. This paper introduces a novel 3D generation framework that\naddresses these challenges, offering scalable, high-quality 3D generation with\nan interactive Point Cloud-structured Latent space. Our framework employs a\nVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)\nrenderings as input, using a unique latent space design that preserves 3D shape\ninformation, and incorporates a cascaded latent diffusion model for improved\nshape-texture disentanglement. The proposed method, GaussianAnything, supports\nmulti-modal conditional 3D generation, allowing for point cloud, caption, and\nsingle/multi-view image inputs. Notably, the newly proposed latent space\nnaturally enables geometry-texture disentanglement, thus allowing 3D-aware\nediting. Experimental results demonstrate the effectiveness of our approach on\nmultiple datasets, outperforming existing methods in both text- and\nimage-conditioned 3D generation.",
            "pdf_url": "http://arxiv.org/pdf/2411.08033v1",
            "published": "2024-11-12 18:59:32+00:00",
            "updated": "2024-11-12 18:59:32+00:00"
        },
        {
            "title": "Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model with Compact Wavelet Encodings",
            "authors": "Aditya Sanghi, Aliasghar Khani, Pradyumna Reddy, Arianna Rampini, Derek Cheung, Kamal Rahimi Malekshan, Kanika Madan, Hooman Shayani",
            "summary": "Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.",
            "pdf_url": "http://arxiv.org/pdf/2411.08017v1",
            "published": "2024-11-12 18:49:06+00:00",
            "updated": "2024-11-12 18:49:06+00:00"
        },
        {
            "title": "Diverse capability and scaling of diffusion and auto-regressive models when learning abstract rules",
            "authors": "Binxu Wang, Jiaqi Shang, Haim Sompolinsky",
            "summary": "Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.",
            "pdf_url": "http://arxiv.org/pdf/2411.07873v1",
            "published": "2024-11-12 15:29:50+00:00",
            "updated": "2024-11-12 15:29:50+00:00"
        },
        {
            "title": "Stochastic Super-resolution of Cosmological Simulations with Denoising Diffusion Models",
            "authors": "Andreas Schanz, Florian List, Oliver Hahn",
            "summary": "In recent years, deep learning models have been successfully employed for\naugmenting low-resolution cosmological simulations with small-scale\ninformation, a task known as \"super-resolution\". So far, these cosmological\nsuper-resolution models have relied on generative adversarial networks (GANs),\nwhich can achieve highly realistic results, but suffer from various\nshortcomings (e.g. low sample diversity). We introduce denoising diffusion\nmodels as a powerful generative model for super-resolving cosmic large-scale\nstructure predictions (as a first proof-of-concept in two dimensions). To\nobtain accurate results down to small scales, we develop a new \"filter-boosted\"\ntraining approach that redistributes the importance of different scales in the\npixel-wise training objective. We demonstrate that our model not only produces\nconvincing super-resolution images and power spectra consistent at the percent\nlevel, but is also able to reproduce the diversity of small-scale features\nconsistent with a given low-resolution simulation. This enables uncertainty\nquantification for the generated small-scale features, which is critical for\nthe usefulness of such super-resolution models as a viable surrogate model for\ncosmic structure formation.",
            "pdf_url": "http://arxiv.org/pdf/2310.06929v2",
            "published": "2023-10-10 18:32:11+00:00",
            "updated": "2024-11-12 08:24:28+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Evaluating Large Language Models on Financial Report Summarization: An Empirical Study",
            "authors": "Xinqi Yang, Scott Zang, Yong Ren, Dingjie Peng, Zheng Wen",
            "summary": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\nversatility across various applications, including natural language\nunderstanding, domain-specific knowledge tasks, etc. However, applying LLMs to\ncomplex, high-stakes domains like finance requires rigorous evaluation to\nensure reliability, accuracy, and compliance with industry standards. To\naddress this need, we conduct a comprehensive and comparative study on three\nstate-of-the-art LLMs, GLM-4, Mistral-NeMo, and LLaMA3.1, focusing on their\neffectiveness in generating automated financial reports. Our primary motivation\nis to explore how these models can be harnessed within finance, a field\ndemanding precision, contextual relevance, and robustness against erroneous or\nmisleading information. By examining each model's capabilities, we aim to\nprovide an insightful assessment of their strengths and limitations. Our paper\noffers benchmarks for financial report analysis, encompassing proposed metrics\nsuch as ROUGE-1, BERT Score, and LLM Score. We introduce an innovative\nevaluation framework that integrates both quantitative metrics (e.g.,\nprecision, recall) and qualitative analyses (e.g., contextual fit, consistency)\nto provide a holistic view of each model's output quality. Additionally, we\nmake our financial dataset publicly available, inviting researchers and\npractitioners to leverage, scrutinize, and enhance our findings through broader\ncommunity engagement and collaborative improvement. Our dataset is available on\nhuggingface.",
            "pdf_url": "http://arxiv.org/pdf/2411.06852v1",
            "published": "2024-11-11 10:36:04+00:00",
            "updated": "2024-11-11 10:36:04+00:00"
        }
    ]
}