{
    "Physics": [
        {
            "title": "Nabla-R2D3: Effective and Efficient 3D Diffusion Alignment with 2D Rewards",
            "authors": "Qingming Liu, Zhen Liu, Dinghuai Zhang, Kui Jia",
            "summary": "Generating high-quality and photorealistic 3D assets remains a longstanding\nchallenge in 3D vision and computer graphics. Although state-of-the-art\ngenerative models, such as diffusion models, have made significant progress in\n3D generation, they often fall short of human-designed content due to limited\nability to follow instructions, align with human preferences, or produce\nrealistic textures, geometries, and physical attributes. In this paper, we\nintroduce Nabla-R2D3, a highly effective and sample-efficient reinforcement\nlearning alignment framework for 3D-native diffusion models using 2D rewards.\nBuilt upon the recently proposed Nabla-GFlowNet method, which matches the score\nfunction to reward gradients in a principled manner for reward finetuning, our\nNabla-R2D3 enables effective adaptation of 3D diffusion models using only 2D\nreward signals. Extensive experiments show that, unlike vanilla finetuning\nbaselines which either struggle to converge or suffer from reward hacking,\nNabla-R2D3 consistently achieves higher rewards and reduced prior forgetting\nwithin a few finetuning steps.",
            "pdf_url": "http://arxiv.org/pdf/2506.15684v1",
            "published": "2025-06-18 17:59:59+00:00",
            "updated": "2025-06-18 17:59:59+00:00"
        },
        {
            "title": "Particle-Grid Neural Dynamics for Learning Deformable Object Models from RGB-D Videos",
            "authors": "Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li",
            "summary": "Modeling the dynamics of deformable objects is challenging due to their\ndiverse physical properties and the difficulty of estimating states from\nlimited visual information. We address these challenges with a neural dynamics\nframework that combines object particles and spatial grids in a hybrid\nrepresentation. Our particle-grid model captures global shape and motion\ninformation while predicting dense particle movements, enabling the modeling of\nobjects with varied shapes and materials. Particles represent object shapes,\nwhile the spatial grid discretizes the 3D space to ensure spatial continuity\nand enhance learning efficiency. Coupled with Gaussian Splattings for visual\nrendering, our framework achieves a fully learning-based digital twin of\ndeformable objects and generates 3D action-conditioned videos. Through\nexperiments, we demonstrate that our model learns the dynamics of diverse\nobjects -- such as ropes, cloths, stuffed animals, and paper bags -- from\nsparse-view RGB-D recordings of robot-object interactions, while also\ngeneralizing at the category level to unseen instances. Our approach\noutperforms state-of-the-art learning-based and physics-based simulators,\nparticularly in scenarios with limited camera views. Furthermore, we showcase\nthe utility of our learned models in model-based planning, enabling\ngoal-conditioned object manipulation across a range of tasks. The project page\nis available at https://kywind.github.io/pgnd .",
            "pdf_url": "http://arxiv.org/pdf/2506.15680v1",
            "published": "2025-06-18 17:59:38+00:00",
            "updated": "2025-06-18 17:59:38+00:00"
        },
        {
            "title": "Embodied Web Agents: Bridging Physical-Digital Realms for Integrated Agent Intelligence",
            "authors": "Yining Hong, Rui Sun, Bingxuan Li, Xingcheng Yao, Maxine Wu, Alexander Chien, Da Yin, Ying Nian Wu, Zhecan James Wang, Kai-Wei Chang",
            "summary": "AI agents today are mostly siloed - they either retrieve and reason over vast\namount of digital information and knowledge obtained online; or interact with\nthe physical world through embodied perception, planning and action - but\nrarely both. This separation limits their ability to solve tasks that require\nintegrated physical and digital intelligence, such as cooking from online\nrecipes, navigating with dynamic map data, or interpreting real-world landmarks\nusing web knowledge. We introduce Embodied Web Agents, a novel paradigm for AI\nagents that fluidly bridge embodiment and web-scale reasoning. To\noperationalize this concept, we first develop the Embodied Web Agents task\nenvironments, a unified simulation platform that tightly integrates realistic\n3D indoor and outdoor environments with functional web interfaces. Building\nupon this platform, we construct and release the Embodied Web Agents Benchmark,\nwhich encompasses a diverse suite of tasks including cooking, navigation,\nshopping, tourism, and geolocation - all requiring coordinated reasoning across\nphysical and digital realms for systematic assessment of cross-domain\nintelligence. Experimental results reveal significant performance gaps between\nstate-of-the-art AI systems and human capabilities, establishing both\nchallenges and opportunities at the intersection of embodied cognition and\nweb-scale knowledge access. All datasets, codes and websites are publicly\navailable at our project page https://embodied-web-agent.github.io/.",
            "pdf_url": "http://arxiv.org/pdf/2506.15677v1",
            "published": "2025-06-18 17:58:17+00:00",
            "updated": "2025-06-18 17:58:17+00:00"
        },
        {
            "title": "Analog Quantum Phase Estimation with Single-Mode Readout",
            "authors": "Wei-Chen Lin, Chiao-Hsuan Wang",
            "summary": "Eigenvalue estimation is a central problem for demonstrating quantum\nadvantage, yet its implementation on digital quantum computers remains limited\nby circuit depth and operational overhead. We present an analog quantum phase\nestimation (aQPE) protocol that extracts the eigenenergies of a target\nHamiltonian via continuous time evolution and single-mode cavity measurement.\nBy encoding eigenvalue information as conditional cavity phase-space rotations,\nthe scheme avoids deep quantum circuits and entangling gates, while enabling\nreadout through established cavity tomography techniques. We further illustrate\nthe feasibility of this approach by engineering a Hamiltonian that implements\naQPE of the XY model, whose ground-state energy problem is QMA-complete, within\na physical architecture compatible with existing circuit quantum\nelectrodynamics technology. Our results provide a resource-efficient and\nscalable framework for implementing quantum phase estimation in near-term\nquantum platforms.",
            "pdf_url": "http://arxiv.org/pdf/2506.15668v1",
            "published": "2025-06-18 17:50:42+00:00",
            "updated": "2025-06-18 17:50:42+00:00"
        },
        {
            "title": "Exact solution for a class of quantum models of interacting bosons",
            "authors": "Valery Shchesnovich",
            "summary": "Quantum models of interacting bosons have a wide range of applications,\nincluding the propagation of optical modes in nonlinear media, such as the\n$k$-photon down-conversion. Many of these models are related to nonlinear\ndeformations of finite group algebras and, in this sense, are exactly solvable.\nWhile advanced group-theoretic methods were developed to study the eigenvalue\nspectrum, in quantum optics, the primary focus is not on the spectrum of the\nHamiltonian but rather on the evolution of an initial state -- such as the\ngeneration of optical signal modes by a strong pump mode propagating through a\nnonlinear medium. I propose a simple and general method to solve the state\nevolution problem, applicable to a broad class of quantum models of interacting\nbosons. For the k-photon down-conversion model and its generalizations, the\nsolution to the state evolution problem is expressed as an infinite series\nexpansion in powers of the propagation time, with coefficients determined by a\nrecursion relation involving only a single polynomial function. This polynomial\nfunction is unique to each nonlinear model. As an application, I compare the\nexact solution of the parametric down-conversion process with the semiclassical\nparametric approximation.",
            "pdf_url": "http://arxiv.org/pdf/2411.14204v4",
            "published": "2024-11-21 15:13:03+00:00",
            "updated": "2025-06-18 17:42:04+00:00"
        },
        {
            "title": "Fokker-Planck Score Learning: Efficient Free-Energy Estimation under Periodic Boundary Conditions",
            "authors": "Daniel Nagel, Tristan Bereau",
            "summary": "Accurate free-energy estimation is essential in molecular simulation, yet the\nperiodic boundary conditions (PBC) commonly used in computer simulations have\nrarely been explicitly exploited. Equilibrium methods such as umbrella\nsampling, metadynamics, and adaptive biasing force require extensive sampling,\nwhile non-equilibrium pulling with Jarzynski's equality suffers from poor\nconvergence due to exponential averaging. Here, we introduce a\nphysics-informed, score-based diffusion framework: by mapping PBC simulations\nonto a Brownian particle in a periodic potential, we derive the Fokker-Planck\nsteady-state score that directly encodes free-energy gradients. A neural\nnetwork is trained on non-equilibrium trajectories to learn this score,\nproviding a principled scheme to efficiently reconstruct the potential of mean\nforce (PMF). On benchmark periodic potentials and small-molecule membrane\npermeation, our method is up to one order of magnitude more efficient than\numbrella sampling.",
            "pdf_url": "http://arxiv.org/pdf/2506.15653v1",
            "published": "2025-06-18 17:30:54+00:00",
            "updated": "2025-06-18 17:30:54+00:00"
        },
        {
            "title": "Embedding physical symmetries into machine-learned reduced plasma physics models via data augmentation",
            "authors": "Madox C. McGrae-Menge, Jacob R. Pierce, Frederico Fiuza, E. Paulo Alves",
            "summary": "Machine learning is offering powerful new tools for the development and\ndiscovery of reduced models of nonlinear, multiscale plasma dynamics from the\ndata of first-principles kinetic simulations. However, ensuring the physical\nconsistency of such models requires embedding fundamental symmetries of plasma\ndynamics. In this work, we explore a symmetry-embedding strategy based on data\naugmentation, where symmetry-preserving transformations (e.g., Lorentz and\nGalilean boosts) are applied to simulation data. Using both sparse regression\nand neural networks, we show that models trained on symmetry-augmented data\nmore accurately infer the plasma fluid equations and pressure tensor closures\nfrom fully kinetic particle-in-cell simulations of magnetic reconnection. We\nshow that this approach suppresses spurious inertial-frame-dependent\ncorrelations between dynamical variables, improves data efficiency, and\nsignificantly outperforms models trained without symmetry-augmented data, as\nwell as commonly used theoretical pressure closure models. Our results\nestablish symmetry-based data augmentation as a broadly applicable method for\nincorporating physical structure into machine-learned reduced plasma models.",
            "pdf_url": "http://arxiv.org/pdf/2506.14048v2",
            "published": "2025-06-16 22:53:36+00:00",
            "updated": "2025-06-18 17:26:58+00:00"
        },
        {
            "title": "Duplication-divergence growing graph models",
            "authors": "Dario Borrelli",
            "summary": "In recent decades, it has been emphasized that the evolving structure of\nnetworks may be shaped by interaction principles that yield sparse graphs with\na vertex degree distribution exhibiting an algebraic tail, and other structural\ntraits that are not featured in traditional random graphs. In this respect,\nthrough a mean-field approach, this review tackles the statistical physics of\ngraph models based on the interaction principle of duplication-divergence.\nAdditional sophistications extending the duplication-divergence model are also\nreviewed as well as generalizations of other known models. Possible research\ngaps and related prior results are then discussed.",
            "pdf_url": "http://arxiv.org/pdf/2506.15640v1",
            "published": "2025-06-18 17:10:29+00:00",
            "updated": "2025-06-18 17:10:29+00:00"
        },
        {
            "title": "Robust Physics-Informed Neural Network Approach for Estimating Heterogeneous Elastic Properties from Noisy Displacement Data",
            "authors": "Tatthapong Srikitrungruang, Matthew Lemon, Sina Aghaee Dabaghan Fard, Jaesung Lee, Yuxiao Zhou",
            "summary": "Accurately estimating spatially heterogeneous elasticity parameters,\nparticularly Young's modulus and Poisson's ratio, from noisy displacement\nmeasurements remains significantly challenging in inverse elasticity problems.\nExisting inverse estimation techniques are often limited by instability,\npronounced sensitivity to measurement noise, and difficulty in recovering\nabsolute-scale Young's modulus. This work presents a novel Inverse Elasticity\nPhysics-Informed Neural Network (IE-PINN) specifically designed to robustly\nreconstruct heterogeneous distributions of elasticity parameters from noisy\ndisplacement data based on linear elasticity physics. IE-PINN integrates three\ndistinct neural network architectures dedicated to separately modeling\ndisplacement fields, strain fields, and elasticity distributions, thereby\nsignificantly enhancing stability and accuracy against measurement noise.\nAdditionally, a two-phase estimation strategy is introduced: the first phase\nrecovers relative spatial distributions of Young's modulus and Poisson's ratio,\nand the second phase calibrates the absolute scale of Young's modulus using\nimposed loading boundary conditions. Additional methodological innovations,\nincluding positional encoding, sine activation functions, and a sequential\npretraining protocol, further enhance the model's performance and robustness.\nExtensive numerical experiments demonstrate that IE-PINN effectively overcomes\ncritical limitations encountered by existing methods, delivering accurate\nabsolute-scale elasticity estimations even under severe noise conditions. This\nadvancement holds substantial potential for clinical imaging diagnostics and\nmechanical characterization, where measurements typically encounter substantial\nnoise.",
            "pdf_url": "http://arxiv.org/pdf/2506.14036v2",
            "published": "2025-06-16 22:20:44+00:00",
            "updated": "2025-06-18 17:08:53+00:00"
        },
        {
            "title": "A covariant description of the interactions of axion-like particles and hadrons",
            "authors": "Reuven Balkin, Ta'el Coren, Yotam Soreq, Mike Williams",
            "summary": "We present a covariant framework for analyzing the interactions and decay\nrates of axion-like particles (ALPs) that couple to both gluons and quarks. We\nidentify combinations of couplings that are invariant under quark-field\nredefinitions, and use them to obtain physical expressions for the prominent\ndecay rates of such ALPs, which are compared with previous calculations for\nscenarios where ALPs couple exclusively to quarks or to gluons. Our framework\ncan be used to obtain ALP decay rates for arbitrary ALP couplings to gluons and\nquarks across a broad range of ALP masses.",
            "pdf_url": "http://arxiv.org/pdf/2506.15637v1",
            "published": "2025-06-18 17:08:01+00:00",
            "updated": "2025-06-18 17:08:01+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "One-Step Diffusion for Detail-Rich and Temporally Consistent Video Super-Resolution",
            "authors": "Yujing Sun, Lingchen Sun, Shuaizheng Liu, Rongyuan Wu, Zhengqiang Zhang, Lei Zhang",
            "summary": "It is a challenging problem to reproduce rich spatial details while\nmaintaining temporal consistency in real-world video super-resolution\n(Real-VSR), especially when we leverage pre-trained generative models such as\nstable diffusion (SD) for realistic details synthesis. Existing SD-based\nReal-VSR methods often compromise spatial details for temporal coherence,\nresulting in suboptimal visual quality. We argue that the key lies in how to\neffectively extract the degradation-robust temporal consistency priors from the\nlow-quality (LQ) input video and enhance the video details while maintaining\nthe extracted consistency priors. To achieve this, we propose a Dual LoRA\nLearning (DLoRAL) paradigm to train an effective SD-based one-step diffusion\nmodel, achieving realistic frame details and temporal consistency\nsimultaneously. Specifically, we introduce a Cross-Frame Retrieval (CFR) module\nto aggregate complementary information across frames, and train a\nConsistency-LoRA (C-LoRA) to learn robust temporal representations from\ndegraded inputs. After consistency learning, we fix the CFR and C-LoRA modules\nand train a Detail-LoRA (D-LoRA) to enhance spatial details while aligning with\nthe temporal space defined by C-LoRA to keep temporal coherence. The two phases\nalternate iteratively for optimization, collaboratively delivering consistent\nand detail-rich outputs. During inference, the two LoRA branches are merged\ninto the SD model, allowing efficient and high-quality video restoration in a\nsingle diffusion step. Experiments show that DLoRAL achieves strong performance\nin both accuracy and speed. Code and models are available at\nhttps://github.com/yjsunnn/DLoRAL.",
            "pdf_url": "http://arxiv.org/pdf/2506.15591v1",
            "published": "2025-06-18 16:06:30+00:00",
            "updated": "2025-06-18 16:06:30+00:00"
        },
        {
            "title": "CLAIM: Clinically-Guided LGE Augmentation for Realistic and Diverse Myocardial Scar Synthesis and Segmentation",
            "authors": "Farheen Ramzan, Yusuf Kiberu, Nikesh Jathanna, Shahnaz Jamil-Copley, Richard H. Clayton, Chen, Chen",
            "summary": "Deep learning-based myocardial scar segmentation from late gadolinium\nenhancement (LGE) cardiac MRI has shown great potential for accurate and timely\ndiagnosis and treatment planning for structural cardiac diseases. However, the\nlimited availability and variability of LGE images with high-quality scar\nlabels restrict the development of robust segmentation models. To address this,\nwe introduce CLAIM: \\textbf{C}linically-Guided \\textbf{L}GE\n\\textbf{A}ugmentation for Real\\textbf{i}stic and Diverse \\textbf{M}yocardial\nScar Synthesis and Segmentation framework, a framework for anatomically\ngrounded scar generation and segmentation. At its core is the SMILE module\n(Scar Mask generation guided by cLinical knowledgE), which conditions a\ndiffusion-based generator on the clinically adopted AHA 17-segment model to\nsynthesize images with anatomically consistent and spatially diverse scar\npatterns. In addition, CLAIM employs a joint training strategy in which the\nscar segmentation network is optimized alongside the generator, aiming to\nenhance both the realism of synthesized scars and the accuracy of the scar\nsegmentation performance. Experimental results show that CLAIM produces\nanatomically coherent scar patterns and achieves higher Dice similarity with\nreal scar distributions compared to baseline models. Our approach enables\ncontrollable and realistic myocardial scar synthesis and has demonstrated\nutility for downstream medical imaging task.",
            "pdf_url": "http://arxiv.org/pdf/2506.15549v1",
            "published": "2025-06-18 15:21:34+00:00",
            "updated": "2025-06-18 15:21:34+00:00"
        },
        {
            "title": "Intrinsic and Extrinsic Organized Attention: Softmax Invariance and Network Sparsity",
            "authors": "Oluwadamilola Fasina, Ruben V. C. Pohle, Pei-Chun Su, Ronald R. Coifman",
            "summary": "We examine the intrinsic (within the attention head) and extrinsic (amongst\nthe attention heads) structure of the self-attention mechanism in transformers.\nTheoretical evidence for invariance of the self-attention mechanism to softmax\nactivation is obtained by appealing to paradifferential calculus, (and is\nsupported by computational examples), which relies on the intrinsic\norganization of the attention heads. Furthermore, we use an existing\nmethodology for hierarchical organization of tensors to examine network\nstructure by constructing hierarchal partition trees with respect to the query,\nkey, and head axes of network 3-tensors. Such an organization is consequential\nsince it allows one to profitably execute common signal processing tasks on a\ngeometry where the organized network 3-tensors exhibit regularity. We exemplify\nthis qualitatively, by visualizing the hierarchical organization of the tree\ncomprised of attention heads and the diffusion map embeddings, and\nquantitatively by investigating network sparsity with the expansion\ncoefficients of individual attention heads and the entire network with respect\nto the bi and tri-haar bases (respectively) on the space of queries, keys, and\nheads of the network. To showcase the utility of our theoretical and\nmethodological findings, we provide computational examples using vision and\nlanguage transformers. The ramifications of these findings are two-fold: (1) a\nsubsequent step in interpretability analysis is theoretically admitted, and can\nbe exploited empirically for downstream interpretability tasks (2) one can use\nthe network 3-tensor organization for empirical network applications such as\nmodel pruning (by virtue of network sparsity) and network architecture\ncomparison.",
            "pdf_url": "http://arxiv.org/pdf/2506.15541v1",
            "published": "2025-06-18 15:14:56+00:00",
            "updated": "2025-06-18 15:14:56+00:00"
        },
        {
            "title": "A Comprehensive Survey on Continual Learning in Generative Models",
            "authors": "Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu, Shijie Ma, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu",
            "summary": "The rapid advancement of generative models has enabled modern AI systems to\ncomprehend and produce highly sophisticated content, even achieving human-level\nperformance in specific domains. However, these models remain fundamentally\nconstrained by catastrophic forgetting - a persistent challenge where adapting\nto new tasks typically leads to significant degradation in performance on\npreviously learned tasks. To address this practical limitation, numerous\napproaches have been proposed to enhance the adaptability and scalability of\ngenerative models in real-world applications. In this work, we present a\ncomprehensive survey of continual learning methods for mainstream generative\nmodels, including large language models, multimodal large language models,\nvision language action models, and diffusion models. Drawing inspiration from\nthe memory mechanisms of the human brain, we systematically categorize these\napproaches into three paradigms: architecture-based, regularization-based, and\nreplay-based methods, while elucidating their underlying methodologies and\nmotivations. We further analyze continual learning setups for different\ngenerative models, including training objectives, benchmarks, and core\nbackbones, offering deeper insights into the field. The project page of this\npaper is available at\nhttps://github.com/Ghy0501/Awesome-Continual-Learning-in-Generative-Models.",
            "pdf_url": "http://arxiv.org/pdf/2506.13045v2",
            "published": "2025-06-16 02:27:25+00:00",
            "updated": "2025-06-18 15:06:34+00:00"
        },
        {
            "title": "Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models",
            "authors": "Teysir Baoueb, Xiaoyu Bie, Xi Wang, Ga\u00ebl Richard",
            "summary": "Breakthroughs in text-to-music generation models are transforming the\ncreative landscape, equipping musicians with innovative tools for composition\nand experimentation like never before. However, controlling the generation\nprocess to achieve a specific desired outcome remains a significant challenge.\nEven a minor change in the text prompt, combined with the same random seed, can\ndrastically alter the generated piece. In this paper, we explore the\napplication of existing text-to-music diffusion models for instrument editing.\nSpecifically, for an existing audio track, we aim to leverage a pretrained\ntext-to-music diffusion model to edit the instrument while preserving the\nunderlying content. Based on the insight that the model first focuses on the\noverall structure or content of the audio, then adds instrument information,\nand finally refines the quality, we show that selecting a well-chosen\nintermediate timestep, identified through an instrument classifier, yields a\nbalance between preserving the original piece's content and achieving the\ndesired timbre. Our method does not require additional training of the\ntext-to-music diffusion model, nor does it compromise the generation process's\nspeed.",
            "pdf_url": "http://arxiv.org/pdf/2506.15530v1",
            "published": "2025-06-18 15:01:25+00:00",
            "updated": "2025-06-18 15:01:25+00:00"
        }
    ]
}