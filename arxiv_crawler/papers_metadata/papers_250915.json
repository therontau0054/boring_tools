{
    "Physics": [
        {
            "title": "Gravitational Wave Signature and the Nature of Neutrino Masses: Majorana, Dirac, or Pseudo-Dirac?",
            "authors": "Sudip Jana, Sudip Manna, Vishnu P. K",
            "summary": "The fermionic nature of neutrinos and the origin of their tiny masses remain\nunresolved issues in particle physics, intrinsically connected to lepton number\nsymmetry-conserved for Dirac, violated for Majorana, and effectively\npseudo-Dirac when global symmetries invoked for conservation are broken by\nquantum gravity. We investigate whether distinctive gravitational-wave (GW)\nsignatures can illuminate the nature of neutrino masses and their underlying\nsymmetries, particularly in scenarios where Yukawa couplings are not\nunnaturally small. To this end, we consider the minimal $B-L$ gauge extension\nof the Standard Model, where quantum numbers of beyond-SM states determine the\nneutrino nature and the scale of spontaneous $B-L$ breaking governs mass\ngeneration. In this framework, we show that neutrinos yield characteristic GW\nspectra: Majorana neutrinos with high-scale breaking ($\\sim 10^{14}$ GeV)\nproduce local cosmic strings and a flat spectrum across broad frequencies,\nDirac neutrinos with low-scale breaking ($\\sim 10^{7}$ GeV) generate peaked\nspectra from first-order phase transitions, and pseudo-Dirac scenarios give\nkink-like features from domain wall annihilation.",
            "pdf_url": "http://arxiv.org/pdf/2509.10456v1",
            "published": "2025-09-12 17:59:59+00:00",
            "updated": "2025-09-12 17:59:59+00:00"
        },
        {
            "title": "New opportunities for rare charm from $Z\\to c\\bar{c}$ decays",
            "authors": "Angelo Di Canto, Tabea Hacheney, Gudrun Hiller, Dominik Stefan Mitzel, St\u00e9phane Monteil, Lars R\u00f6hrig, Dominik Suelmann",
            "summary": "We analyze the potential of rare charm decays as probes of new physics at a\nhigh-luminosity flavor facility operating at the $Z$ pole, such as the FCC-ee\nor CEPC. In particular, we identify clean null-test observables in $D^0 \\to\n\\pi^+ \\pi^- \\nu\\bar{\\nu}$ and in polarized $\\Lambda_c^+ \\to p \\ell^+ \\ell^-$\ndecays with $\\ell=e, \\mu$. Complementarity with the LHC and HL-LHC flavor\nprograms arises from the characteristic features of a Tera-$Z$ environment: the\ncapability to study missing-energy modes and charm production with significant\npolarization. We improve the theoretical description of $D^0 \\to \\pi^+ \\pi^-\n\\nu\\bar{\\nu}$ decays and work out the phenomenology of polarization-induced\nnull-test observables in $\\Lambda_c^+ \\to p \\ell^+ \\ell^-$ decays. In regions\nof dilepton mass near the $\\phi$ resonance, polarization asymmetries can reach\n$O(5 \\%)$ for muons and $O(14 \\%)$ for electrons times the $\\Lambda_c^+$\npolarization. We also point out synergies between the dineutrino and the\ndilepton modes using the SMEFT framework of heavy new physics. Using the IDEA\ndetector concept at FCC-ee, we find in simulation studies that dineutrino\nbranching fractions as low as $\\sim 2 \\times 10^{-7}$ can be probed, which\nreaches well into the parameter space of new physics, and also allows for\ndiscrimination of lepton flavor structures. Furthermore, the measurement of\nasymmetries in $\\Lambda_c^+ \\to p \\mu^+ \\mu^-$ at $O(1 \\%)$ will be possible.\nSimilar sensitivities are expected for dielectron final states, although robust\npredictions will require further dedicated studies.",
            "pdf_url": "http://arxiv.org/pdf/2509.10447v1",
            "published": "2025-09-12 17:53:36+00:00",
            "updated": "2025-09-12 17:53:36+00:00"
        },
        {
            "title": "Near-Hamiltonian dynamics and energy-like quantities of next-generation neural mass models",
            "authors": "Daniele Andrean, Morten Gram Pedersen",
            "summary": "Neural mass models describe the mean-field dynamics of populations of\nneurons. In this work we illustrate how fundamental ideas of physics, such as\nenergy and conserved quantities, can be explored for such models. We show that\ntime-rescaling renders recent next-generation neural mass models Hamiltonian in\nthe limit of a homogeneous population or strong coupling. The corresponding\nenergy-like quantity provides considerable insight into the model dynamics even\nin the case of heterogeneity, and explain for example why orbits are\nnear-ellipsoidal and predict spike amplitude during bursting dynamics. We\nillustrate how these energy considerations provide a possible link between\nneuronal population behavior and energy landscape theory, which has been used\nto analyze data from brain recordings. Our introduction of near-Hamiltonian\ndescriptions of neuronal activity could permit the application of highly\ndeveloped physics theory to get insight into brain behavior.",
            "pdf_url": "http://arxiv.org/pdf/2509.10428v1",
            "published": "2025-09-12 17:32:46+00:00",
            "updated": "2025-09-12 17:32:46+00:00"
        },
        {
            "title": "Provable avoidance of barren plateaus for GM-QAOA",
            "authors": "Boris Tsvelikhovskiy, Matthew Nuyten, Bojko N. Bakalov",
            "summary": "We analyze the dynamical Lie algebras (DLAs) associated with the Grover-mixer\nvariant of the Quantum Approximate Optimization Algorithm (GM-QAOA). When the\ninitial state is the uniform superposition of computational basis states, we\nshow that the corresponding DLA is isomorphic to either $\\mathfrak{su}_{r}\n\\oplus \\mathfrak{u}_{1}^{\\oplus 2}$ or $\\mathfrak{su}_{r} \\oplus\n\\mathfrak{u}_{1}$, where \\(r\\) denotes the number of distinct values of the\nobjective function. We also establish an analogous classification for other\nchoices of initial states and Grover-type mixers.\n  Furthermore, we prove that the DLA of GM-QAOA has the largest possible\ncommutant among all QAOA variants initialized with the same state\n$|\\xi\\rangle$, corresponding physically to the maximal set of conserved\nquantities. In addition, we derive an explicit formula for the variance of the\nGM-QAOA loss function in terms of the objective function values, and we show\nthat, for a broad class of optimization problems, GM-QAOA with sufficiently\nmany layers avoids barren plateaus.",
            "pdf_url": "http://arxiv.org/pdf/2509.10424v1",
            "published": "2025-09-12 17:25:13+00:00",
            "updated": "2025-09-12 17:25:13+00:00"
        },
        {
            "title": "Emergence of Dark Phases in Scalar Particles within the Schwarzschild-Kiselev-Letelier Spacetime",
            "authors": "B. V. Sim\u00e3o, M. L. Deglmann, C. C. Barros Jr",
            "summary": "This work focuses on the emergence of dark phases (dark energy-induced\nphases) in the radial wave function of scalar particles. We achieve this by\npresenting novel solutions to the Klein-Gordon equation in a spherically\nsymmetric spacetime, which encompasses a black hole, a quintessential fluid,\nand a cloud of strings. We determine the exact solution for the spacetime\nmetric, analyze the admissible ranges for its physical parameters, and discuss\nthe formation of the event horizon. Subsequently, we detail the solution of the\nKlein-Gordon equation and explore three distinct cases of dark phases,\ncorresponding to the quintessence state parameter $\\alpha_{Q}$ taking the\nvalues $0$, $1/2$, and $1$. Notably, the case where $\\alpha_{Q} = 1$ holds\nparticular significance due to current observational constraints on dark\nenergy.",
            "pdf_url": "http://arxiv.org/pdf/2504.20287v3",
            "published": "2025-04-28 22:01:13+00:00",
            "updated": "2025-09-12 17:04:32+00:00"
        },
        {
            "title": "Multipole Semantic Attention: A Fast Approximation of Softmax Attention for Pretraining",
            "authors": "Rupert Mitchell, Kristian Kersting",
            "summary": "We present Multipole Semantic Attention (MuSe), an efficient approximation of\nsoftmax attention that combines semantic clustering with multipole expansions\nfrom computational physics. Our method addresses the quadratic computational\ncomplexity of transformers in the context length by clustering queries and keys\nseparately in their learned representation spaces, enabling a hierarchical\ntwo-stage attention mechanism. Unlike prior clustering approaches that group\nonly keys or use unified clustering, we maintain separate clusterings that\nrespect attention's asymmetric treatment of these spaces. We augment\ncentroid-based (monopole) approximations with dipole corrections that capture\ndirectional variance within clusters, preserving richer information during\ntraining. The method operates as a drop-in replacement for standard attention,\nrequiring only hyperparameter specification without architectural\nmodifications. Our approach achieves $\\mathcal{O}(NCD)$ complexity for acausal\nattention with $C$ clusters and $\\mathcal{O}(NCD \\log N)$ for causal attention.\nOn isolated attention layers, we demonstrate $3\\times$ speedup over CUDNN Flash\nAttention at 8k context length, with relative squared errors below 20%. For\ncausal attention, we develop a hierarchical block decomposition that combines\nexact local computation with efficient long-range approximation. In end-to-end\npretraining of a 30M parameter model on book-length texts with 16k context, we\nachieve 12.2% runtime reduction with only 0.36% loss degradation, establishing\nthe viability of multipole approximations for efficient transformer\npretraining.",
            "pdf_url": "http://arxiv.org/pdf/2509.10406v1",
            "published": "2025-09-12 16:58:17+00:00",
            "updated": "2025-09-12 16:58:17+00:00"
        },
        {
            "title": "Is the $w_0w_a$CDM cosmological parameterization evidence for dark energy dynamics partially caused by the excess smoothing of Planck CMB anisotropy data?",
            "authors": "Chan-Gyung Park, Javier de Cruz Perez, Bharat Ratra",
            "summary": "We study the performance of the spatially-flat dynamical dark energy (DE)\n$w_0w_a$CDM parameterization, with redshift-dependent DE fluid equation of\nstate parameter $w(z) = w_0 + w_a z/(1+z)$, with and without a varying CMB\nlensing consistency parameter $A_L$, against Planck cosmic microwave background\n(CMB) data (P18 and lensing) and a combination of non-CMB data composed of\nbaryonic acoustic oscillation (BAO) measurements that do not include DESI BAO\ndata, Pantheon+ type Ia supernovae (SNIa) observations, Hubble parameter\n[$H(z)$] measurements, and growth factor ($f\\sigma_8$) data points. From our\nmost restrictive data set, P18+lensing+non-CMB, for the $w_0w_a$CDM+$A_L$\nparameterization, we obtain $w_0=-0.879\\pm 0.060$, $w_a=-0.39^{+0.26}_{-0.22}$,\nthe asymptotic limit $w(z\\to\\infty) = w_0+w_a=-1.27^{+0.20}_{-0.17}$, and\n$A_L=1.078^{+0.036}_{-0.040}$ (all $1\\sigma$ errors). This joint analysis of\nCMB and non-CMB data favors DE dynamics over a cosmological constant at $\\sim\n1\\sigma$ and $A_L>1$ at $\\sim 2\\sigma$, i.e. more smoothing of the Planck CMB\nanisotropy data than is predicted by the best-fit model. For the $w_0w_a$CDM\nparameterization with $A_L=1$ the evidence in favor of DE dynamics is larger,\n$\\sim 2\\sigma$, suggesting that at least part of the evidence for DE dynamics\ncomes from the excess smoothing of the Planck CMB anisotropy data. For the\n$w_0w_a$CDM parameterization with $A_L=1$, there is a difference of $2.8\\sigma$\nbetween P18 and non-CMB cosmological parameter constraints and $2.7\\sigma$\nbetween P18+lensing and non-CMB constraints. When $A_L$ is allowed to vary\nthese tensions reduced to $1.9\\sigma$ and $2.1\\sigma$ respectively. Our\nP18+lensing+non-CMB data compilation positively favors the $w_0w_a$CDM\nparameterization without and with a varying $A_L$ parameter over the flat\n$\\Lambda$CDM model, and $w_0w_a$CDM+$A_L$ is also positively favored over\n$w_0w_a$CDM.",
            "pdf_url": "http://arxiv.org/pdf/2410.13627v3",
            "published": "2024-10-04 13:12:49+00:00",
            "updated": "2025-09-12 16:30:40+00:00"
        },
        {
            "title": "Sparse modeling study of extracting charmonium spectral functions from lattice QCD at finite temperature",
            "authors": "Junichi Takahashi, Hiroshi Ohno, Akio Tomiya",
            "summary": "We present spectral functions extracted from Euclidean-time correlation\nfunctions using sparse modeling (SpM). SpM solves inverse problems by\nconsidering only the sparsity of the target solution. To assess the\napplicability of the method, we first test it with mock data that mimic\ncharmonium correlation functions. We show that, while resonance peaks in the\nspectral functions can be reconstructed using this method, it is difficult to\nreconstruct transport peaks without further assumptions beyond SpM. Then we\nextract charmonium spectral functions from correlation functions obtained from\nlattice QCD at temperatures below and above the critical temperature. We show\nthat this method yields results qualitatively consistent with those obtained\nusing the maximum entropy method, although the transport peak is not obtained\nclearly. This suggests that the results solely from the assumption of the\nsparse solution can partially reflect underlying physics.",
            "pdf_url": "http://arxiv.org/pdf/2509.10386v1",
            "published": "2025-09-12 16:22:38+00:00",
            "updated": "2025-09-12 16:22:38+00:00"
        },
        {
            "title": "Physics-informed sensor coverage through structure preserving machine learning",
            "authors": "Benjamin David Shaffer, Brooks Kinch, Joseph Klobusicky, M. Ani Hsieh, Nathaniel Trask",
            "summary": "We present a machine learning framework for adaptive source localization in\nwhich agents use a structure-preserving digital twin of a coupled\nhydrodynamic-transport system for real-time trajectory planning and data\nassimilation. The twin is constructed with conditional neural Whitney forms\n(CNWF), coupling the numerical guarantees of finite element exterior calculus\n(FEEC) with transformer-based operator learning. The resulting model preserves\ndiscrete conservation, and adapts in real time to streaming sensor data. It\nemploys a conditional attention mechanism to identify: a reduced Whitney-form\nbasis; reduced integral balance equations; and a source field, each compatible\nwith given sensor measurements. The induced reduced-order environmental model\nretains the stability and consistency of standard finite-element simulation,\nyielding a physically realizable, regular mapping from sensor data to the\nsource field. We propose a staggered scheme that alternates between evaluating\nthe digital twin and applying Lloyd's algorithm to guide sensor placement, with\nanalysis providing conditions for monotone improvement of a coverage\nfunctional. Using the predicted source field as an importance function within\nan optimal-recovery scheme, we demonstrate recovery of point sources under\ncontinuity assumptions, highlighting the role of regularity as a sufficient\ncondition for localization. Experimental comparisons with physics-agnostic\ntransformer architectures show improved accuracy in complex geometries when\nphysical constraints are enforced, indicating that structure preservation\nprovides an effective inductive bias for source identification.",
            "pdf_url": "http://arxiv.org/pdf/2509.10363v1",
            "published": "2025-09-12 15:54:13+00:00",
            "updated": "2025-09-12 15:54:13+00:00"
        },
        {
            "title": "First operation of the FAMU experiment at the RIKEN-RAL high intensity muon beam facility",
            "authors": "FAMU Collaboration, A. Adamczak, D. Bakalov, G. Baldazzi, M. Baruzzo, R. Benocci, R. Bertoni, M. Bonesini, S. Capra, D. Cirrincione, M. Clemenza, L. Colace, M. Danailov, P. Danev, A. De Bari, C. De Vecchi, D. Di Ferdinando, E. Fasci, R. Gaigher, L. Gianfrani, A. D. Hillier, K. Ishida, J. S. Lord, A. Menegolli, E. Mocchiutti, S. Monzani, L. Moretti, G. Morgante, C. Pizzolotto, A. Pullia, M. Pullia, R. Ramponi, H. E. Roman, M. Rossella, R. Rossini, A. Sbrizzi, M. Stoilov, J. J. Suarez-Vargas, G. Toci, L. Tortora, E. Vallazza, K. Yokoyama, A. Vacchi",
            "summary": "The FAMU experiment, supported and funded by the Italian Institute of Nuclear\nPhysics (INFN) and by the Science and Technology Facilities Council (STFC),\naims to perform the first measurement of the ground-state hyperfine splitting\n(1S-hfs) of muonic hydrogen ($\\mu H$). This quantity is highly sensitive to the\nproton's Zemach radius $R_Z$. An experimental determination of $R_Z$ provides\nsignificant constraints on the parametrization of the proton form factors as\nwell as on theoretical models describing the proton's electromagnetic\nstructure. Following years of technological and methodological development, the\nFAMU experiment began operations in 2023 at Port 1 of the RIKEN-RAL muon beam\nline at the ISIS Neutron and Muon Source facility (Didcot, UK). In this paper,\nwe first describe the unique detection technique employed by FAMU to determine\nthe 1S-hfs of muonic hydrogen, followed by a detailed presentation of the final\nexperimental layout. Finally, we report the first outcome from the 2023\ncommissioning run and from the initial physics runs performed in 2023 and 2024.",
            "pdf_url": "http://arxiv.org/pdf/2509.10350v1",
            "published": "2025-09-12 15:37:58+00:00",
            "updated": "2025-09-12 15:37:58+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Inpainting-Guided Policy Optimization for Diffusion Large Language Models",
            "authors": "Siyan Zhao, Mengchen Liu, Jing Huang, Miao Liu, Chenyu Wang, Bo Liu, Yuandong Tian, Guan Pang, Sean Bell, Aditya Grover, Feiyu Chen",
            "summary": "Masked diffusion large language models (dLLMs) are emerging as promising\nalternatives to autoregressive LLMs, offering competitive performance while\nsupporting unique generation capabilities such as inpainting. We explore how\ninpainting can inform RL algorithm design for dLLMs. Aligning LLMs with\nreinforcement learning faces an exploration challenge: sparse reward signals\nand sample waste when models fail to discover correct solutions. While this\ninefficiency affects LLMs broadly, dLLMs offer a distinctive opportunity--their\ninpainting ability can guide exploration. We introduce IGPO (Inpainting Guided\nPolicy Optimization), an RL framework that strategically inserts partial\nground-truth reasoning traces during online sampling. Unlike providing full\nsolutions, inpainting steers exploration toward promising trajectory spaces\nwhile preserving self-generated reasoning, bridging supervised fine-tuning and\nreinforcement learning. We apply IGPO to group-based optimization methods such\nas GRPO, where exploration failures cause zero advantages and gradients. IGPO\nrestores meaningful gradients while improving sample efficiency. We also\npropose supervised fine-tuning on synthetically rewritten concise traces that\nbetter align with dLLM generation patterns. With additional techniques\nincluding entropy-based filtering, our training recipe yields substantial gains\nacross three mathematical benchmarks--GSM8K, Math500, and AMC--achieving new\nstate-of-the-art results for full-attention masked dLLMs.",
            "pdf_url": "http://arxiv.org/pdf/2509.10396v1",
            "published": "2025-09-12 16:44:31+00:00",
            "updated": "2025-09-12 16:44:31+00:00"
        },
        {
            "title": "The Precautionary Principle and the Innovation Principle: Incompatible Guides for AI Innovation Governance?",
            "authors": "Kim Kaivanto",
            "summary": "In policy debates concerning the governance and regulation of Artificial\nIntelligence (AI), both the Precautionary Principle (PP) and the Innovation\nPrinciple (IP) are advocated by their respective interest groups. Do these\nprinciples offer wholly incompatible and contradictory guidance? Does one\nnecessarily negate the other? I argue here that provided attention is\nrestricted to weak-form PP and IP, the answer to both of these questions is\n\"No.\" The essence of these weak formulations is the requirement to fully\naccount for type-I error costs arising from erroneously preventing the\ninnovation's diffusion through society (i.e. mistaken regulatory red-lighting)\nas well as the type-II error costs arising from erroneously allowing the\ninnovation to diffuse through society (i.e. mistaken regulatory\ngreen-lighting). Within the Signal Detection Theory (SDT) model developed here,\nweak-PP red-light (weak-IP green-light) determinations are optimal for\nsufficiently small (large) ratios of expected type-I to type-II error costs.\nFor intermediate expected cost ratios, an amber-light 'wait-and-monitor' policy\nis optimal. Regulatory sandbox instruments allow AI testing and experimentation\nto take place within a structured environment of limited duration and societal\nscale, whereby the expected cost ratio falls within the 'wait-and-monitor'\nrange. Through sandboxing regulators and innovating firms learn more about the\nexpected cost ratio, and what respective adaptations -- of regulation, of\ntechnical solution, of business model, or combination thereof, if any -- are\nneeded to keep the ratio out of the weak-PP red-light zone. Nevertheless AI\nfoundation models are ill-suited for regulatory sandboxing as their\ngeneral-purpose nature precludes credible identification of misclassification\ncosts.",
            "pdf_url": "http://arxiv.org/pdf/2505.02846v2",
            "published": "2025-05-01 17:48:18+00:00",
            "updated": "2025-09-12 16:39:39+00:00"
        },
        {
            "title": "P3D: Scalable Neural Surrogates for High-Resolution 3D Physics Simulations with Global Context",
            "authors": "Benjamin Holzschuh, Georg Kohl, Florian Redinger, Nils Thuerey",
            "summary": "We present a scalable framework for learning deterministic and probabilistic\nneural surrogates for high-resolution 3D physics simulations. We introduce a\nhybrid CNN-Transformer backbone architecture targeted for 3D physics\nsimulations, which significantly outperforms existing architectures in terms of\nspeed and accuracy. Our proposed network can be pretrained on small patches of\nthe simulation domain, which can be fused to obtain a global solution,\noptionally guided via a fast and scalable sequence-to-sequence model to include\nlong-range dependencies. This setup allows for training large-scale models with\nreduced memory and compute requirements for high-resolution datasets. We\nevaluate our backbone architecture against a large set of baseline methods with\nthe objective to simultaneously learn the dynamics of 14 different types of\nPDEs in 3D. We demonstrate how to scale our model to high-resolution isotropic\nturbulence with spatial resolutions of up to $512^3$. Finally, we demonstrate\nthe versatility of our network by training it as a diffusion model to produce\nprobabilistic samples of highly turbulent 3D channel flows across varying\nReynolds numbers, accurately capturing the underlying flow statistics.",
            "pdf_url": "http://arxiv.org/pdf/2509.10186v1",
            "published": "2025-09-12 12:26:06+00:00",
            "updated": "2025-09-12 12:26:06+00:00"
        },
        {
            "title": "Diffusion Buffer: Online Diffusion-based Speech Enhancement with Sub-Second Latency",
            "authors": "Bunlong Lay, Rostislav Makarov, Timo Gerkmann",
            "summary": "Diffusion models are a class of generative models that have been recently\nused for speech enhancement with remarkable success but are computationally\nexpensive at inference time. Therefore, these models are impractical for\nprocessing streaming data in real-time. In this work, we adapt a sliding window\ndiffusion framework to the speech enhancement task. Our approach progressively\ncorrupts speech signals through time, assigning more noise to frames close to\nthe present in a buffer. This approach outputs denoised frames with a delay\nproportional to the chosen buffer size, enabling a trade-off between\nperformance and latency. Empirical results demonstrate that our method\noutperforms standard diffusion models and runs efficiently on a GPU, achieving\nan input-output latency in the order of 0.3 to 1 seconds. This marks the first\npractical diffusion-based solution for online speech enhancement.",
            "pdf_url": "http://arxiv.org/pdf/2506.02908v2",
            "published": "2025-06-03 14:14:28+00:00",
            "updated": "2025-09-12 11:49:57+00:00"
        },
        {
            "title": "Realism Control One-step Diffusion for Real-World Image Super-Resolution",
            "authors": "Zongliang Wu, Siming Zheng, Peng-Tao Jiang, Xin Yuan",
            "summary": "Pre-trained diffusion models have shown great potential in real-world image\nsuper-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.\nWhile one-step diffusion (OSD) methods significantly improve efficiency\ncompared to traditional multi-step approaches, they still have limitations in\nbalancing fidelity and realism across diverse scenarios. Since the OSDs for SR\nare usually trained or distilled by a single timestep, they lack flexible\ncontrol mechanisms to adaptively prioritize these competing objectives, which\nare inherently manageable in multi-step methods through adjusting sampling\nsteps. To address this challenge, we propose a Realism Controlled One-step\nDiffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping\nstrategy that enables explicit control over fidelity-realism trade-offs during\nthe noise prediction phase with minimal training paradigm modifications and\noriginal training data. A degradation-aware sampling strategy is also\nintroduced to align distillation regularization with the grouping strategy and\nenhance the controlling of trade-offs. Moreover, a visual prompt injection\nmodule is used to replace conventional text prompts with degradation-aware\nvisual tokens, enhancing both restoration accuracy and semantic consistency.\nOur method achieves superior fidelity and perceptual quality while maintaining\ncomputational efficiency. Extensive experiments demonstrate that RCOD\noutperforms state-of-the-art OSD methods in both quantitative metrics and\nvisual qualities, with flexible realism control capabilities in the inference\nstage. The code will be released.",
            "pdf_url": "http://arxiv.org/pdf/2509.10122v1",
            "published": "2025-09-12 10:32:04+00:00",
            "updated": "2025-09-12 10:32:04+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs",
            "authors": "Andy Zhu, Yingjun Du",
            "summary": "Question answering (QA) plays a central role in financial education, yet\nexisting large language model (LLM) approaches often fail to capture the\nnuanced and specialized reasoning required for financial problem-solving. The\nfinancial domain demands multistep quantitative reasoning, familiarity with\ndomain-specific terminology, and comprehension of real-world scenarios. We\npresent a multi-agent framework that leverages role-based prompting to enhance\nperformance on domain-specific QA. Our framework comprises a Base Generator, an\nEvidence Retriever, and an Expert Reviewer agent that work in a single-pass\niteration to produce a refined answer. We evaluated our framework on a set of\n3,532 expert-designed finance education questions from Study.com, an online\nlearning platform. We leverage retrieval-augmented generation (RAG) for\ncontextual evidence from 6 finance textbooks and prompting strategies for a\ndomain-expert reviewer. Our experiments indicate that critique-based refinement\nimproves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,\nwith the highest performance from Gemini-2.0-Flash. Furthermore, our method\nenables GPT-4o-mini to achieve performance comparable to the finance-tuned\nFinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to\nenhancing financial QA and offer insights for further research in multi-agent\nfinancial LLM systems.",
            "pdf_url": "http://arxiv.org/pdf/2509.09727v1",
            "published": "2025-09-10 09:40:18+00:00",
            "updated": "2025-09-10 09:40:18+00:00"
        }
    ]
}