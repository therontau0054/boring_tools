{
    "Physics": [
        {
            "title": "A Localized Burst of Relativistic Electrons in Earth's Plasma Sheet: Low- and High-Altitude Signatures During a Substorm",
            "authors": "M. Shumko, D. L. Turner, A. Y. Ukhorskiy, I. J. Cohen, G. K. Stephens, A. Artemyev, X. Zhang, C. Wilkins, E. Tsai, C. Gabrielse, S. Raptis, M. Sitnov, V. Angelopoulos",
            "summary": "Earth's magnetotail, and the plasma sheet embedded in it, is a highly dynamic\nregion that is coupled to both the solar wind and to the inner magnetosphere.\nAs a consequence of this coupling, the plasma sheet undergoes explosive energy\nreleases in the form of substorms. One consequence of this energy release is\nheating of thermal electrons and acceleration of energetic (non-thermal)\nelectrons. The upper-energy limit as well as the spatial scale size of the\nelectron acceleration regions remain mysteries in magnetotail physics because\ncurrent missions can effectively only offer us a single-point glimpse into the\nnumerous magnetotail phenomena ranging from electron- to global-scales. These\nenergetic electrons can provide a significant source of seed electrons for the\nVan Allen Radiation belts. Here we use a unique approach to study relativistic\nplasma sheet electron acceleration. We combine high-altitude Magnetospheric\nMultiscale (MMS) mission observations with low-altitude Electron Losses and\nFields Investigation (ELFIN) observations, to quantify the upper-energy extent\nand radial scale of a burst of plasma sheet electrons that mapped to 33 Earth\nradii. The plasma sheet locally accelerated an intense mesoscale burst of 3 MeV\nelectrons -- far higher and more intense than the outer Van Allen radiation\nbelt -- and scattered them into the atmospheric loss cone. High-altitude\nobservations Earthward of the burst at 17 Earth radii showed only the usual\nsubstorm activity signatures -- demonstrating that this burst was 1) intense,\n2) localized to the far magnetotail, and 3) likely accelerated by a very\nefficient and rapid mechanism.",
            "pdf_url": "http://arxiv.org/pdf/2410.16412v2",
            "published": "2024-10-21 18:28:38+00:00",
            "updated": "2024-11-18 18:48:01+00:00"
        },
        {
            "title": "Logical computation demonstrated with a neutral atom quantum processor",
            "authors": "Ben W. Reichardt, Adam Paetznick, David Aasen, Ivan Basov, Juan M. Bello-Rivas, Parsa Bonderson, Rui Chao, Wim van Dam, Matthew B. Hastings, Andres Paz, Marcus P. da Silva, Aarthi Sundaram, Krysta M. Svore, Alexander Vaschillo, Zhenghan Wang, Matt Zanner, William B. Cairncross, Cheng-An Chen, Daniel Crow, Hyosub Kim, Jonathan M. Kindem, Jonathan King, Michael McDonald, Matthew A. Norcia, Albert Ryou, Mark Stone, Laura Wadleigh, Katrina Barnes, Peter Battaglino, Thomas C. Bohdanowicz, Graham Booth, Andrew Brown, Mark O. Brown, Kayleigh Cassella, Robin Coxe, Jeffrey M. Epstein, Max Feldkamp, Christopher Griger, Eli Halperin, Andre Heinz, Frederic Hummel, Matthew Jaffe, Antonia M. W. Jones, Eliot Kapit, Krish Kotru, Joseph Lauigan, Ming Li, Jan Marjanovic, Eli Megidish, Matthew Meredith, Ryan Morshead, Juan A. Muniz, Sandeep Narayanaswami, Ciro Nishiguchi, Timothy Paule, Kelly A. Pawlak, Kristen L. Pudenz, David Rodr\u00edguez P\u00e9rez, Jon Simon, Aaron Smull, Daniel Stack, Miroslav Urbanek, Ren\u00e9 J. M. van de Veerdonk, Zachary Vendeiro, Robert T. Weverka, Thomas Wilkason, Tsung-Yao Wu, Xin Xie, Evan Zalys-Geller, Xiaogang Zhang, Benjamin J. Bloom",
            "summary": "Transitioning from quantum computation on physical qubits to quantum\ncomputation on encoded, logical qubits can improve the error rate of\noperations, and will be essential for realizing valuable quantum computational\nadvantages. Using a neutral atom quantum processor with 256 qubits, each an\nindividual Ytterbium atom, we demonstrate the entanglement of 24 logical qubits\nusing the distance-two [[4,2,2]] code, simultaneously detecting errors and\ncorrecting for lost qubits. We also implement the Bernstein-Vazirani algorithm\nwith up to 28 logical qubits encoded in the [[4,1,2]] code, showing\nbetter-than-physical error rates. We demonstrate fault-tolerant quantum\ncomputation in our approach, guided by the proposal of Gottesman (2016), by\nperforming repeated loss correction for both structured and random circuits\nencoded in the [[4,2,2]] code. Finally, since distance-two codes can correct\nqubit loss, but not other errors, we show repeated loss and error correction\nusing the distance-three [[9,1,3]] Bacon-Shor code. These results begin to\nclear a path for achieving scientific quantum advantage with a programmable\nneutral atom quantum processor.",
            "pdf_url": "http://arxiv.org/pdf/2411.11822v1",
            "published": "2024-11-18 18:39:23+00:00",
            "updated": "2024-11-18 18:39:23+00:00"
        },
        {
            "title": "Angular analysis of the B$^0$ $\\to$ K$^*$(892)$^0\u03bc^+\u03bc^-$ decay in proton-proton collisions at $\\sqrt{s}$ = 13 TeV",
            "authors": "CMS Collaboration",
            "summary": "A full set of optimized observables is measured in an angular analysis of the\ndecay B$^0$ $\\to$ K$^*$(892)$^0\\mu^+\\mu^-$ using a sample of proton-proton\ncollisions at $\\sqrt{s}$ = 13 TeV, collected with the CMS detector at the LHC,\ncorresponding to an integrated luminosity of 140 fb$^{-1}$. The analysis is\nperformed in six bins of the squared invariant mass of the dimuon system,\n$q^2$, over the range 1.1 $\\lt$ $q^2$ $\\lt$ 16 GeV$^2$. The results are among\nthe most precise experimental measurements of the angular observables for this\ndecay and are compared to a variety of predictions based on the standard model.",
            "pdf_url": "http://arxiv.org/pdf/2411.11820v1",
            "published": "2024-11-18 18:38:52+00:00",
            "updated": "2024-11-18 18:38:52+00:00"
        },
        {
            "title": "In-Silico Analysis of Curve Fitting in Angiographic Parametric Imaging in Intracranial Aneurysms",
            "authors": "Parmita Mondal, Allison Shields, Mohammad Mahdi Shiraz Bhurwani, Kyle A Williams, Ciprian N Ionita",
            "summary": "In Angiographic Parametric Imaging (API), accurate estimation of parameters\nfrom Time Density Curves (TDC) is crucial. However, these estimations are often\nmarred by errors arising from factors such as patient motion, procedural\npreferences, image noise, and injection variability. While fitting methods like\ngamma-variate fitting offer a solution to recover incomplete or corrupted TDC\ndata, they might also introduce unforeseen biases. This study investigates the\ntrade-offs and benefits of employing gamma-variate fitting on virtual\nangiograms to enhance the precision of API biomarkers. Utilizing Computational\nFluid Dynamics (CFD) in patient specific 3D geometries, we generated a series\nof high-definition virtual angiograms at distinct inlet velocities: 0.25m/s,\n0.35m/s, and 0.45m/s. These velocities were investigated across injection\ndurations ranging from 0.5s to 2.0s. From these angiograms, TDCs for aneurysms\nand their corresponding inlets were constructed. To emulate typical clinical\nchallenges, we introduced noise, simulated patient motion, and generated\ntemporally incomplete data sets. These modified TDCs underwent gamma-variate\nfitting. We quantified both the original and fitted TDC curves using standard\nangiography metrics such as Cross-Correlation (Cor), Time to Peak (TTP), Mean\nTransit Time (MTT), Peak Height (PH), Area Under the Curve (AUC), and Maximum\nGradient (Max-Gr) for a comprehensive comparison. TDCs enhanced by\ngamma-variate fitting exhibited a robust correlation with vascular flow\ndynamics. Our results affirm that gamma-variate fitting can adeptly restore\nTDCs from fragmentary sequences, elevating the precision of derived API\nparameters.",
            "pdf_url": "http://arxiv.org/pdf/2411.05287v2",
            "published": "2024-11-08 02:40:09+00:00",
            "updated": "2024-11-18 18:17:05+00:00"
        },
        {
            "title": "KAN/MultKAN with Physics-Informed Spline fitting (KAN-PISF) for ordinary/partial differential equation discovery of nonlinear dynamic systems",
            "authors": "Ashish Pal, Satish Nagarajaiah",
            "summary": "Machine learning for scientific discovery is increasingly becoming popular\nbecause of its ability to extract and recognize the nonlinear characteristics\nfrom the data. The black-box nature of deep learning methods poses difficulties\nin interpreting the identified model. There is a dire need to interpret the\nmachine learning models to develop a physical understanding of dynamic systems.\nAn interpretable form of neural network called Kolmogorov-Arnold networks (KAN)\nor Multiplicative KAN (MultKAN) offers critical features that help recognize\nthe nonlinearities in the governing ordinary/partial differential equations\n(ODE/PDE) of various dynamic systems and find their equation structures. In\nthis study, an equation discovery framework is proposed that includes i)\nsequentially regularized derivatives for denoising (SRDD) algorithm to denoise\nthe measure data to obtain accurate derivatives, ii) KAN to identify the\nequation structure and suggest relevant nonlinear functions that are used to\ncreate a small overcomplete library of functions, and iii) physics-informed\nspline fitting (PISF) algorithm to filter the excess functions from the library\nand converge to the correct equation. The framework was tested on the forced\nDuffing oscillator, Van der Pol oscillator (stiff ODE), Burger's equation, and\nBouc-Wen model (coupled ODE). The proposed method converged to the true\nequation for the first three systems. It provided an approximate model for the\nBouc-Wen model that could acceptably capture the hysteresis response. Using KAN\nmaintains low complexity, which helps the user interpret the results throughout\nthe process and avoid the black-box-type nature of machine learning methods.",
            "pdf_url": "http://arxiv.org/pdf/2411.11801v1",
            "published": "2024-11-18 18:14:51+00:00",
            "updated": "2024-11-18 18:14:51+00:00"
        },
        {
            "title": "A Multi-Component, Multi-Physics Computational Model for Solving Coupled Cardiac Electromechanics and Vascular Haemodynamics",
            "authors": "Sharp C. Y. Lo, Alberto Zingaro, Jon W. S. McCullough, Xiao Xue, Mariano V\u00e1zquez, Peter V. Coveney",
            "summary": "The circulatory system, comprising the heart and blood vessels, is vital for\nnutrient transport, waste removal, and homeostasis. Traditional computational\nmodels often isolate individual biophysical processes, such as cardiac\nelectromechanics and blood flow dynamics, failing to capture the system's\nintegrated nature. This paper presents an innovative approach that couples a 3D\nelectromechanical model of the heart with a 3D fluid mechanics model of\nvascular blood flow. Our file-based partitioned coupling scheme allows these\nmodels to run independently while sharing essential data through intermediate\nfiles. We validate this approach using two solvers: one for cardiac\nelectromechanics and the other for vascular blood flow. Developed by separate\nresearch groups, these solvers emphasise different dynamical scales and utilise\ndistinct discretisation schemes. Numerical simulations using idealised and\nrealistic anatomies show that the implemented coupling scheme is reliable and\nrequires minimal additional computation time relative to advancing individual\ntime steps in the heart and blood flow models. Notably, the coupled model\npredicts muscle displacement differently than the standalone heart model,\nhighlighting the influence of detailed vascular blood flow on cardiac function.\nThis study presents a paradigm case of how to build virtual human models and\ndigital twins by productive collaboration between teams with complementary\nexpertise.",
            "pdf_url": "http://arxiv.org/pdf/2411.11797v1",
            "published": "2024-11-18 18:10:37+00:00",
            "updated": "2024-11-18 18:10:37+00:00"
        },
        {
            "title": "Lorentz covariant physical Brownian motion: Classical and quantum",
            "authors": "Henryk Gzyl",
            "summary": "In this work, we re-examine the Goldstein-Ka\\c{c} velocity switching model\nfrom two points of view. On the one hand, we prove that the forward and\nbackward Chapman-Kolmogorov equations of the stochastic process are Lorentz\ncovariant when the trajectories are parameterized by their proper time. On the\nother hand, to recast the model as a quantum random evolution, we consider\nrestating the Goldstein-Ka\\c{c} model as a Hamiltonian system, which can then\nbe quantized using the standard correspondence rules. It turns out that the\ndensity for the random quantum evolution satisfies a Chapman-Kolmogorov\nequation similar to that of the classical case, and therefore, it is also\nLorentz covariant. We compute the average quantum variance. To finish, we\nverify that the quantum model is also consistent with special relativity and\nthat transitions outside the light cone, that is, transitions between states\nwith disjoint supports in space-time, cannot occur.",
            "pdf_url": "http://arxiv.org/pdf/2407.08905v2",
            "published": "2024-07-12 00:49:36+00:00",
            "updated": "2024-11-18 18:02:42+00:00"
        },
        {
            "title": "A Puzzle About General Covariance and Gauge",
            "authors": "Eleanor March, James Owen Weatherall",
            "summary": "We consider two simple criteria for when a physical theory should be said to\nbe \"generally covariant\", and we argue that these criteria are not met by\nYang-Mills theory, even on geometric formulations of that theory. The reason,\nwe show, is that the bundles encountered in Yang-Mills theory are not natural\nbundles; instead, they are gauge-natural. We then show how these observations\nrelate to previous arguments about the significance of solder forms in\nassessing disanalogies between general relativity and Yang-Mills theory. We\nconclude by suggesting that general covariance is really about functoriality.",
            "pdf_url": "http://arxiv.org/pdf/2405.03906v2",
            "published": "2024-05-06 23:43:37+00:00",
            "updated": "2024-11-18 18:02:26+00:00"
        },
        {
            "title": "Bounds on new neutrino interactions from the first CE$\u03bd$NS data at direct detection experiments",
            "authors": "Valentina De Romeri, Dimitrios K. Papoulias, Christoph A. Ternes",
            "summary": "Recently, two dark matter direct detection experiments have announced the\nfirst indications of nuclear recoils from solar $^8$B neutrinos via coherent\nelastic neutrino-nucleus scattering (CE$\\nu$NS) with xenon nuclei. These\nresults constitute a turning point, not only for dark matter searches that are\nnow entering the \\textit{neutrino fog}, but they also bring out new\nopportunities to exploit dark matter facilities as neutrino detectors. We\ninvestigate the implications of recent data from the PandaX-4T and XENONnT\nexperiments on both Standard Model physics and new neutrino interactions. We\nfirst extract information on the weak mixing angle at low momentum transfer.\nThen, following a phenomenological approach, we consider Lorentz-invariant\ninteractions (scalar, vector, axial-vector, and tensor) between neutrinos,\nquarks and charged leptons. Furthermore, we study the $U(1)_\\mathrm{B-L}$\nscenario as a concrete example of a new anomaly-free vector interaction. We\nfind that despite the low statistics of these first experimental results, the\ninferred bounds are in some cases already competitive. For the scope of this\nwork we also compute new bounds on some of the interactions using CE$\\nu$NS\ndata from COHERENT and electron recoil data from XENONnT, LUX-ZEPLIN,\nPandaX-4T, and TEXONO. It seems clear that while direct detection experiments\ncontinue to take data, more precise measurements will be available, thus\nallowing to test new neutrino interactions at the same level or even improving\nover dedicated neutrino facilities.",
            "pdf_url": "http://arxiv.org/pdf/2411.11749v1",
            "published": "2024-11-18 17:25:22+00:00",
            "updated": "2024-11-18 17:25:22+00:00"
        },
        {
            "title": "Lattice calculation of the $\u03c0^0$, $\u03b7$ and $\u03b7^{\\prime}$ transition form factors and the hadronic light-by-light contribution to the muon $g-2$",
            "authors": "Antoine G\u00e9rardin, Willem E. A. Verplanke, Gen Wang, Zoltan Fodor, Jana N. Guenther, Laurent Lellouch, Kalman K. Szabo, Lukas Varnhorst",
            "summary": "In this paper we present a first ab-initio calculation of the $\\pi^0$, $\\eta$\nand $\\eta^{\\prime}$ transition form factors performed with physical light-quark\nmasses. We provide a complete parametrization of the form factors that includes\nboth single and double-virtual kinematics. Our results are compared with\nexperimental measurements of the form factors in the space-like region and with\nthe measured two-photon decay widths. In a second step, our parametrizations of\nthe transition form factors are used to compute the dominant pseudoscalar-pole\ncontributions to the hadronic light-by-light scattering in the muon $g-2$. Our\nfinal result reads $a_{\\mu}^{\\rm hlbl, ps-pole} = (85.1 \\pm 5.2) \\times\n10^{-11}$. Although the pion-pole is dominant, we confirm that, together, the\n$\\eta$ and $\\eta^{\\prime}$ provide roughly half of its contribution.",
            "pdf_url": "http://arxiv.org/pdf/2305.04570v2",
            "published": "2023-05-08 09:27:45+00:00",
            "updated": "2024-11-18 16:55:10+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure",
            "authors": "Xiang Li, Yixiang Dai, Qing Qu",
            "summary": "In this work, we study the generalizability of diffusion models by looking\ninto the hidden properties of the learned score functions, which are\nessentially a series of deep denoisers trained on various noise levels. We\nobserve that as diffusion models transition from memorization to\ngeneralization, their corresponding nonlinear diffusion denoisers exhibit\nincreasing linearity. This discovery leads us to investigate the linear\ncounterparts of the nonlinear diffusion models, which are a series of linear\nmodels trained to match the function mappings of the nonlinear diffusion\ndenoisers. Surprisingly, these linear denoisers are approximately the optimal\ndenoisers for a multivariate Gaussian distribution characterized by the\nempirical mean and covariance of the training dataset. This finding implies\nthat diffusion models have the inductive bias towards capturing and utilizing\nthe Gaussian structure (covariance information) of the training dataset for\ndata generation. We empirically demonstrate that this inductive bias is a\nunique property of diffusion models in the generalization regime, which becomes\nincreasingly evident when the model's capacity is relatively small compared to\nthe training dataset size. In the case that the model is highly\noverparameterized, this inductive bias emerges during the initial training\nphases before the model fully memorizes its training data. Our study provides\ncrucial insights into understanding the notable strong generalization\nphenomenon recently observed in real-world diffusion models.",
            "pdf_url": "http://arxiv.org/pdf/2410.24060v3",
            "published": "2024-10-31 15:57:04+00:00",
            "updated": "2024-11-18 17:04:09+00:00"
        },
        {
            "title": "Aligning Few-Step Diffusion Models with Dense Reward Difference Learning",
            "authors": "Ziyi Zhang, Li Shen, Sen Zhang, Deheng Ye, Yong Luo, Miaojing Shi, Bo Du, Dacheng Tao",
            "summary": "Aligning diffusion models with downstream objectives is essential for their\npractical applications. However, standard alignment methods often struggle with\nstep generalization when directly applied to few-step diffusion models, leading\nto inconsistent performance across different denoising step scenarios. To\naddress this, we introduce Stepwise Diffusion Policy Optimization (SDPO), a\nnovel alignment method tailored for few-step diffusion models. Unlike prior\napproaches that rely on a single sparse reward from only the final step of each\ndenoising trajectory for trajectory-level optimization, SDPO incorporates dense\nreward feedback at every intermediate step. By learning the differences in\ndense rewards between paired samples, SDPO facilitates stepwise optimization of\nfew-step diffusion models, ensuring consistent alignment across all denoising\nsteps. To promote stable and efficient training, SDPO introduces an online\nreinforcement learning framework featuring several novel strategies designed to\neffectively exploit the stepwise granularity of dense rewards. Experimental\nresults demonstrate that SDPO consistently outperforms prior methods in\nreward-based alignment across diverse step configurations, underscoring its\nrobust step generalization capabilities. Code is avaliable at\nhttps://github.com/ZiyiZhang27/sdpo.",
            "pdf_url": "http://arxiv.org/pdf/2411.11727v1",
            "published": "2024-11-18 16:57:41+00:00",
            "updated": "2024-11-18 16:57:41+00:00"
        },
        {
            "title": "Robust Reinforcement Learning under Diffusion Models for Data with Jumps",
            "authors": "Chenyang Jiang, Donggyu Kim, Alejandra Quintos, Yazhen Wang",
            "summary": "Reinforcement Learning (RL) has proven effective in solving complex\ndecision-making tasks across various domains, but challenges remain in\ncontinuous-time settings, particularly when state dynamics are governed by\nstochastic differential equations (SDEs) with jump components. In this paper,\nwe address this challenge by introducing the Mean-Square Bipower Variation\nError (MSBVE) algorithm, which enhances robustness and convergence in scenarios\ninvolving significant stochastic noise and jumps. We first revisit the\nMean-Square TD Error (MSTDE) algorithm, commonly used in continuous-time RL,\nand highlight its limitations in handling jumps in state dynamics. The proposed\nMSBVE algorithm minimizes the mean-square quadratic variation error, offering\nimproved performance over MSTDE in environments characterized by SDEs with\njumps. Simulations and formal proofs demonstrate that the MSBVE algorithm\nreliably estimates the value function in complex settings, surpassing MSTDE's\nperformance when faced with jump processes. These findings underscore the\nimportance of alternative error metrics to improve the resilience and\neffectiveness of RL algorithms in continuous-time frameworks.",
            "pdf_url": "http://arxiv.org/pdf/2411.11697v1",
            "published": "2024-11-18 16:17:34+00:00",
            "updated": "2024-11-18 16:17:34+00:00"
        },
        {
            "title": "Conceptwm: A Diffusion Model Watermark for Concept Protection",
            "authors": "Liangqi Lei, Keke Gai, Jing Yu, Liehuang Zhu, Qi Wu",
            "summary": "The personalization techniques of diffusion models succeed in generating\nspecific concepts but also pose threats to copyright protection and illegal\nuse. Model Watermarking is an effective method to prevent the unauthorized use\nof subject-driven or style-driven image generation, safeguarding concept\ncopyrights. However, under the goal of concept-oriented protection, current\nwatermarking schemes typically add watermarks to all images rather than\napplying them in a refined manner targeted at specific concepts. Additionally,\nthe personalization techniques of diffusion models can easily remove\nwatermarks. Existing watermarking methods struggle to achieve fine-grained\nwatermark embedding with a few images of specific concept and prevent removal\nof watermarks through personalized fine-tuning. Therefore, we introduce a novel\nconcept-oriented watermarking framework that seamlessly embeds imperceptible\nwatermarks into the concept of diffusion models. We conduct extensive\nexperiments and ablation studies to verify our framework. Our code is available\nat https://anonymous.4open.science/r/Conceptwm-4EB3/.",
            "pdf_url": "http://arxiv.org/pdf/2411.11688v1",
            "published": "2024-11-18 16:11:25+00:00",
            "updated": "2024-11-18 16:11:25+00:00"
        },
        {
            "title": "Hierarchical Structure Enhances the Convergence and Generalizability of Linear Molecular Representation",
            "authors": "Juan-Ni Wu, Tong Wang, Li-Juan Tang, Hai-Long Wu, Ru-Qin Yu",
            "summary": "Language models demonstrate fundamental abilities in syntax, semantics, and\nreasoning, though their performance often depends significantly on the inputs\nthey process. This study introduces TSIS (Simplified TSID) and its\nvariants:TSISD (TSIS with Depth-First Search), TSISO (TSIS in Order), and TSISR\n(TSIS in Random), as integral components of the t-SMILES framework. These\nadditions complete the framework's design, providing diverse approaches to\nmolecular representation. Through comprehensive analysis and experiments\nemploying deep generative models, including GPT, diffusion models, and\nreinforcement learning, the findings reveal that the hierarchical structure of\nt-SMILES is more straightforward to parse than initially anticipated.\nFurthermore, t-SMILES consistently outperforms other linear representations\nsuch as SMILES, SELFIES, and SAFE, demonstrating superior convergence speed and\nenhanced generalization capabilities.",
            "pdf_url": "http://arxiv.org/pdf/2402.02164v4",
            "published": "2024-02-03 14:24:21+00:00",
            "updated": "2024-11-18 16:01:29+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Portfolio Optimization with Feedback Strategies Based on Artificial Neural Networks",
            "authors": "Yaacov Kopeliovich, Michael Pokojovy",
            "summary": "With the recent advancements in machine learning (ML), artificial neural\nnetworks (ANN) are starting to play an increasingly important role in\nquantitative finance. Dynamic portfolio optimization is among many problems\nthat have significantly benefited from a wider adoption of deep learning (DL).\nWhile most existing research has primarily focused on how DL can alleviate the\ncurse of dimensionality when solving the Hamilton-Jacobi-Bellman (HJB)\nequation, some very recent developments propose to forego derivation and\nsolution of HJB in favor of empirical utility maximization over dynamic\nallocation strategies expressed through ANN. In addition to being simple and\ntransparent, this approach is universally applicable, as it is essentially\nagnostic about market dynamics. To showcase the method, we apply it to optimal\nportfolio allocation between a cash account and the S&P 500 index modeled using\ngeometric Brownian motion or the Heston model. In both cases, the results are\ndemonstrated to be on par with those under the theoretical optimal weights\nassuming isoelastic utility and real-time rebalancing. A set of R codes for a\nbroad class of stochastic volatility models are provided as a supplement.",
            "pdf_url": "http://arxiv.org/pdf/2411.09899v1",
            "published": "2024-11-15 02:46:38+00:00",
            "updated": "2024-11-15 02:46:38+00:00"
        }
    ]
}