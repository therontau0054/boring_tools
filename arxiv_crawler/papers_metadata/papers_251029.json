{
    "Physics": [
        {
            "title": "Physics-Informed Latent Neural Operator for Real-time Predictions of time-dependent parametric PDEs",
            "authors": "Sharmila Karumuri, Lori Graham-Brady, Somdatta Goswami",
            "summary": "Deep operator network (DeepONet) has shown significant promise as surrogate\nmodels for systems governed by partial differential equations (PDEs), enabling\naccurate mappings between infinite-dimensional function spaces. However, when\napplied to systems with high-dimensional input-output mappings arising from\nlarge numbers of spatial and temporal collocation points, these models often\nrequire heavily overparameterized networks, leading to long training times.\nLatent DeepONet addresses some of these challenges by introducing a two-step\napproach: first learning a reduced latent space using a separate model,\nfollowed by operator learning within this latent space. While efficient, this\nmethod is inherently data-driven and lacks mechanisms for incorporating\nphysical laws, limiting its robustness and generalizability in data-scarce\nsettings. In this work, we propose PI-Latent-NO, a physics-informed latent\nneural operator framework that integrates governing physics directly into the\nlearning process. Our architecture features two coupled DeepONets trained\nend-to-end: a Latent-DeepONet that learns a low-dimensional representation of\nthe solution, and a Reconstruction-DeepONet that maps this latent\nrepresentation back to the physical space. By embedding PDE constraints into\nthe training via automatic differentiation, our method eliminates the need for\nlabeled training data and ensures physics-consistent predictions. The proposed\nframework is both memory and compute-efficient, exhibiting near-constant\nscaling with problem size and demonstrating significant speedups over\ntraditional physics-informed operator models. We validate our approach on a\nrange of parametric PDEs, showcasing its accuracy, scalability, and suitability\nfor real-time prediction in complex physical systems.",
            "pdf_url": "http://arxiv.org/pdf/2501.08428v3",
            "published": "2025-01-14 20:38:30+00:00",
            "updated": "2025-10-28 17:58:31+00:00"
        },
        {
            "title": "DeltaPhi: Physical States Residual Learning for Neural Operators in Data-Limited PDE Solving",
            "authors": "Xihang Yue, Yi Yang, Linchao Zhu",
            "summary": "The limited availability of high-quality training data poses a major obstacle\nin data-driven PDE solving, where expensive data collection and resolution\nconstraints severely impact the ability of neural operator networks to learn\nand generalize the underlying physical system. To address this challenge, we\npropose DeltaPhi, a novel learning framework that transforms the PDE solving\ntask from learning direct input-output mappings to learning the residuals\nbetween similar physical states, a fundamentally different approach to neural\noperator learning. This reformulation provides implicit data augmentation by\nexploiting the inherent stability of physical systems where closer initial\nstates lead to closer evolution trajectories. DeltaPhi is architecture-agnostic\nand can be seamlessly integrated with existing neural operators to enhance\ntheir performance. Extensive experiments demonstrate consistent and significant\nimprovements across diverse physical systems including regular and irregular\ndomains, different neural architectures, multiple training data amount, and\ncross-resolution scenarios, confirming its effectiveness as a general\nenhancement for neural operators in data-limited PDE solving.",
            "pdf_url": "http://arxiv.org/pdf/2406.09795v2",
            "published": "2024-06-14 07:45:07+00:00",
            "updated": "2025-10-28 17:56:59+00:00"
        },
        {
            "title": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?",
            "authors": "Shuqing Li, Jiayi Yan, Chenyu Niu, Jen-tse Huang, Yun Peng, Wenxuan Wang, Yepang Liu, Michael R. Lyu",
            "summary": "Virtual Reality (VR) games require players to translate high-level semantic\nactions into precise device manipulations using controllers and head-mounted\ndisplays (HMDs). While humans intuitively perform this translation based on\ncommon sense and embodied understanding, whether Large Language Models (LLMs)\ncan effectively replicate this ability remains underexplored. This paper\nintroduces a benchmark, ComboBench, evaluating LLMs' capability to translate\nsemantic actions into VR device manipulation sequences across 262 scenarios\nfrom four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,\nand Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,\nGemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against\nannotated ground truth and human performance. Our results reveal that while\ntop-performing models like Gemini-1.5-Pro demonstrate strong task decomposition\ncapabilities, they still struggle with procedural reasoning and spatial\nunderstanding compared to humans. Performance varies significantly across\ngames, suggesting sensitivity to interaction complexity. Few-shot examples\nsubstantially improve performance, indicating potential for targeted\nenhancement of LLMs' VR manipulation capabilities. We release all materials at\nhttps://sites.google.com/view/combobench.",
            "pdf_url": "http://arxiv.org/pdf/2510.24706v1",
            "published": "2025-10-28 17:55:42+00:00",
            "updated": "2025-10-28 17:55:42+00:00"
        },
        {
            "title": "Fast algorithms enabling optimization and deep learning for photoacoustic tomography in a circular detection geometry",
            "authors": "Andreas Hauptmann, Leonid Kunyansky, Jenni Poimala",
            "summary": "The inverse source problem arising in photoacoustic tomography and in several\nother coupled-physics modalities is frequently solved by iterative algorithms.\nSuch algorithms are based on the minimization of a certain cost functional. In\naddition, novel deep learning techniques are currently being investigated to\nfurther improve such optimization approaches. All such methods require multiple\napplications of the operator defining the forward problem, and of its adjoint.\nIn this paper, we present new asymptotically fast algorithms for numerical\nevaluation of the forward and adjoint operators, applicable in the circular\nacquisition geometry. For an $(n \\times n)$ image, our algorithms compute these\noperators in $\\mathcal{O}(n^2 \\log n)$ floating point operations. We\ndemonstrate the performance of our algorithms in numerical simulations, where\nthey are used as an integral part of several iterative image reconstruction\ntechniques: classic variational methods, such as non-negative least squares and\ntotal variation regularized least squares, as well as deep learning methods,\nsuch as learned primal dual. A Python implementation of our algorithms and\ncomputational examples is available to the general public.",
            "pdf_url": "http://arxiv.org/pdf/2510.24687v1",
            "published": "2025-10-28 17:49:31+00:00",
            "updated": "2025-10-28 17:49:31+00:00"
        },
        {
            "title": "Learning constitutive models and rheology from partial flow measurements",
            "authors": "Alp M. Sunol, James V. Roggeveen, Mohammed G. Alhashim, Henry S. Bae, Michael P. Brenner",
            "summary": "Constitutive laws are at the core of fluid mechanics, relating the fluid\nstress to its deformation rate. Unlike Newtonian fluids, most industrial and\nbiological fluids are non-Newtonian, exhibiting a nonlinear relation.\nAccurately characterizing this nonlinearity is essential for predicting flow\nbehavior in real-world engineering and translational applications. Yet current\nmethods fall short by relying on bulk rheometer data and simple fits that fail\nto capture behaviors relevant in complex geometries and flow conditions.\nData-driven approaches can capture more complex behaviors, but lack\ninterpretability or consistency. To close this gap, we leverage automatic\ndifferentiation to build an end-to-end framework for robust rheological\nlearning. We develop a differentiable non-Newtonian fluid solver with a tensor\nbasis neural network closure that learns stress directly from arbitrary flow\nmeasurements, such as velocimetry data. In parallel, we implement\ndifferentiable versions of major constitutive relations, enabling Bayesian\nmodel parametrization and selection from rheometer data. Our framework predicts\nflows in unseen geometries and ensures physical consistency and\ninterpretability by matching neural network responses to known constitutive\nlaws. Ultimately, this work lays the groundwork for advanced digital rheometry\ncapable of comprehensively characterizing non-Newtonian and viscoelastic fluids\nunder realistic in-situ or in-line operating conditions.",
            "pdf_url": "http://arxiv.org/pdf/2510.24673v1",
            "published": "2025-10-28 17:38:33+00:00",
            "updated": "2025-10-28 17:38:33+00:00"
        },
        {
            "title": "Pearl: A Foundation Model for Placing Every Atom in the Right Location",
            "authors": "Genesis Research Team, Alejandro Dobles, Nina Jovic, Kenneth Leidal, Pranav Murugan, David C. Williams, Drausin Wulsin, Nate Gruver, Christina X. Ji, Korrawat Pruegsanusak, Gianluca Scarpellini, Ansh Sharma, Wojciech Swiderski, Andrea Bootsma, Richard Strong Bowen, Charlotte Chen, Jamin Chen, Marc Andr\u00e9 D\u00e4mgen, Roy Tal Dew, Benjamin DiFrancesco, J. D. Fishman, Alla Ivanova, Zach Kagin, David Li-Bland, Zuli Liu, Igor Morozov, Jeffrey Ouyang-Zhang, Frank C. Pickard IV, Kushal S. Shah, Ben Shor, Gabriel Monteiro da Silva, Maxx Tessmer, Carl Tilbury, Cyr Vetcher, Daniel Zeng, Maruan Al-Shedivat, Aleksandra Faust, Evan N. Feinberg, Michael V. LeVine, Matteus Pan",
            "summary": "Accurately predicting the three-dimensional structures of protein-ligand\ncomplexes remains a fundamental challenge in computational drug discovery that\nlimits the pace and success of therapeutic design. Deep learning methods have\nrecently shown strong potential as structural prediction tools, achieving\npromising accuracy across diverse biomolecular systems. However, their\nperformance and utility are constrained by scarce experimental data,\ninefficient architectures, physically invalid poses, and the limited ability to\nexploit auxiliary information available at inference. To address these issues,\nwe introduce Pearl (Placing Every Atom in the Right Location), a foundation\nmodel for protein-ligand cofolding at scale. Pearl addresses these challenges\nwith three key innovations: (1) training recipes that include large-scale\nsynthetic data to overcome data scarcity; (2) architectures that incorporate an\nSO(3)-equivariant diffusion module to inherently respect 3D rotational\nsymmetries, improving generalization and sample efficiency, and (3)\ncontrollable inference, including a generalized multi-chain templating system\nsupporting both protein and non-polymeric components as well as dual\nunconditional/conditional modes. Pearl establishes a new state-of-the-art\nperformance in protein-ligand cofolding. On the key metric of generating\naccurate (RMSD < 2 \\r{A}) and physically valid poses, Pearl surpasses AlphaFold\n3 and other open source baselines on the public Runs N' Poses and PoseBusters\nbenchmarks, delivering 14.5% and 14.2% improvements, respectively, over the\nnext best model. In the pocket-conditional cofolding regime, Pearl delivers\n$3.6\\times$ improvement on a proprietary set of challenging, real-world drug\ntargets at the more rigorous RMSD < 1 \\r{A} threshold. Finally, we demonstrate\nthat model performance correlates directly with synthetic dataset size used in\ntraining.",
            "pdf_url": "http://arxiv.org/pdf/2510.24670v1",
            "published": "2025-10-28 17:36:51+00:00",
            "updated": "2025-10-28 17:36:51+00:00"
        },
        {
            "title": "Study of the Semileptonic Decay $\u039b\\to p\\,\\ell\\,\\bar\u03bd_{\\ell}$ in QCD",
            "authors": "M. Ahmadi, Z. Rajabi Najjar, K. Azizi",
            "summary": "We conduct a comprehensive study of the semileptonic decay process \\(\\Lambda\n\\to p\\,\\ell\\,\\bar{\\nu}_{\\ell}\\), focusing on the determination of all six\nvector and axial-vector form factors that govern the low-energy hadronic matrix\nelements of the underlying theory. These invariant form factors constitute the\nessential inputs for describing the decay, and their dependence on the momentum\ntransfer \\(q^{2}\\) is analyzed across the entire physical kinematic region. To\nparameterize the \\(q^{2}\\)-dependence, we adopt both the \\(z\\)-expansion\nformalism and a polynomial fitting approach. Utilizing these parameterizations,\nwe compute the exclusive decay widths for both the electron and muon channels\nand subsequently extract the corresponding branching ratios. Furthermore, we\nevaluate the ratio of decay widths between the muon and electron channels,\ndefined as $R^{\\mu e} \\equiv \\frac{\\Gamma(\\Lambda \\to\np\\,\\mu\\,\\bar{\\nu}_{\\mu})}{\\Gamma(\\Lambda \\to p\\,e\\,\\bar{\\nu}_{e})}$, obtaining\n\\(R^{\\mu e} = 0.196^{+0.009}_{-0.012}\\) from the polynomial fit and \\(R^{\\mu e}\n= 0.174^{+0.002}_{-0.005}\\) from the \\(z\\)-expansion. While both ratios are\ncompatible with previously reported values in the literature, the result from\nthe \\(z\\)-expansion exhibits particularly strong agreement with the averages\nreported by the Particle Data Group (PDG).",
            "pdf_url": "http://arxiv.org/pdf/2509.23421v2",
            "published": "2025-09-27 17:31:23+00:00",
            "updated": "2025-10-28 17:20:04+00:00"
        },
        {
            "title": "Radiation enhanced diffusion in cartilages as a physical mechanism underlying radiation treatments of osteoarthritis and related disorders",
            "authors": "Diana Shvydka, Victor Karpov",
            "summary": "Degradation of joint cartilages can result in osteoarthritis (OA) affecting\nabout 10\\% of the US population and responsible for significant hospitalization\ncosts. While observations show that low dose radiation treatments (LDRT) bring\nimprovements for a majority of OA patients, the underlying mechanism is not\nsufficiently understood. Here, we show how the radiation enhanced diffusion\n(RED) can boost the molecular transport in cartilages promoting cartilage\nself-healing rendering a mechanism for the observed positive LDRT effects on\nOA. Along with quantitative estimates for RED, we predict a related phenomenon\nof the electric charge build up that allows LDRT schedules promoting desirable\ntypes of molecular transports dominated by either positive or negative\nmolecular species. Our analyses call upon further experimental verifications\nand clinical trials with curative rather than palliative intent. In addition to\nOA applications, our developed approaches can be useful for sports medicine\ndealing with damage or degeneration of the articular cartilages.",
            "pdf_url": "http://arxiv.org/pdf/2510.22903v2",
            "published": "2025-10-27 01:18:36+00:00",
            "updated": "2025-10-28 16:54:51+00:00"
        },
        {
            "title": "Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation",
            "authors": "Jean Barbier, Francesco Camilli, Minh-Toan Nguyen, Mauro Pastore, Rudy Skerk",
            "summary": "For three decades statistical physics has been providing a framework to\nanalyse neural networks. A long-standing question remained on its capacity to\ntackle deep learning models capturing rich feature learning effects, thus going\nbeyond the narrow networks or kernel methods analysed until now. We positively\nanswer through the study of the supervised learning of a multi-layer\nperceptron. Importantly, (i) its width scales as the input dimension, making it\nmore prone to feature learning than ultra wide networks, and more expressive\nthan narrow ones or with fixed embedding layers; and (ii) we focus on the\nchallenging interpolation regime where the number of trainable parameters and\ndata are comparable, which forces the model to adapt to the task. We consider\nthe matched teacher-student setting. It provides the fundamental limits of\nlearning random deep neural network targets and helps in identifying the\nsufficient statistics describing what is learnt by an optimally trained network\nas the data budget increases. A rich phenomenology emerges with various\nlearning transitions. With enough data optimal performance is attained through\nmodel's \"specialisation\" towards the target, but it can be hard to reach for\ntraining algorithms which get attracted by sub-optimal solutions predicted by\nthe theory. Specialisation occurs inhomogeneously across layers, propagating\nfrom shallow towards deep ones, but also across neurons in each layer.\nFurthermore, deeper targets are harder to learn. Despite its simplicity, the\nBayesian-optimal setting provides insights on how the depth, non-linearity and\nfinite (proportional) width influence neural networks in the feature learning\nregime that are potentially relevant way beyond it.",
            "pdf_url": "http://arxiv.org/pdf/2510.24616v1",
            "published": "2025-10-28 16:44:34+00:00",
            "updated": "2025-10-28 16:44:34+00:00"
        },
        {
            "title": "Efficient magic state cultivation with lattice surgery",
            "authors": "Yutaka Hirano, Riki Toshio, Tomohiro Itogawa, Keisuke Fujii",
            "summary": "Magic state distillation plays a crucial role in fault-tolerant quantum\ncomputation and represents a major bottleneck. In contrast to traditional\nlogical-level distillation, physical-level distillation offers significant\noverhead reduction by enabling direct implementation with physical gates. Magic\nstate cultivation is a state-of-the-art physical-level distillation protocol\nthat is compatible with the square-grid connectivity and yields high-fidelity\nmagic states. However, it relies on the complex grafted code, which incurs\nsubstantial spacetime overhead and complicates practical implementation. In\nthis work, we propose an efficient cultivation-based protocol compatible with\nthe square-grid connectivity. We reduce the spatial overhead by avoiding the\ngrafted code and further reduce the average spacetime overhead by utilizing\ncode expansion and enabling early rejection. Numerical simulations show that,\nwith a color code distance of 3 and a physical error probability of $10^{-3}$,\nour protocol achieves a logical error probability for the resulting magic state\ncomparable to that of magic state cultivation ($\\approx 3 \\times 10^{-6}$),\nwhile requiring about half the spacetime overhead. Our work provides an\nefficient and simple distillation protocol suitable for megaquop use cases and\nearly fault-tolerant devices.",
            "pdf_url": "http://arxiv.org/pdf/2510.24615v1",
            "published": "2025-10-28 16:44:34+00:00",
            "updated": "2025-10-28 16:44:34+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Generative View Stitching",
            "authors": "Chonghyuk Song, Michal Stary, Boyuan Chen, George Kopanas, Vincent Sitzmann",
            "summary": "Autoregressive video diffusion models are capable of long rollouts that are\nstable and consistent with history, but they are unable to guide the current\ngeneration with conditioning from the future. In camera-guided video generation\nwith a predefined camera trajectory, this limitation leads to collisions with\nthe generated scene, after which autoregression quickly collapses. To address\nthis, we propose Generative View Stitching (GVS), which samples the entire\nsequence in parallel such that the generated scene is faithful to every part of\nthe predefined camera trajectory. Our main contribution is a sampling algorithm\nthat extends prior work on diffusion stitching for robot planning to video\ngeneration. While such stitching methods usually require a specially trained\nmodel, GVS is compatible with any off-the-shelf video model trained with\nDiffusion Forcing, a prevalent sequence diffusion framework that we show\nalready provides the affordances necessary for stitching. We then introduce\nOmni Guidance, a technique that enhances the temporal consistency in stitching\nby conditioning on both the past and future, and that enables our proposed\nloop-closing mechanism for delivering long-range coherence. Overall, GVS\nachieves camera-guided video generation that is stable, collision-free,\nframe-to-frame consistent, and closes loops for a variety of predefined camera\npaths, including Oscar Reutersv\\\"ard's Impossible Staircase. Results are best\nviewed as videos at https://andrewsonga.github.io/gvs.",
            "pdf_url": "http://arxiv.org/pdf/2510.24718v1",
            "published": "2025-10-28 17:59:58+00:00",
            "updated": "2025-10-28 17:59:58+00:00"
        },
        {
            "title": "Causal Ordering for Structure Learning From Time Series",
            "authors": "Pedro P. Sanchez, Damian Machlanski, Steven McDonagh, Sotirios A. Tsaftaris",
            "summary": "Predicting causal structure from time series data is crucial for\nunderstanding complex phenomena in physiology, brain connectivity, climate\ndynamics, and socio-economic behaviour. Causal discovery in time series is\nhindered by the combinatorial complexity of identifying true causal\nrelationships, especially as the number of variables and time points grow. A\ncommon approach to simplify the task is the so-called ordering-based methods.\nTraditional ordering methods inherently limit the representational capacity of\nthe resulting model. In this work, we fix this issue by leveraging multiple\nvalid causal orderings, instead of a single one as standard practice. We\npropose DOTS (Diffusion Ordered Temporal Structure), using diffusion-based\ncausal discovery for temporal data. By integrating multiple orderings, DOTS\neffectively recovers the transitive closure of the underlying directed acyclic\ngraph, mitigating spurious artifacts inherent in single-ordering approaches. We\nformalise the problem under standard assumptions such as stationarity and the\nadditive noise model, and leverage score matching with diffusion processes to\nenable efficient Hessian estimation. Extensive experiments validate the\napproach. Empirical evaluations on synthetic and real-world datasets\ndemonstrate that DOTS outperforms state-of-the-art baselines, offering a\nscalable and robust approach to temporal causal discovery. On synthetic\nbenchmarks ($d{=}\\!3-\\!6$ variables, $T{=}200\\!-\\!5{,}000$ samples), DOTS\nimproves mean window-graph $F1$ from $0.63$ (best baseline) to $0.81$. On the\nCausalTime real-world benchmark ($d{=}20\\!-\\!36$), while baselines remain the\nbest on individual datasets, DOTS attains the highest average summary-graph\n$F1$ while halving runtime relative to graph-optimisation methods. These\nresults establish DOTS as a scalable and accurate solution for temporal causal\ndiscovery.",
            "pdf_url": "http://arxiv.org/pdf/2510.24639v1",
            "published": "2025-10-28 17:06:15+00:00",
            "updated": "2025-10-28 17:06:15+00:00"
        },
        {
            "title": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel Estimation to AI-Native 6G Receivers",
            "authors": "Yuzhi Yang, Sen Yan, Weijie Zhou, Brahim Mefgouda, Ridong Li, Zhaoyang Zhang, M\u00e9rouane Debbah",
            "summary": "With the development of artificial intelligence (AI) techniques, implementing\nAI-based techniques to improve wireless transceivers becomes an emerging\nresearch topic. Within this context, AI-based channel characterization and\nestimation become the focus since these methods have not been solved by\ntraditional methods very well and have become the bottleneck of transceiver\nefficiency in large-scale orthogonal frequency division multiplexing (OFDM)\nsystems. Specifically, by formulating channel estimation as a generative AI\nproblem, generative AI methods such as diffusion models (DMs) can efficiently\ndeal with rough initial estimations and have great potential to cooperate with\ntraditional signal processing methods. This paper focuses on the transceiver\ndesign of OFDM systems based on DMs, provides an illustration of the potential\nof DMs in wireless transceivers, and points out the related research directions\nbrought by DMs. We also provide a proof-of-concept case study of further\nadapting DMs for better wireless receiver performance.",
            "pdf_url": "http://arxiv.org/pdf/2510.24495v1",
            "published": "2025-10-28 15:10:11+00:00",
            "updated": "2025-10-28 15:10:11+00:00"
        },
        {
            "title": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies",
            "authors": "Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Tian Nian, Liuao Pei, Shunbo Zhou, Xiaokang Yang, Jiangmiao Pang, Yao Mu, Ping Luo",
            "summary": "Vision-Language-Action (VLA) models adapt large vision-language backbones to\nmap images and instructions into robot actions. However, prevailing VLAs either\ngenerate actions auto-regressively in a fixed left-to-right order or attach\nseparate MLP or diffusion heads outside the backbone, leading to fragmented\ninformation pathways and specialized training requirements that hinder a\nunified, scalable architecture. We present Discrete Diffusion VLA, a\nunified-transformer policy that models discretized action chunks with discrete\ndiffusion. The design retains diffusion's progressive refinement paradigm while\nremaining natively compatible with the discrete token interface of VLMs. Our\nmethod achieves an adaptive decoding order that resolves easy action elements\nbefore harder ones and uses secondary re-masking to revisit uncertain\npredictions across refinement rounds, which improves consistency and enables\nrobust error correction. This unified decoder preserves pre-trained\nvision-language priors, supports parallel decoding, breaks the autoregressive\nbottleneck, and reduces the number of function evaluations. Discrete Diffusion\nVLA achieves 96.3% avg. success rates on LIBERO, 71.2% visual matching on\nSimplerEnv-Fractal and 54.2% overall on SimplerEnv-Bridge, improving over\nautoregressive, MLP decoder and continuous diffusion baselines. These findings\nindicate that discrete-diffusion VLA supports precise action modeling and\nconsistent training, laying groundwork for scaling VLA to larger models and\ndatasets. Our project page is https://github.com/Liang-ZX/DiscreteDiffusionVLA",
            "pdf_url": "http://arxiv.org/pdf/2508.20072v2",
            "published": "2025-08-27 17:39:11+00:00",
            "updated": "2025-10-28 14:22:20+00:00"
        },
        {
            "title": "Rethinking Visual Intelligence: Insights from Video Pretraining",
            "authors": "Pablo Acuaviva, Aram Davtyan, Mariam Hassan, Sebastian Stapf, Ahmad Rahimi, Alexandre Alahi, Paolo Favaro",
            "summary": "Large language models (LLMs) have demonstrated that large-scale pretraining\nenables systems to adapt rapidly to new problems with little supervision in the\nlanguage domain. This success, however, has not translated as effectively to\nthe visual domain, where models, including LLMs, continue to struggle with\ncompositional understanding, sample efficiency, and general-purpose\nproblem-solving. We investigate Video Diffusion Models (VDMs) as a promising\ndirection for bridging this gap. Pretraining on spatiotemporal data endows\nthese models with strong inductive biases for structure and dynamics, which we\nhypothesize can support broad task adaptability. To test this, we design a\ncontrolled evaluation in which both a pretrained LLM and a pretrained VDM are\nequipped with lightweight adapters and presented with tasks in their natural\nmodalities. Across benchmarks including ARC-AGI, ConceptARC, visual games,\nroute planning, and cellular automata, VDMs demonstrate higher data efficiency\nthan their language counterparts. Taken together, our results indicate that\nvideo pretraining offers inductive biases that support progress toward visual\nfoundation models.",
            "pdf_url": "http://arxiv.org/pdf/2510.24448v1",
            "published": "2025-10-28 14:12:11+00:00",
            "updated": "2025-10-28 14:12:11+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "Stochastic PDEs and Quantitative Finance: The Black-Scholes-Merton Model of Options Pricing and Riskless Trading",
            "authors": "Brandon Kaplowitz, Siddharth G. Reddy",
            "summary": "Differential equations can be used to construct predictive models of a\ndiverse set of real-world phenomena like heat transfer, predator-prey\ninteractions, and missile tracking. In our work, we explore one particular\napplication of stochastic differential equations, the Black-Scholes-Merton\nmodel, which can be used to predict the prices of financial derivatives and\nmaintain a riskless, hedged position in the stock market. This paper is\nintended to provide the reader with a history, derivation, and implementation\nof the canonical model as well as an improved trading strategy that better\nhandles arbitrage opportunities in high-volatility markets. Our attempted\nimprovements may be broken into two components: an implementation of 24-hour,\nworldwide trading designed to create a continuous trading scenario and the use\nof the Student's t-distribution (with two degrees of freedom) in evaluating the\nBlack-Scholes equations.",
            "pdf_url": "http://arxiv.org/pdf/1212.1919v3",
            "published": "2012-12-09 21:10:23+00:00",
            "updated": "2025-10-26 19:42:56+00:00"
        }
    ]
}