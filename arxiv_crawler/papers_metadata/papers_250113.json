{
    "Physics": [
        {
            "title": "Sub-2 Kelvin characterization of nitrogen-vacancy centers in silicon carbide nanopillars",
            "authors": "Victoria A. Norman, Sridhar Majety, Alex H. Rubin, Pranta Saha, Jeanette Simo, Bradi Palomarez, Liang Li, Pietra B. Curro, Scott Dhuey, Selven Virasawmy, Marina Radulaski",
            "summary": "The development of efficient quantum communication technologies depends on\nthe innovation in multiple layers of its implementation, a challenge we address\nfrom the fundamental properties of the physical system at the nano-scale to the\ninstrumentation level at the macro-scale. We select a promising near infrared\nquantum emitter, the nitrogen-vacancy (NV) center in 4H-SiC, and integrate it,\nat an ensemble level, with nanopillar structures that enhance photon collection\nefficiency into an objective lens. Moreover, changes in collection efficiency\nin pillars compared to bulk can serve as indicators of color center orientation\nin the lattice. To characterize NV center properties at the unprecedented sub-2\nKelvin temperatures, we incorporate compatible superconducting nanowire single\nphoton detectors inside the chamber of an optical cryostat and create the\nICECAP, the Integrated Cryogenic system for Emission, Collection And\nPhoton-detection. ICECAP measurements show no significant linewidth broadening\nof NV ensemble emission and up to 14-fold enhancement in collected emission.\nWith additional filtering, we measure emitter lifetimes of NV centers in a\nbasal ($hk$) and an axial ($kk$) orientation unveiling their cryogenic values\nof 2.2 ns and 2.8 ns.",
            "pdf_url": "http://arxiv.org/pdf/2401.10509v3",
            "published": "2024-01-19 05:56:11+00:00",
            "updated": "2025-01-10 18:55:22+00:00"
        },
        {
            "title": "Meta-Learning for Physically-Constrained Neural System Identification",
            "authors": "Ankush Chakrabarty, Gordon Wichern, Vedang M. Deshpande, Abraham P. Vinod, Karl Berntorp, Christopher R. Laughman",
            "summary": "We present a gradient-based meta-learning framework for rapid adaptation of\nneural state-space models (NSSMs) for black-box system identification. When\napplicable, we also incorporate domain-specific physical constraints to improve\nthe accuracy of the NSSM. The major benefit of our approach is that instead of\nrelying solely on data from a single target system, our framework utilizes data\nfrom a diverse set of source systems, enabling learning from limited target\ndata, as well as with few online training iterations. Through benchmark\nexamples, we demonstrate the potential of our approach, study the effect of\nfine-tuning subnetworks rather than full fine-tuning, and report real-world\ncase studies to illustrate the practical application and generalizability of\nthe approach to practical problems with physical-constraints. Specifically, we\nshow that the meta-learned models result in improved downstream performance in\nmodel-based state estimation in indoor localization and energy systems.",
            "pdf_url": "http://arxiv.org/pdf/2501.06167v1",
            "published": "2025-01-10 18:46:28+00:00",
            "updated": "2025-01-10 18:46:28+00:00"
        },
        {
            "title": "Supercharging Single-Atom Traps by Collisional Blockade",
            "authors": "Mark IJspeert, Naomi Holland, Benjamin Yuen, Axel Kuhn",
            "summary": "Reconfigurable arrays of trapped single atoms are an excellent platform for\nthe simulation of many-body physics and the realisation of high-fidelity\nquantum gates. The confinement of atoms is often achieved with focussed laser\nbeams acting as optical dipole-force traps that allow for both static and\ndynamic positioning of atoms. In these traps, light-assisted collisions --\nenhancing the two-atom loss rate -- ensure that single atom occupation of traps\ncan be realised. However, the time-averaged probability of trapping a single\natom is limited to $0.5$ when loading directly from a surrounding cloud of\nlaser-cooled atoms, preventing deterministic filling of large arrays. In this\nwork, we demonstrate that increasing the depth of a static, optical dipole trap\nenables the transition from fast loading on a timescale of $2.1\\,$s to an\nextended trap lifetime of $7.9\\,$s. This method demonstrates an achievable\nfilling ratio of $(79\\pm2)\\,\\%$ without the need of rearranging atoms to fill\nvacant traps.",
            "pdf_url": "http://arxiv.org/pdf/2501.06162v1",
            "published": "2025-01-10 18:38:59+00:00",
            "updated": "2025-01-10 18:38:59+00:00"
        },
        {
            "title": "Multilingual Performance of a Multimodal Artificial Intelligence System on Multisubject Physics Concept Inventories",
            "authors": "Gerd Kortemeyer, Marina Babayeva, Giulia Polverini, Bor Gregorcic, Ralf Widenhorn",
            "summary": "We investigate the multilingual and multimodal performance of a large\nlanguage model-based artificial intelligence (AI) system, GPT-4o, on a diverse\nset of physics concept inventories spanning multiple languages and subject\nareas. The inventories taken from the PhysPort website cover the classical\nphysics topics of mechanics, electromagnetism, optics, and thermodynamics as\nwell as relativity, quantum mechanics, astronomy, mathematics, and laboratory\nskills. Unlike previous text-only studies, we uploaded the inventories as\nimages mirroring what a student would see on paper, assessing the system's\nmultimodal functionality. The AI is prompted in English and autonomously\nchooses the language of its response - either remaining in the nominal language\nof the test, switching entirely to English, or mixing languages - revealing\nadaptive behavior dependent on linguistic complexity and data availability. Our\nresults indicate some variation in performance across subject areas, with\nlaboratory skills standing out as the area of poorest performance. Furthermore,\nthe AI's performance on questions that require visual interpretation of images\nis worse than on purely text-based questions. Questions that are difficult for\nthe AI tend to be that way invariably of the inventory language. We also find\nlarge variations in performance across languages, with some appearing to\nbenefit substantially from language switching, a phenomenon similar to\ncode-switching ofhuman speakers. Overall, comparing the obtained AI results to\nthe existing literature, we find that the AI system outperforms average\nundergraduate students post-instruction in all subject areas but laboratory\nskills.",
            "pdf_url": "http://arxiv.org/pdf/2501.06143v1",
            "published": "2025-01-10 18:08:07+00:00",
            "updated": "2025-01-10 18:08:07+00:00"
        },
        {
            "title": "Detecting LHC Neutrinos at Surface Level",
            "authors": "Akitaka Ariga, Steven Barwick, Jamie Boyd, Max Fieg, Felix Kling, Toni M\u00e4kel\u00e4, Camille Vendeuvre, Benjamin Weyer",
            "summary": "The first direct detection of neutrinos at the LHC not only marks the\nbeginning of a novel collider neutrino program at CERN but also motivates\nconsidering additional neutrino detectors to fully exploit the associated\nphysics potential. We investigate the feasibility and physics potential of\nneutrino experiments located at the surface-level. A topographic desk study was\nperformed to identify all points at which the LHC's neutrino beams exit the\nearth. The closest location lies about 9 km east of the CMS interaction point,\nat the bottom of Lake Geneva. Several detectors to be placed at this location\nare considered, including a water Cherenkov detector and an emulsion detector.\nThe detector concepts are introduced, and projections for their contribution to\nthe LHC forward neutrino program and searches for dark sector particles are\npresented. However, the dilution of the neutrino flux over distance reduces the\nneutrino yield significantly, limiting the physics potential of surface-level\ndetectors compared to ones closer to the interaction point, including the\nproposed FPF.",
            "pdf_url": "http://arxiv.org/pdf/2501.06142v1",
            "published": "2025-01-10 18:03:59+00:00",
            "updated": "2025-01-10 18:03:59+00:00"
        },
        {
            "title": "Theory for the Rydberg states of helium: Comparison with experiment for the $1s24p\\;^1P_1$ state ($n=24$)",
            "authors": "Aaron T. Bondy, G. W. F. Drake, Cody McLeod, Evan M. R. Petrimoulx, Xiao-Qiu Qi, Zhen-Xiang Zhong",
            "summary": "Recent measurements of the ionization energies of the Rydberg $^1P$ states of\nhelium for principal quantum number $n = 24$ and higher present a new challenge\nto theoretical atomic physics. A long-standing obstacle to high precision\natomic theory for three-body systems is a rapid loss of accuracy for\nvariational calculations with increasing principal quantum number $n$. We show\nthat this problem can be overcome with the use of a ``triple\" basis set in\nHylleraas coordinates. Nonrelativistic energies accurate to 23 significant\nfigures are obtained with basis sets of relatively modest size (6744 terms).\nRelativistic and quantum electrodynamic effects are calculated, including an\nestimate of terms of order $m\\alpha^6$ from a $1/n^3$ extrapolation, resulting\nin an estimated accuracy of $\\pm$1 kHz. The calculated ionization energy of\n5704 980.348(1) MHz is in excellent agreement with the experimental value 5704\n980.312(95) MHz. These results establish the ionization energy of the\n$1s24p\\;^1P_1$ state as an absolute point of reference for transitions to\nlower-lying states, and they confirm an $11\\sigma$ disagreement between theory\nand experiment in the triplet spectrum of helium. Results are also given for\nthe $1s24p\\;^3P_J$ states in agreement with a recent experiment on the triplet\nRydberg series, thereby confirming a discrepancy of of $0.468 \\pm 0.055$ MHz\nfor the ionization energy of the $1s2s\\;^3S_1$ state.",
            "pdf_url": "http://arxiv.org/pdf/2501.06096v1",
            "published": "2025-01-10 16:50:43+00:00",
            "updated": "2025-01-10 16:50:43+00:00"
        },
        {
            "title": "The Spectre of Underdetermination in Modern Cosmology",
            "authors": "Pedro G. Ferreira, William J. Wolf, James Read",
            "summary": "The scientific status of physical cosmology has been the subject of\nphilosophical debate ever since detailed mathematical models of the Universe\nemerged from Einstein's general theory of relativity. Such debates revolve\naround whether and to what extent cosmology meets established demarcation\ncriteria for a discipline to be scientific, as well as determining how to best\ncharacterize cosmology as a science, given the unique challenges and\nlimitations faced by a discipline which aims to study the origin, composition,\nand fate of the Universe itself. The present article revisits, in light of the\ndramatic progress in cosmology in recent decades, an earlier debate held in the\n1950s between Herman Bondi and Gerald Whitrow regarding the scientific status\nof cosmology. We analyse cosmology's transition from an emerging science to a\ncornerstone of modern physics, highlighting its empirical successes in\nestablishing the $\\Lambda$-Cold Dark Matter ($\\Lambda$CDM) model and in its\ndelivery of various successful novel predictions. Despite this remarkable\nscientific success and progress, we argue that modern cosmology faces a further\nprofound challenge: the permanent underdetermination of the microphysical\nnature of its exotic energy components: inflation, dark matter, and dark\nenergy. Drawing historical parallels with the role of spectroscopy in revealing\nthe microphysical nature of atomic physics, we argue that the epistemic\nbarriers obstructing us from ascertaining the microphysical nature of these\nexotic energy components are significant, in turn casting doubt upon whether\ncosmology can ever transcend these particular epistemic challenges. We conclude\nby reflecting on the prospects for future breakthroughs and/or non-empirical\narguments which could decide this issue conclusively.",
            "pdf_url": "http://arxiv.org/pdf/2501.06095v1",
            "published": "2025-01-10 16:45:43+00:00",
            "updated": "2025-01-10 16:45:43+00:00"
        },
        {
            "title": "Averaged Adam accelerates stochastic optimization in the training of deep neural network approximations for partial differential equation and optimal control problems",
            "authors": "Steffen Dereich, Arnulf Jentzen, Adrian Riekert",
            "summary": "Deep learning methods - usually consisting of a class of deep neural networks\n(DNNs) trained by a stochastic gradient descent (SGD) optimization method - are\nnowadays omnipresent in data-driven learning problems as well as in scientific\ncomputing tasks such as optimal control (OC) and partial differential equation\n(PDE) problems. In practically relevant learning tasks, often not the\nplain-vanilla standard SGD optimization method is employed to train the\nconsidered class of DNNs but instead more sophisticated adaptive and\naccelerated variants of the standard SGD method such as the popular Adam\noptimizer are used. Inspired by the classical Polyak-Ruppert averaging\napproach, in this work we apply averaged variants of the Adam optimizer to\ntrain DNNs to approximately solve exemplary scientific computing problems in\nthe form of PDEs and OC problems. We test the averaged variants of Adam in a\nseries of learning problems including physics-informed neural network (PINN),\ndeep backward stochastic differential equation (deep BSDE), and deep Kolmogorov\napproximations for PDEs (such as heat, Black-Scholes, Burgers, and Allen-Cahn\nPDEs), including DNN approximations for OC problems, and including DNN\napproximations for image classification problems (ResNet for CIFAR-10). In each\nof the numerical examples the employed averaged variants of Adam outperform the\nstandard Adam and the standard SGD optimizers, particularly, in the situation\nof the scientific machine learning problems. The Python source codes for the\nnumerical experiments associated to this work can be found on GitHub at\nhttps://github.com/deeplearningmethods/averaged-adam.",
            "pdf_url": "http://arxiv.org/pdf/2501.06081v1",
            "published": "2025-01-10 16:15:25+00:00",
            "updated": "2025-01-10 16:15:25+00:00"
        },
        {
            "title": "Searches for Top-associated Dark Matter Production at the LHC",
            "authors": "Dominic Stafford",
            "summary": "Recent searches for dark matter (DM) produced in association with top quarks\nfrom the ATLAS and CMS experiments using data collected between 2015 and 2018\nare presented. These comprise searches from both experiments for DM in\nassociation with a single top quark; an improved ATLAS search for DM in single\nlepton $t\\bar{t}$ final states; an ATLAS search stop squarks decaying to a top\nquark, a charm quark and neutralinos, and a CMS search for DM produced in\nassociation with a pair of top quarks or a single top. These analyses feature\nnovel machine learning and advanced background estimation techniques. No\nstatistically significant excess is observed in any of these searches.",
            "pdf_url": "http://arxiv.org/pdf/2501.06072v1",
            "published": "2025-01-10 16:09:22+00:00",
            "updated": "2025-01-10 16:09:22+00:00"
        },
        {
            "title": "Precision determination of the track-position resolution of beam telescopes",
            "authors": "M. Antonello, L. Eikelmann, E. Garutti, R. Klanner, J. Schwandt, G. Steinbr\u00fcck, A. Vauth",
            "summary": "Beam tests using tracking telescopes are a standard method for determining\nthe spatial resolution of detectors. This requires the precise knowledge of the\nposition resolution of beam tracks reconstructed at the Device Under Test\n(DUT). A method is proposed which achieves this using a segmented silicon\ndetector with readout with charge digitization. It is found that the DUT\nspatial resolution for particles with normal incidence is less than 1 $\\mu$m\nfor events where clusters consist of two pixels (or strips). Given this\naccuracy, the residual of the beam track-position at the DUT and the position\nreconstructed in the DUT provides the beam track-position resolution\ndistribution. The method is developed using simulated events, which are also\nused to study how to deal with cross-talk, electronics noise, energetic $\\delta\n$-electrons, and incident beams with a few degrees off the normal to the sensor\nplane. To validate the method, the position resolution of beam tracks\nreconstructed by the EUDET beam telescope of the DESY II Test Beam Facility is\ndetermined using a CMS Phase-2 prototype pixel sensor.",
            "pdf_url": "http://arxiv.org/pdf/2408.17215v2",
            "published": "2024-08-30 11:43:31+00:00",
            "updated": "2025-01-10 16:08:41+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "GenMol: A Drug Discovery Generalist with Discrete Diffusion",
            "authors": "Seul Lee, Karsten Kreis, Srimukh Prasad Veccham, Meng Liu, Danny Reidenbach, Yuxing Peng, Saee Paliwal, Weili Nie, Arash Vahdat",
            "summary": "Drug discovery is a complex process that involves multiple scenarios and\nstages, such as fragment-constrained molecule generation, hit generation and\nlead optimization. However, existing molecular generative models can only\ntackle one or two of these scenarios and lack the flexibility to address\nvarious aspects of the drug discovery pipeline. In this paper, we present\nGeneralist Molecular generative model (GenMol), a versatile framework that\naddresses these limitations by applying discrete diffusion to the Sequential\nAttachment-based Fragment Embedding (SAFE) molecular representation. GenMol\ngenerates SAFE sequences through non-autoregressive bidirectional parallel\ndecoding, thereby allowing utilization of a molecular context that does not\nrely on the specific token ordering and enhanced computational efficiency.\nMoreover, under the discrete diffusion framework, we introduce fragment\nremasking, a strategy that optimizes molecules by replacing fragments with\nmasked tokens and regenerating them, enabling effective exploration of chemical\nspace. GenMol significantly outperforms the previous GPT-based model trained on\nSAFE representations in de novo generation and fragment-constrained generation,\nand achieves state-of-the-art performance in goal-directed hit generation and\nlead optimization. These experimental results demonstrate that GenMol can\ntackle a wide range of drug discovery tasks, providing a unified and versatile\napproach for molecular design.",
            "pdf_url": "http://arxiv.org/pdf/2501.06158v1",
            "published": "2025-01-10 18:30:05+00:00",
            "updated": "2025-01-10 18:30:05+00:00"
        },
        {
            "title": "From discrete-time policies to continuous-time diffusion samplers: Asymptotic equivalences and faster training",
            "authors": "Julius Berner, Lorenz Richter, Marcin Sendera, Jarrid Rector-Brooks, Nikolay Malkin",
            "summary": "We study the problem of training neural stochastic differential equations, or\ndiffusion models, to sample from a Boltzmann distribution without access to\ntarget samples. Existing methods for training such models enforce time-reversal\nof the generative and noising processes, using either differentiable simulation\nor off-policy reinforcement learning (RL). We prove equivalences between\nfamilies of objectives in the limit of infinitesimal discretization steps,\nlinking entropic RL methods (GFlowNets) with continuous-time objects (partial\ndifferential equations and path space measures). We further show that an\nappropriate choice of coarse time discretization during training allows greatly\nimproved sample efficiency and the use of time-local objectives, achieving\ncompetitive performance on standard sampling benchmarks with reduced\ncomputational cost.",
            "pdf_url": "http://arxiv.org/pdf/2501.06148v1",
            "published": "2025-01-10 18:18:25+00:00",
            "updated": "2025-01-10 18:18:25+00:00"
        },
        {
            "title": "Guess What I Think: Streamlined EEG-to-Image Generation with Latent Diffusion Models",
            "authors": "Eleonora Lopez, Luigi Sigillo, Federica Colonnese, Massimo Panella, Danilo Comminiello",
            "summary": "Generating images from brain waves is gaining increasing attention due to its\npotential to advance brain-computer interface (BCI) systems by understanding\nhow brain signals encode visual cues. Most of the literature has focused on\nfMRI-to-Image tasks as fMRI is characterized by high spatial resolution.\nHowever, fMRI is an expensive neuroimaging modality and does not allow for\nreal-time BCI. On the other hand, electroencephalography (EEG) is a low-cost,\nnon-invasive, and portable neuroimaging technique, making it an attractive\noption for future real-time applications. Nevertheless, EEG presents inherent\nchallenges due to its low spatial resolution and susceptibility to noise and\nartifacts, which makes generating images from EEG more difficult. In this\npaper, we address these problems with a streamlined framework based on the\nControlNet adapter for conditioning a latent diffusion model (LDM) through EEG\nsignals. We conduct experiments and ablation studies on popular benchmarks to\ndemonstrate that the proposed method beats other state-of-the-art models.\nUnlike these methods, which often require extensive preprocessing, pretraining,\ndifferent losses, and captioning models, our approach is efficient and\nstraightforward, requiring only minimal preprocessing and a few components. The\ncode is available at https://github.com/LuigiSigillo/GWIT.",
            "pdf_url": "http://arxiv.org/pdf/2410.02780v2",
            "published": "2024-09-17 19:07:13+00:00",
            "updated": "2025-01-10 18:14:56+00:00"
        },
        {
            "title": "Advances in Diffusion Models for Image Data Augmentation: A Review of Methods, Models, Evaluation Metrics and Future Research Directions",
            "authors": "Panagiotis Alimisis, Ioannis Mademlis, Panagiotis Radoglou-Grammatikis, Panagiotis Sarigiannidis, Georgios Th. Papadopoulos",
            "summary": "Image data augmentation constitutes a critical methodology in modern computer\nvision tasks, since it can facilitate towards enhancing the diversity and\nquality of training datasets; thereby, improving the performance and robustness\nof machine learning models in downstream tasks. In parallel, augmentation\napproaches can also be used for editing/modifying a given image in a context-\nand semantics-aware way. Diffusion Models (DMs), which comprise one of the most\nrecent and highly promising classes of methods in the field of generative\nArtificial Intelligence (AI), have emerged as a powerful tool for image data\naugmentation, capable of generating realistic and diverse images by learning\nthe underlying data distribution. The current study realizes a systematic,\ncomprehensive and in-depth review of DM-based approaches for image\naugmentation, covering a wide range of strategies, tasks and applications. In\nparticular, a comprehensive analysis of the fundamental principles, model\narchitectures and training strategies of DMs is initially performed.\nSubsequently, a taxonomy of the relevant image augmentation methods is\nintroduced, focusing on techniques regarding semantic manipulation,\npersonalization and adaptation, and application-specific augmentation tasks.\nThen, performance assessment methodologies and respective evaluation metrics\nare analyzed. Finally, current challenges and future research directions in the\nfield are discussed.",
            "pdf_url": "http://arxiv.org/pdf/2407.04103v2",
            "published": "2024-07-04 18:06:48+00:00",
            "updated": "2025-01-10 15:37:26+00:00"
        },
        {
            "title": "A Steerable Deep Network for Model-Free Diffusion MRI Registration",
            "authors": "Gianfranco Cortes, Xiaoda Qu, Baba C. Vemuri",
            "summary": "Nonrigid registration is vital to medical image analysis but remains\nchallenging for diffusion MRI (dMRI) due to its high-dimensional,\norientation-dependent nature. While classical methods are accurate, they are\ncomputationally demanding, and deep neural networks, though efficient, have\nbeen underexplored for nonrigid dMRI registration compared to structural\nimaging. We present a novel, deep learning framework for model-free, nonrigid\nregistration of raw diffusion MRI data that does not require explicit\nreorientation. Unlike previous methods relying on derived representations such\nas diffusion tensors or fiber orientation distribution functions, in our\napproach, we formulate the registration as an equivariant diffeomorphism of\nposition-and-orientation space. Central to our method is an\n$\\mathsf{SE}(3)$-equivariant UNet that generates velocity fields while\npreserving the geometric properties of a raw dMRI's domain. We introduce a new\nloss function based on the maximum mean discrepancy in Fourier space,\nimplicitly matching ensemble average propagators across images. Experimental\nresults on Human Connectome Project dMRI data demonstrate competitive\nperformance compared to state-of-the-art approaches, with the added advantage\nof bypassing the overhead for estimating derived representations. This work\nestablishes a foundation for data-driven, geometry-aware dMRI registration\ndirectly in the acquisition space.",
            "pdf_url": "http://arxiv.org/pdf/2501.04794v2",
            "published": "2025-01-08 19:18:44+00:00",
            "updated": "2025-01-10 14:59:31+00:00"
        }
    ]
}