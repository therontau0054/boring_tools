{
    "Physics": [
        {
            "title": "Optimal-order Trotter-Suzuki decomposition for quantum simulation on noisy quantum computers",
            "authors": "A. A. Avtandilyan, W. V. Pogosov",
            "summary": "The potential of employing higher orders of the Trotter-Suzuki decomposition\nof the evolution operator for more effective simulations of quantum systems on\na noisy quantum computer is explored. By examining the transverse-field Ising\nmodel and the XY model, it is demonstrated that when the gate error is\ndecreased by approximately an order of magnitude relative to typical modern\nvalues, higher-order Trotterization becomes advantageous. This form of\nTrotterization yields a global minimum of the overall simulation error,\ncomprising both the mathematical error of Trotterization and the physical error\narising from gate execution.",
            "pdf_url": "http://arxiv.org/pdf/2405.01131v3",
            "published": "2024-05-02 09:48:52+00:00",
            "updated": "2024-12-30 18:56:59+00:00"
        },
        {
            "title": "Cut-Out Wedges in $H_{3}$ and the Borel-Resurgent Chern-Simons Matrix Integrals",
            "authors": "Tuo Jia, Zhaojie Xu",
            "summary": "In this paper, we present a systematic study of the Chern--Simons theory with\ngauge group \\(\\mathrm{SL}(2,\\mathbb{R})\\times\\mathrm{SL}(2,\\mathbb{R})\\)\nrestricted to a wedge-identified manifold in the hyperbolic upper-half-space.\nThe wedge geometry is created by imposing an angular cutoff in the \\((x,y)\\)\nplane and identifying two boundary lines, which introduces a single\nnoncontractible loop in the manifold. By imposing the flat-connection condition\nof the Chern--Simons gauge fields, the path integral reduces to a\nfinite-dimensional matrix integral in\n\\(\\mathrm{SL}(2,\\mathbb{R})\\times\\mathrm{SL}(2,\\mathbb{R})\\) . Although\nChern-Simons theory is a topological theory, the resulting matrix integral\nremains nontrivial due to noncompact directions and boundary constraints.\n  The large-\\(k\\) expansion of the matrix integral is carried out by selecting\na classical configuration in the space of holonomies and expanding around it in\ninverse powers of \\(k\\). The resulting coefficients of the asymptotic series\nexhibit factorial growth, enabling us to apply the Borel resummation\ntechniques. Summation over these subleading sectors removes potential\nambiguities in the Borel integral and clarifies the emergence of a resurgent\ntransseries structure. In the Borel-resurgent analysis, we show that, despite\nthe apparent simplicity of the reduced action, the wedge geometry yields a rich\ninterplay of perturbative and non-perturbative phenomena. This work presents an\nexplicit example of how a finite-dimensional matrix integral in its expansions\nis physically meaningful through Borel resummation.",
            "pdf_url": "http://arxiv.org/pdf/2412.21190v1",
            "published": "2024-12-30 18:56:02+00:00",
            "updated": "2024-12-30 18:56:02+00:00"
        },
        {
            "title": "Quantum algorithms for the simulation of QCD processes in the perturbative regime",
            "authors": "Herschel A. Chawdhry, Mathieu Pellen",
            "summary": "Theoretical predictions for high-energy collision processes at particle\ncolliders, such as the Large Hadron Collider (LHC), rely on calculations in\nperturbative Quantum Chromodynamics (QCD), which are often computationally\nchallenging. In these conference proceedings, we explore the possibility of\nusing quantum computers to simulate QCD processes in the perturbative QCD\nregime. In particular, as a first step towards that goal, we present quantum\ncircuits to simulate the colour part of perturbative QCD. The circuits are\nvalidated by implementing them on a simulated quantum computer and verifying\nthe colour factors for several example Feynman diagrams.",
            "pdf_url": "http://arxiv.org/pdf/2412.21177v1",
            "published": "2024-12-30 18:50:20+00:00",
            "updated": "2024-12-30 18:50:20+00:00"
        },
        {
            "title": "Hint at an axion-like particle from GRB 221009A",
            "authors": "Giorgio Galanti, Lara Nava, Marco Roncadelli, Fabrizio Tavecchio, Giacomo Bonnoli",
            "summary": "The detection by the LHAASO Collaboration of the gamma-ray burst GRB 221009A\nat redshift $z = 0.151$ with energies up to $(13-18) \\, \\rm TeV$ challenges\nconventional physics. Photons emitted with energies above $10 \\, \\rm TeV$ at\nthis redshift can hardly be observed on Earth due to their interaction with the\nextragalactic background light (EBL). We show that indeed the LHAASO\nCollaboration should not have observed photons with energies above $10 \\, \\rm\nTeV$ if the state-of-the-art EBL model by Saldana-Lopez et al. is taken into\naccount. A problem therefore arises: the Universe should be more transparent\nthan currently believed. We also show that the issue is solved if we introduce\nthe interaction of photons with axion-like particles (ALPs). ALPs are predicted\nby String Theory, are among the best candidates for dark matter and can produce\nspectral and polarization effects on astrophysical sources in the presence of\nexternal magnetic fields. In particular, for GRB 221009A, photon-ALP\noscillations occur within the crossed magnetized media, i.e. the host galaxy,\nthe extragalactic space, the Milky Way, partially reducing the EBL absorption\nto a level that explains the LHAASO detection of GRB 221009A and its observed\nspectrum without the need of contrived choices of parameter values, which are\ninstead compulsory within proposed emission models within conventional physics.\nThis fact regarding GRB 221009A represents a strong hint at the ALP existence,\nwhich adds to two other indications coming from blazars, a class of active\ngalactic nuclei.",
            "pdf_url": "http://arxiv.org/pdf/2412.21175v1",
            "published": "2024-12-30 18:49:58+00:00",
            "updated": "2024-12-30 18:49:58+00:00"
        },
        {
            "title": "Quantum Error Correction near the Coding Theoretical Bound",
            "authors": "Daiki Komoto, Kenta Kasai",
            "summary": "Recent advancements in quantum computing have led to the realization of\nsystems comprising tens of reliable logical qubits, constructed from thousands\nof noisy physical qubits. However, many of the critical applications that\nquantum computers aim to solve require quantum computations involving millions\nor more logical qubits. This necessitates highly efficient quantum error\ncorrection capable of handling large numbers of logical qubits. Classical error\ncorrection theory is well-developed, with low-density parity-check (LDPC) codes\nachieving performance limits by encoding large classical bits. Despite more\nthan two decades of effort, no efficiently decodable quantum error-correcting\ncode that approaches the hashing bound, which is a fundamental lower bound on\nquantum capacity, had been discovered. Here, we present quantum\nerror-correcting codes constructed from classical LDPC codes that approach the\nhashing bound while maintaining linear computational complexity in the number\nof physical qubits. This result establishes a pathway toward realizing\nlarge-scale, fault-tolerant quantum computers. By integrating our quantum error\ncorrection scheme with devices capable of managing vast numbers of qubits, the\nprospect of solving critical real-world problems through quantum computation is\nbrought significantly closer.",
            "pdf_url": "http://arxiv.org/pdf/2412.21171v1",
            "published": "2024-12-30 18:48:54+00:00",
            "updated": "2024-12-30 18:48:54+00:00"
        },
        {
            "title": "Causality and Stability from Acoustic Geometry",
            "authors": "Ignacy Sawicki, Georg Trenkler, Alexander Vikman",
            "summary": "Scalar-tensor theories with derivative interactions form backgrounds which\nspontaneously break Lorentz invariance. We investigate the dynamics of free\nscalar perturbations on general anisotropic backgrounds. We demonstrate that\nthe phonons move on null geodesics of an acoustic spacetime described by its\nown metric and own connection featuring nonmetricity with respect to the usual\nspacetime metric. We give distinct physical interpretations to the acoustic\nmetric and its inverse. The first defines rays and their phase velocities. The\nlatter defines momenta and the dispersion relation. We classify possible\nacoustic geometries and provide a physical interpretation for them.\n  We discuss the phonon properties that moving observers, inequivalent owing to\nthe breaking of Lorentz invariance, would measure. Ghosts and true gradient\ninstabilities are to be read off from invariant properties of the acoustic\nmetric - its signature and determinant. However, the choice of the observer's\nframe can cause some confusion and paradoxes, including apparent instabilities.\nFor instance, complex phonon energies can appear entirely due to the\nill-posedness of the Cauchy problem in the frame chosen. On the other hand,\nunbounded negative phonon energies can appear, without ghosts or gradient\ninstabilities, for observers moving supersonically, when phonon Cherenkov\nradiation can be emitted.\n  The action for phonons also gives an acoustically covariantly conserved\nenergy-momentum tensor (EMT) which is, however, not conserved in the usual\nspacetime. Nonetheless, in the presence of an acoustic timelike Killing vector,\nthe acoustic Hamiltonian functional is a conserved charge in both the acoustic\nand in the usual spacetimes, and even has the same value in both. Thus, the\nacoustic Hamiltonian can be used to bound the motion of phonons interacting\nwith other species living in the usual spacetime.",
            "pdf_url": "http://arxiv.org/pdf/2412.21169v1",
            "published": "2024-12-30 18:46:51+00:00",
            "updated": "2024-12-30 18:46:51+00:00"
        },
        {
            "title": "Measuring Quantum Discord at the LHC",
            "authors": "Tao Han, Matthew Low, Navin McGinnis, Shufang Su",
            "summary": "There has been an increasing interest in exploring quantities associated with\nquantum information at colliders. We perform a detailed analysis describing how\nto measure the quantum discord in the top anti-top quantum state at the Large\nHadron Collider (LHC). While for pure states, quantum discord, entanglement,\nand Bell nonlocality all probe the same correlations, for mixed states they\nprobe different aspects of quantum correlations. The quantum discord, in\nparticular, is interesting because it aims to encapsulate all correlations\nbetween systems that cannot have a classical origin. We employ two\ncomplementary approaches for the study of the top anti-top system, namely the\ndecay method and the kinematic method. We highlight subtleties associated with\nmeasuring discord for reconstructed quantum states at colliders. Usually\nquantum discord is difficult to compute due to an extremization that must be\nperformed. We show, however, that for the $t\\bar{t}$ system this extremization\ncan be performed analytically and we provide closed-form formulas for the\nquantum discord. We demonstrate that at the high luminosity LHC, discord is\nprojected to be measurable with a precision of approximately 5% using the decay\nmethod and sub-percent levels using the kinematic method. Even with current LHC\ndatasets, discord can be measured with 1-2% precision with the kinematic\nmethod. By systematically investigating quantum discord for the first time\nthrough a detailed collider analysis, this work expands the toolkit for quantum\ninformation studies in particle physics and lays the groundwork for deeper\ninsights into the quantum properties in high-energy collisions.",
            "pdf_url": "http://arxiv.org/pdf/2412.21158v1",
            "published": "2024-12-30 18:36:43+00:00",
            "updated": "2024-12-30 18:36:43+00:00"
        },
        {
            "title": "Systematic Benchmarking of Macrosegregation: The Performance of a Modified Hybrid Model",
            "authors": "Ali Moeinirad, Ehsan Amani",
            "summary": "Recently, a new alloy solidification benchmark, called AFRODITE, with\nwell-defined setups and state-of-the-art measurements has emerged, enabling a\nthorough assessment of MacroSegregation (MS) solvers, particularly in terms of\ntheir ability to predict different features of MS maps. In this research, we\nfirst develop an analytical solution for the alloy-solidification Stefan\nproblem, which involves melt, solid, and mushy regions. This new analytical\nsolution extends a previous solution (S. Cho and J. Sunderland,\n\"Heat-conduction problems with melting or freezing\", J. Heat Transfer, vol. 91,\npp. 421-426, 1969) by incorporating a linear microsegregation law as a function\nof temperature in place of spatial coordinate. Then, we adopt this solution to\nverify an OpenFOAM MS solver in a limiting condition, where only heat diffusion\nis present. Subsequently, to capture the MS map of the Sn-3%Pb AFRODITE\nbenchmark, the solver is incorporated using the standard Blake-Kozeny-Carman\npermeability law and one of its hybrid variants, slightly modified in this work\nto better align with physics by ensuring a continuous transition of\ncharacteristics from the slurry to the porous regions of the mush. It is\ndemonstrated that the hybrid model predicts the main features of the MS map,\nincluding the channel segregates morphology and peak segregation degree due to\nthe pile-up effect, in much finer agreement with the experimental observation.\nCareful analyses of the results reveal that these improved predictions stem\nfrom the hybrid model's more accurate estimation of the re-melting, melt flow\nadvection parallel, and advection normal to the solidification front.",
            "pdf_url": "http://arxiv.org/pdf/2412.21143v1",
            "published": "2024-12-30 18:19:51+00:00",
            "updated": "2024-12-30 18:19:51+00:00"
        },
        {
            "title": "DeepF-fNet: a physics-informed neural network for vibration isolation optimization",
            "authors": "A. Tollardo, F. Cadini, M. Giglio, L. Lomazzi",
            "summary": "Structural optimization is essential for designing safe, efficient, and\ndurable components with minimal material usage. Traditional methods for\nvibration control often rely on active systems to mitigate unpredictable\nvibrations, which may lead to resonance and potential structural failure.\nHowever, these methods face significant challenges when addressing the\nnonlinear inverse eigenvalue problems required for optimizing structures\nsubjected to a wide range of frequencies. As a result, no existing approach has\neffectively addressed the need for real-time vibration suppression within this\ncontext, particularly in high-performance environments such as automotive\nnoise, vibration and harshness, where computational efficiency is crucial.\n  This study introduces DeepF-fNet, a novel neural network framework designed\nto replace traditional active systems in vibration-based structural\noptimization. Leveraging DeepONets within the context of physics-informed\nneural networks, DeepF-fNet integrates both data and the governing physical\nlaws. This enables rapid identification of optimal parameters to suppress\ncritical vibrations at specific frequencies, offering a more efficient and\nreal-time alternative to conventional methods.\n  The proposed framework is validated through a case study involving a locally\nresonant metamaterial used to isolate structures from user-defined frequency\nranges. The results demonstrate that DeepF-fNet outperforms traditional genetic\nalgorithms in terms of computational speed while achieving comparable results,\nmaking it a promising tool for vibration-sensitive applications. By replacing\nactive systems with machine learning techniques, DeepF-fNet paves the way for\nmore efficient and cost-effective structural optimization in real-world\nscenarios.",
            "pdf_url": "http://arxiv.org/pdf/2412.21132v1",
            "published": "2024-12-30 18:08:55+00:00",
            "updated": "2024-12-30 18:08:55+00:00"
        },
        {
            "title": "High-Rank Irreducible Cartesian Tensor Decomposition and Bases of Equivariant Spaces",
            "authors": "Shihao Shao, Yikang Li, Zhouchen Lin, Qinghua Cui",
            "summary": "Irreducible Cartesian tensors (ICTs) play a crucial role in the design of\nequivariant graph neural networks, as well as in theoretical chemistry and\nchemical physics. Meanwhile, the design space of available linear operations on\ntensors that preserve symmetry presents a significant challenge. The ICT\ndecomposition and a basis of this equivariant space are difficult to obtain for\nhigh-order tensors. After decades of research, we recently achieve an explicit\nICT decomposition for $n=5$ \\citep{bonvicini2024irreducible} with factorial\ntime/space complexity. This work, for the first time, obtains decomposition\nmatrices for ICTs up to rank $n=9$ with reduced and affordable complexity, by\nconstructing what we call path matrices. The path matrices are obtained via\nperforming chain-like contraction with Clebsch-Gordan matrices following the\nparentage scheme. We prove and leverage that the concatenation of path matrices\nis an orthonormal change-of-basis matrix between the Cartesian tensor product\nspace and the spherical direct sum spaces. Furthermore, we identify a complete\northogonal basis for the equivariant space, rather than a spanning set\n\\citep{pearce2023brauer}, through this path matrices technique. We further\nextend our result to the arbitrary tensor product and direct sum spaces,\nenabling free design between different spaces while keeping symmetry. The\nPython code is available in\nhttps://github.com/ShihaoShao-GH/ICT-decomposition-and-equivariant-bases where\nthe $n=6,\\dots,9$ ICT decomposition matrices are obtained in 1s, 3s, 11s, and\n4m32s, respectively.",
            "pdf_url": "http://arxiv.org/pdf/2412.18263v2",
            "published": "2024-12-24 08:25:38+00:00",
            "updated": "2024-12-30 18:07:15+00:00"
        }
    ],
    "Diffusion": [
        {
            "title": "Sparse chaos in cortical circuits",
            "authors": "Rainer Engelken, Michael Monteforte, Fred Wolf",
            "summary": "Nerve impulses, the currency of information flow in the brain, are generated\nby an instability of the neuronal membrane potential dynamics. Neuronal\ncircuits exhibit collective chaos that appears essential for learning, memory,\nsensory processing, and motor control. However, the factors controlling the\nnature and intensity of collective chaos in neuronal circuits are not well\nunderstood. Here we use computational ergodic theory to demonstrate that basic\nfeatures of nerve impulse generation profoundly affect collective chaos in\nneuronal circuits. Numerically exact calculations of Lyapunov spectra,\nKolmogorov-Sinai-entropy, and upper and lower bounds on attractor dimension\nshow that changes in nerve impulse generation in individual neurons moderately\nimpact information encoding rates but qualitatively transform phase space\nstructure. Specifically, we find a drastic reduction in the number of unstable\nmanifolds, Kolmogorov-Sinai entropy, and attractor dimension. Beyond a critical\npoint, marked by the simultaneous breakdown of the diffusion approximation, a\npeak in the largest Lyapunov exponent, and a localization transition of the\nleading covariant Lyapunov vector, networks exhibit sparse chaos: prolonged\nperiods of near stable dynamics interrupted by short bursts of intense chaos.\nAnalysis of large, more realistically structured networks supports the\ngenerality of these findings. In cortical circuits, biophysical properties\nappear tuned to this regime of sparse chaos. Our results reveal a close link\nbetween fundamental aspects of single-neuron biophysics and the collective\ndynamics of cortical circuits, suggesting that nerve impulse generation\nmechanisms are adapted to enhance circuit controllability and information flow.",
            "pdf_url": "http://arxiv.org/pdf/2412.21188v1",
            "published": "2024-12-30 18:55:35+00:00",
            "updated": "2024-12-30 18:55:35+00:00"
        },
        {
            "title": "Quantum Diffusion Model for Quark and Gluon Jet Generation",
            "authors": "Mariia Baidachna, Rey Guadarrama, Gopal Ramesh Dahale, Tom Magorsch, Isabel Pedraza, Konstantin T. Matchev, Katia Matcheva, Kyoungchul Kong, Sergei Gleyzer",
            "summary": "Diffusion models have demonstrated remarkable success in image generation,\nbut they are computationally intensive and time-consuming to train. In this\npaper, we introduce a novel diffusion model that benefits from quantum\ncomputing techniques in order to mitigate computational challenges and enhance\ngenerative performance within high energy physics data. The fully quantum\ndiffusion model replaces Gaussian noise with random unitary matrices in the\nforward process and incorporates a variational quantum circuit within the U-Net\nin the denoising architecture. We run evaluations on the structurally complex\nquark and gluon jets dataset from the Large Hadron Collider. The results\ndemonstrate that the fully quantum and hybrid models are competitive with a\nsimilar classical model for jet generation, highlighting the potential of using\nquantum techniques for machine learning problems.",
            "pdf_url": "http://arxiv.org/pdf/2412.21082v1",
            "published": "2024-12-30 17:00:54+00:00",
            "updated": "2024-12-30 17:00:54+00:00"
        },
        {
            "title": "PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion",
            "authors": "Sophia Tang, Yinuo Zhang, Pranam Chatterjee",
            "summary": "Peptide therapeutics, a major class of medicines, have achieved remarkable\nsuccess across diseases such as diabetes and cancer, with landmark examples\nsuch as GLP-1 receptor agonists revolutionizing the treatment of type-2\ndiabetes and obesity. Despite their success, designing peptides that satisfy\nmultiple conflicting objectives, such as target binding affinity, solubility,\nand membrane permeability, remains a major challenge. Classical drug\ndevelopment and structure-based design are ineffective for such tasks, as they\nfail to optimize global functional properties critical for therapeutic\nefficacy. Existing generative frameworks are largely limited to continuous\nspaces, unconditioned outputs, or single-objective guidance, making them\nunsuitable for discrete sequence optimization across multiple properties. To\naddress this, we present PepTune, a multi-objective discrete diffusion model\nfor the simultaneous generation and optimization of therapeutic peptide SMILES.\nBuilt on the Masked Discrete Language Model (MDLM) framework, PepTune ensures\nvalid peptide structures with state-dependent masking schedules and\npenalty-based objectives. To guide the diffusion process, we propose a Monte\nCarlo Tree Search (MCTS)-based strategy that balances exploration and\nexploitation to iteratively refine Pareto-optimal sequences. MCTS integrates\nclassifier-based rewards with search-tree expansion, overcoming gradient\nestimation challenges and data sparsity inherent to discrete spaces. Using\nPepTune, we generate diverse, chemically-modified peptides optimized for\nmultiple therapeutic properties, including target binding affinity, membrane\npermeability, solubility, hemolysis, and non-fouling characteristics on various\ndisease-relevant targets. In total, our results demonstrate that MCTS-guided\ndiscrete diffusion is a powerful and modular approach for multi-objective\nsequence design in discrete state spaces.",
            "pdf_url": "http://arxiv.org/pdf/2412.17780v2",
            "published": "2024-12-23 18:38:49+00:00",
            "updated": "2024-12-30 16:41:00+00:00"
        },
        {
            "title": "BridgePure: Revealing the Fragility of Black-box Data Protection",
            "authors": "Yihan Wang, Yiwei Lu, Xiao-Shan Gao, Gautam Kamath, Yaoliang Yu",
            "summary": "Availability attacks, or unlearnable examples, are defensive techniques that\nallow data owners to modify their datasets in ways that prevent unauthorized\nmachine learning models from learning effectively while maintaining the data's\nintended functionality. It has led to the release of popular black-box tools\nfor users to upload personal data and receive protected counterparts. In this\nwork, we show such black-box protections can be substantially bypassed if a\nsmall set of unprotected in-distribution data is available. Specifically, an\nadversary can (1) easily acquire (unprotected, protected) pairs by querying the\nblack-box protections with the unprotected dataset; and (2) train a diffusion\nbridge model to build a mapping. This mapping, termed BridgePure, can\neffectively remove the protection from any previously unseen data within the\nsame distribution. Under this threat model, our method demonstrates superior\npurification performance on classification and style mimicry tasks, exposing\ncritical vulnerabilities in black-box data protection.",
            "pdf_url": "http://arxiv.org/pdf/2412.21061v1",
            "published": "2024-12-30 16:30:50+00:00",
            "updated": "2024-12-30 16:30:50+00:00"
        },
        {
            "title": "AlignAb: Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies",
            "authors": "Yibo Wen, Chenwei Xu, Jerry Yao-Chieh Hu, Han Liu",
            "summary": "We present a three-stage framework for training deep learning models\nspecializing in antibody sequence-structure co-design. We first pre-train a\nlanguage model using millions of antibody sequence data. Then, we employ the\nlearned representations to guide the training of a diffusion model for joint\noptimization over both sequence and structure of antibodies. During the final\nalignment stage, we optimize the model to favor antibodies with low repulsion\nand high attraction to the antigen binding site, enhancing the rationality and\nfunctionality of the designs. To mitigate conflicting energy preferences, we\nextend AbDPO (Antibody Direct Preference Optimization) to guide the model\ntowards Pareto optimality under multiple energy-based alignment objectives.\nFurthermore, we adopt an iterative learning paradigm with temperature scaling,\nenabling the model to benefit from diverse online datasets without requiring\nadditional data. In practice, our proposed methods achieve high stability and\nefficiency in producing a better Pareto front of antibody designs compared to\ntop samples generated by baselines and previous alignment techniques. Through\nextensive experiments, we showcase the superior performance of our methods in\ngenerating nature-like antibodies with high binding affinity consistently.",
            "pdf_url": "http://arxiv.org/pdf/2412.20984v1",
            "published": "2024-12-30 14:50:32+00:00",
            "updated": "2024-12-30 14:50:32+00:00"
        }
    ],
    "Quantitative Finance": [
        {
            "title": "GISExplainer: On Explainability of Graph Neural Networks via Game-theoretic Interaction Subgraphs",
            "authors": "Xingping Xian, Jianlu Liu, Chao Wang, Tao Wu, Shaojie Qiao, Xiaochuan Tang, Qun Liu",
            "summary": "Explainability is crucial for the application of black-box Graph Neural\nNetworks (GNNs) in critical fields such as healthcare, finance, cybersecurity,\nand more. Various feature attribution methods, especially the\nperturbation-based methods, have been proposed to indicate how much each\nnode/edge contributes to the model predictions. However, these methods fail to\ngenerate connected explanatory subgraphs that consider the causal interaction\nbetween edges within different coalition scales, which will result in\nunfaithful explanations. In our study, we propose GISExplainer, a novel\ngame-theoretic interaction based explanation method that uncovers what the\nunderlying GNNs have learned for node classification by discovering\nhuman-interpretable causal explanatory subgraphs. First, GISExplainer defines a\ncausal attribution mechanism that considers the game-theoretic interaction of\nmulti-granularity coalitions in candidate explanatory subgraph to quantify the\ncausal effect of an edge on the prediction. Second, GISExplainer assumes that\nthe coalitions with negative effects on the predictions are also significant\nfor model interpretation, and the contribution of the computation graph stems\nfrom the combined influence of both positive and negative interactions within\nthe coalitions. Then, GISExplainer regards the explanation task as a sequential\ndecision process, in which a salient edges is successively selected and\nconnected to the previously selected subgraph based on its causal effect to\nform an explanatory subgraph, ultimately striving for better explanations.\nAdditionally, an efficiency optimization scheme is proposed for the causal\nattribution mechanism through coalition sampling. Extensive experiments\ndemonstrate that GISExplainer achieves better performance than state-of-the-art\napproaches w.r.t. two quantitative metrics: Fidelity and Sparsity.",
            "pdf_url": "http://arxiv.org/pdf/2409.15698v2",
            "published": "2024-09-24 03:24:31+00:00",
            "updated": "2024-12-30 13:28:24+00:00"
        },
        {
            "title": "Digital transformation: A systematic review and bibliometric analysis from the corporate finance perspective",
            "authors": "Ping Zhang, Yiru Wang",
            "summary": "Digital transformation significantly impacts firm investment, financing, and\nvalue enhancement. A systematic investigation from the corporate finance\nperspective has not yet been formed. This paper combines bibliometric and\ncontent analysis methods to systematically review the evolutionary trend,\nstatus quo, hotspots and overall structure of research in digital\ntransformation from 2011 to 2024. The study reveals an emerging and rapidly\ngrowing focus on digital transformation research, particularly in developed\ncountries. We categorize the literature into three areas according to\nbibliometric clustering: the measurements (qualitative and quantitative),\nimpact factors (internal and external), and the economic consequences\n(investment, financing, and firm value). These areas are divided into ten\nsub-branches, with a detailed literature review. We also review the existing\ntheories related to digital transformation, identify the current gaps in these\npapers, and provide directions for future research on each sub-branches.",
            "pdf_url": "http://arxiv.org/pdf/2412.19817v1",
            "published": "2024-12-13 03:26:26+00:00",
            "updated": "2024-12-13 03:26:26+00:00"
        }
    ]
}